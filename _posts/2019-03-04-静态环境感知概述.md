---
layout:     post                    # 使用的布局（不需要改）
title:      ROS学习               # 标题 
subtitle:   静态环境感知概述                #副标题
date:       2019/3/4            # 时间
author:     Euraxluo                      # 作者
header-img: img/post-bg-github-cup.jpg  #这篇文章标题背景图片
catalog: true                 # 是否归档
tags:                               #标签
    - ROS

---
# 静态环境感知与分割算法概述
## 广义感知
### 感知外界
#### 目的
- 识别静态物体
- 识别动态物体的位姿
#### 传感器
- 单目：图片->ML,DL,分类，物体检测
- 双目：深度图->SLAM
- 激光雷达：稀疏点云
- 超声波雷达
### 感知自身
#### 目的：
- 感知自身的位姿
#### 传感器
- IMU,HD map,SLAM,gps

## 分割
### 传统的算法（opencv）
#### 边缘检测
Canny 边缘检测

-  原理
Canny 边缘检测是一种非常流行的边缘检测算法，是 John F.Canny 在
1986 年提出的。它是一个有很多步构成的算法，我们接下来会逐步介绍。

-  噪声去除
由于边缘检测很容易受到噪声影响，所以第一步是使用 5x5 的高斯滤波器
去除噪声

-  计算图像梯度
对平滑后的图像使用 Sobel 算子计算水平方向和竖直方向的一阶导数（图
像梯度）（Gx 和 Gy）。根据得到的这两幅梯度图（Gx 和 Gy）找到边界的梯
度和方向，公式如下：
$$
Edge-Gradient(G) =\sqrt{G^2_x + G^2_y}
$$

$$
Angle(θ) = tan^{−1}(\frac{G_x}{G_y})
$$
梯度的方向一般总是与边界垂直。梯度方向被归为四类：垂直，水平，和
两个对角线。

- 非极大值抑制
在获得梯度的方向和大小之后，应该对整幅图像做一个扫描，去除那些非
边界上的点。对每一个像素进行检查，看这个点的梯度是不是周围具有相同梯
度方向的点中最大的。得到的是一个包含“窄边界”的二值图像。

- 滞后阈值
现在要确定那些边界才是真正的边界。这时我们需要设置两个阈值：
minVal 和 maxVal。当图像的灰度梯度高于 maxVal 时被认为是真的边界，
那些低于 minVal 的边界会被抛弃。如果介于两者之间的话，就要看这个点是
否与某个被确定为真正的边界点相连，如果是就认为它也是边界点，如果不是
就抛弃。
在这一步一些小的噪声点也会被除去，因为我们假设边界都是一些长的线
段。

#### 手动分割图像
- 手动指定一个三角形来分割出路面区域，去除其他干扰

#### 霍夫曼变换
- 使用霍夫曼变化（极坐标系下）
可以把直线变换成曲线。通过一系列连续的线段，最终可以得到很多可能的直线（车道线）

#### 叠加到原图
- 使用opencv叠加到原图

#### 使用传统方法实现车道线检测（直线）
```python3
import cv2 as cv
import numpy as np
#import matplotlib.pyplot as plt

def do_canny(frame):#处理每一桢
    # 将帧转换为灰度图，因为我们只需要通过亮度梯度检测边缘，减少计算成本
    gray = cv.cvtColor(frame, cv.COLOR_RGB2GRAY)
    # 用 5*5 的高斯滤波器卷积（平滑）图像，从而降低检测器对噪声的敏感度（也可以使用canny来做）
    blur = cv.GaussianBlur(gray, (5, 5), 0)
    # 应用canny边缘检测器，最小值50，最大值150
    canny = cv.Canny(blur, 50, 150)
    return canny

def do_segment(frame):
    # 由于图像是一个三维数组，包含图像中每个像素的强度
    # frame.shape[0] 返回了像素数
    height = frame.shape[0]
    # 创建由三个坐标定义的一个三角形的，作为车道区域
    polygons = np.array([
                            [(0, height), (800, height), (380, 290)]
                        ])
    # 创建与图像尺寸相同的零矩阵
    mask = np.zeros_like(frame)    
    # 把polygons区域用mask来填充，颜色为255
    cv.fillPoly(mask, polygons, 255)
    # 按位操作，只保留我们的三角形区域
    segment = cv.bitwise_and(frame, mask)
    return segment

def calculate_lines(frame, lines):
    # Empty arrays to store the coordinates of the left and right lines
    left = []
    right = []
    # Loops through every detected line
    for line in lines:
        # Reshapes line from 2D array to 1D array
        x1, y1, x2, y2 = line.reshape(4)
        # Fits a linear polynomial to the x and y coordinates and returns a vector of coefficients which describe the slope and y-intercept
        parameters = np.polyfit((x1, x2), (y1, y2), 1)
        slope = parameters[0]
        y_intercept = parameters[1]
        # If slope is negative, the line is to the left of the lane, and otherwise, the line is to the right of the lane
        if slope < 0:
            left.append((slope, y_intercept))
        else:
            right.append((slope, y_intercept))
    # Averages out all the values for left and right into a single slope and y-intercept value for each line
    left_avg = np.average(left, axis = 0)
    right_avg = np.average(right, axis = 0)
    # Calculates the x1, y1, x2, y2 coordinates for the left and right lines
    left_line = calculate_coordinates(frame, left_avg)
    right_line = calculate_coordinates(frame, right_avg)
    return np.array([left_line, right_line])

def calculate_coordinates(frame, parameters):
    slope, intercept = parameters
    # Sets initial y-coordinate as height from top down (bottom of the frame)
    y1 = frame.shape[0]
    # Sets final y-coordinate as 150 above the bottom of the frame
    y2 = int(y1 - 150)
    # Sets initial x-coordinate as (y1 - b) / m since y1 = mx1 + b
    x1 = int((y1 - intercept) / slope)
    # Sets final x-coordinate as (y2 - b) / m since y2 = mx2 + b
    x2 = int((y2 - intercept) / slope)
    return np.array([x1, y1, x2, y2])

def visualize_lines(frame, lines):
    # Creates an image filled with zero intensities with the same dimensions as the frame
    lines_visualize = np.zeros_like(frame)
    # Checks if any lines are detected
    if lines is not None:
        for x1, y1, x2, y2 in lines:
            # Draws lines between two coordinates with green color and 5 thickness
            cv.line(lines_visualize, (x1, y1), (x2, y2), (0, 255, 0), 5)
    return lines_visualize

# 读取视频
cap = cv.VideoCapture("input.mp4")
while (cap.isOpened()):
    # ret是从视频中读取每一帧的bool指
    ret, frame = cap.read()
    # canny边缘检测
    canny = do_canny(frame)
    cv.imshow("canny", canny)
    # 分割车道区域
    segment = do_segment(canny)
    # 霍夫变换
    hough = cv.HoughLinesP(segment, 2, np.pi / 180, 100, np.array([]), minLineLength = 100, maxLineGap = 50)
    # Averages multiple detected lines from hough into one line for left border of lane and one line for right border of lane
    lines = calculate_lines(frame, hough)
    # Visualizes the lines
    lines_visualize = visualize_lines(frame, lines)
    cv.imshow("hough", lines_visualize)
    # Overlays lines on frame by taking their weighted sums and adding an arbitrary scalar value of 1 as the gamma argument
    output = cv.addWeighted(frame, 0.9, lines_visualize, 1, 1)
    # Opens a new window and displays the output frame
    cv.imshow("output", output)
    # Frames are read by intervals of 10 milliseconds. The programs breaks out of the while loop when the user presses the 'q' key
    if cv.waitKey(10) & 0xFF == ord('q'):
        break
# The following frees up resources and closes all windows
cap.release()
cv.destroyAllWindows()


```

### DL
类型： 普通分割（前景与背景），语义分割（猫和狗），实例分割（分割每一个人）
#### 思路：
- 前端
下采样+上采样：Convlution + Deconvlution／Resize
多尺度特征融合：特征逐点相加／特征channel维度拼接
获得像素级别的segement map：对每一个像素点进行判断类别
- 后端
使用CRF条件随机场，MRF马尔科夫随机场，优化（确定一个像素属于谁的几率大）
#### 常用算法
![](/image/DLsplit.png)

[A Survey on DNN based Semantic Segmentation](https://blog.csdn.net/Julialove102123/article/details/80493066)
FCN
U-Net
SeqNet/DeconvNet
DeepLab
PSPNet
Mask rcnn
laneNet
[Towards End-to-End Lane Detection: an Instance Segmentation Approach](https://arxiv.org/abs/1802.05591)

## 检测

## 分类
## 跟踪