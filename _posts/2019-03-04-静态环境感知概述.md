---
layout:   post          
title:   静态环境感知概述        
date:    2019/3/4      
author:   Euraxluo           
categories: ROS
tags:  图像 分割 检测
---
* TOC
{:toc}


# 静态环境感知与分割算法概述
## 广义感知
### 感知外界
#### 目的

- 识别静态物体

- 识别动态物体的位姿

#### 传感器

- 单目：图片->ML,DL,分类，物体检测

- 双目：深度图->SLAM

- 激光雷达：稀疏点云

- 超声波雷达

### 感知自身

#### 目的：

- 感知自身的位姿

#### 传感器

- IMU,HD map,SLAM,gps



## 分割

[车道线检测论文集合](https://github.com/amusi/awesome-lane-detection)



### 传统的算法（opencv）

#### 边缘检测

Canny 边缘检测



-  原理

Canny 边缘检测是一种非常流行的边缘检测算法，是 John F.Canny 在

1986 年提出的。它是一个有很多步构成的算法，我们接下来会逐步介绍。



-  噪声去除

由于边缘检测很容易受到噪声影响，所以第一步是使用 5x5 的高斯滤波器

去除噪声



-  计算图像梯度

对平滑后的图像使用 Sobel 算子计算水平方向和竖直方向的一阶导数（图

像梯度）（Gx 和 Gy）。根据得到的这两幅梯度图（Gx 和 Gy）找到边界的梯

度和方向，公式如下：

$$

Edge-Gradient(G) =\sqrt{G^2_x + G^2_y}

$$



$$

Angle(θ) = tan^{−1}(\frac{G_x}{G_y})

$$

梯度的方向一般总是与边界垂直。梯度方向被归为四类：垂直，水平，和

两个对角线。



- 非极大值抑制

在获得梯度的方向和大小之后，应该对整幅图像做一个扫描，去除那些非

边界上的点。对每一个像素进行检查，看这个点的梯度是不是周围具有相同梯

度方向的点中最大的。得到的是一个包含“窄边界”的二值图像。



- 滞后阈值

现在要确定那些边界才是真正的边界。这时我们需要设置两个阈值：

minVal 和 maxVal。当图像的灰度梯度高于 maxVal 时被认为是真的边界，

那些低于 minVal 的边界会被抛弃。如果介于两者之间的话，就要看这个点是

否与某个被确定为真正的边界点相连，如果是就认为它也是边界点，如果不是

就抛弃。

在这一步一些小的噪声点也会被除去，因为我们假设边界都是一些长的线

段。



#### 手动分割图像

- 手动指定一个三角形来分割出路面区域，去除其他干扰



#### 霍夫曼变换

- 使用霍夫曼变化（极坐标系下）

可以把直线变换成曲线。通过一系列连续的线段，最终可以得到很多可能的直线（车道线）

通过这一系列的线段，我们计算平均斜率，得到车道线

#### 叠加到原图

- 使用opencv叠加到原图



#### 使用传统方法实现车道线检测（直线）



```python3

import cv2 as cv

import numpy as np

#import matplotlib.pyplot as plt



def do_canny(frame):#处理每一桢

    # 将帧转换为灰度图，因为我们只需要通过亮度梯度检测边缘，减少计算成本

    gray = cv.cvtColor(frame, cv.COLOR_RGB2GRAY)

    # 用 5*5 的高斯滤波器卷积（平滑）图像，从而降低检测器对噪声的敏感度（也可以使用canny来做）

    blur = cv.GaussianBlur(gray, (5, 5), 0)

    # 应用canny边缘检测器，最小值50，最大值150

    canny = cv.Canny(blur, 50, 150)

    return canny



def do_segment(frame):

    # 由于图像是一个三维数组，包含图像中每个像素的强度

    # frame.shape[0] 返回了像素数

    height = frame.shape[0]

    # 创建由三个坐标定义的一个三角形的，作为车道区域

    polygons = np.array([

                            [(0, height), (800, height), (380, 290)]

                        ])

    # 创建与图像尺寸相同的零矩阵

    mask = np.zeros_like(frame)    

    # 把polygons区域用mask来填充，颜色为255

    cv.fillPoly(mask, polygons, 255)

    # 按位操作，只保留我们的三角形区域

    segment = cv.bitwise_and(frame, mask)

    return segment



def calculate_lines(frame, lines):

    left = []

    right = []

    # 遍历每个检测到的行

    for line in lines:

        # R把线从2d数组reshape到一数组

        x1, y1, x2, y2 = line.reshape(4)

        # 拟合直线

        parameters = np.polyfit((x1, x2), (y1, y2), 1)

        slope = parameters[0]#直线的斜率

        y_intercept = parameters[1]#直线的截距

        # 如果斜率是负数，则这条线位于车道左侧，否者是右边的

        if slope < 0:

            left.append((slope, y_intercept))

        else:

            right.append((slope, y_intercept))

    #有很多个线，平均计算作为斜率（也就是把多个线化为一个线）

    left_avg = np.average(left, axis = 0)

    right_avg = np.average(right, axis = 0)

    #计算左右线段的起始坐标

    left_line = calculate_coordinates(frame, left_avg)

    right_line = calculate_coordinates(frame, right_avg)

    return np.array([left_line, right_line])



def calculate_coordinates(frame, parameters):

    slope, intercept = parameters

    # 将y1坐标设置图片的高度

    y1 = frame.shape[0]

    #将y2坐标设置为上方150

    y2 = int(y1 - 150)

    # x1坐标设置为(y1-b)/m，因为y1=mx1+b

    x1 = int((y1 - intercept) / slope)

    # x2坐标设置为(y1-b)/m，因为y1=mx1+b

    x2 = int((y2 - intercept) / slope)

    return np.array([x1, y1, x2, y2])



def visualize_lines(frame, lines):

    # 创建和图片尺寸相同的零矩阵填充

    lines_visualize = np.zeros_like(frame)

    # 检查是否由线段传进来了

    if lines is not None:

        for x1, y1, x2, y2 in lines:

            # 在两个坐标之间画出一条5像素的线段

            cv.line(lines_visualize, (x1, y1), (x2, y2), (0, 255, 0), 5)

    return lines_visualize



# 读取视频

cap = cv.VideoCapture("input.mp4")

while (cap.isOpened()):

    # ret是从视频中读取每一帧的bool指

    ret, frame = cap.read()

    # canny边缘检测

    canny = do_canny(frame)

    cv.imshow("canny", canny)

    # 分割车道区域

    segment = do_segment(canny)

    # 霍夫变换

    # 当这条线垂直时，梯度是无穷大的，无法在霍夫空间中表示出来。我们用极坐标绘制的是r对θ的图。

    hough = cv.HoughLinesP(segment, 2, np.pi / 180, 100, np.array([]), minLineLength = 100, maxLineGap = 50)

    # 将霍夫变换后检测到的多个线段计算为车道左右两边的两个线

    lines = calculate_lines(frame, hough)

    # 可视化线段

    lines_visualize = visualize_lines(frame, lines)

    cv.imshow("hough", lines_visualize)

    # 叠加两个图

    output = cv.addWeighted(frame, 0.9, lines_visualize, 1, 1)

    # 打开一个新窗口来显示叠加后的图像

    cv.imshow("output", output)

    # 每秒10帧的读取视频，q退出循环

    if cv.waitKey(10) & 0xFF == ord('q'):

        break

# 释放资源

cap.release()

cv.destroyAllWindows()

```





### DL

类型： 

- 普通分割（前景与背景），将不同的物体的像素区域分开即可

- 语义分割（猫和狗），在普通分割的基础上，还要分类出每一块区域的语义

- 实例分割（分割每一个人），在语义分割的基础上，还要区分同种物体的不同个体

#### 思路：

- 前端

下采样+上采样：Convlution + Deconvlution／Resize

多尺度特征融合：特征逐点相加／特征channel维度拼接

获得像素级别的segement map：对每一个像素点进行判断类别

- 后端

使用CRF条件随机场，MRF马尔科夫随机场，优化（确定一个像素属于谁的几率大）

#### 常用算法

![](/image/DLsplit.png)



[A Survey on DNN based Semantic Segmentation](https://blog.csdn.net/Julialove102123/article/details/80493066)

FCN

U-Net

SeqNet/DeconvNet

DeepLab

PSPNet

Mask rcnn

laneNet

[Towards End-to-End Lane Detection: an Instance Segmentation Approach](https://arxiv.org/abs/1802.05591)



##### 实现一个laneNet

主要特点：

实例分割来检测车道线

更灵活的透视变换：一般将图像透视变换到鸟橄图，可以进一步优化车道线，固定的透视变换矩阵遇到上下坡就不行了

因此作者提出用CNN学习透视变换

输入RGB图像+分割结果 -> H-Network -> 输出透视变换参数

参考：https://maybeshewill-cv.github.io/lanenet-lane-detection/

代码：https://github.com/andylei77/lanenet-lane-detection 







## 检测



## 分类

## 跟踪
