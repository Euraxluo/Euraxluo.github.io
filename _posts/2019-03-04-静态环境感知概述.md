---
layout:     post                    # 使用的布局（不需要改）
title:      ROS学习               # 标题 
subtitle:   静态环境感知概述                #副标题
date:       2019/3/4            # 时间
author:     Euraxluo                      # 作者
header-img: img/post-bg-github-cup.jpg  #这篇文章标题背景图片
catalog: true                 # 是否归档
tags:                               #标签
    - ROS

---
# 静态环境感知与分割算法概述
## 广义感知
### 感知外界
#### 目的
- 识别静态物体
- 识别动态物体的位姿
#### 传感器
- 单目：图片->ML,DL,分类，物体检测
- 双目：深度图->SLAM
- 激光雷达：稀疏点云
- 超声波雷达
### 感知自身
#### 目的：
- 感知自身的位姿
#### 传感器
- IMU,HD map,SLAM,gps

## 分割
[车道线检测论文集合](https://github.com/amusi/awesome-lane-detection)

### 传统的算法（opencv）
#### 边缘检测
Canny 边缘检测

-  原理
Canny 边缘检测是一种非常流行的边缘检测算法，是 John F.Canny 在
1986 年提出的。它是一个有很多步构成的算法，我们接下来会逐步介绍。

-  噪声去除
由于边缘检测很容易受到噪声影响，所以第一步是使用 5x5 的高斯滤波器
去除噪声

-  计算图像梯度
对平滑后的图像使用 Sobel 算子计算水平方向和竖直方向的一阶导数（图
像梯度）（Gx 和 Gy）。根据得到的这两幅梯度图（Gx 和 Gy）找到边界的梯
度和方向，公式如下：
$$
Edge-Gradient(G) =\sqrt{G^2_x + G^2_y}
$$

$$
Angle(θ) = tan^{−1}(\frac{G_x}{G_y})
$$
梯度的方向一般总是与边界垂直。梯度方向被归为四类：垂直，水平，和
两个对角线。

- 非极大值抑制
在获得梯度的方向和大小之后，应该对整幅图像做一个扫描，去除那些非
边界上的点。对每一个像素进行检查，看这个点的梯度是不是周围具有相同梯
度方向的点中最大的。得到的是一个包含“窄边界”的二值图像。

- 滞后阈值
现在要确定那些边界才是真正的边界。这时我们需要设置两个阈值：
minVal 和 maxVal。当图像的灰度梯度高于 maxVal 时被认为是真的边界，
那些低于 minVal 的边界会被抛弃。如果介于两者之间的话，就要看这个点是
否与某个被确定为真正的边界点相连，如果是就认为它也是边界点，如果不是
就抛弃。
在这一步一些小的噪声点也会被除去，因为我们假设边界都是一些长的线
段。

#### 手动分割图像
- 手动指定一个三角形来分割出路面区域，去除其他干扰

#### 霍夫曼变换
- 使用霍夫曼变化（极坐标系下）
可以把直线变换成曲线。通过一系列连续的线段，最终可以得到很多可能的直线（车道线）
通过这一系列的线段，我们计算平均斜率，得到车道线
#### 叠加到原图
- 使用opencv叠加到原图

#### 使用传统方法实现车道线检测（直线）

```python3
import cv2 as cv
import numpy as np
#import matplotlib.pyplot as plt

def do_canny(frame):#处理每一桢
    # 将帧转换为灰度图，因为我们只需要通过亮度梯度检测边缘，减少计算成本
    gray = cv.cvtColor(frame, cv.COLOR_RGB2GRAY)
    # 用 5*5 的高斯滤波器卷积（平滑）图像，从而降低检测器对噪声的敏感度（也可以使用canny来做）
    blur = cv.GaussianBlur(gray, (5, 5), 0)
    # 应用canny边缘检测器，最小值50，最大值150
    canny = cv.Canny(blur, 50, 150)
    return canny

def do_segment(frame):
    # 由于图像是一个三维数组，包含图像中每个像素的强度
    # frame.shape[0] 返回了像素数
    height = frame.shape[0]
    # 创建由三个坐标定义的一个三角形的，作为车道区域
    polygons = np.array([
                            [(0, height), (800, height), (380, 290)]
                        ])
    # 创建与图像尺寸相同的零矩阵
    mask = np.zeros_like(frame)    
    # 把polygons区域用mask来填充，颜色为255
    cv.fillPoly(mask, polygons, 255)
    # 按位操作，只保留我们的三角形区域
    segment = cv.bitwise_and(frame, mask)
    return segment

def calculate_lines(frame, lines):
    left = []
    right = []
    # 遍历每个检测到的行
    for line in lines:
        # R把线从2d数组reshape到一数组
        x1, y1, x2, y2 = line.reshape(4)
        # 拟合直线
        parameters = np.polyfit((x1, x2), (y1, y2), 1)
        slope = parameters[0]#直线的斜率
        y_intercept = parameters[1]#直线的截距
        # 如果斜率是负数，则这条线位于车道左侧，否者是右边的
        if slope < 0:
            left.append((slope, y_intercept))
        else:
            right.append((slope, y_intercept))
    #有很多个线，平均计算作为斜率（也就是把多个线化为一个线）
    left_avg = np.average(left, axis = 0)
    right_avg = np.average(right, axis = 0)
    #计算左右线段的起始坐标
    left_line = calculate_coordinates(frame, left_avg)
    right_line = calculate_coordinates(frame, right_avg)
    return np.array([left_line, right_line])

def calculate_coordinates(frame, parameters):
    slope, intercept = parameters
    # 将y1坐标设置图片的高度
    y1 = frame.shape[0]
    #将y2坐标设置为上方150
    y2 = int(y1 - 150)
    # x1坐标设置为(y1-b)/m，因为y1=mx1+b
    x1 = int((y1 - intercept) / slope)
    # x2坐标设置为(y1-b)/m，因为y1=mx1+b
    x2 = int((y2 - intercept) / slope)
    return np.array([x1, y1, x2, y2])

def visualize_lines(frame, lines):
    # 创建和图片尺寸相同的零矩阵填充
    lines_visualize = np.zeros_like(frame)
    # 检查是否由线段传进来了
    if lines is not None:
        for x1, y1, x2, y2 in lines:
            # 在两个坐标之间画出一条5像素的线段
            cv.line(lines_visualize, (x1, y1), (x2, y2), (0, 255, 0), 5)
    return lines_visualize

# 读取视频
cap = cv.VideoCapture("input.mp4")
while (cap.isOpened()):
    # ret是从视频中读取每一帧的bool指
    ret, frame = cap.read()
    # canny边缘检测
    canny = do_canny(frame)
    cv.imshow("canny", canny)
    # 分割车道区域
    segment = do_segment(canny)
    # 霍夫变换
    # 当这条线垂直时，梯度是无穷大的，无法在霍夫空间中表示出来。我们用极坐标绘制的是r对θ的图。
    hough = cv.HoughLinesP(segment, 2, np.pi / 180, 100, np.array([]), minLineLength = 100, maxLineGap = 50)
    # 将霍夫变换后检测到的多个线段计算为车道左右两边的两个线
    lines = calculate_lines(frame, hough)
    # 可视化线段
    lines_visualize = visualize_lines(frame, lines)
    cv.imshow("hough", lines_visualize)
    # 叠加两个图
    output = cv.addWeighted(frame, 0.9, lines_visualize, 1, 1)
    # 打开一个新窗口来显示叠加后的图像
    cv.imshow("output", output)
    # 每秒10帧的读取视频，q退出循环
    if cv.waitKey(10) & 0xFF == ord('q'):
        break
# 释放资源
cap.release()
cv.destroyAllWindows()
```


### DL
类型： 
- 普通分割（前景与背景），将不同的物体的像素区域分开即可
- 语义分割（猫和狗），在普通分割的基础上，还要分类出每一块区域的语义
- 实例分割（分割每一个人），在语义分割的基础上，还要区分同种物体的不同个体
#### 思路：
- 前端
下采样+上采样：Convlution + Deconvlution／Resize
多尺度特征融合：特征逐点相加／特征channel维度拼接
获得像素级别的segement map：对每一个像素点进行判断类别
- 后端
使用CRF条件随机场，MRF马尔科夫随机场，优化（确定一个像素属于谁的几率大）
#### 常用算法
![](/image/DLsplit.png)

[A Survey on DNN based Semantic Segmentation](https://blog.csdn.net/Julialove102123/article/details/80493066)
FCN
U-Net
SeqNet/DeconvNet
DeepLab
PSPNet
Mask rcnn
laneNet
[Towards End-to-End Lane Detection: an Instance Segmentation Approach](https://arxiv.org/abs/1802.05591)

##### 实现一个laneNet
主要特点：
实例分割来检测车道线
更灵活的透视变换：一般将图像透视变换到鸟橄图，可以进一步优化车道线，固定的透视变换矩阵遇到上下坡就不行了
因此作者提出用CNN学习透视变换
输入RGB图像+分割结果 -> H-Network -> 输出透视变换参数
参考：https://maybeshewill-cv.github.io/lanenet-lane-detection/
代码：https://github.com/andylei77/lanenet-lane-detection 



## 检测

## 分类
## 跟踪