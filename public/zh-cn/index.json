[{"categories":["Shortcode"],"content":"本文展示了如何使用 alert shortcode。\n{{\u0026lt; alert \u0026#34;Message\u0026#34; [type] \u0026gt;}}  The parameter type is optional. Default to info.\n Info {{\u0026lt; alert \u0026#34;Info\u0026#34; \u0026gt;}} Info  Success {{\u0026lt; alert \u0026#34;Success\u0026#34; success \u0026gt;}} Success  Warning {{\u0026lt; alert \u0026#34;Warning\u0026#34; warning \u0026gt;}} Warning  Danger {{\u0026lt; alert \u0026#34;Danger\u0026#34; danger \u0026gt;}} Danger ","permalink":"/zh-cn/posts/shortcodes/alert/","series":["用户手册"],"tags":["Alert"],"title":"Alert Shortcode"},{"categories":["Shortcode"],"content":"关于哔哩哔哩 shortcode 的详细使用说明。\n使用 {{\u0026lt; bilibili \u0026#34;video id\u0026#34; \u0026gt;}} 例子  ","permalink":"/zh-cn/posts/shortcodes/bilibili/","series":null,"tags":["哔哩哔哩"],"title":"Bilibili Shortcode"},{"categories":["读书笔记"],"content":"CleanCode读书笔记 最小惊异原则 1.从一而终，便于修改 2.遵守大家的约定 有意义的命名 1.名副其实 1.命名需要注释来补充，那就不算名副其实 2.在命名时尽量采用有意义的名称，代码的简洁不会改变（运算符和常量的数量，嵌套数量） 2.避免误导 1.避免使用与本意相驳的词 2.提防使用不同之处较小的词 3.不要使用小写l和大写O作为变量名 4.命名有区分，应当有明显的区分，应使读者可以鉴别 3.使用读得出来的名称 4.使用可搜索的名称 1.长名称胜于短名称，搜得到的名称胜于自造的名称 2.单字母仅用于短方法中的本地变量 3.名称长短应与其作用域大小相对应 4.若变量或常量可能在代码中多次使用，则应赋予其便于搜索的名称 5.避免使用编码和前缀 6.避免思维映射 不应当让读者在脑中把你的名称翻译为他们熟知的名称 7.类名和方法名 1.类名和对象名应该是名词 2.类名不应是动词 3.方法名应当是动词或动词短语 4.属性访问器，修改器和断言应该根据其值命名 8.宁可明确，勿为好玩 9.每个概念对应一个词 10.避免将同一单词用于不同目的 11.使用解决方案领域名称 12.使用源自所涉问题领域的名称 13.添加有意义的语境 2.函数 1.短小 1.if,else,while 语句，其中的代码块应该只有一行 并且应该大抵是一个函数调用语句 2.函数不应该大到足以容纳嵌套语句 3.永不调用的函数应该丢弃 2.只做一件事 要判断函数是否不止做了一件事，就是看能否再拆出一个函数 3.使用描述性的名称 1.函数越短小，功能越集中，就便于取个好名字 2.长而具有描述性的名称要比短的名称或者注释好 4.函数参数应少，并且不要使用输出参数 1.如果函数需要很多参数，说明需要封装为类 2.函数名称为动词可以明确函数是做什么的 3.函数参数自然而然的视为输入参数 4.将代码集中到基类i，避免冗余和重复 3.注释 1.注释不能美化糟糕的代码 2.注释的内容 1.版权及著作权声明 2.提供基本信息 3.对意图解释（提供某个决定的意图） 4.阐释（如果参数或者返回值是某个标准库的一部分，或者不能修改，帮助其阐释含义） 5.警告其他程序员会出现某种后果 6.//TODO注释（放置工作列表：程序员认为应该做，但由于某些原因还没有做的工作）  7.不要留下注释代码 格式 1.纵向格式 1.封包声明，导入声明，每个函数之间，用空白行隔开 2.关系密切或概念相关的代码应该互相靠近 3.变量声明应尽可能的靠近使用位置 4.实体变量应该在类的顶部声明 5.循环中的控制变量应该在循环语中声明 6.相关函数（相互靠近，调用者应该在被调用者的上面） 2.横向格式 1.赋值操作符周围加空格 2.函数名和左圆括号不能分开（函数于其参数关系紧密） 3.根据运算符优先级在运算部分加空格 4.if,whle,短函数 不要违反或忽视缩进 5.while,for 语句的语句体为空，应该把语句体分号换行缩进 对象和数据结构 1.数据对象的反对称性 1.过程式（使用数据结构）代码便于在添加新函数 2.面向对象代码难以添加新类 2.Demeter律 1.模块不应了解他所操作对象内部的情况 3.DTO 1.数据传送对象，只有一个公共变量，没有函数的类 2.使用于数据库通信，解析套接字传递 错误和异常处理 1.给出异常发生的环境说明 2.依调用者需要定义异常类 3.不能返回和传递NULL值 类应该短小 启发 一般性问题 1.一个源文件不要使用多种语言（尽力） 2.明显的行为未被实现，阅读者不会再相信编写者 3.尽可能找到并且删除重复 4.基类不能依赖于派生类 5.不执行的代码应该删除 java 1.通过使用通配符避免过长的导入清单 2.不要继承常量 3.多使用enum而非常量 单元测试及JUnit以后再读一遍 1.测试不充分 2.使用覆盖率工具（容易发现测试不足的模块） 3.别略过过小的测试 4.特别注意测试边界条件 5.缺陷趋于扎堆，全面测试相近的部分 6.测试应该快速 ","permalink":"/zh-cn/posts/reading/cleancode/","series":["读书笔记"],"tags":["ClearnCode"],"title":"CleanCode读书笔记"},{"categories":["Shortcode"],"content":"关于 CodePen shortcode 的详细说明。\n使用 {{\u0026lt; codepen \u0026#34;id\u0026#34; \u0026gt;}} 例子  ","permalink":"/zh-cn/posts/shortcodes/codepen/","series":null,"tags":["CodePen"],"title":"CodePen Shortcode"},{"categories":["Shortcode"],"content":"关于 JSFiddle shortcode 的详细说明。\n使用 {{\u0026lt; jsfiddle \u0026#34;user/id\u0026#34; \u0026gt;}} 例子  ","permalink":"/zh-cn/posts/shortcodes/jsfiddle/","series":null,"tags":["JSFiddle"],"title":"JSFiddle Shortcode"},{"categories":["Shortcode"],"content":"关于 JSRun shortcode 的详细说明。\n使用 {{\u0026lt; jsrun \u0026#34;id\u0026#34; \u0026gt;}} 例子  ","permalink":"/zh-cn/posts/shortcodes/jsrun/","series":null,"tags":["JSRun"],"title":"JSRun Shortcode"},{"categories":["读书笔记"],"content":"MVC分层模型 DAO 模式初识 PO(persistant object) 持久对象 在o/r映射的时候出现的概念，如果没有o/r映射，没有这个概念存在了。通常对应数据模型(数据库),本身还有部分业务逻辑的处理。可以看成是与数据库中的表相映射的java对象。最简单的PO就是对应数据库中某个表中的一条记录，多个记录可以用PO的集合。PO中应该不包含任何对数据库的操作。\n最形象的理解就是一个PO就是数据库中的一条记录。\n好处是可以把一条记录作为一个对象处理，可以方便的转为其它对象。\nVO(value object) 值对象 通常用于业务层之间的数据传递，和PO一样也是仅仅包含数据而已。但应是抽象出的业务对象,可以和表对应,也可以不,这根据业务的需要.个人觉得同TO(数据传输对象),在web上传递。\n主要对应界面显示的数据对象。对于一个WEB页面，或者SWT、SWING的一个界面，用一个VO对象对应整个界面的值。\nTO(Transfer Object)，数据传输对象 在应用程序不同tie(关系)之间传输的对象\nBO(business object) 业务对象 从业务模型的角度看,见UML元件领域模型中的领域对象。封装业务逻辑的java对象,通过调用DAO方法,结合PO,VO进行业务操作。\nPOJO(plain ordinary java object) 简单无规则java对象 纯的传统意义的java对象。就是说在一些Object/Relation Mapping工具中，能够做到维护数据库表记录的persisent object完全是一个符合Java Bean规范的纯Java对象，没有增加别的属性和方法。我的理解就是最基本的Java Bean，只有属性字段及setter和getter方法！。\nDTO（Data Transfer Object）：数据传输对象 这个概念来源于J2EE的设计模式，原来的目的是为了EJB的分布式应用提供粗粒度的数据实体，以减少分布式调用的次数，从而提高分布式调用的性能和降低网络负载，但在这里，我泛指用于展示层与服务层之间的数据传输对象。\nDAO(data access object) 数据访问对象 是一个sun的一个标准j2ee设计模式，这个模式中有个接口就是DAO，它负持久层的操作。为业务层提供接口。此对象用于访问数据库。通常和PO结合使用，DAO中包含了各种数据库的操作方法。通过它的方法,结合PO对数据库进行相关的操作。夹在业务逻辑与数据库资源中间。配合VO, 提供数据库的CRUD操作\u0026hellip;\n这个大家最熟悉，和上面几个O区别最大，基本没有互相转化的可能性和必要.\n主要用来封装对数据库的访问。通过它可以把POJO持久化为PO，用PO组装出来VO、DTO\nO/R Mapper 对象/关系 映射 定义好所有的mapping之后，这个O/R Mapper可以帮我们做很多的工作。通过这些mappings,这个O/R Mapper可以生成所有的关于对象保存，删除，读取的SQL语句，我们不再需要写那么多行的DAL代码了。\n实体Model(实体模式)\nDAL(数据访问层)\nIDAL(接口层)\nDALFactory(类工厂)\nBLL(业务逻辑层)\nBOF Business Object Framework 业务对象框架\nSOA Service Orient Architecture 面向服务的设计\nEMF Eclipse Model Framework Eclipse建模框架\nDAO模式 分为四层\n  客户层{包括Web浏览器,Applet}\n  Web{包括Servlet,JSP}\n  业务逻辑{EJB}\n  数据持久层{数据库}\n  DAO过程\n客户端向服务器发出请求,服务器端由Web层进行接收,交给业务逻辑处理层来处理,对数据的访问由业务逻辑层去访问数据持久层\n简单的例子和结构 com.demo\n utils(工具类,公共类,模板类)\n   数据库连接池工具类\n     static:获取配置\n      获取数据源\n      获取连接\n      获取配置信息\n     DAO操作模板类IDUS{不同的impl实现类都可以用}\n   dao{大部分都是一些接口}\n     exception:定义异常处理的接口\n     DAO异常类\n       传参异常\u0026hellip;\n        等等\n       其他异常类\n     DAO#接口#:定义IDUS操作,都会和DAO异常有关系\n     学生DAO\n      教师DAO\n      课程DAO\n     impl:DAO接口的具体实现\n     DAO的具体实现时,我们先优先采用组合后考虑继承\n      StudentDAOImpl\n       insert:定义我们的UpdateSQL模板,从pojo中get字段,交给DAO操作模板类,完成Update操作(把结果交给匿名类)\n        select:QuerySQL模板+字段-\u0026gt;模板类的Query == 完成select(把结果交给匿名类)\n       其他实现类\n     refactor:内部匿名类\n     RowMapper\n       把从数据库中获取的结果(resultSet对象)set到pojo中\n        将数据中的每一行数据封装成用户定义的类。\n       RowCall\n    pojo(数据持久层)\n   学生\n    教师\n    课程\n    其他表的实体类\n     getXXX\n      setXXX\n      表字段\n    DAOFactory(工厂类)\n   使用单例模式,采取反射机制获取具体的DAO及其实现类的对象,在业务层就直接利用工厂类调用接口,完成业务(对DAO和业务层解耦)\n  ","permalink":"/zh-cn/posts/nlp/mvc/","series":["读书笔记"],"tags":["mvc分层模型"],"title":"MVC分层模型"},{"categories":["NLP"],"content":"NLP概览 什么是NLP   自然语言处理,是探讨如何处理及运用自然语言\n  自然语言认知,是让电脑明白人类的语言\n  自然语言处理主要包括:文本分析,信息检索,词性标注,问答系统QA\n  NLP技术  词法分析\n - 分词技术\r- 词性标注part-of-speech tagging\r- 命名实体识别NER(识别出3大类和7小类主要用于信息提取,QA,句法分析,机翻元数据标注)\r实体边界识别\r基于规则和词典进行识别(字典大小,新词?)\r基于统计的方法\r\u0026gt;隐马尔科夫模型HMM\r\u0026gt;较大熵ME\r\u0026gt;支持向量机SVM\r\u0026gt;条件随机场CRF\r确定实体类别(英文,中文需要先分词)\r- 词义消歧\r  句法分析\n  语义分析\n 常见模型   传统感知机模型\n  BP神经网络:前馈神经网络(反向传播算法),是现代神经网络的基础\n输入层:数据模型的输入,也就是说我们要传入到模型中的数据\n隐藏层:用于处理数据,并将处理的结果传递给输出层\n输出层:经过隐藏层的计算过后输出的模型内容,分类信息,或者是模型的最终参数\n训练过程概述:\n  正向传播:网络初始化(定义网络参数),隐藏层的输出,输出层的输出\n  误差计算:通过误差计算的公式,计算出误差\n  反向传播:通过计算的误差,从输出层向后传播,并在过程中更新权重参数\n  偏置更新:通过计算的误差,更新隐藏层到输出层,输入层到隐藏层的权重参数\n  特点:\n  可以通过逐层信息传递到最后的输出\n  沿着一条直线计算,直到最后一层,求出计算结果\n  包含输入层,输出层和隐藏层,目的是实现输入到输出的映射\n  一般包含多层,并且层与层之间是全链接的不会出现同层和跨层连接\n    CNN:是一种前馈神经网络,包括卷积层(convolutional)和池化层(pooling layer)\n  RNN:循环神经网络是一种节点定向连接成环的人工神经网络,这种网络的内部状态可以动态的展示时序行为(短文本)\n特点:记忆特性;接受两个参数W和当前时间的特征;参数共享(确保每一步都在做相同的事)\n网络结构和BP神经网络的对比:\nRNN的类型:\n  one to one:适合用于分类任务\n  one to many:文本生成,音乐生成\n  many to one:多分类任务\n  many to many(不同维度):翻译任务\n  many to many(同维度):命名实体识别\n    LSTM:长短期记忆网络,是一种时间递归神经网络.适合于处理和预测时间序列中间隔和延迟相对较长的重要事件(长文本)\n在普通的RNN中增加了一种由门控制的保存单元状态的结构:c\n通过遗忘门,输出门,输入门\n  GRU\n只要更新门和重置门,没有隐藏层(可能不太关注时序的各种关系???我不太懂)\n  双向循环神经网络:\n特点:\n  每个时刻有两个隐藏层\n  一个Forward Layer;另一个Backward Layer\n  向前传播和向后传播的参数是独立的\n    ##　梯度消失和梯度爆炸\n在训练RNN中最常见的问题\n解决方法:\n  选择合适的激活函数\n ReLu函数(最常使用)\n  Sigmod函数和Tanh函数(这两个的导数在大部分区域很小,容易产生梯度消散)\n   选择合适的参数初始化方法不能设置为0\n 权重参数=np.random.randn(w的shape)*0.01(适用于小任务,解决参数对称)\n  权重参数=np.random.randn(w的shape)*np.sqrt(1/(上一层的神经元数))(主要适用于ReLu激活函数,可以缓解梯度消散)\n   使用权重参数正则化\n  使用BatchNormailzation\n 通过规范化的操作将输出信号x规范化到均值为0,方差为1保证网络的稳定性(把偏离的参数规范到高斯分布上)\n  可以加大神经网络的训练速度\n  提高训练的稳定性\n  缓解梯度抱着和梯度消散的问题\n   使用残差网络\n 在神经网络中加入以下结构:\n  通过跨层连接,使得快速下降的参数能得到缓解,让神经网络的深度大大提高,同时解决了梯度消失的问题\n   使用梯度裁剪\n 强制的让我们的梯度变小\n  算法:$if ||g||\u0026gt;v ;then g\u0026lt;\u0026ndash; gv/(||g||)$\n  在可视化的层面上将,就是让我们的导数不去跨越面,温和的梯度下降\n   隐马尔可夫模型实现命名实体识别 马尔科夫过程   马尔科夫过程(Markov process)是一类随机过程\n  在已知目前状态(现在)的条件下,它未来的演变(将来)不依赖于它以往的演变(过去).主要研究一个系统的状态及其转移的理论.他是通过对不同状态的初始概率以及状态的转移概率的研究,来确定状态的变化趋势,从而达到预测未来的目的\n  马尔科夫链(Markov chain)  是指具有马尔科夫性质的离散事件随机过程,即时间和状态参数都是离散的马尔科夫过程,是最简单的马尔科夫过程  隐马尔可夫模型(Hidden Markov Model,HMM)   一种统计分析模型,是马尔科夫链的一种,它的状态不能被直接观察到,但能通过观测向量序列观察到,每个观测向量都是通过某些概率密度分布变现为个各种状态,每一个观测向量是由一个具有响应概率密度分布的状态序列产生\n  是结构最简单的动态贝叶斯网(一种有向图模型),主要用于时序数据建模(语音识别,自然语言处理)\n  隐马尔可夫模型由五个要素组成,其中两个状态集合(N.M),三个概率矩阵(A.B,π)\n  N:表示模型中的状态数,状态之间可以相互转移\n  M:表示每个状态不同的观察符号,即输出字符的个数\n  A:状态转移概率\n  B:观察符号在各个状态下的概率分布\n  π:表示初始状态分布\n    隐马尔可夫模型的输入和输出\n输入:HMMs的五元组(N,M,A,B,π)\n输出:一个观察符号的序列,这个序列的每个元素都是M中的元素\n  使用隐马尔科夫模型实现命名实体识别   训练:通过语料进行训练,输出概率用于NE识别,这当中用了大量的贝叶斯\n  NE识别:给定各种状态下不同分词的概率以及完成人工词性标注的句子求出词性标注概率最大的状态\n  规则修正:对于一些特殊名词的标注进行规则修正\n  标注转换:通过序列处理把实现NE标注多个词复合,求得整个序列串概率最大的标注方案\n  语料 语料库   语言材料.语料是语言学研究的内容.语料是构成语料库的基本单元\n  语料库中存放的是在语言的实际使用中真实出现的语言材料\n  语料库是以电子计算机为载体承载语言知识的基础资源\n  真实语料需要经过加工(分析和处理),才能成为有用的资源\n  语料库的种类   异质\n  同质\n  系统\n  专用\n  获取途径   爬虫\n  平台\n  语料的处理   获取语料\n  格式化文本\n  特征工程\n  NLP中的语言模型 语言模型是自然语言处理中的一个利器,是NLP领域一个基本又重要的任务.它的主要更能是计算一个词语序列构成一个句子的概率,或者说计算一个词语序列的联合概率,这可以用来判断一句话出现的概率高不高,是否符合我们的表达习惯,这句话是否正确\n概率语言模型 预测字符串概率,考虑动机,考虑计算方式\n  Unigram models(一元文法统计模型)\n  N-gram 语言模型(N元模型)\n  一元文法统计模型 p(s) = p(w1)*p(w2)*p(w3)*p(w4)*p(w5)*p(w6)*p(w7)\n我们假设每个词都条件无关\n二元文法统计模型 p(s) = p(w1|)*p(w2|w1)p(w3|w2)\u0026hellip;*p(|wn)\n二元语言模型可以比一元语言模型更考虑到两个词之间的关系信息\nN元模型 $P( w1,w2,\u0026hellip;,w_m) = i\u0026hellip;m(*) P(w_i|w1,\u0026hellip;,w_(i-1)) = i\u0026hellip;m(*) P(w_i|w_(i-n+1),\u0026hellip;,w_(i-1))$\n注: n大于3时基本无法处理,参数空间太大.另外它不能表示词与词之间的关联性\n词向量(Word embedding) 即词嵌入,是自然语言处理中的一组语言建模和特征学习技术的统称,其中来自词汇表的单词或短语被映射到实数的向量\nWord2vec 是为一群用来产生词向量的相关模型.这些模型为浅而双层的神经网络,用来训练以重新构建语言学之词文本\n CBOW   CBOW模型由输入层,映射层,输出层共同构成\n  CBOW所构建的模型结构实际上是一个二叉树结构,应用到Word2vec中被称为Hierarchical Softmax\n  Skip-gram   Skip-Gram模型由输入层,映射层,输出层共同构成\n  Skip-Gram所构建的模型结构实际上是一个二叉树结构,并且刚好和CBOW模型相反\n 文本处理方法   数据清洗(去掉无意义的标签,url,符号等)\n  分词,大小写转换,添加句首句尾,词性标注\n  统计词频,抽取文本个特征,特征选择,计算特征权重,归一化\n  划分训练集,测试集\n  ","permalink":"/zh-cn/posts/nlp/nlp%E5%9F%BA%E7%A1%80/","series":["NLP"],"tags":["NLP"],"title":"NLP基础 "},{"categories":["Java"],"content":"Servlet HTTP协议 是客户端与服务器通信的一种方式\n参考链接 request: 请求行\r请求头\r请求体\r response: 响应行\r响应头\r响应体\r Get: GET用于信息获取，而且应该是安全的和幂等的\n  带上数据,在URL上面拼接\nwww.baidu.com\nname = zhanshan\nage = 18\nurl:www.baidu.com?name = zhanshan\u0026amp;age = 18\nurl可见\n  传输方式\nHTTP header\n  设计目的\n获取数据\n  具有安全隐患,GET方法不会改变服务器端数据，所以不会产生副作用\n  GET请求返回的内容可以被浏览器缓存起来\n  Post:   以流的方式传输,数据无限制\nurl不可见\n  传输方式\nHTTP body\n  设计目的\n发送数据\n  用户可能会提交一些错误的数据\n  浏览器不会缓存POST请求返回的内容\n  ####　幂等（idempotent、idempotence）是一个数学或计算机学概念，常见于抽象代数中。\n幂等有以下几种定义：\n​\t对于单目运算，如果一个运算对于在范围内的所有的一个数多次进行该运算所得的结果和进行一次该运算所得的结果是一样的，那么我们就称该运算是幂等的。 比如绝对值运算就是一个例子，在实数集中，有abs(a) = abs(abs(a)) 。\n​\t对于双目运算，则要求当参与运算的两个值是等值的情况下，如果满足运算结果与参与运算的两个值相等，则称该运算幂等，如求两个数的最大值的函数，有在实数集中幂等，即max(x,x) = x 。\n看完上述解释后，应该可以理解GET幂等的含义了。\n幂等：如果目标是当用户打开一个链接时，他可以确信从自身的角度来看没有改变资源即可。\n非幂等：以新闻网站为例，读者对新闻发表自己的评论应该通过POST实现，因为在评论提交后站点的资源已经不同了，或者说资源被修改了。\nServletConfig 写在xml文件中,一个servlet可以有多个配置信息{以servlet为单位}，同时也可以设置全局配置信息，因为可能会部署很多个servlet容器。\n\u0026lt;servlet\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;data4\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;value4\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!--配置信息--\u0026gt; \u0026lt;servlet-name\u0026gt;demo\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;main.netjava.com.servlet.example.demo\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;!--全局：--\u0026gt; \u0026lt;/context-param\u0026gt; web.xml 1.servlet声明\nservlet:配置servlet\nservlet-name：逻辑名称\nservlet-class：逻辑名称对应的servlet的实际地址\nservlet_mapping:servlet的对外映射\nurl-pattern:对外映射的路径{支持模糊匹配}\nservlet支持多个url-pattern对应同一个Servlet\nservlet的优先级匹配规则：\n​\t精确路径匹配，完全匹配\n​\t最长路径匹配\n​\t扩展名匹配\n​\tdefault匹配\n​\nload-on-startup 改变Servlet的默认初始化时间\n\u0026lt;load-on-startup\u0026gt;0 \u0026lt;load-on-startup\u0026gt;\n当 它\u0026gt;=0,Servlet启动时就加载相应的操作\n当其\u0026lt;0,Servlet 在客户端第一次请求servlet才加载\n当有多个servlet时，数字越高，优先级越高\n2.servlet的配置\nservletconfig：配置信息\nservlet下的init-param：\nparam-name：配置的key\nparam-value：配置的value\n错误页面配置 \u0026lt;error-page\u0026gt; \u0026lt;error-code\u0026gt;404\u0026lt;/error-code\u0026gt; \u0026lt;location\u0026gt;/404.html\u0026lt;/location\u0026gt; \u0026lt;/error-page\u0026gt; 欢迎页面 \u0026lt;welcome-file-list\u0026gt; \u0026lt;!--可以加很多个吗、，顺序加载一个--\u0026gt; \u0026lt;welcome-file\u0026gt;postget.html\u0026lt;/welcome-file\u0026gt; \u0026lt;/welcome-file-list\u0026gt; MIME类型映射 \u0026lt;mime-mapping\u0026gt;:定义扩展文件名隐射类型{打开文件还是下载文件} \u0026lt;extension\u0026gt;:浏览器所要解析的文件的扩展名 \u0026lt;mime-type\u0026gt;:指定映射类型 \u0026lt;/mime-mapping\u0026gt; Cookie和 Session Cookie 保存浏览器客户端\n过程：浏览器提出HTTP请求，发送给服务器后，服务器生成Cookie包含在响应头中发送给浏览器，最后浏览器会把Cookie保存起来\n通过setMaxAge设置cookie有效期 如果不设置，cookie会在会话结束后在内存中被销毁\nSession:保存在服务器端\n当浏览器发起HTTP请求时，服务器会把发送过来的数据进行逻辑处理，变成Session，并且把Session id包含在Cookie中，发送给浏览器\n当下一次访问时，浏览器会根据cookie中的Session信息返回特定的http响应\n通过setMaxInactiveInterval设置过期时间 通过invalidata使Session失效 通过ServletContext的动态属性方法，共享数据 Servlet的请求转发{RequestDispatcher} forward:将当前的request和response对象交给指定的web组件处理\n必须的步骤：转发对象：\n通过HttpServletRequest获取\n通过ServletContext获取\n###ServletContext\n Servlet 上下文\n  每个web工程都只有一个ServletContext对象。 说白了也就是不管在哪个servlet里面，获取到的这个类的对象都是同一个。\n ###如何得到对象\n\r//1. 获取对象\rServletContext context = getServletContext();\r有什么作用   获取全局配置参数\n  获取web工程中的资源\n  存取数据，servlet间共享数据 域对象\n  ####.可以获取全局配置参数\n\u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;address\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;绵阳\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; 获取全局参数\nServletContext context = getServletContext(); String address = context.getInitParameter(\u0026#34;address\u0026#34;); System.out.println(\u0026#34;这是获取的数据:\u0026#34;+address) ####. 可以获取Web应用中的资源\n 获取资源在tomcat里面的绝对路径  先得到路径，然后自己new InpuStream\ncontext.getRealPath(\u0026#34;\u0026#34;) //这里得到的是项目在tomcat里面的根目录。  D:\\tomcat\\apache-tomcat-7.0.52\\apache-tomcat-7.0.52\\wtpwebapps\\Demo03\\ String path = context.getRealPath(\u0026#34;file/config.properties\u0026#34;); D:\\tomcat\\apache-tomcat-7.0.52\\apache-tomcat-7.0.52\\wtpwebapps\\Demo03\\file\\config.properties  getResourceAsStream 获取资源 流对象\n直接给相对的路径，然后获取流对象。\n  //获取web工程下的资源,转化为流对象,前面隐藏当前工程的根目录  //在我们使用相对路径时,我们应该注意,有没有参照物  //这里的参照物是tomcat里面的根目录  通过classloader去获取web工程下的资源 ServletContext的目录是.tomcat里面的根目录\nClassLoder 的路径是根目录下的WEB-INF下的classer目录\n使用ServletContext存取数据。   定义一个登陆的html页面， 定义一个form表单\n  定义一个Servlet，名为LoginServlet\n  针对成功或者失败，进行判断，然后跳转到不一样的网页\n  ###ServletContext存取值分析\n##细节：\n\r\u0026lt;!-- A路径： Servlet的路径\rhttp://localhost:8080/Demo4/login\rB路径： 当前这个html的路径：\rhttp://localhost:8080/Demo4/login.html --\u0026gt;\r​\n\r\u0026lt;form action=\u0026quot;login\u0026quot; method=\u0026quot;get\u0026quot;\u0026gt;\r账号:\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;username\u0026quot;/\u0026gt;\u0026lt;br\u0026gt;\r密码:\u0026lt;input type=\u0026quot;text\u0026quot; name=\u0026quot;password\u0026quot;/\u0026gt;\u0026lt;br\u0026gt;\r\u0026lt;input type=\u0026quot;submit\u0026quot; value=\u0026quot;登录\u0026quot;/\u0026gt;\r\u0026lt;/form\u0026gt;\r###ServletContext 何时创建， 何时销毁?\n服务器启动的时候，会为托管的每一个web应用程序，创建一个ServletContext对象\n从服务器移除托管，或者是关闭服务器。\n ServletContext 的作用范围   只要在这个项目里面，都可以取。 只要同一个项目。 A项目 存， 在B项目取，是取不到的？ ServletContext对象不同。\n ","permalink":"/zh-cn/posts/java/servlet1/","series":["Java"],"tags":["Java"],"title":"Servlet1"},{"categories":["Java"],"content":"Cookie和Session 会话：浏览器发出http请求。服务器接受，对请求进行响应，浏览器接受http响应\nCookie 把会话数据保存在浏览器客户端\n服务器第一次访问时，服务端生成cookie，并且把这个cookie通过响应，发送给客户端，客户端把cookie保存下来，以便在最近的下一次访问中使用\n缺点\n  Cookie有大小和数量的限制\n  明文传递有风险\n  //创建Cookie对象  Cookie userNameCookie = new Cookie(\u0026#34;userName\u0026#34;,userName); Cookie userPasswordCookie = new Cookie(\u0026#34;userPassword\u0026#34;,userPassword); //返回给访问对象  resp.addCookie(userNameCookie); resp.addCookie(userPasswordCookie); /、对外部浏览器返回的响应头进行处理 Cookie[] cookies = req.getCookies(); if(cookies != null){ for(Cookie cookie:cookies){ if (cookie.getName().equals(\u0026#34;userName\u0026#34;)) { userName = cookie.getValue(); }else if (cookie.getName().equals(\u0026#34;userPassword\u0026#34;)) { userPassword = cookie.getValue(); } } } 例子一 显示最近访问的时间。   判断账号是否正确\n  如果正确，则获取cookie。 但是得到的cookie是一个数组， 我们要从数组里面找到我们想要的对象。\n  如果找到的对象为空，表明是第一次登录。那么要添加cookie\n  如果找到的对象不为空， 表明不是第一次登录。\n  if(\u0026#34;admin\u0026#34;.equals(userName) \u0026amp;\u0026amp; \u0026#34;123\u0026#34;.equals(password)){ //获取cookie last-name --- \u0026gt;  Cookie [] cookies = request.getCookies(); //从数组里面找出我们想要的cookie  Cookie cookie = CookieUtil.findCookie(cookies, \u0026#34;last\u0026#34;); //是第一次登录，没有cookie  if(cookie == null){ Cookie c = new Cookie(\u0026#34;last\u0026#34;, System.currentTimeMillis()+\u0026#34;\u0026#34;); c.setMaxAge(60*60); //一个小时  response.addCookie(c); response.getWriter().write(\u0026#34;欢迎您, \u0026#34;+userName); }else{ //1. 去以前的cookie第二次登录，有cookie  long lastVisitTime = Long.parseLong(cookie.getValue()); //2. 输出到界面，  response.getWriter().write(\u0026#34;欢迎您, \u0026#34;+userName +\u0026#34;,上次来访时间是：\u0026#34;+new Date(lastVisitTime)); //3. 重置登录的时间  cookie.setValue(System.currentTimeMillis()+\u0026#34;\u0026#34;); response.addCookie(cookie); } }else{ response.getWriter().write(\u0026#34;登陆失败 \u0026#34;); } 例子二： 显示商品浏览记录。 准备工作   拷贝基础课第一天的 htmll原型文件，到工程的WebContent里面。\n  在WebContent目录下新建一个jsp文件， product_list.jsp, 然后拷贝原来product_list.html的内容到jsp里面。 建好之后，jsp里面的所有ISO-8859-1 改成 UTF-8\n拷贝html标签的所有内容。 替换jsp的html标签即可\n  修改product_info.htm里面的手机数码超链接地址\n  \u0026lt;li class=\u0026quot;active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;product_list.jsp\u0026quot;\u0026gt;手机数码\u0026lt;span class=\u0026quot;sr-only\u0026quot;\u0026gt;(current)\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n修改首页(index.html)顶部的手机数码跳转的位置为 product_list.jsp  \u0026lt;li class=\u0026quot;active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;product_list.jsp\u0026quot;\u0026gt;手机数码\u0026lt;span class=\u0026quot;sr-only\u0026quot;\u0026gt;(current)\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n#####分析\n显示浏览记录 Cookie[] cookies = request.getCookies(); Cookie cookie = CookieUtil.findCookie(cookies,\u0026#34;history\u0026#34;); //如果cookie是空的,表img01明没有浏览任何商品  if(cookie == null){ out.println(\u0026#34;你还没有浏览任何商品\u0026#34;); }else{ //不是空,表明有浏览记录  String[] ids = cookie,getValue().split(\u0026#34;#\u0026#34;); for(String id:ids){ //输出浏览记录  } } 清除浏览记录  其实就是清除Cookie， 删除cookie是没有什么delete方法的。只有设置maxAge 为0 。\n Cookie cookie = new Cookie(\u0026#34;history\u0026#34;,\u0026#34;\u0026#34;); cookie.setMaxAge(0); //设置立即删除  cookie.setPath(\u0026#34;/CookieDemo02\u0026#34;); response.addCookie(cookie); Cookie总结   服务器给客户端发送过来的一小份数据，并且存放在客户端上。\n  获取cookie， 添加cookie\nrequest.getCookie();\nresponse.addCookie();\n  Cookie分类\n 会话Cookie  ​\t默认情况下，关闭了浏览器，那么cookie就会消失。\n2)持久Cookie\n​\t在一定时间内，都有效，并且会保存在客户端上。\n​\tcookie.setMaxAge(0); //设置立即删除\n​\tcookie.setMaxAge(100); //100 秒\n  Cookie的安全问题。\n   由于Cookie会保存在客户端上，所以有安全隐患问题。 还有一个问题， Cookie的大小与个数有限制。 为了解决这个问题 \u0026mdash;\u0026gt; Session .\n HttpSession 把会话数据保存在服务器端\n客户端把请求等发送给服务器，服务器根据这个请求，生成一个session，并且，把这个Session的id处理通过cookie发送给客户端，下一次客户端访问时，就可以找到这个Session\n 会话 ， Session是基于Cookie的一种会话机制。 Cookie是服务器返回一小份数据给客户端，并且存放在客户端上。 Session是，数据存放在服务器端。\n  常用API  //得到会话ID  String id = session.getId(); //存值  session.setAttribute(name, value); //取值  session.getAttribute(name); //移除值  session.removeAttribute(name);   Session何时创建 ， 何时销毁?\n  创建\n   如果有在servlet里面调用了 request.getSession()\n  销毁   session 是存放在服务器的内存中的一份数据。 当然可以持久化. Redis . 即使关了浏览器，session也不会销毁。\n  销毁方式\n    关闭服务器      session会话时间过期。 有效期过了，默认有效期： 30分钟。        Session的优先级\n​\tsetMaxInaxtiveInterval　＞　部署描述符配置\n​\tinvalidate使Session失效\n  //创建session  HttpSession session = req.getSession(); //把表单数据放入session中  String sessioname = (String) session.getAttribute(\u0026#34;userName\u0026#34;); //查看一下二次登录的session  if(sessioname != null){ System.out.println(\u0026#34;second Session:\u0026#34;); } 例子三： 简单购物车。 CartServlet 代码 response.setContentType(\u0026#34;text/html;charset=utf-8\u0026#34;); //1. 获取要添加到购物车的商品id  int id = Integer.parseInt(request.getParameter(\u0026#34;id\u0026#34;)); // 0 - 1- 2 -3 -4  String [] names = {\u0026#34;Iphone7\u0026#34;,\u0026#34;小米6\u0026#34;,\u0026#34;三星Note8\u0026#34;,\u0026#34;魅族7\u0026#34; , \u0026#34;华为9\u0026#34;}; //取到id对应的商品名称  String name = names[id]; //2. 获取购物车存放东西的session Map\u0026lt;String , Integer\u0026gt; iphoen7 3  //把一个map对象存放到session里面去，并且保证只存一次。  Map\u0026lt;String, Integer\u0026gt; map = (Map\u0026lt;String, Integer\u0026gt;) request.getSession().getAttribute(\u0026#34;cart\u0026#34;); //session里面没有存放过任何东西。  if(map == null){ map = new LinkedHashMap\u0026lt;String , Integer\u0026gt;(); request.getSession().setAttribute(\u0026#34;cart\u0026#34;, map); } //3. 判断购物车里面有没有该商品  if(map.containsKey(name)){ //在原来的值基础上 + 1  map.put(name, map.get(name) + 1 ); }else{ //没有购买过该商品，当前数量为1 。  map.put(name, 1); } //4. 输出界面。（跳转）  response.getWriter().write(\u0026#34;\u0026lt;a href=\u0026#39;product_list.jsp\u0026#39;\u0026gt;\u0026lt;h3\u0026gt;继续购物\u0026lt;/h3\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt;\u0026#34;); response.getWriter().write(\u0026#34;\u0026lt;a href=\u0026#39;cart.jsp\u0026#39;\u0026gt;\u0026lt;h3\u0026gt;去购物车结算\u0026lt;/h3\u0026gt;\u0026lt;/a\u0026gt;\u0026#34;); 移除Session中的元素 //强制干掉会话，里面存放的任何数据就都没有了。  session.invalidate(); //从session中移除某一个数据  //session.removeAttribute(\u0026#34;cart\u0026#34;);  请求转发 定义：将当前的request和response 对象交给指定的web组件进行处理\n注意：\n  请求转发时，浏览器url不会改变\n  地址上显示的是请求servlet的地址。 返回200 ok\n  请求次数只有一次， 因为是服务器内部帮客户端执行了后续的工作。\n  只能跳转自己项目的资源路径 。\n  效率上稍微高一点，因为只执行一次请求。\n  可以使用上一次的request对象。\n  //请求转发的写法：\n include{RequestDispatcher}  request.getRequestDispatcher(\u0026quot;login_success.html\u0026quot;).forward(request, response);\n1) 通过HttpServletRequest\r2) 通过ServletContext\r 使用forward  //3中请求转发的方式  RequestDispatcher rd = req.getRequestDispatcher(\u0026#34;/ServletForwardExample/*\u0026#34;);//1  rd = this.getServletContext().getNamedDispatcher(\u0026#34;servletForwardExample\u0026#34;);//2  rd = this.getServletContext().getRequestDispatcher(\u0026#34;/servletForwardExample/*\u0026#34;);//3  rd.forward(req,resp); 请求重定向 sendRedirect\n通过response对象发送给浏览器一个新的地址，让其重新请求（两次请求，两次响应）\nex：网页登录跳转：\n  浏览器发出登录请求\n  服务器请求转发进行登录处理\n  服务器把请求响应发送给客户端，同事包含另一个url的响应信息\n  浏览器接收到响应信息，得到另一个url\n  随即，浏览器向服务器发出跳转请求\n  服务器返回跳转结果\n  resp.sendRedirect(\u0026quot;/SendRedirectExample/*\u0026quot;);\n注：转发和重定向的区别\n  转发的浏览器地址栏不会发生变化，重定向则会\n  请求转发只能在同一个web应用下进行转发。重定向可以跨web资源和地址\n  请求转发一次请求一次响应。重定向是两次转发，两次响应\n  过滤器和监听器   过滤源：请求和响应\n  过滤规则：自己定义\n  简单地说：过滤器会在请求发送给Servlet之前先对请求进行处理，\n  如果响应要发送给浏览器也需要先经过过滤器\n 应用场景：\n  用户认证（验证用户是否有权限）\n  编解码处理\n  请求压缩\n    过滤器的生命周期\n  init - 初始化（只运行一次）\n  doFilter - 进行过滤操作\n  destroy - 释放资源，销毁过滤器对象（只运行一次）\n    public class TestFilter implements Filter{ // 可以像servlet配置一样，对TestFilter的init传入FilterConfig filterConfig  @Override public void init(FilterConfig filterConfig) throws ServletException {} @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {} @Override public void destroy() {} } filter配置：\n\u0026lt;filter\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;filterParam\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;euraxluo\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;filter-name\u0026gt;testFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;com.controller.filter.TestFilter\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;testFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/testFilter/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; 在写doFilter时，参数\nServletRequest servletRequest, ServletResponse servletResponse\n，不能直接处理Servlet中的HttpServletRequest req, HttpServletResponse resp\n应该使用类型转换HttpServletRequest req = (HttpServletRequest)servletRequest; \n通过过滤器验证登录的逻辑部分\n//通过判断是否有session来判断是否登录  HttpSession session = req.getSession(); if(session.getAttribute(\u0026#34;userName\u0026#34;)==null){ HttpServletResponse resp = (HttpServletResponse)servletResponse; resp.sendRedirect(\u0026#34;/GetPostServlet/*\u0026#34;); }else{ filterChain.doFilter(servletRequest,servletResponse); } 如果有多个filter，会根据在部署描述符中的先后顺序来决定过滤器的顺序\n在第一filter被调用时会产生filterchain传递给dofilter函数即，\ndofilter函数的FilterChain filterChain参数指的就是Filter链，\n再dofilter执行快结束时，会检查Filterchain，如果filterchain还有其他的filter，就会继续执行其他filter。如果没有了，就会执行跳转，把过滤后的请求给servlet。\nservlet返回响应时，也要经过filter链，并且顺序是反着的\n监听器{监听事件发生后，在事件发生前后能够做出相应处理的web应用组件} 事件源：我们需要监听的东西\n注册： 把监听器放在我们需要监听的地方\n通知：如果发生了我们监听的事件，就会通知\n最后监听到事件后，对其进行处理\nservlet中的注册不直接注册到事件，而是交给servlet，开发人员只需要配置部署描述符，servlet会自己注册到事件源\n监听器分类：\n  监听应用程序环境：ServletContext\n1)ServletContextListener(对创建和销毁进行监听)\n2)ServletContextAttributeListener(对属性的增删改查监听)\n  监听用户请求对象:ServletRequest\n1)ServletRequestListener(对创建和销毁进行监听)\n2)ServletRequestAttributeListener(对属性的增删改查监听)\n  监听用户会话对象:HTTPSession\n1)HTTPSessionListener(对创建和销毁进行监听)\n2)HTTPSessionAttributeListener(对属性的增删改查监听)\n3)HTTPSessionActivationListener(对session持久化到磁盘和重新加载到JVM时监听)\n4)HTTPSessionBindingListenner(对调用Attribute和removeAttribute的方法监听)\n  使用场景：\n  应用统计（用户登录统计）\n  任务触发\n  业务需求\n  监听器可能会有很多个，和过滤器一样，顺序由部署描述符中的部署顺序决定事件注册的顺序\neg：HTTPSessionAttributeListener，ServletContextListener，ServletRequestListener\npublic class TestListener implements HttpSessionAttributeListener, ServletContextListener, ServletRequestListener {} xml部署\n\u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;com.controller.listener.TestListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; 注：监听器和过滤器和servlet的启动顺序：   监听器\n  过滤器\n  Servlet\n  servlet 并发处理 先了解一下servlet的处理过程\n经常会出现多个客户端同事对一个servlet发起请求，\n我们的处理方式一般为：\n  串行处理，对每个客户端的请求依次处理\n  并发处理\n  客户端发送请求给服务器，服务器的servlet容器将请求转发给调度器，由调度器在工作线程池中选取一个线程，把请求交个这个线程，但不关心这个请求的servlet。多个线程可以同时指向一个servlet。但是当线程池满了过后，下一个请求就必须排队，并且排队队列可以设置上限\n  总结：单实例，多线程，线程不安全\n    问题：怎么保证servlet的线程安全\n  变量的线程安全\n  参数变量本地化(局部变量不会线程共享)\n  使用同步快synchronized(加锁处理，并且要尽量减小synchronized的范围)\n    属性的线程安全\n  ServletContext线程不安全\n  HTTPSession理论上线程安全，但是我们一般还是会做加锁处理\n  ServletRequest线程安全\n    避免在Servlet中创建线程\n  多个Servlet需要同时访问一个web应用（访问外部对象）应该做加锁处理\n  尽量避免使用实例变量，如果必须使用实例变量，就要用同步的操作（控制同步的范围）\n  synchronized(this){ //代码块  } ","permalink":"/zh-cn/posts/java/servlet2/","series":["Java"],"tags":["Java"],"title":"Servlet2"},{"categories":["Shortcode"],"content":"关于 echarts shortcode 的详细说明。\n    var options = { \"data\": [ { \"year\": \"1991\", \"value\": 3 }, { \"year\": \"1992\", \"value\": 4 }, { \"year\": \"1993\", \"value\": 3.5 }, { \"year\": \"1994\", \"value\": 5 }, { \"year\": \"1995\", \"value\": 4.9 }, { \"year\": \"1996\", \"value\": 6 }, { \"year\": \"1997\", \"value\": 7 }, { \"year\": \"1998\", \"value\": 9 }, { \"year\": \"1999\", \"value\": 13 }, ], \"xField\": \"year\", \"yField\": \"value\", }; options[\"width\"]= 100 ; options[\"height\"]= 300 ; var plot_385 = new G2Plot.Bar(\"385\",options); plot_385.render();      var options = { \"data\" : [ { \"country\": \"北美\", \"date\": 1965, \"value\": 1390.5 }, { \"country\": \"北美\", \"date\": 1966, \"value\": 1469.5 }, { \"country\": \"北美\", \"date\": 1967, \"value\": 1521.7 }, { \"country\": \"北美\", \"date\": 1968, \"value\": 1615.9 }, { \"country\": \"北美\", \"date\": 1969, \"value\": 1703.7 }, { \"country\": \"北美\", \"date\": 1970, \"value\": 1767.8 }, { \"country\": \"北美\", \"date\": 1971, \"value\": 1806.2 }, { \"country\": \"北美\", \"date\": 1972, \"value\": 1903.5 }, { \"country\": \"北美\", \"date\": 1973, \"value\": 1986.6 }, { \"country\": \"北美\", \"date\": 1974, \"value\": 1952 }, { \"country\": \"北美\", \"date\": 1975, \"value\": 1910.4 }, { \"country\": \"北美\", \"date\": 1976, \"value\": 2015.8 }, { \"country\": \"北美\", \"date\": 1977, \"value\": 2074.7 }, { \"country\": \"北美\", \"date\": 1978, \"value\": 2092.7 }, { \"country\": \"北美\", \"date\": 1979, \"value\": 2123.8 }, { \"country\": \"北美\", \"date\": 1980, \"value\": 2068.3 }, { \"country\": \"北美\", \"date\": 1981, \"value\": 2018 }, { \"country\": \"北美\", \"date\": 1982, \"value\": 1951.5 }, { \"country\": \"北美\", \"date\": 1983, \"value\": 1941.1 }, { \"country\": \"北美\", \"date\": 1984, \"value\": 2046.2 }, { \"country\": \"北美\", \"date\": 1985, \"value\": 2053.1 }, { \"country\": \"北美\", \"date\": 1986, \"value\": 2060.7 }, { \"country\": \"北美\", \"date\": 1987, \"value\": 2130.8 }, { \"country\": \"北美\", \"date\": 1988, \"value\": 2223.5 }, { \"country\": \"北美\", \"date\": 1989, \"value\": 2275.9 }, { \"country\": \"北美\", \"date\": 1990, \"value\": 2280.7 }, { \"country\": \"北美\", \"date\": 1991, \"value\": 2282 }, { \"country\": \"北美\", \"date\": 1992, \"value\": 2319.7 }, { \"country\": \"北美\", \"date\": 1993, \"value\": 2366.6 }, { \"country\": \"北美\", \"date\": 1994, \"value\": 2420.2 }, { \"country\": \"北美\", \"date\": 1995, \"value\": 2466.9 }, { \"country\": \"北美\", \"date\": 1996, \"value\": 2547.4 }, { \"country\": \"北美\", \"date\": 1997, \"value\": 2569 }, { \"country\": \"北美\", \"date\": 1998, \"value\": 2585.2 }, { \"country\": \"北美\", \"date\": 1999, \"value\": 2633.8 }, { \"country\": \"北美\", \"date\": 2000, \"value\": 2699.4 }, { \"country\": \"北美\", \"date\": 2001, \"value\": 2640.1 }, { \"country\": \"北美\", \"date\": 2002, \"value\": 2687.7 }, { \"country\": \"北美\", \"date\": 2003, \"value\": 2700.7 }, { \"country\": \"北美\", \"date\": 2004, \"value\": 2759.4 }, { \"country\": \"北美\", \"date\": 2005, \"value\": 2775.6 }, { \"country\": \"北美\", \"date\": 2006, \"value\": 2761.9 }, { \"country\": \"北美\", \"date\": 2007, \"value\": 2809.5 }, { \"country\": \"北美\", \"date\": 2008, \"value\": 2759.4 }, { \"country\": \"北美\", \"date\": 2009, \"value\": 2632.5 }, { \"country\": \"北美\", \"date\": 2010, \"value\": 2720.7 }, { \"country\": \"北美\", \"date\": 2011, \"value\": 2722.9 }, { \"country\": \"北美\", \"date\": 2012, \"value\": 2665.1 }, { \"country\": \"北美\", \"date\": 2013, \"value\": 2738.3 }, { \"country\": \"北美\", \"date\": 2014, \"value\": 2766.8 }, { \"country\": \"北美\", \"date\": 2015, \"value\": 2739.7 }, { \"country\": \"北美\", \"date\": 2016, \"value\": 2761.9 }, { \"country\": \"北美\", \"date\": 2017, \"value\": 2772.8 }, { \"country\": \"中南美\", \"date\": 1965, \"value\": 109.2 }, { \"country\": \"中南美\", \"date\": 1966, \"value\": 115.7 }, { \"country\": \"中南美\", \"date\": 1967, \"value\": 120.5 }, { \"country\": \"中南美\", \"date\": 1968, \"value\": 128 }, { \"country\": \"中南美\", \"date\": 1969, \"value\": 134.4 }, { \"country\": \"中南美\", \"date\": 1970, \"value\": 142.2 }, { \"country\": \"中南美\", \"date\": 1971, \"value\": 157.5 }, { \"country\": \"中南美\", \"date\": 1972, \"value\": 169.5 }, { \"country\": \"中南美\", \"date\": 1973, \"value\": 186.3 }, { \"country\": \"中南美\", \"date\": 1974, \"value\": 195.5 }, { \"country\": \"中南美\", \"date\": 1975, \"value\": 198 }, { \"country\": \"中南美\", \"date\": 1976, \"value\": 211.7 }, { \"country\": \"中南美\", \"date\": 1977, \"value\": 223.8 }, { \"country\": \"中南美\", \"date\": 1978, \"value\": 236.5 }, { \"country\": \"中南美\", \"date\": 1979, \"value\": 251.8 }, { \"country\": \"中南美\", \"date\": 1980, \"value\": 262.9 }, { \"country\": \"中南美\", \"date\": 1981, \"value\": 262.7 }, { \"country\": \"中南美\", \"date\": 1982, \"value\": 265.9 }, { \"country\": \"中南美\", \"date\": 1983, \"value\": 268.3 }, { \"country\": \"中南美\", \"date\": 1984, \"value\": 278.3 }, { \"country\": \"中南美\", \"date\": 1985, \"value\": 285.2 }, { \"country\": \"中南美\", \"date\": 1986, \"value\": 304.2 }, { \"country\": \"中南美\", \"date\": 1987, \"value\": 315.4 }, { \"country\": \"中南美\", \"date\": 1988, \"value\": 324.6 }, { \"country\": \"中南美\", \"date\": 1989, \"value\": 329.9 }, { \"country\": \"中南美\", \"date\": 1990, \"value\": 331.1 }, { \"country\": \"中南美\", \"date\": 1991, \"value\": 339.7 }, { \"country\": \"中南美\", \"date\": 1992, \"value\": 355.8 }, { \"country\": \"中南美\", \"date\": 1993, \"value\": 368.8 }, { \"country\": \"中南美\", \"date\": 1994, \"value\": 390.9 }, { \"country\": \"中南美\", \"date\": 1995, \"value\": 408.3 }, { \"country\": \"中南美\", \"date\": 1996, \"value\": 425.8 }, { \"country\": \"中南美\", \"date\": 1997, \"value\": 448.2 }, { \"country\": \"中南美\", \"date\": 1998, \"value\": 465.5 }, { \"country\": \"中南美\", \"date\": 1999, \"value\": 463.7 }, { \"country\": \"中南美\", \"date\": 2000, \"value\": 476.1 }, { \"country\": \"中南美\", \"date\": 2001, \"value\": 477.7 }, { \"country\": \"中南美\", \"date\": 2002, \"value\": 483.5 }, { \"country\": \"中南美\", \"date\": 2003, \"value\": 489.3 }, { \"country\": \"中南美\", \"date\": 2004, \"value\": 515.5 }, { \"country\": \"中南美\", \"date\": 2005, \"value\": 533.6 }, { \"country\": \"中南美\", \"date\": 2006, \"value\": 564 }, { \"country\": \"中南美\", \"date\": 2007, \"value\": 587 }, { \"country\": \"中南美\", \"date\": 2008, \"value\": 605.8 }, { \"country\": \"中南美\", \"date\": 2009, \"value\": 596.8 }, { \"country\": \"中南美\", \"date\": 2010, \"value\": 632.5 }, { \"country\": \"中南美\", \"date\": 2011, \"value\": 658.9 }, { \"country\": \"中南美\", \"date\": 2012, \"value\": 676.5 }, { \"country\": \"中南美\", \"date\": 2013, \"value\": 692 }, { \"country\": \"中南美\", \"date\": 2014, \"value\": 697.7 }, { \"country\": \"中南美\", \"date\": 2015, \"value\": 701.1 }, { \"country\": \"中南美\", \"date\": 2016, \"value\": 696.8 }, { \"country\": \"中南美\", \"date\": 2017, \"value\": 700.6 }, { \"country\": \"欧洲\", \"date\": 1965, \"value\": 1058.1 }, { \"country\": \"欧洲\", \"date\": 1966, \"value\": 1089.7 }, { \"country\": \"欧洲\", \"date\": 1967, \"value\": 1121.7 }, { \"country\": \"欧洲\", \"date\": 1968, \"value\": 1196.6 }, { \"country\": \"欧洲\", \"date\": 1969, \"value\": 1285.5 }, { \"country\": \"欧洲\", \"date\": 1970, \"value\": 1369 }, { \"country\": \"欧洲\", \"date\": 1971, \"value\": 1406.2 }, { \"country\": \"欧洲\", \"date\": 1972, \"value\": 1472.7 }, { \"country\": \"欧洲\", \"date\": 1973, \"value\": 1558 }, { \"country\": \"欧洲\", \"date\": 1974, \"value\": 1535.5 }, { \"country\": \"欧洲\", \"date\": 1975, \"value\": 1519.3 }, { \"country\": \"欧洲\", \"date\": 1976, \"value\": 1606.9 }, { \"country\": \"欧洲\", \"date\": 1977, \"value\": 1632.4 }, { \"country\": \"欧洲\", \"date\": 1978, \"value\": 1687.5 }, { \"country\": \"欧洲\", \"date\": 1979, \"value\": 1749.6 }, { \"country\": \"欧洲\", \"date\": 1980, \"value\": 1706.4 }, { \"country\": \"欧洲\", \"date\": 1981, \"value\": 1661.4 }, { \"country\": \"欧洲\", \"date\": 1982, \"value\": 1630.2 }, { \"country\": \"欧洲\", \"date\": 1983, \"value\": 1645.2 }, { \"country\": \"欧洲\", \"date\": 1984, \"value\": 1686.9 }, { \"country\": \"欧洲\", \"date\": 1985, \"value\": 1779.4 }, { \"country\": \"欧洲\", \"date\": 1986, \"value\": 1811.3 }, { \"country\": \"欧洲\", \"date\": 1987, \"value\": 1849.7 }, { \"country\": \"欧洲\", \"date\": 1988, \"value\": 1870 }, { \"country\": \"欧洲\", \"date\": 1989, \"value\": 1875 }, { \"country\": \"欧洲\", \"date\": 1990, \"value\": 1853.3 }, { \"country\": \"欧洲\", \"date\": 1991, \"value\": 1844.6 }, { \"country\": \"欧洲\", \"date\": 1992, \"value\": 1814.1 }, { \"country\": \"欧洲\", \"date\": 1993, \"value\": 1805.3 }, { \"country\": \"欧洲\", \"date\": 1994, \"value\": 1791.3 }, { \"country\": \"欧洲\", \"date\": 1995, \"value\": 1836.2 }, { \"country\": \"欧洲\", \"date\": 1996, \"value\": 1896.1 }, { \"country\": \"欧洲\", \"date\": 1997, \"value\": 1896.4 }, { \"country\": \"欧洲\", \"date\": 1998, \"value\": 1918.8 }, { \"country\": \"欧洲\", \"date\": 1999, \"value\": 1907.7 }, { \"country\": \"欧洲\", \"date\": 2000, \"value\": 1932.1 }, { \"country\": \"欧洲\", \"date\": 2001, \"value\": 1959.2 }, { \"country\": \"欧洲\", \"date\": 2002, \"value\": 1954.8 }, { \"country\": \"欧洲\", \"date\": 2003, \"value\": 1991.6 }, { \"country\": \"欧洲\", \"date\": 2004, \"value\": 2025.4 }, { \"country\": \"欧洲\", \"date\": 2005, \"value\": 2037.4 }, { \"country\": \"欧洲\", \"date\": 2006, \"value\": 2056.4 }, { \"country\": \"欧洲\", \"date\": 2007, \"value\": 2041.7 }, { \"country\": \"欧洲\", \"date\": 2008, \"value\": 2038.5 }, { \"country\": \"欧洲\", \"date\": 2009, \"value\": 1932.1 }, { \"country\": \"欧洲\", \"date\": 2010, \"value\": 2001.1 }, { \"country\": \"欧洲\", \"date\": 2011, \"value\": 1949.1 }, { \"country\": \"欧洲\", \"date\": 2012, \"value\": 1944.3 }, { \"country\": \"欧洲\", \"date\": 2013, \"value\": 1934 }, { \"country\": \"欧洲\", \"date\": 2014, \"value\": 1871.2 }, { \"country\": \"欧洲\", \"date\": 2015, \"value\": 1908.7 }, { \"country\": \"欧洲\", \"date\": 2016, \"value\": 1934.6 }, { \"country\": \"欧洲\", \"date\": 2017, \"value\": 1969.5 }, { \"country\": \"CIS 地区\", \"date\": 1965, \"value\": 593.3 }, { \"country\": \"CIS 地区\", \"date\": 1966, \"value\": 630.9 }, { \"country\": \"CIS 地区\", \"date\": 1967, \"value\": 663.2 }, { \"country\": \"CIS 地区\", \"date\": 1968, \"value\": 687.8 }, { \"country\": \"CIS 地区\", \"date\": 1969, \"value\": 719 }, { \"country\": \"CIS 地区\", \"date\": 1970, \"value\": 754.8 }, { \"country\": \"CIS 地区\", \"date\": 1971, \"value\": 791.9 }, { \"country\": \"CIS 地区\", \"date\": 1972, \"value\": 832.3 }, { \"country\": \"CIS 地区\", \"date\": 1973, \"value\": 875.1 }, { \"country\": \"CIS 地区\", \"date\": 1974, \"value\": 923.3 }, { \"country\": \"CIS 地区\", \"date\": 1975, \"value\": 969 }, { \"country\": \"CIS 地区\", \"date\": 1976, \"value\": 1006.5 }, { \"country\": \"CIS 地区\", \"date\": 1977, \"value\": 1051.4 }, { \"country\": \"CIS 地区\", \"date\": 1978, \"value\": 1094.2 }, { \"country\": \"CIS 地区\", \"date\": 1979, \"value\": 1127.1 }, { \"country\": \"CIS 地区\", \"date\": 1980, \"value\": 1150.1 }, { \"country\": \"CIS 地区\", \"date\": 1981, \"value\": 1174.5 }, { \"country\": \"CIS 地区\", \"date\": 1982, \"value\": 1204 }, { \"country\": \"CIS 地区\", \"date\": 1983, \"value\": 1229 }, { \"country\": \"CIS 地区\", \"date\": 1984, \"value\": 1274.6 }, { \"country\": \"CIS 地区\", \"date\": 1985, \"value\": 1257 }, { \"country\": \"CIS 地区\", \"date\": 1986, \"value\": 1282 }, { \"country\": \"CIS 地区\", \"date\": 1987, \"value\": 1318 }, { \"country\": \"CIS 地区\", \"date\": 1988, \"value\": 1341.5 }, { \"country\": \"CIS 地区\", \"date\": 1989, \"value\": 1332.5 }, { \"country\": \"CIS 地区\", \"date\": 1990, \"value\": 1350.3 }, { \"country\": \"CIS 地区\", \"date\": 1991, \"value\": 1308.9 }, { \"country\": \"CIS 地区\", \"date\": 1992, \"value\": 1233.1 }, { \"country\": \"CIS 地区\", \"date\": 1993, \"value\": 1121 }, { \"country\": \"CIS 地区\", \"date\": 1994, \"value\": 1012.2 }, { \"country\": \"CIS 地区\", \"date\": 1995, \"value\": 951.2 }, { \"country\": \"CIS 地区\", \"date\": 1996, \"value\": 920 }, { \"country\": \"CIS 地区\", \"date\": 1997, \"value\": 878.4 }, { \"country\": \"CIS 地区\", \"date\": 1998, \"value\": 871.7 }, { \"country\": \"CIS 地区\", \"date\": 1999, \"value\": 881.3 }, { \"country\": \"CIS 地区\", \"date\": 2000, \"value\": 888.5 }, { \"country\": \"CIS 地区\", \"date\": 2001, \"value\": 905.5 }, { \"country\": \"CIS 地区\", \"date\": 2002, \"value\": 904 }, { \"country\": \"CIS 地区\", \"date\": 2003, \"value\": 924.3 }, { \"country\": \"CIS 地区\", \"date\": 2004, \"value\": 938.7 }, { \"country\": \"CIS 地区\", \"date\": 2005, \"value\": 942.3 }, { \"country\": \"CIS 地区\", \"date\": 2006, \"value\": 978.6 }, { \"country\": \"CIS 地区\", \"date\": 2007, \"value\": 989.8 }, { \"country\": \"CIS 地区\", \"date\": 2008, \"value\": 998.1 }, { \"country\": \"CIS 地区\", \"date\": 2009, \"value\": 926.8 }, { \"country\": \"CIS 地区\", \"date\": 2010, \"value\": 967.8 }, { \"country\": \"CIS 地区\", \"date\": 2011, \"value\": 1006 }, { \"country\": \"CIS 地区\", \"date\": 2012, \"value\": 1014.1 }, { \"country\": \"CIS 地区\", \"date\": 2013, \"value\": 989.2 }, { \"country\": \"CIS 地区\", \"date\": 2014, \"value\": 987 }, { \"country\": \"CIS 地区\", \"date\": 2015, \"value\": 960.7 }, { \"country\": \"CIS 地区\", \"date\": 2016, \"value\": 972 }, { \"country\": \"CIS 地区\", \"date\": 2017, \"value\": 978 }, { \"country\": \"中东\", \"date\": 1965, \"value\": 48.3 }, { \"country\": \"中东\", \"date\": 1966, \"value\": 50.4 }, { \"country\": \"中东\", \"date\": 1967, \"value\": 52.7 }, { \"country\": \"中东\", \"date\": 1968, \"value\": 55.6 }, { \"country\": \"中东\", \"date\": 1969, \"value\": 58.5 }, { \"country\": \"中东\", \"date\": 1970, \"value\": 61.5 }, { \"country\": \"中东\", \"date\": 1971, \"value\": 64.9 }, { \"country\": \"中东\", \"date\": 1972, \"value\": 70.6 }, { \"country\": \"中东\", \"date\": 1973, \"value\": 77.4 }, { \"country\": \"中东\", \"date\": 1974, \"value\": 82.3 }, { \"country\": \"中东\", \"date\": 1975, \"value\": 82.1 }, { \"country\": \"中东\", \"date\": 1976, \"value\": 93 }, { \"country\": \"中东\", \"date\": 1977, \"value\": 105.7 }, { \"country\": \"中东\", \"date\": 1978, \"value\": 111 }, { \"country\": \"中东\", \"date\": 1979, \"value\": 130.5 }, { \"country\": \"中东\", \"date\": 1980, \"value\": 126.5 }, { \"country\": \"中东\", \"date\": 1981, \"value\": 137.9 }, { \"country\": \"中东\", \"date\": 1982, \"value\": 152.8 }, { \"country\": \"中东\", \"date\": 1983, \"value\": 167.1 }, { \"country\": \"中东\", \"date\": 1984, \"value\": 188.9 }, { \"country\": \"中东\", \"date\": 1985, \"value\": 200.8 }, { \"country\": \"中东\", \"date\": 1986, \"value\": 209.8 }, { \"country\": \"中东\", \"date\": 1987, \"value\": 224.5 }, { \"country\": \"中东\", \"date\": 1988, \"value\": 238.5 }, { \"country\": \"中东\", \"date\": 1989, \"value\": 251.5 }, { \"country\": \"中东\", \"date\": 1990, \"value\": 260 }, { \"country\": \"中东\", \"date\": 1991, \"value\": 271.7 }, { \"country\": \"中东\", \"date\": 1992, \"value\": 296.4 }, { \"country\": \"中东\", \"date\": 1993, \"value\": 304.7 }, { \"country\": \"中东\", \"date\": 1994, \"value\": 340.3 }, { \"country\": \"中东\", \"date\": 1995, \"value\": 352.4 }, { \"country\": \"中东\", \"date\": 1996, \"value\": 363.9 }, { \"country\": \"中东\", \"date\": 1997, \"value\": 381.3 }, { \"country\": \"中东\", \"date\": 1998, \"value\": 387.7 }, { \"country\": \"中东\", \"date\": 1999, \"value\": 395 }, { \"country\": \"中东\", \"date\": 2000, \"value\": 414.9 }, { \"country\": \"中东\", \"date\": 2001, \"value\": 435.6 }, { \"country\": \"中东\", \"date\": 2002, \"value\": 459.4 }, { \"country\": \"中东\", \"date\": 2003, \"value\": 479.3 }, { \"country\": \"中东\", \"date\": 2004, \"value\": 517.1 }, { \"country\": \"中东\", \"date\": 2005, \"value\": 553.7 }, { \"country\": \"中东\", \"date\": 2006, \"value\": 582.6 }, { \"country\": \"中东\", \"date\": 2007, \"value\": 618.2 }, { \"country\": \"中东\", \"date\": 2008, \"value\": 657.1 }, { \"country\": \"中东\", \"date\": 2009, \"value\": 677.2 }, { \"country\": \"中东\", \"date\": 2010, \"value\": 714.3 }, { \"country\": \"中东\", \"date\": 2011, \"value\": 740.9 }, { \"country\": \"中东\", \"date\": 2012, \"value\": 771.1 }, { \"country\": \"中东\", \"date\": 2013, \"value\": 795.3 }, { \"country\": \"中东\", \"date\": 2014, \"value\": 823.1 }, { \"country\": \"中东\", \"date\": 2015, \"value\": 848.3 }, { \"country\": \"中东\", \"date\": 2016, \"value\": 869.7 }, { \"country\": \"中东\", \"date\": 2017, \"value\": 897.2 }, { \"country\": \"非洲\", \"date\": 1965, \"value\": 60.6 }, { \"country\": \"非洲\", \"date\": 1966, \"value\": 63.3 }, { \"country\": \"非洲\", \"date\": 1967, \"value\": 64 }, { \"country\": \"非洲\", \"date\": 1968, \"value\": 67.4 }, { \"country\": \"非洲\", \"date\": 1969, \"value\": 68.9 }, { \"country\": \"非洲\", \"date\": 1970, \"value\": 74.7 }, { \"country\": \"非洲\", \"date\": 1971, \"value\": 81.2 }, { \"country\": \"非洲\", \"date\": 1972, \"value\": 86.3 }, { \"country\": \"非洲\", \"date\": 1973, \"value\": 92.9 }, { \"country\": \"非洲\", \"date\": 1974, \"value\": 97.6 }, { \"country\": \"非洲\", \"date\": 1975, \"value\": 103.3 }, { \"country\": \"非洲\", \"date\": 1976, \"value\": 112.4 }, { \"country\": \"非洲\", \"date\": 1977, \"value\": 118.4 }, { \"country\": \"非洲\", \"date\": 1978, \"value\": 123.1 }, { \"country\": \"非洲\", \"date\": 1979, \"value\": 134.4 }, { \"country\": \"非洲\", \"date\": 1980, \"value\": 144.8 }, { \"country\": \"非洲\", \"date\": 1981, \"value\": 161.5 }, { \"country\": \"非洲\", \"date\": 1982, \"value\": 172.7 }, { \"country\": \"非洲\", \"date\": 1983, \"value\": 177.5 }, { \"country\": \"非洲\", \"date\": 1984, \"value\": 183.7 }, { \"country\": \"非洲\", \"date\": 1985, \"value\": 190.7 }, { \"country\": \"非洲\", \"date\": 1986, \"value\": 195.1 }, { \"country\": \"非洲\", \"date\": 1987, \"value\": 201.2 }, { \"country\": \"非洲\", \"date\": 1988, \"value\": 215.7 }, { \"country\": \"非洲\", \"date\": 1989, \"value\": 216.3 }, { \"country\": \"非洲\", \"date\": 1990, \"value\": 223.3 }, { \"country\": \"非洲\", \"date\": 1991, \"value\": 223 }, { \"country\": \"非洲\", \"date\": 1992, \"value\": 226.3 }, { \"country\": \"非洲\", \"date\": 1993, \"value\": 227.2 }, { \"country\": \"非洲\", \"date\": 1994, \"value\": 233.9 }, { \"country\": \"非洲\", \"date\": 1995, \"value\": 243.4 }, { \"country\": \"非洲\", \"date\": 1996, \"value\": 250.1 }, { \"country\": \"非洲\", \"date\": 1997, \"value\": 255.1 }, { \"country\": \"非洲\", \"date\": 1998, \"value\": 259.1 }, { \"country\": \"非洲\", \"date\": 1999, \"value\": 267.2 }, { \"country\": \"非洲\", \"date\": 2000, \"value\": 273.4 }, { \"country\": \"非洲\", \"date\": 2001, \"value\": 283.8 }, { \"country\": \"非洲\", \"date\": 2002, \"value\": 287.1 }, { \"country\": \"非洲\", \"date\": 2003, \"value\": 300.6 }, { \"country\": \"非洲\", \"date\": 2004, \"value\": 323.2 }, { \"country\": \"非洲\", \"date\": 2005, \"value\": 326.5 }, { \"country\": \"非洲\", \"date\": 2006, \"value\": 332.8 }, { \"country\": \"非洲\", \"date\": 2007, \"value\": 346.9 }, { \"country\": \"非洲\", \"date\": 2008, \"value\": 368.7 }, { \"country\": \"非洲\", \"date\": 2009, \"value\": 373.4 }, { \"country\": \"非洲\", \"date\": 2010, \"value\": 386.9 }, { \"country\": \"非洲\", \"date\": 2011, \"value\": 385.6 }, { \"country\": \"非洲\", \"date\": 2012, \"value\": 399.8 }, { \"country\": \"非洲\", \"date\": 2013, \"value\": 410.6 }, { \"country\": \"非洲\", \"date\": 2014, \"value\": 425.1 }, { \"country\": \"非洲\", \"date\": 2015, \"value\": 429.4 }, { \"country\": \"非洲\", \"date\": 2016, \"value\": 438 }, { \"country\": \"非洲\", \"date\": 2017, \"value\": 449.5 }, { \"country\": \"亚太地区\", \"date\": 1965, \"value\": 441.6 }, { \"country\": \"亚太地区\", \"date\": 1966, \"value\": 482.9 }, { \"country\": \"亚太地区\", \"date\": 1967, \"value\": 506.1 }, { \"country\": \"亚太地区\", \"date\": 1968, \"value\": 544.1 }, { \"country\": \"亚太地区\", \"date\": 1969, \"value\": 619.8 }, { \"country\": \"亚太地区\", \"date\": 1970, \"value\": 704.9 }, { \"country\": \"亚太地区\", \"date\": 1971, \"value\": 771.4 }, { \"country\": \"亚太地区\", \"date\": 1972, \"value\": 817.9 }, { \"country\": \"亚太地区\", \"date\": 1973, \"value\": 885.1 }, { \"country\": \"亚太地区\", \"date\": 1974, \"value\": 902.2 }, { \"country\": \"亚太地区\", \"date\": 1975, \"value\": 936.1 }, { \"country\": \"亚太地区\", \"date\": 1976, \"value\": 983.2 }, { \"country\": \"亚太地区\", \"date\": 1977, \"value\": 1037.3 }, { \"country\": \"亚太地区\", \"date\": 1978, \"value\": 1106.2 }, { \"country\": \"亚太地区\", \"date\": 1979, \"value\": 1157.6 }, { \"country\": \"亚太地区\", \"date\": 1980, \"value\": 1168 }, { \"country\": \"亚太地区\", \"date\": 1981, \"value\": 1175 }, { \"country\": \"亚太地区\", \"date\": 1982, \"value\": 1186.8 }, { \"country\": \"亚太地区\", \"date\": 1983, \"value\": 1240.7 }, { \"country\": \"亚太地区\", \"date\": 1984, \"value\": 1326.7 }, { \"country\": \"亚太地区\", \"date\": 1985, \"value\": 1395.9 }, { \"country\": \"亚太地区\", \"date\": 1986, \"value\": 1456.5 }, { \"country\": \"亚太地区\", \"date\": 1987, \"value\": 1538 }, { \"country\": \"亚太地区\", \"date\": 1988, \"value\": 1650.5 }, { \"country\": \"亚太地区\", \"date\": 1989, \"value\": 1740.4 }, { \"country\": \"亚太地区\", \"date\": 1990, \"value\": 1812.8 }, { \"country\": \"亚太地区\", \"date\": 1991, \"value\": 1896.9 }, { \"country\": \"亚太地区\", \"date\": 1992, \"value\": 1984.5 }, { \"country\": \"亚太地区\", \"date\": 1993, \"value\": 2088.9 }, { \"country\": \"亚太地区\", \"date\": 1994, \"value\": 2204.3 }, { \"country\": \"亚太地区\", \"date\": 1995, \"value\": 2306.8 }, { \"country\": \"亚太地区\", \"date\": 1996, \"value\": 2413.2 }, { \"country\": \"亚太地区\", \"date\": 1997, \"value\": 2487 }, { \"country\": \"亚太地区\", \"date\": 1998, \"value\": 2481 }, { \"country\": \"亚太地区\", \"date\": 1999, \"value\": 2577.9 }, { \"country\": \"亚太地区\", \"date\": 2000, \"value\": 2671.9 }, { \"country\": \"亚太地区\", \"date\": 2001, \"value\": 2759.7 }, { \"country\": \"亚太地区\", \"date\": 2002, \"value\": 2901.2 }, { \"country\": \"亚太地区\", \"date\": 2003, \"value\": 3145.5 }, { \"country\": \"亚太地区\", \"date\": 2004, \"value\": 3445.8 }, { \"country\": \"亚太地区\", \"date\": 2005, \"value\": 3724.3 }, { \"country\": \"亚太地区\", \"date\": 2006, \"value\": 3944 }, { \"country\": \"亚太地区\", \"date\": 2007, \"value\": 4195.2 }, { \"country\": \"亚太地区\", \"date\": 2008, \"value\": 4310.8 }, { \"country\": \"亚太地区\", \"date\": 2009, \"value\": 4411.1 }, { \"country\": \"亚太地区\", \"date\": 2010, \"value\": 4696.1 }, { \"country\": \"亚太地区\", \"date\": 2011, \"value\": 4951.1 }, { \"country\": \"亚太地区\", \"date\": 2012, \"value\": 5118.2 }, { \"country\": \"亚太地区\", \"date\": 2013, \"value\": 5269.9 }, { \"country\": \"亚太地区\", \"date\": 2014, \"value\": 5382.9 }, { \"country\": \"亚太地区\", \"date\": 2015, \"value\": 5472.4 }, { \"country\": \"亚太地区\", \"date\": 2016, \"value\": 5585.5 }, { \"country\": \"亚太地区\", \"date\": 2017, \"value\": 5743.6 } ], \"appendPadding\": 32, \"xField\": \"date\", \"yField\": \"value\", \"seriesField\": 'country', \"legend\": { \"position\": \"top\" } }; options[\"width\"]= 100 ; options[\"height\"]= 300 ; var plot_833 = new G2Plot.Area(\"833\",options); plot_833.render();      var options = { \"appendPadding\": 32, \"data\": [ { \"year\": '1991', \"value\": 3 }, { \"year\": '1992', \"value\": 4 }, { \"year\": '1993', \"value\": 3.5 }, { \"year\": '1994', \"value\": 5 }, { \"year\": '1995', \"value\": 4.9 }, { \"year\": '1996', \"value\": 6 }, { \"year\": '1997', \"value\": 7 }, { \"year\": '1998', \"value\": 9 }, { \"year\": '1999', \"value\": 13 }, ], \"xField\": \"year\", \"yField\": \"value\", \"label\": {}, \"smooth\": true, \"lineStyle\": { \"lineWidth\": 3, }, \"point\": { \"size\": 5, \"shape\": 'diamond', \"style\": { \"fill\": \"white\", \"stroke\": \"#5B8FF9\", \"lineWidth\": 2, } } }; options[\"width\"]=\"100\"; options[\"height\"]= 300 ; var plot_504 = new G2Plot.Line(\"504\",options); plot_504.render(); ","permalink":"/zh-cn/posts/shortcodes/g2plot_charts_test/","series":null,"tags":["Test"],"title":"TestShortcode"},{"categories":["tools"],"content":"typora画流程图介绍  标准流程图源码格式： st=\u0026gt;start: 开始框\rop=\u0026gt;operation: 处理框\rcond=\u0026gt;condition: 判断框\rsub1=\u0026gt;subroutine: 子流程\rio=\u0026gt;inputoutput: 输入输出框\re=\u0026gt;end: 结束框\rst-\u0026gt;op-\u0026gt;cond\rcond(yes)-\u0026gt;io-\u0026gt;e\rcond(no)-\u0026gt;sub1(right)-\u0026gt;op\r标准流程图源码格式（横向）： st=\u0026gt;start: 开始框\rop=\u0026gt;operation: 处理框\rcond=\u0026gt;condition: 判断框(是或否?)\rsub1=\u0026gt;subroutine: 子流程\rio=\u0026gt;inputoutput: 输入输出框\re=\u0026gt;end: 结束框\rst(right)-\u0026gt;op(right)-\u0026gt;cond\rcond(yes)-\u0026gt;io(bottom)-\u0026gt;e\rcond(no)-\u0026gt;sub1(right)-\u0026gt;op\r流程圖 graph TD\rA[方形] --\u0026gt;B(圆角)\rB --\u0026gt; C{条件a}\rC --\u0026gt;|a=1| D[结果1]\rC --\u0026gt;|a=2| E[结果2]\rF[竖向流程图]\rgraph LR\rA[方形] --\u0026gt;B(圆角)\rB --\u0026gt; C{条件a}\rC --\u0026gt;|a=1| D[结果1]\rC --\u0026gt;|a=2| E[结果2]\rF[横向流程图]\rUML时序图源码样例： 对象A-\u0026gt;对象B: 对象B你好吗?（请求）\rNote right of 对象B: 对象B的描述\rNote left of 对象A: 对象A的描述(提示)\r对象B--\u0026gt;对象A: 我很好(响应)\r对象A-\u0026gt;对象B: 你真的好吗？\rUML时序图源码复杂样例： Title: 标题：复杂使用\r对象A-\u0026gt;对象B: 对象B你好吗?（请求）\rNote right of 对象B: 对象B的描述\rNote left of 对象A: 对象A的描述(提示)\r对象B--\u0026gt;对象A: 我很好(响应)\r对象B-\u0026gt;小三: 你好吗\r小三--\u0026gt;\u0026gt;对象A: 对象B找我了\r对象A-\u0026gt;对象B: 你真的好吗？\rNote over 小三,对象B: 我们是朋友\rparticipant C\rNote right of C: 没人陪我玩\rUML标准时序图样例： %% 时序图例子,-\u0026gt; 直线，--\u0026gt;虚线，-\u0026gt;\u0026gt;实线箭头\rsequenceDiagram\rparticipant 张三\rparticipant 李四\r张三-\u0026gt;王五: 王五你好吗？\rloop 健康检查\r王五-\u0026gt;王五: 与疾病战斗\rend\rNote right of 王五: 合理 食物 \u0026lt;br/\u0026gt;看医生...\r李四--\u0026gt;\u0026gt;张三: 很好!\r王五-\u0026gt;李四: 你怎么样?\r李四--\u0026gt;王五: 很好!\r甘特图样例： %% 语法示例\rgantt\rdateFormat YYYY-MM-DD\rtitle 软件开发甘特图\rsection 设计\r需求 :done, des1, 2014-01-06,2014-01-08\r原型 :active, des2, 2014-01-09, 3d\rUI设计 : des3, after des2, 5d\r未来任务 : des4, after des3, 5d\rsection 开发\r学习准备理解需求 :crit, done, 2014-01-06,24h\r设计框架 :crit, done, after des2, 2d\r开发 :crit, active, 3d\r未来任务 :crit, 5d\r耍 :2d\rsection 测试\r功能测试 :active, a1, after des3, 3d\r压力测试 :after a1 , 20h\r测试报告 : 48h\r","permalink":"/zh-cn/posts/tools/typora%E7%94%BB%E5%9B%BE/","series":[],"tags":["typora"],"title":"Typora画图"},{"categories":["WebSocket"],"content":"WebSocket 一、概念 1.WebSocket 是HTTP协议的补充。使用的TCP协议建立连接\n2.HTML5是指一系列新API，新协议，WebSocket也是其中之一\n二、优点 1.WebSocket是持久化协议，每次通信只需要一次连接\n2.HTTP中一个request只能有一个response\n3.连接过程：进行握手时，使用http协议对服务器发起连接请求，并且升级为websocket协议，确定后服务器建立连接，并且继续使用Websocket\n三、作用 1.实现实时信息传递的其他方式\n​\t(1).ajax轮询：让浏览器隔个几秒就发送一次请求，询问服务器是否有新信息\n​\t(2).HTTP long poll：客户端发起连接后，如果没消息，就一直不返回Response给客户端。直到有消息才返回，返回完之后，客户端再次建立连接，周而复始。\n​\t(3).缺点：\n​\tajax轮询：需要服务器有很快的处理速度和资源。（速度）\n​\tlong poll：需要有很高的并发，也就是说同时接待客户的能力。（资源大小）\n2.服务器完成协议升级后（HTTP-\u0026gt;Websocket），服务端就可以主动推送信息给客户端啦\n3.整个通讯过程是建立在一次连接/状态中，避免了HTTP的非状态性，服务端会一直知道你的信息，直到你关闭请求\n四、特点 1.建立在 TCP 协议之上，服务器端的实现比较容易。\n2.与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。\n3.数据格式比较轻量，性能开销小，通信高效。\n4.可以发送文本，也可以发送二进制数据。\n5.没有同源限制，客户端可以与任意服务器通信。\n6.协议标识符是ws（如果加密，则为wss），服务器网址就是 URL。\n五、客户端 1.创建WebSocket对象： var Socket = new WebSocket(url,[protocol])\nurl = 服务器地址，protocol是可接受的子协议\n2.属性： (1)Socket.readyState//表示连接状态：0：尚未连接，1：已经连接，2：连接正在关闭，3：连接已经关闭，或不能打开。\n(2)Socket.buffererdAmount//表示send()放在队列正在队列中等待传输\n3.事件： | 对象触发的程序 | 描述 |\n| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| Socket.onopen | 连接建立时触发 |\n| Socket.onmessage | 客户端接受服务端数据时触发 |\n| Socket.onerror | 通信错误时触发 |\n| Socket.onclose | 连接关闭时触发 |\n4.方法： | 方法 | 描述 |\n| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| Socket.send() | 使用连接程序发送数据 |\n| Socket.close() | 关闭连接 |\n5.实例： 客户端前端： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; onclick=\u0026#34;online()\u0026#34; value=\u0026#34;连接！\u0026#34; /\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; //初始化一个WebSocket对象  var ws = new WebSocket(\u0026#34;wss://echo.websocket.org\u0026#34;); //建立WebSocket连接成功触发事件  ws.onopen = function online() { //js的事件写法  alert(\u0026#34;我是一个消息框！\u0026#34;) ws.send(\u0026#34;Hello WebSockets!\u0026#34;);//使用send发送数据  }; //接受服务端数据时触发的数据  ws.onmessage = function(evt) { var received_msg = evt.data; alert(\u0026#34;数据已接收...\u0026#34;); ws.close(); }; //断开WebSocket时触发的数据  ws.onclose = function(evt) { alert(\u0026#34;数据已接收...\u0026#34;); }; \u0026lt;/script\u0026gt; \u0026lt;/html\u0026gt; 六、服务器端 Node.js var ws = require(\u0026#39;nodejs-websocket\u0026#39;); console.log(\u0026#39;开始建立连接...\u0026#39;) ws.createServer(function (conn) { conn.on(\u0026#39;text\u0026#39;, function (str) { console.log(\u0026#39;收到的信息为:\u0026#39; + str) conn.sendText(str) }) conn.on(\u0026#39;close\u0026#39;, function (code, reason) { console.log(\u0026#39;关闭连接\u0026#39;, code, reason) }); conn.on(\u0026#39;error\u0026#39;, function (code, reason) { console.log(\u0026#39;异常关闭\u0026#39;, code, reason) }); }).listen(8888) console.log(\u0026#39;WebSocket建立完毕\u0026#39;); java 1.Spring\npublic interface WebSocketHandler { /** * 建立连接后触发的回调 */ void afterConnectionEstablished(WebSocketSession session) throws Exception; /** * 收到消息时触发的回调 */ void handleMessage(WebSocketSession session, WebSocketMessage\u0026lt;?\u0026gt; message) throws Exception; /** * 传输消息出错时触发的回调 */ void handleTransportError(WebSocketSession session, Throwable exception) throws Exception; /** * 断开连接后触发的回调 */ void afterConnectionClosed(WebSocketSession session, CloseStatus closeStatus) throws Exception; /** * 是否处理分片消息 */ boolean supportsPartialMessages(); } 2.javax.websocket\n// 收到消息触发事件  @OnMessage public void onMessage(String message, Session session) throws IOException, InterruptedException { ... } // 打开连接触发事件  @OnOpen public void onOpen(Session session, EndpointConfig config, @PathParam(\u0026#34;id\u0026#34;) String id) { ... } // 关闭连接触发事件  @OnClose public void onClose(Session session, CloseReason closeReason) { ... } // 传输消息错误触发事件  @OnError public void onError(Throwable error) { ... } 七、完整实例（环境：tomcat8，idea） 服务器端： /** * netstat -aon | findstr 1099 * taskkill -f -pid PID */ package servlet; import javax.websocket.*; import javax.websocket.server.ServerEndpoint; import java.io.IOException; import java.util.concurrent.CopyOnWriteArraySet; //指明websocket名字  @ServerEndpoint(\u0026#34;/chat\u0026#34;) public class WS { //通过SESSION发送数据  private Session session; //静态变量，用来记录当前在线连接数。应该把它设计成线程安全的。  private static int onlineCount = 0; //concurrent包的线程安全Set，用来存放每个客户端对应的MyWebSocket对象。若要实现服务端与单一客户端通信的话，可以使用Map来存放，其中Key可以为用户标识  private static CopyOnWriteArraySet\u0026lt;WS\u0026gt; webSocketSet = new CopyOnWriteArraySet\u0026lt;WS\u0026gt;(); /* * 连接建立成功调用的方法 * @param session */ @OnOpen public void onOpen(Session session){ this.session = session; webSocketSet.add(this); //加入set中  } /** * 收到客户端消息后调用的方法 * @param message 客户端发送过来的消息 * @param session 可选的参数 */ @OnMessage public void onMessage(String message, Session session) throws IOException { System.out.println(\u0026#34;来自客户端的消息:\u0026#34; + message); //群发消息  for(WS item: webSocketSet){ try { item.sendMessage(message); } catch (IOException e) { e.printStackTrace(); continue; } } } /** * 连接关闭调用的方法 */ @OnClose public void onClose(){ webSocketSet.remove(this); //从set中删除  } /** * 发生错误时调用 * @param session * @param error */ @OnError public void onError(Session session, Throwable error){ System.out.println(\u0026#34;发生错误\u0026#34;); error.printStackTrace(); } /* 这个方法与上面几个方法不一样。没有用注解，是根据自己需要添加的方法。 * @param message * @throws IOException */ public void sendMessage(String message) throws IOException { this.session.getAsyncRemote().sendText(message); } } 浏览器端： \u0026lt;%-- Created by IntelliJ IDEA. User: Euraxluo Date: 2018/7/30 Time: 14:19 To change this template use File | Settings | File Templates. --%\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;%@ page contentType=\u0026#34;text/html;charset=UTF-8\u0026#34; language=\u0026#34;java\u0026#34; %\u0026gt; \u0026lt;html doctype=\u0026#34;html\u0026#34;\u0026gt;\u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;content-type\u0026#34; content=\u0026#34;text/html; charset=UTF-8\u0026#34;\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;chat\u0026lt;/title\u0026gt; \u0026lt;!-- 输入框--\u0026gt; \u0026lt;link href=\u0026#34;css/vendor/bootstrap/bootstrap.min.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;js/vendor/summernote/summernote.css\u0026#34;\u0026gt; \u0026lt;style\u0026gt; * { padding: 0; margin: 0; } body{ height: 100%; border:2px solid; border-radius:5px; background-image: url(\u0026#39;images/bkg.jpg\u0026#39;); scrollbar-face-color: #22beef; } ::-webkit-scrollbar-button{ background-color: #1ccdaa; } ::-webkit-scrollbar-track{ background-color: #1296db; } ::-webkit-scrollbar-thumb{ background-color: #22beef; } \u0026lt;!----\u0026gt; .welcome { color:#fff; margin-left: -1px; background-color: #2cc1f0; border-color: #4cae4c; width: 100%; height: 70%; border-radius:10px; font-size: 30px; } header{ border:2px solid #2a6496; border-radius:8px; height:80px; width: 100%; position: relative; overflow-y: auto; margin-top: 2%; padding: 5px; } \u0026lt;!----\u0026gt; .hist{ margin-bottom: 2px; margin-left: 1px; width: 100%; overflow-y: scroll; background-image: url(\u0026#34;images/bgk2.jpg\u0026#34;); } .hist span{ background-color: #11b4e7; } .hist li{ list-style:none; margin-left: 2px; margin-top: 5px; padding: 0px; float:bottom; padding-left: 5px; padding-right: 3px; display: table; overflow: auto; min-width: 100px; max-width: 100vw; word-break: break-all; word-wrap: break-word; min-height: 100px; border:2px solid #2a6496; border-radius: 5px; background-image: url(\u0026#39;images/bgk0.jpg\u0026#39;); } .but{ height: 30px; line-height: 35px; position: fixed; bottom: 180px; width: 100%; text-align: center; color: #fff; font-size: 14px; letter-spacing: 1px; background-color: #96e6f1; } .left{ text-align: center; vertical-align: middle; cursor: pointer; white-space: nowrap; color: #fff; background-color: #5cb85c; border-color: #4cae4c; padding: 6px 12px; font-size: 14px; line-height: 1.5; border-radius: 4px; height: 30px; float: left; display: inline-block; font-weight: 400; } .right{ text-align: center; vertical-align: middle; cursor: pointer; white-space: nowrap; color: #fff; background-color: #5cb85c; border-color: #4cae4c; float: right; display: inline-block; font-weight: 400; padding: 6px 12px; font-size: 14px; line-height: 1.5; border-radius: 4px; height: 30px; } .foot{ height: 180px; line-height: 35px; position: fixed; bottom: 0; width: 100%; color: #fff; font-size: 14px; letter-spacing: 1px; background-image: url(\u0026#39;images/bgk3.gif\u0026#39;); } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;header id=\u0026#34;top\u0026#34;\u0026gt; \u0026lt;button class=\u0026#34;welcome\u0026#34; onclick=\u0026#34;printme()\u0026#34;\u0026gt;\u0026lt;strong\u0026gt;Welcome\u0026lt;/strong\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;!--状态栏--\u0026gt; \u0026lt;strong style=\u0026#34;float: left\u0026#34;\u0026gt;状态：\u0026lt;/strong\u0026gt; \u0026lt;strong id=\u0026#34;message\u0026#34; \u0026gt;\u0026lt;/strong\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;div style=\u0026#34;clear: both\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;historyMsg\u0026#34; class=\u0026#34;hist\u0026#34; \u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;but\u0026#34;\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;right\u0026#34; onclick=\u0026#34;send()\u0026#34;\u0026gt;\u0026lt;strong\u0026gt;Send\u0026lt;/strong\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;left\u0026#34; onclick=\u0026#34;closeWebSocket()\u0026#34;\u0026gt;\u0026lt;strong\u0026gt;Close\u0026lt;/strong\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;foot\u0026#34;\u0026gt; \u0026lt;!--summernote--\u0026gt; \u0026lt;div id=\u0026#34;summernote\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;js/jquery.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;js/vendor/bootstrap/bootstrap.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/vendor/mmenu/js/jquery.mmenu.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/vendor/sparkline/jquery.sparkline.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/vendor/nicescroll/jquery.nicescroll.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;js/vendor/tabdrop/bootstrap-tabdrop.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;js/vendor/summernote/summernote.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;js/minimal.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; window.onload = windowHeight; //页面载入完毕执行函数  function windowHeight() { var h = document.documentElement.clientHeight; //获取当前窗口可视操作区域高度  var history = document.getElementById(\u0026#34;historyMsg\u0026#34;); history.style.height = (h-294-30) + \u0026#34;px\u0026#34;; //你想要自适应高度的对象  } setInterval(windowHeight, 100)//每100微秒执行一次windowHeight函数  //精简版  $(document).ready(function () { $(\u0026#39;#summernote\u0026#39;).summernote({ height: 180, focus:true, toolbar: [ [\u0026#39;style\u0026#39;, [\u0026#39;bold\u0026#39;, \u0026#39;italic\u0026#39;, \u0026#39;underline\u0026#39;, \u0026#39;clear\u0026#39;]], [\u0026#39;fontsize\u0026#39;, [\u0026#39;fontsize\u0026#39;]], [\u0026#39;color\u0026#39;, [\u0026#39;color\u0026#39;]], [\u0026#39;para\u0026#39;, [\u0026#39;ul\u0026#39;, \u0026#39;ol\u0026#39;, \u0026#39;paragraph\u0026#39;]], [\u0026#39;height\u0026#39;, [\u0026#39;height\u0026#39;]], ]/*, callbacks: { onImageUpload: function (files) { //the onImageUpload API send(sendFile(files[0])); } }*/ }); }); /* function sendFile(file) { var data = new FormData(); data.append(\u0026#34;file\u0026#34;, file); alert(data); console.log(data); $.ajax({ data: data, type: \u0026#34;POST\u0026#34;, url: \u0026#34;/upload/uploadPic.html\u0026#34;, cache: false, contentType: false, processData: false, //dataType: \u0026#34;json\u0026#34;, success: function (url) {//data是返回的hash,key之类的值，key是定义的文件名 alert(url); $(\u0026#39;#summernote\u0026#39;).summernote(\u0026#39;insertImage\u0026#39;,url,\u0026#39;image name\u0026#39;); }, error:function () { alert(\u0026#34;上传失败\u0026#34;); }, }); } */ //构建通道  var websocket = new WebSocket(\u0026#34;ws://localhost:8080/chat\u0026#34;); //连接成功建立的回调方法  websocket.onopen = function(evt){ loginMessage(\u0026#34;open\u0026#34;); }; var name=\u0026#34;root\u0026#34;; //连接发生错误的回调方法  websocket.onerror = function(evt){ loginMessage(\u0026#34;error\u0026#34;); }; //接收到消息的回调方法  websocket.onmessage = function(evt){ setMessageInnerHTML(\u0026#34;\u0026lt;li\u0026gt;\u0026lt;sanp\u0026gt;\u0026lt;strong\u0026gt;\u0026#34;+name+\u0026#34;:\u0026lt;/strong\u0026gt;\u0026lt;br\u0026gt;\u0026#34;+evt.data+\u0026#34;\u0026lt;/sanp\u0026gt;\u0026lt;/li\u0026gt;\u0026#34;); }; //连接关闭的回调方法  websocket.onclose = function(evt){ loginMessage(\u0026#34;close\u0026#34;); }; //监听窗口关闭事件，当窗口关闭时，主动去关闭websocket连接，防止连接还没断开就关闭窗口，server端会抛异常。  window.onbeforeunload = function(evt){ websocket.close(); }; //将消息显示在网页上  function loginMessage(innerHTML){ document.getElementById(\u0026#39;message\u0026#39;).innerHTML = innerHTML; } //将消息显示在网页上  function setMessageInnerHTML(innerHTML){ document.getElementById(\u0026#39;historyMsg\u0026#39;).innerHTML += innerHTML; } //将消息显示在网页上  function setMessagehistory(innerHTML){ document.getElementById(\u0026#39;historyMsg\u0026#39;).innerHTML += innerHTML;s } //关闭连接  function closeWebSocket(evt){ websocket.close(); } //发送消息  function send(evt){ var message = $(\u0026#34;#summernote\u0026#34;).summernote(\u0026#39;code\u0026#39;); $(\u0026#34;#summernote\u0026#34;).summernote(\u0026#39;code\u0026#39;,\u0026#39;\u0026#39;); var regexstr =new RegExp(\u0026#39;\u0026lt;(?!img|br/|p|/p).*?\u0026gt;\u0026#39;); //去除标签  var str=message.replace(regexstr,\u0026#34;\u0026#34;); websocket.send(str); } //发送给自己  function printme(evt){ alert(\u0026#34;Welocom to chat_room!\u0026#34;); } \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","permalink":"/zh-cn/posts/java/websocket/","series":["WebSocket"],"tags":["Java","WebSocket"],"title":"WebSocket"},{"categories":["java"],"content":"Xml Xml  eXtendsible markup language 可扩展的标记语言\n XML 有什么用?   可以用来保存数据\n  可以用来做配置文件\n  数据传输载体\n  定义xml  其实就是一个文件，文件的后缀为 .xml\n 文档声明   简单声明， version : 解析这个xml的时候，使用什么版本的解析器解析\n `\u0026lt;?xml version=\u0026quot;1.0\u0026quot; ?\u0026gt;`\r   encoding : 解析xml中的文字的时候，使用什么编码来翻译\n `\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;gbk\u0026quot; ?\u0026gt;`\r   standalone : no - 该文档会依赖关联其他文档 ， yes\u0026ndash; 这是一个独立的文档\n `\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;gbk\u0026quot; standalone=\u0026quot;no\u0026quot; ?\u0026gt;`\r   encoding详解 在解析这个xml的时候，使用什么编码去解析。 ---解码。  文本存储时不直接存储文字， 而是存储这些文字对应的二进制 。 那么这些文字对应的二进制到底是多少呢？ 根据文件使用的编码 来得到。\n 默认文件保存的时候，使用的是GBK的编码保存。\n 所以要想让我们的xml能够正常的显示中文,解决方法:\n  让encoding也是GBK 或者 gb2312 .\n  如果encoding是 utf-8 ， 那么保存文件的时候也必须使用utf-8\n  保存的时候见到的ANSI 对应的其实是我们的本地编码 GBK。\n  为了通用，建议使用UTF-8编码保存，以及encoding 都是 utf-8\n元素定义（标签）  其实就是里面的标签， \u0026lt;\u0026gt; 括起来的都叫元素 。 成对出现。 如下：  \u0026lt;stu\u0026gt; \u0026lt;/stu\u0026gt;\n 文档声明下来的第一个元素叫做根元素 (根标签)\n  标签里面可以嵌套标签\n  空标签:既是开始也是结束。 一般配合属性来用。\n  \u0026lt;age/\u0026gt;\neg:\n\u0026lt;stu\u0026gt; \u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt; \u0026lt;age/\u0026gt; \u0026lt;/stu\u0026gt; 标签可以自定义。  XML 元素必须遵循以下命名规则：\n​\t1. 名称可以含字母、数字以及其他的字符\n​\t2. 名称不能以数字或者标点符号开始\n​\t3. 名称不能以字符 “xml”（或者 XML、Xml）开始\n​\t4. 名称不能包含空格\n​\t5. 命名尽量简单，做到见名知义\n简单元素 \u0026amp; 复杂元素  简单元素   元素里面包含了普通的文字\n  复杂元素   元素里面还可以嵌套其他的元素\n 属性的定义  定义在元素里面， \u0026lt;元素名称 属性名称=\u0026ldquo;属性的值\u0026rdquo;\u0026gt;\u0026lt;/元素名称\u0026gt;\n \u0026lt;stus\u0026gt;\r\u0026lt;stu id=\u0026quot;10086\u0026quot;\u0026gt;\r\u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt;\r\u0026lt;age\u0026gt;18\u0026lt;/age\u0026gt;\r\u0026lt;/stu\u0026gt;\r\u0026lt;stu id=\u0026quot;10087\u0026quot;\u0026gt;\r\u0026lt;name\u0026gt;李四\u0026lt;/name\u0026gt;\r\u0026lt;age\u0026gt;28\u0026lt;/age\u0026gt;\r\u0026lt;/stu\u0026gt;\r\u0026lt;/stus\u0026gt;\rxml注释：  与html的注释一样。\n ｀｀\n如：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- //这里有两个学生 //一个学生，名字叫张三， 年龄18岁， 学号：10086 //另外一个学生叫李四 。。。 --\u0026gt;  xml的注释，不允许放置在文档的第一行。 必须在文档声明的下面。\n CDATA区 ####　非法字符\n严格地讲，在 XML 中仅有字符 \u0026ldquo;\u0026lt;\u0026ldquo;和\u0026rdquo;\u0026amp;\u0026rdquo; 是非法的。省略号、引号和大于号是合法的，但是把它们替换为实体引用是个好的习惯。\n\u0026lt; \u0026amp;lt; \u0026amp; \u0026amp;amp; \u0026#34; \u0026amp;quot; 如果某段字符串里面有过多的字符， 并且里面包含了类似标签或者关键字的这种文字，不想让xml的解析器去解析。 那么可以使用CDATA来包装。 不过这个CDATA 一般比较少看到。 通常在服务器给客户端返回数据的时候。\n\u0026lt;des\u0026gt;\u0026lt;![CDATA[\u0026lt;a href=\u0026quot;http://www.baidu.com\u0026quot;\u0026gt;我爱黑马训练营\u0026lt;/a\u0026gt;]]\u0026gt;\u0026lt;/des\u0026gt;\nXML 解析  其实就是获取元素里面的字符数据或者属性数据。\n XML解析方式(面试常问)  有很多种，但是常用的有两种。\n   DOM:把所有的文件全部读取到内存中,形成树状结构.整个文档称为document对象.,属性对应Attribute对象,所有的元素节点对应Element对象,文本也可以称为Text对象 ,以上所有对象都可以称为Node节点,如果xml特别大,就会造成内存溢出.优点:可以对文档进行增删操作\n  SAX:Simple API for XML 基于事件驱动,读取一行,解析一行,不会造成内存泄漏,不可以增删,只能查询\n  针对这两种解析方式的API  一些组织或者公司， 针对以上两种解析方式， 给出的解决方案有哪些？\n     jaxp sun公司。 比较繁琐    jdom\n  dom4j 使用比较广泛,对SAX进行了增强,也可以完成增删操作\n  Dom4j 基本用法 element.element(\u0026#34;stu\u0026#34;) ;// 返回该元素下的第一个stu元素 element.elements();// 返回该元素下的所有子元素。   创建SaxReader对象\nSAXReader reader= newSAXReader();\n  指定解析的xml\nDocument document = reader.read(path|file|inputStream);\n  获取根元素。\nElemennt rootElement = document.getRootElement();\n  根据根元素获取子元素或者下面的子孙元素\nrootElement.element(\u0026quot;age\u0026quot;) \nrootElement.element(\u0026quot;stu\u0026quot;).element(\u0026quot;age\u0026quot;).getText();\n  try { //1. 创建sax读取对象 SAXReader reader = new SAXReader(); //jdbc -- classloader //2. 指定解析的xml源 Document document = reader.read(new File(\u0026#34;src/xml/stus.xml\u0026#34;)); //3. 得到元素、 //得到根元素 Element rootElement= document.getRootElement(); //获取根元素下面的子元素 age //rootElement.element(\u0026#34;age\u0026#34;) //System.out.println(rootElement.element(\u0026#34;stu\u0026#34;).element(\u0026#34;age\u0026#34;).getText()); //获取根元素下面的所有子元素 。 stu元素 List\u0026lt;Element\u0026gt; elements = rootElement.elements(); //遍历所有的stu元素 for (Element element : elements) { //获取stu元素下面的name元素 String name = element.element(\u0026#34;name\u0026#34;).getText(); String age = element.element(\u0026#34;age\u0026#34;).getText(); String address = element.element(\u0026#34;address\u0026#34;).getText(); System.out.println(\u0026#34;name=\u0026#34;+name+\u0026#34;==age+\u0026#34;+age+\u0026#34;==address=\u0026#34;+address); } } catch (Exception e) { e.printStackTrace(); } SaxReader 创建好对象 。\nDocumentElement\n  看文档\n  记住关键字 。\n  有对象先点一下。\n  看一下方法的返回值。\n  根据平时的积累。 getXXX setXXX\n  Dom4j 的 Xpath使用  dom4j里面支持Xpath的写法。 xpath其实是xml的路径语言，支持我们在解析xml的时候，能够快速的定位到具体的某一个元素。在爬虫中经常使用.\n   添加jar包依赖\njaxen-1.1-beta-6.jar\n  在查找指定节点的时候，根据XPath语法规则来查找\n  //要想使用Xpath， 还得添加支持的jar 获取的是第一个 只返回一个。 Element nameElement = (Element) rootElement.selectSingleNode(\u0026#34;//name\u0026#34;);//双斜杠不能少 //获取文档里面的所有name元素 List\u0026lt;Element\u0026gt; list = rootElement.selectNodes(\u0026#34;//name\u0026#34;); for (Element element : list) { System.out.println(element.getText()); } XML 约束 如下的文档， 属性的ID值是一样的。 这在生活中是不可能出现的。 并且第二个学生的姓名有好几个。 一般也很少。那么怎么规定ID的值唯一， 或者是元素只能出现一次，不能出现多次？ 甚至是规定里面只能出现具体的元素名字。\n\u0026lt;stus\u0026gt; \u0026lt;stu id=\u0026#34;10086\u0026#34;\u0026gt; \u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;18\u0026lt;/age\u0026gt; \u0026lt;address\u0026gt;深圳\u0026lt;/address\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;stu id=\u0026#34;10086\u0026#34;\u0026gt; \u0026lt;name\u0026gt;李四\u0026lt;/name\u0026gt; \u0026lt;name\u0026gt;李五\u0026lt;/name\u0026gt; \u0026lt;name\u0026gt;李六\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;28\u0026lt;/age\u0026gt; \u0026lt;address\u0026gt;北京\u0026lt;/address\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;/stus\u0026gt; DTD 文档类型定义，可以定义合法的ＸＭＬ文档构建模块.\n可以成行的声明于XML文档中,也可以作为外部引用\n可读性比较差。\n 引入网络上的DTD  \u0026lt;!-- 引入dtd 来约束这个xml --\u0026gt; \u0026lt;!--文档类型 根标签名字 网络上的dtd dtd的名称 dtd的路径 --\u0026gt; \u0026lt;! DOCTYPE stus PUBLIC \u0026#34;//UNKNOWN/\u0026#34; \u0026#34;unknown.dtd\u0026#34;\u0026gt; 引入本地的DTD  \u0026lt;!-- 引入本地的DTD 忽略dtd的路径--\u0026gt; \u0026lt;!-- 根标签名字 引入本地的DTD dtd的位置 --\u0026gt; \u0026lt;!DOCTYPE stus SYSTEM \u0026#34;stus.dtd\u0026#34;\u0026gt; 直接在XML里面嵌入DTD的约束规则  \u0026lt;!-- xml文档里面直接嵌入DTD的约束法则 --\u0026gt; \u0026lt;!DOCTYPE stus [ \u0026lt;!ELEMENT stus (stu)+\u0026gt; \u0026lt;!ELEMENT stu (name,age)\u0026gt; \u0026lt;!ELEMENT name (#PCDATA)\u0026gt; \u0026lt;!ELEMENT age (#PCDATA)\u0026gt; \u0026lt;!ATTLIST stu id CDATA #IMPLIED\u0026gt; ]\u0026gt; \u0026lt;stus\u0026gt; \u0026lt;stu id=\u0026#34;10086\u0026#34;\u0026gt; \u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;18\u0026lt;/age\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;stu id=\u0026#34;10ds\u0026#34;\u0026gt; \u0026lt;name\u0026gt;李四\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;18\u0026lt;/age\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;/stus\u0026gt; \u0026lt;!-- \u0026lt;!ELEMENT stus (stu)\u0026gt;:stus 下面有一个元素 stu ， 但是只有一个 \u0026lt;!ELEMENT stu (name,age)\u0026gt;:stu下面有两个元素 name,age顺序必须name-age \u0026lt;!ELEMENT name (#PCDATA)\u0026gt;:name 只有PCDATA \u0026lt;!ELEMENT age (#PCDATA)\u0026gt;:age 只有PCDATA \u0026lt;!ATTLIST stu id CDATA #IMPLIED\u0026gt;:stu有一个属性名为id,字符数据CDATA,该属性可有可无 \u0026lt;!ELEMENT br EMPTY\u0026gt;:空元素,例子;\u0026lt;br /\u0026gt; --\u0026gt; 元素的个数：  \r+ 一个或多个\r* 零个或多个\r? 零个或一个\r属性的类型定义  CDATA : 属性是普通文字 ID : 属性的值必须唯一 元素的选择  \u0026lt;!ELEMENT stu (name , age)\u0026gt;\t\u0026lt;!--按照顺序来--\u0026gt; \u0026lt;!ELEMENT stu (name | age)\u0026gt; \u0026lt;!--两个中只能包含一个子元素--\u0026gt; Schema 其实就是一个xml ， 使用xml的语法规则， xml解析器解析起来比较方便 ， 是为了替代DTD 。\n但是Schema 约束文本内容比DTD的内容还要多。 所以目前也没有真正意义上的替代DTD\n约束文档：\n\u0026lt;!-- xmlns : xml namespace : 名称空间 / 命名空间 targetNamespace : 目标名称空间 。 下面定义的那些元素都与这个名称空间绑定上。 elementFormDefault ： 元素的格式化情况。 --\u0026gt; \u0026lt;schema xmlns=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; argetNamespace=\u0026#34;http://www.itheima.com/teacher\u0026#34; elementFormDefault=\u0026#34;qualified\u0026#34; \u0026gt; \u0026lt;element name=\u0026#34;teachers\u0026#34;\u0026gt; \u0026lt;complexType\u0026gt; \u0026lt;sequence maxOccurs=\u0026#34;unbounded\u0026#34;\u0026gt; \u0026lt;!-- 这是一个复杂元素 --\u0026gt; \u0026lt;element name=\u0026#34;teacher\u0026#34;\u0026gt; \u0026lt;complexType\u0026gt; \u0026lt;sequence\u0026gt; \u0026lt;!-- 以下两个是简单元素 --\u0026gt; \u0026lt;element name=\u0026#34;name\u0026#34; type=\u0026#34;string\u0026#34;\u0026gt;\u0026lt;/element\u0026gt; \u0026lt;element name=\u0026#34;age\u0026#34; type=\u0026#34;int\u0026#34;\u0026gt;\u0026lt;/element\u0026gt; \u0026lt;/sequence\u0026gt; \u0026lt;/complexType\u0026gt; \u0026lt;/element\u0026gt; \u0026lt;/sequence\u0026gt; \u0026lt;/complexType\u0026gt; \u0026lt;/element\u0026gt; \u0026lt;/schema\u0026gt; 实例文档：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- xmlns:xsi : 这里必须是这样的写法，也就是这个值已经固定了。 xmlns : 这里是名称空间，也固定了，写的是schema里面的顶部目标名称空间 xsi:schemaLocation : 有两段： 前半段是名称空间，也是目标空间的值 ， 后面是约束文档的路径。 --\u0026gt; \u0026lt;teachers xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://www.itheima.com/teacher\u0026#34; xsi:schemaLocation=\u0026#34;http://www.itheima.com/teacher teacher.xsd\u0026#34; \u0026gt; \u0026lt;teacher\u0026gt; \u0026lt;name\u0026gt;zhangsan\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;19\u0026lt;/age\u0026gt; \u0026lt;/teacher\u0026gt; \u0026lt;teacher\u0026gt; \u0026lt;name\u0026gt;lisi\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;29\u0026lt;/age\u0026gt; \u0026lt;/teacher\u0026gt; \u0026lt;teacher\u0026gt; \u0026lt;name\u0026gt;lisi\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;29\u0026lt;/age\u0026gt; \u0026lt;/teacher\u0026gt; \u0026lt;/teachers\u0026gt; 名称空间的作用 一个xml如果想指定它的约束规则， 假设使用的是DTD ，那么这个xml只能指定一个DTD ， 不能指定多个DTD 。 但是如果一个xml的约束是定义在schema里面，并且是多个schema，那么是可以的。简单的说： 一个xml 可以引用多个schema约束。 但是只能引用一个DTD约束。\n名称空间的作用就是在 写元素的时候，可以指定该元素使用的是哪一套约束规则默认情况下 ，如果只有一套规则，那么都可以这么写\n\u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt; \u0026lt;aa:name\u0026gt;\u0026lt;/aa:name\u0026gt; \u0026lt;bb:name\u0026gt;\u0026lt;/bb:name\u0026gt; ","permalink":"/zh-cn/posts/java/xml/","series":["java"],"tags":["java"],"title":"XML"},{"categories":["Shortcode"],"content":"关于优酷 shortcode 的详细说明。\n使用 {{\u0026lt; youku \u0026#34;XNTQwMTgxMTE2\u0026#34; \u0026gt;}} 例子  ","permalink":"/zh-cn/posts/shortcodes/youku/","series":null,"tags":["Youku"],"title":"优酷 Shortcode"},{"categories":["无人驾驶"],"content":"无人驾驶概述\n无人驾驶能够解决的问题 车辆利用率  点对点交通 共享交通  驾驶安全  减少车祸  提高交通效率   减少堵塞\n  提高路口通行效率\n  无人驾驶分级 L1：定速巡航（ACC）可以纵向控制 L2：车道保持辅助（Lane Keeping）可以横向和纵向控制。人负全责 L3：可以提供简单路况下的变道，但是条件限制。自动驾驶时车负责 L4：大部分时间按由车主导，接管工具减少 L5：全区域无人驾驶 实现思路 V2X（车路协同）   V2V（车）\n  V2I（公共设施）\n  V2P（行人）\n  可以降低单车成本，提供超视距感知，车辆意图协商，车辆协同控制\n边缘计算   RSU：路侧单元\n  OBU：车载单元\n  5G通信能力  LTE-V协议  主车智能   感知能力\n  决策能力\n  高精地图（HD map）\n  定位\n  权责问题  RSS模型（责任敏感安全模型）  自动驾驶硬件概述 感知传感器   摄像头（用于车道线检测，交通信号灯识别）\n  激光雷达（准确率高）\n  毫米波雷法（观测距离远）\n  超声波（近处高敏感传感器）\n  定位系统传感器   IMU：实时测量自身位姿\n  GNSS：GPS\n  车载计算单元-IPC   高效连接计算单元内部的各个计算设备，连接外部传感器的信息输入和存储\n  冗余设计，防止单点故障\n  符合车规，抗电磁干扰能力\n  车辆线控系统 由液压系统和真空助力泵变为电子液压系统\n自动驾驶软件概述 感知系统（位姿，目标对象，场景语义分割） 定位系统（检测，分类，跟踪，分割） 硬件   HD map：高精地图，提供精确的三维表征，地图语义信息\n  INS：惯性导航\n  IMU：通过当前自身状态推算下一时刻位置\n  RTK：载波相位差分系统\n  激光雷达，摄像头：获取信息，和高精地图进行物体匹配，获取定位\n  软件   监督学习，半监督学习，强化学习\n  RCNN，YOLO，SSD\n  前融合，后融合\n  决策规划（实时，准确） 预测 基于状态预测   Kalman Filter\n  Particle Filter\n  基于车道序列预测  机器学习，深度学习  行人预测  人的突发位姿变化  规划   导肮线路规划\n  精细轨迹表述\n  实时控制（准确性，时效性，精确性） 通过轨迹和车辆状态，来控制方向盘和油门\nOS RTOS   QNX：类Unix系统\n  RT Linux：加了Linux补丁，通过软实时进行监控\n  Framework   ROS\n  YARP,MOOS,Cybertron\n  阅读材料  综述文章  • 基于深度学习的自动驾驶技术综述\n• Self-Driving Cars:A Survey\n• Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art\n无人驾驶实现结构概览  • ISPRS 2017  实践  • Python plays Grand Theft Auto ","permalink":"/zh-cn/posts/driverless/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E6%A6%82%E8%BF%B0/","series":["无人驾驶"],"tags":["无人驾驶"],"title":"无人驾驶概述"},{"categories":["Shortcode"],"content":"关于爱奇艺 shortcode 的详细说明。\n使用 {{\u0026lt; iqiyi \u0026#34;vid\u0026#34; \u0026#34;tvid\u0026#34; \u0026gt;}} 例子  ","permalink":"/zh-cn/posts/shortcodes/iqiyi/","series":null,"tags":["爱奇艺"],"title":"爱奇艺 Shortcode"},{"categories":["缓存"],"content":"缓存的使用和设计 缓存的收益与成本 收益   加速读写\n 通过缓存加速读写：CPU L1/L2/L3 Cache，浏览器缓存，Ehcache缓存数据库结果    降低后端负载\n 后端服务器通过前端缓存降低负载：业务端使用Redis降低后端MySQL负载    成本   数据不一致\n 缓存层和数据层有时间窗口不一致，和更新策略有关    代码维护成本：多了一层缓存逻辑\n  运维成本：Redis Cluster\n  使用场景   降低后端负载\n 用于高消耗的SQL：join结果集/分组统计结果    加速请求响应\n 利用Redis/Memcache优化IO时间    大量写合并为批量写\n 计数器线Redis累加再批量更新到后端数据库    缓存更新策略   LRU/LFU/FIFO算法剔除：例如maxmemory-policy\n  超时剔除：例如expire\n  主动更新：开发控制生命周期\n   推荐结合剔除，超时，主动更新三种方案完成  三种策略比较 | 策略 | 一致性 | 维护成本 |\n| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash; | \u0026mdash;\u0026mdash;\u0026ndash; |\n| LRU/LIRS算法剔除 | 最差 | 底 |\n| 超时剔除 | 较差 | 低 |\n| 主动更新 | 强 | 高 |\nTIPS   低一致性：最大内存和淘汰策略\n  高一致性：超时剔除和主动更新结合，最大内存和淘汰策略兜底\n  缓存粒度控制 什么是缓存粒度   从MySQL获取用户信息\n select * from usr where id={id}    设置用户信息缓存\n ```set usr:{id} `select * from usr where id={id}````    缓存粒度\n 部分重要属性    ```set usr:{id} `select * from usr where id={id}````\n- 全部属性\r ```set usr:{id} `select * from usr where id={id}````\n缓存粒度控制   通用性：全量属性更好\n  占用空间：部分属性更好\n  代码维护：综合考虑，是否使用这么多属性\n  缓存穿透优化 缓存穿透：大量请求不命中 大量没有结果的请求通过cache访问到后端，后端也没有命中\n原因   业务代码，没有正确从后端拿到数据\n  恶意攻击，爬虫{大量请求携带未知数据去访问缓存以及数据库}\n  及时发现   业务的相应时间\n  业务的本身问题\n  监控几个指标\n  总调用数\n  缓存层命中数\n  存储层命中数\n    解决方法   缓存空对象\n  如果从后端数据库中的请求结果是一个空值，我们也保存，不过设置一个过期时间（有可能后端数据库故障或者接口故障），这样减小后端数据库的压力\n  问题：\n1). 需要更多的键（设置过期时间解决）\n2). 缓存层和存储层数据“短期”不一致（订阅故障消息解决）\n  伪代码\n    public String getPassThrough(String key){ String cacheValue = cache.get(key); if(StringUtils.isBlank(cacheValue)){ String storgeValue = storage.get(key)//如果cache中为空，就从storage中拿数据  cache.set(key,storageValue); if(StringUtils.isBlank(storageValue)){ cache.expire(key,60*5);//如果从后端接口获取值为空，设置一个过期时间  } return storageValue; }else{ return cacheValue; } }  布隆过滤器\n  数据很大不能做到实时\n  利用算法，可以使用很小的内存判断一个值是否在一个大数据集中\n  在请求cache之前先通过bloom filter过滤一次，判断请求是否有效\n    缓存无底洞：节点增加，性能下降 原因   更多的机器!=更高的性能\n  批量接口需求(mget，mset)等（节点增加，io时间增加）\n  数据增长与水平扩展需求\n  优化   命令优化：例如慢查询keys，hgetall\n  减少网络通信次数\n  降低接入成本：例如客户端长连接/连接池.NIO\n  优化方案比较 | 方案 | 优点 | 缺点 | 网络IO |\n| \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| 串行mget | 编程简单少量keys满足需求 | 大量keys请求延迟严重 | O(keys) |\n| 串行IO | 编程简单少量节点满足需求 | 大量node延迟严重 | O(nodes) |\n| 并行IO | 利用并行特性延迟取决于最慢的节点 | 编程复杂超时定位问题难 | O(max_slow(node)) |\n| hash_tag | 性能最高 | 读写增加tag维护成本tag分布易出现数据倾斜 | O1 |\n缓存雪崩 缓存集中过期或者缓存服务器宕机\n缓存集中过期 在某一时间段，缓存集中过期失效，访问压力会给到后端数据库\n  为不同的分类设置不同的过期时间\n  同一分类的不同商品在设置过期时间时加一个随机因子\n  根据请求数量和密度设置过期时间\n  服务器宕机   缓存层实现高可用\n  客户端降级\n  提前演练\n  热点key重建优化 原因 热点key在多次访问时，线程一直在做查询数据源，重建缓存的操作\n例如微博热搜\n优化目标   减少重缓存的次数\n  数据尽可能一致\n  减少潜在危险\n  优化思路 互斥锁 在查询数据源和重建缓存这个过程中加锁，如果有线程在执行这个操作，其他线程只能等待缓存重建完毕\n 伪代码：  String get(String key){ String value = redis.get(key); if(value == null){ String mutexKey = \u0026#34;mutex🔑\u0026#34; + key; if(redis.set(mutexKey,\u0026#34;1\u0026#34;,\u0026#34;ex 180\u0026#34;,\u0026#34;nx\u0026#34;)){ value = db.get(key); redis.set(key,value); redis.delete(mutexKey); }else{ //其他线程休息50ms  Thread.sleep(50); get(key); } } return value; } 永不过期   缓存：没有加expire\n  功能层面：为每个value添加逻辑过期时间，如果发现超过逻辑过期时间，使用单独的线程去构建缓存\n  我们的key永不过期，线程获取缓存不需要等待，如果中间发现value的过期时间到了，就新开一个线程去更新key。在更新完成前所有的请求获取得到的都是更新前的旧值，知道更新完成后，才会得到新值\n 伪代码  String get(final String key){ V v= redis.get(key); String value = v.getValue(); long logicTimeout = v.getLogicTimeout(); if(logicTimeout \u0026gt;= System.currentTimeMills()){ String mutexKey = \u0026#34;mutex🔑\u0026#34; + key; if(redis.set(mutexKey,\u0026#34;1\u0026#34;,\u0026#34;ex 180\u0026#34;,\u0026#34;nx\u0026#34;)){ //异步更新  threadPool.execute(new Runnable(){ public void run(){ String dbValue = db.get(Key); redis.set(key,(dbValue,newLogicTimeout)); redis.delete(muteKey); } }); } } return value; } 两种方案对比 | 方案 | y优点 | 缺点 |\n| \u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| 永远不过期 | 基本杜绝热点key重建按问题 | 不保证一致性逻辑过期时间增加维护成本和内存成本 |\n| 互斥锁 | 思路简单保证一致性 | 代码复杂度增加存在死锁的风险 |\n","permalink":"/zh-cn/posts/redis/%E7%BC%93%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E8%AE%BE%E8%AE%A1/","series":["缓存"],"tags":["缓存"],"title":"缓存的使用和设计"},{"categories":["Shortcode"],"content":"关于网易云音乐 Shortcode 的详细使用说明。\n使用 {{\u0026lt; neteasemusic \u0026#34;id\u0026#34; [auto [type]] \u0026gt;}}    Parameter Description     auto The auto controls whether to autoplay. Boolean and optional, default to false.   type The type parameter is optional. Default to 2.    例子  ","permalink":"/zh-cn/posts/shortcodes/neteasemusic/","series":null,"tags":["网易云音乐"],"title":"网易云音乐 Shortcode"},{"categories":["Shortcode"],"content":"关于腾讯视频 shortcode 的详细说明。\n使用 {{\u0026lt; tencentvideo \u0026#34;vid\u0026#34; \u0026gt;}} 例子  ","permalink":"/zh-cn/posts/shortcodes/tencentvideo/","series":null,"tags":["腾讯视频"],"title":"腾讯视频 Shortcode"},{"categories":["读书笔记"],"content":"链表 单链表  data.next\u0026ndash;\u0026gt;data.next\u0026ndash;\u0026gt;NULL\n 插入节点:\n时间复杂度:O1\n删除节点\n时间复杂度:O1\n查找节点\n时间复杂度:O(n)\n链表想要随机访问第K个元素\narr[k],需要根据指针一个一个找\n双向链表 支持两个方向,每个节点不知有一个后继指针next,还有一个前驱指针prev指向前面的结点\n \u0026ndash;\u0026gt;prev.data.next\u0026lt;==\u0026gt;prev.data.next\u0026lt;==\u0026gt;prev.data.next\n 双向链表需要额外的两个空间来存储后继结点和其前驱结点的地址.所以,如果存储同样多的数据,双向链表要比单链表占用更多的内存空间.虽然两个指针比较浪费存储空间,但是可以支持双向遍历.这样也带来了双向链表操作的灵活性\n特点:双向链表可以支持O1时间复杂度的情况下找到前驱结点,这样,双向链表在某些情况的插入,删除操作都要比单链表简单高校.\n循环链表 单链表的尾节点指针指向空地址\n循环链表的尾节点指针指向链表的头结点\n优点:从链尾到链头比较方便.当要处理的数据具有环型结构特点时,就特别适合采用循环链表\n把约瑟夫问题降低到O(n)时间复杂度\n具体的复杂度分析: 删除操作,有两种情况   删除结点中 “ 值等于某个给定值 ” 的结点;    删除给定指针指向的结点。   第一种情况,为了找到节点的值等于给定值的结点,单链表和双向链表都要从头结点一个一个一次遍历比较,直到找到这个节点,才利用指正操作进行删除.\n 主要的时间复杂度在于遍历结点,时间复杂度为On\n 第二种情况,我们知道要删除哪一个结点,可是删除这个结点的操作需要其前驱结点的参与,因此我们还要知道指向前驱结点的指正.这时双向链表和单链表的区别就体现出来了.\n 单链表依然需要从头结点开始遍历链表.因此,单链表删除的时间复杂度为On\n  双向链表的结点中有prev,可以直接删除,因此,双向链表删除的时间复杂度为O1\n 查找 除了插入和删除操作以外,双向链表的按值查询效率也比单链表快\n 记录上次查找的位置P,每次查询时,根据要查找的值与P的大小关系,决定是往前还是往后查找,平均下来只需要查找一般的数据\n LinkedHashMap,采用了双向链表的数据结构 用空间换取时间: 当我们的空间足够时,我们可以使用空间复杂度较高,时间复杂度较小的的算法或者数据结构.\n而当我们的空间比较紧缺时,我们就需要采用时间换空间的设计思想\n缓存的设计: 如果我们把数据存储在硬盘上,会比较节约空间.但是我们每次查找数据都需要询问一次硬盘,很慢.如果我们通过缓存技术,实现将数据加载在内存中,每次查询的速度就会大大提高\n链表与数组的性能比较 数组:实现上使用的是连续的内存空间,可以借助CPU的缓存机制,预读数组中的数据,所以访问效率高\n缺点:大小固定,如果内存不够,只能重新再申请一个更大的内存空间,把原数组拷贝进去,费时\n链表:在内存中并不是连续存储,对于CPU缓存不友好,没有办法有效预读.\n与数组相比,天然支持动态扩容\n缺点:需要消耗额外的存储空间去存储一份指向下一个结点的指正,所以内存消耗会翻倍.并且,对链表进行频繁的插入,删除操作,还会导致频繁的内存申请和释放,容易造成内存碎片.比如java:会导致频繁的GC(垃圾回收)\n如何基于链表实现LRU缓存淘汰法 思路:\n  我们维护一个有序单链表,越靠近链表尾部的结点是越早之前访问的,当有一个新的数据被访问时,我们从链表头开始顺序遍历链表.\n  如果此数据之前已经被缓存在链表中了,我们遍历得到这个数据对应的结点,并将其从原来的位置删除,然后插入到链表的头部\n  如果这数据没有在缓存链表中,又可以分为两种情况:\n   如果此时缓存未满,则将此节点直接插入到链表的头部\n  如果此时缓存已满,则链表尾结点删除,将新的数据结点插入到链表的头部\n 时间复杂度:O(n)\n优化:引入散列表,来记录每个数据的位置,将缓存访问的时间复杂度降到O1\n代码: 注意点:\n 理解指针或引用的含义:  java,Python没有指针,而是引用{都是用来存储所指对象的内存地址}\n警惕指针丢失和内存泄露  简单地说,对结点进行操作时,注意操作的顺序\n例如C语言:\n//--\u0026gt;a.next--\u0026gt;b.next--\u0026gt;,插入一个结点x.next  x-\u0026gt;next = p-\u0026gt;next;//将x的结点的next指针指向b结点  p-\u0026gt;next = x//将p的next指针指向x结点  利用哨兵简化实现难度  普通的实现方式,在针对链表的插入删除时,需要对插入第一个结点和最后一个节点的情况进行特殊处理,例如:\n//向空链表插入第一个节点  if(head == null){ head = new_node; } //删除链表中的是最后一个节点  if(head-\u0026gt;next == null){ head = null; } 引入哨兵结点:处理边界问题,我们不管链表是否为空,head指针都会一直指向这个哨兵结点.\n带头链表:有哨兵节点的链表\n null.next\u0026ndash;\u0026gt;a.next\u0026ndash;\u0026gt;b.next\n   留意边界条件处理  检查边界条件是否考虑全面,代码在边界条件下能否正确运行\n 如果链表为空,代码能否正常工作\n  如果链表只包含一个结点时,代码能否正常工作\n  如果链表只包含两个结点,代码能否正常工作\n  代码逻辑在处理头结点和尾节点时,能否正常工作\n  对于复杂的链表操作,可以举例,画图进行理解\n  常见的链表操作:\n   单链表反转\n  链表中环的检测\n  两个有序的链表的合并\n  删除链表倒数第n个结点\n  求链表的中间结点\n   内存池  查找key:\n//在数组中a中,查找key,返回key所在的位置  int find(char* a, int n, char key) { //边界条件处理,如果 a 为空,或者n\u0026lt;=0,说明数组中没有数据,就不用while循环比较了  if(a == null || n \u0026lt;= 0) { return -1; } int i = 0; //这里有两个比较操作: i\u0026lt;n 和 a[i]==key.  while (i \u0026lt; n) { if (a[i] == key) { return i; } ++i; } return -1; } //在数组a中,查找key,返回key所在的位置  //n表示数组a的长度  int find(char*　ａ，int n,char key){ if(a == null || n\u0026lt;= 0 ){ return -1; } //这里因为要将a[n-1]的值替换成key,所以要特殊处理这个值  if(a[n-1]==key){ return n-1; } //要把a[n-1]的值临时保存在变量tmp中,以便之后恢复  char tmp = a[n-1]; a[n-1] = key; int i = 0; while (a[i] != key){ ++i; } //恢复a[n-1]原来的值  a[n-1] = tmp; if(i == n-1){ //如果i == n-1 说明,在0...n-2之间没有key,所以返回-1  return -1; }else{ //否则,返回i,就是要等key值的元素的下标  return i; } } ","permalink":"/zh-cn/posts/algorithm/%E9%93%BE%E8%A1%A8/","series":["读书笔记"],"tags":["数据结构"],"title":"链表"},{"categories":["bigData"],"content":"Hbase 基础 Hbase 能做什么\n 海量数据存储 准实时查询  HBase在实际业务场景中的应用\n 交通:gps,摄像头信息 金融:交易信息 电商:交易信息,浏览信息,物流信息  HBase特点\n 容量大:Hbase单表可以有百亿行,百万列,数据矩阵的横纵维度所支持的数据量级都十分具有弹性 面向列:HBase是面向列的存储和权限控制,并支持独立检索.列式存储,其数据在表中是按照某列存储的,这样在查询只需要少数几个字段的时候,能大大减少读取的数据量.并且 可以动态增加列 多版本:HBase每一列的数据存储有多个Version 稀疏性:为空的列并不占用存储空间,表可以设计的很稀疏 扩展性:底层依赖于HDFS(只需要增加机器就可以扩大容量) 高可靠性:WAL机制保证了数据写入时不会因集群异常而导致写入数据丢失;HBase底层使用的HDFS,会有备份 高性能:底层的LSM数据结构和Rowkey有序排列等架构的独特设计,使得HBase具有非常高的写入性能.region切分,主键索引和缓存机制使得HBase在海量数据下具备-定的随机读取性能,该性能针对Rowkey的查询能够达到毫秒级别  HBase数据模型\n列簇:\n 一张表列簇不会超过5个,多个会增加磁盘交互,降低性能 每个列簇中的列数没有限制 列只有插入数据后存在 列在列簇中是有序的  基本操作\nhbase(main):001:0\u0026gt; create \u0026#39;test\u0026#39;,\u0026#39;info\u0026#39; 0 row(s) in 11.7610 seconds =\u0026gt; Hbase::Table - test hbase(main):002:0\u0026gt; put \u0026#39;test\u0026#39;,\u0026#39;0001\u0026#39;,\u0026#39;info:username\u0026#39;,\u0026#39;euraxluo\u0026#39; 0 row(s) in 6.6130 seconds hbase(main):003:0\u0026gt; scan \u0026#39;test\u0026#39; ROW COLUMN+CELL 0001 column=info:username, timestamp=1577270839695, value=euraxluo 1 row(s) in 0.6160 seconds hbase(main):004:0\u0026gt; put \u0026#39;test\u0026#39;,\u0026#39;0001\u0026#39;,\u0026#39;info:age\u0026#39;,\u0026#39;12\u0026#39; 0 row(s) in 0.3720 seconds hbase(main):005:0\u0026gt; scan \u0026#39;test\u0026#39; ROW COLUMN+CELL 0001 column=info:age, timestamp=1577270880203, value=12 0001 column=info:username, timestamp=1577270839695, value=euraxluo 1 row(s) in 0.0240 seconds hbase(main):006:0\u0026gt; describe \u0026#39;test\u0026#39; Table test is ENABLED test COLUMN FAMILIES DESCRIPTION {NAME =\u0026gt; \u0026#39;info\u0026#39;, BLOOMFILTER =\u0026gt; \u0026#39;ROW\u0026#39;, VERSIONS =\u0026gt; \u0026#39;1\u0026#39;, IN_MEMORY =\u0026gt; \u0026#39;false\u0026#39;, KEEP_DELETED_CELLS =\u0026gt; \u0026#39;FALSE\u0026#39;, DATA_BLOCK_ENCODING =\u0026gt; \u0026#39;NONE\u0026#39;, TTL =\u0026gt; \u0026#39;FOREVER\u0026#39;, COMPRESSION =\u0026gt; \u0026#39;NONE\u0026#39;, MIN_VERSIONS =\u0026gt; \u0026#39;0\u0026#39;, BLOCKCACHE =\u0026gt; \u0026#39;true\u0026#39;, BLOCKSIZE =\u0026gt; \u0026#39;65536\u0026#39;, REPLICATION_SCOPE =\u0026gt; \u0026#39;0\u0026#39;} 1 row(s) in 0.3110 seconds hbase(main):007:0\u0026gt; get \u0026#39;test\u0026#39;,\u0026#39;0001\u0026#39;,\u0026#39;info:age\u0026#39; COLUMN CELL info:age timestamp=1577283627980, value=12 hbase(main):008:0\u0026gt; truncate \u0026#39;test\u0026#39; Truncating \u0026#39;test\u0026#39; table (it may take a while): - Disabling table... - Truncating table... 0 row(s) in 4.2500 seconds hbase(main):009:0\u0026gt; disable \u0026#39;test\u0026#39; 0 row(s) in 9.8040 seconds hbase(main):010:0\u0026gt; is_enabled \u0026#39;test\u0026#39; false 0 row(s) in 0.1060 seconds hbase(main):011:0\u0026gt; drop \u0026#39;test\u0026#39; 0 row(s) in 5.0910 seconds Hadoop,ZooKeeper,HBase,Kafka 单机伪分布式安装过程及注意事项 参考1 参考2 tar包地址: hadoop hbase zookeeper hadoop-native kafka /etc/profile export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL export JAVA_HOME=/home/software/app/jdk1.8.0_202 export CLASSPATH=.:${JAVA_HOME}/jre/lib/rt.jar:${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar export PATH=$JAVA_HOME/bin:$PATH export SCALA_HOME=/home/software/app/scala-2.12.8 export PATH=$SCALA_HOME/bin:$PATH export MAVEN_HOME=/home/software/app/apache-maven-3.3.9 export PATH=$MAVEN_HOME/bin:$PATH export HADOOP_HOME=/home/software/app/hadoop-2.6.0-cdh5.7.0 export CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$CLASSPATH export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH export HADOOP_OPTS=\u0026#34;-Djava.library.path=$HADOOP_HOME/lib\u0026#34; export ZOOKEEPER_HOME=/home/software/app/zookeeper-3.4.10 export PATH=$ZOOKEEPER_HOME/bin:$PATH export HBASE_HOME=/home/software/app/hbase-1.2.0-cdh5.7.0 export PATH=$HBASE_HOME/bin:$PATH export KAFKA_HOME=/home/software/app/kafka #_2.12-0.10.2.0 export PATH=$KAFKA_HOME/bin:$PATH export JAVA_OPTS=\u0026#34;-server -Xms256m -Xmx512m -XX:PermSize=128m -XX:MaxPermSize=256m\u0026#34; 安装JDK  略过,就是解压,然后配置环境变量  Hadoop 安装配置过程:   选择 app 目录存放这些软件\n  解压缩 tar -zxvf hadoop-2.6.0-cdh5.7.0.tar.gz -C app\n  配置环境变量\n  解压缩 native 文件,因为我们的lib文件夹是空的 tar -xvf hadoop-native-64-2.6.0.tar -C hadoop-2.6.0-cdh5.7.0.tar.g/lib/native/ ; tar -xvf hadoop-native-64-2.6.0.tar -C hadoop-2.6.0-cdh5.7.0.tar.g/lib\n  写配置文件:\n\u0026lt;!-- app/hadoop-2.6.0-cdh5.7.0/etc/hadoop/coite.xml--\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/home/software/hadoop_tmp\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:9001\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;!-- app/hadoop-2.6.0-cdh5.7.0/etc/hadoop/hdfs-site.xml--\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///home/software/hadoop_tmp/dfs/name\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///home/software/hadoop_tmp/dfs/data\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.checkpoint.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///home/software/hadoop_tmp/dfs/fcd\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.checkpoint.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///home/software/hadoop_tmp/dfs/fce\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.permissions.enabled\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;false\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; [software]# cat app/hadoop-2.6.0-cdh5.7.0/etc/hadoop/slaves localhost [software]# cat app/hadoop-2.6.0-cdh5.7.0/etc/hadoop/hadoop-env.sh |grep JAVA_HOME # The only required environment variable is JAVA_HOME. All others are # set JAVA_HOME in this file, so that it is correctly defined on export JAVA_HOME=/home/software/app/jdk1.8.0_202   关闭防火墙\nfirewall-cmd --state systemctl stop firewalld.service firewall-cmd --state   测试\nhdfs namenode -format\u0026gt;{ 查看有无报错 } start-dfs.sh\u0026gt;{ 查看日志有无报错 } jps\u0026gt;{ 21366 DataNode 7958 Jps 20888 NameNode 21869 SecondaryNameNode } 最后去网页上查看存活节点数   Hadoop 伪分布式问题 17/09/22 14:53:21 WARN hdfs.DFSClient: DataStreamer Exception org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /input/data.txt._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1). There are 0 datanode(s) running and no node(s) are excluded in this operation. 解决方案: 看它的报错信息好像是节点没有启动，但是我的节点都启动起来了，使用jps也能查看到节点信息。 使用hadoop dfsadmin -report命令查看磁盘使用情况，发现出现以下问题： Configured Capacity: 0 (0 B)Present Capacity: 0 (0 B)DFS Remaining: 0 (0 B)DFS Used: 0 (0 B)DFS Used%: NaN%Under replicated blocks: 0Blocks with corrupt replicas: 0Missing blocks: 0-------------------------------------------------Datanodes available: 0 (0 total, 0 dead) 节点下存储空间都是空的，问题应该就是出现在这了。 查阅资料发现造成这个问题的原因可能是使用hadoop namenode -format格式化时格式化了多次造成那么spaceID不一致，解决方案： 1、停止集群（切换到/sbin目录下） stop-all.sh 2、删除在hdfs中配置的data目录（即在core-site.xml中配置的hadoop.tmp.dir对应文件件）下面的所有数据; rm -rf /root/training/hadoop-2.7.3/tmp 3、重新格式化namenode(切换到hadoop目录下的bin目录下) hdfs namenode -format 4、重新启动hadoop集群（切换到hadoop目录下的sbin目录下） start-all.sh Zookeeper 安装配置   解压缩tar -zxvf zookeeper-3.4.10.tar.gz -C app\n  写配置 zoo1.cfg,zoo2.cfg,zoo3.cfg\ncat app/zookeeper-3.4.10/conf/zoo1.cfg\ndataDir=/home/software/zookeeper/zoo1 clientPort=2191 server.1=127.0.0.1:8801:7701 server.2=127.0.0.1:8802:7702 server.3=127.0.0.1:8803:7703 cat app/zookeeper-3.4.10/conf/zoo2.cfg\ndataDir=/home/software/zookeeper/zoo2 clientPort=2192 server.1=127.0.0.1:8801:7701 server.2=127.0.0.1:8802:7702 server.3=127.0.0.1:8803:7703 cat app/zookeeper-3.4.10/conf/zoo3.cfg\ndataDir=/home/software/zookeeper/zoo3 clientPort=2193 server.1=127.0.0.1:8801:7701 server.2=127.0.0.1:8802:7702 server.3=127.0.0.1:8803:7703   配置myid文件\necho \u0026#34;1\u0026#34; \u0026gt; zoo1/myid echo \u0026#34;2\u0026#34; \u0026gt; zoo2/myid echo \u0026#34;3\u0026#34; \u0026gt; zoo3/myid   启动zookeeper服务\nzkServer.sh start app/zookeeper-3.4.10/conf/zoo1.cfg zkServer.sh start app/zookeeper-3.4.10/conf/zoo2.cfg zkServer.sh start app/zookeeper-3.4.10/conf/zoo3.cfg   检查是否启动成功\n10626 QuorumPeerMain 10568 QuorumPeerMain 13450 Jps 10732 QuorumPeerMain 21366 DataNode 20888 NameNode 21869 SecondaryNameNode zkCli.sh -server 127.0.0.1:8802   HBASE配置   解压缩 tar -zxvf hbase-1.2.0-cdh5.7.0.tar.gz -C app\n  配置\n[software]# cat app/hbase-1.2.0-cdh5.7.0/conf/hbase-env.sh | grep ^export export JAVA_HOME=/home/software/app/jdk1.8.0_202 export HBASE_OPTS=\u0026#34;-XX:+UseConcMarkSweepGC\u0026#34; export HBASE_MASTER_OPTS=\u0026#34;$HBASE_MASTER_OPTS-XX:PermSize=128m -XX:MaxPermSize=128m\u0026#34; export HBASE_REGIONSERVER_OPTS=\u0026#34;$HBASE_REGIONSERVER_OPTS-XX:PermSize=128m -XX:MaxPermSize=128m\u0026#34; export HBASE_MANAGES_ZK=false \u0026lt;!--app/hbase-1.2.0-cdh5.7.0/conf/hbase-site.xml --\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.rootdir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:9001/hbase\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.cluster.distributed\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.zookeeper.quorum\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;127.0.0.1:2191,127.0.0.1:2192,127.0.0.1:2193\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/home/software/hbase/data\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt;   启动start-hbase.sh\n  检验\n21361 HMaster 10626 QuorumPeerMain 21366 DataNode 20888 NameNode 10568 QuorumPeerMain 21512 HRegionServer 10732 QuorumPeerMain 21869 SecondaryNameNode 20638 Jps #查看网页: http://47.107.44.224:60010/master-status   Kafka 安装配置 参考链接   解压  tar -zxvf kafka_2.12-0.10.2.0.tgz -C app\n  环境变量\nexport KAFKA_HOME=/home/software/app/kafka #_2.11-2.3.1 export PATH=$KAFKA_HOME/bin:$PATH #export JAVA_OPTS=\u0026#34;-server -Xms256m -Xmx512m -XX:PermSize=128m -XX:MaxPermSize=256m\u0026#34;   修改配置\napp/kafka/config/server1.properties\nbroker.id=1 log.dirs=/home/software/kafka/logs1 zookeeper.connect=localhost:2191,localhost:2192,localhost:2193 advertised.listeners=PLAINTEXT://47.107.44.224:9011 listeners=PLAINTEXT://172.17.50.121:9011 app/kafka/config/server2.properties\nbroker.id=2 log.dirs=/home/software/kafka/logs2 zookeeper.connect=localhost:2191,localhost:2192,localhost:2193 advertised.listeners=PLAINTEXT://47.107.44.224:9012 listeners=PLAINTEXT://172.17.50.121:9012 app/kafka/config/server3.properties\nbroker.id=3 log.dirs=/home/software/kafka/logs3 zookeeper.connect=localhost:2191,localhost:2192,localhost:2193 advertised.listeners=PLAINTEXT://47.107.44.224:9013 listeners=PLAINTEXT://172.17.50.121:9013   启动\nkafka-server-start.sh kafka/config/server1.properties \u0026amp; kafka-server-start.sh kafka/config/server2.properties \u0026amp; kafka-server-start.sh kafka/config/server3.properties \u0026amp;   检验\n# 创建一个topic kafka-topics.sh --create --zookeeper localhost:2191,localhost:2192,localhost:2193 --replication-factor 1 --partitions 1 --topic testing # 查看topic list kafka-topics.sh --list --zookeeper localhost:2192 # 运行生产者 kafka-console-producer.sh --broker-list localhost:9011,localhost:9012,localhost:9013 --topic testing #运行消费者 kafka-console-consumer.sh --bootstrap-server localhost:9011 --topic testing --from-beginning   ","permalink":"/zh-cn/posts/distributed/hbase%E5%9F%BA%E7%A1%80/","series":["Hbase"],"tags":["Hbase","Hadoop","ZooKeeper"],"title":"Hbase基础"},{"categories":["redis"],"content":"本文介绍了redisApi以及数据结构\nRedis的API以及数据结构详解 数据结构和内部编码 面向接口编程的思想\nredisObject   type（对外的数据类型）\n  encoding（内部编码方式）\n  ptr（数据指针）\n  vm（虚拟内存）\n  string（二进制安全） 特性：可以包含任何数据，图片或者序列化对象，一个键最大存储512m\n  raw\n  int\n  embstr\n  hash（键值对集合，即map类型） 特性：适合存储对象，并且可以像数据库的update一样，只修改某一个属性值\n使用场景：存储，读取，修改用户属性\n  hashtable\n  ziplist\n  list（双向链表） 特性：增删快，提供了操作某一段元素的API\n使用场景：消息队列，排行榜\n  linkedlist\n  ziplist\n  set（哈希表，元素不重复） 特性：添加，删除，查找的复杂度都是O1；提供了集合运算的API\n使用场景：利用唯一性，统计访问网站的独立ip；好友推荐时，标签交集达到阈值就推荐\n  hashtable\n  intset\n  zset（将set中的元素增加一个score，元素按score有序排列） 特性：数据插入时，已经进行天然排序\n使用场景：排行榜；带权重的消息队列\n  skiplist\n  ziplist\n  redis单线程 特点：   在一个时间只会进行一个操作\n  拒绝长（慢）命令：\n  keys,flushall,flushdb,show lua script,mutil/exec,operate big value(collection)\n 有些命令会启新的线程：  fysnc file descriptor,close file descriptor\nredis使用单线程的原因：   纯内存\n  非阻塞IO\n  避免线程切换和竞态消耗\n  字符串 键值结构   key：字符串\n  value：字符串，整型，json串，位图\n  使用场景   缓存\n  计数器\n  分布式锁\n  API   get key，获取key对应的value (O1)\n  set key value，设置key-value (O1)\n  del key，删除 key-value (O1)\n  incr key，key自增1 (O1)\n  decr key，key 自减1 (O1)\n  incrby key k ，key 自增 k (O1)\n  decrby key k，key 自减 k (O1)\n  实战  记录网站每个用户个人主页的访问量  incr userid：pageview\n缓存视频的基本信息(数据源在MySQL中)  public VideoInfo get(long id){ String redisKey = redisPrefix + id;//定义一个rediskey  VedeoInfo vedeoInfo = redis.get(redisKey); if(videoInfo == null){ videoInfo = mysql.get(id); if(videoInfo != null){ redis.set(key=redisKey,value=serialize(videoInfo)); } } } 分布式id生成器  多个服务并发获取自增id\nincr id\n其他命令   set key value，不管key是否存在，都设置 (O1)\n  setnx key value，key不存在，才设置（add操作）(O1)\n  set key value xx，key存在，才设置（update 操作） (O1)\n  setex key seconds value，set key value + EXPIRE key seconds (O1)\n  mget k1 k2 \u0026hellip; kn,批量获取key，原子操作（On）\n  mset k1 v1 k2 v2 \u0026hellip;,批量设置key-value（On）\n  getset key newvalue，设置新的value，并返回旧的value（O1）\n  append key value，将value追加到旧的value中（O1）\n  strlen key，返回字符串的长度（O1）\n  incrbyfloat key -1，增加key对应的值 -1.0（O1）\n  getrange key start end，获取key对应value的指定下标的字符，（O1）\n  setrange key index value，设置key对应的value，指定index下标的字符换成 value （O1）\n  哈希 键值结构 key\nfield:value ：是很多的键值对\n#key： userid：1 #field:value email:xxxx@xx.com name:euraxluo Password:sasasasasa id:1 中存储一个个属性值以及对应的value\n和string比较 string要实现这个方式，需要把这些键值对序列化后存到redis中，取出来的时候也要反序列化。并且属性是空值，也要序列化进去，但是我们的哈希中，如果这个属性没有，可以不写\n特点   在value中，存储了一个更小的redis\n  field不能相同，value可以相同\n  API   hget key field，获取hash key 对应的field的value （O1）\n  hset key field value，设置hash key 对应的field的value（O1）\n  hdel key field,删除hash key 对应field的value（O1）\n  hexists key field，判断hash key 是否有field（O1）\n  hlen key ,获取hash key field的数量（O1）\n  hmset key field1 value1 field2 value2 \u0026hellip;fieldN valueN，批量设置hash key 的一批field value（On）\n  hmget key field1 field2 ..fieldN,批量获取hash key 的一批field的值（O1）\n  实战  记录每个用户主页的访问量  hash key为user:1:info的数据，为pageview属性设置自增\nhincriby user:1:info pageview count\n缓存视频的基本信息  public VideoInfo get(long id){ String redisKey = redisPrefix + id;//定义一个rediskey  Map\u0026lt;String,String\u0026gt; hashMap = redis.hgetAll(redisKey); VideoInfo videoInfo = transformMapToVideo(hashMap); if(videoInfo == null){ videoInfo = mysql.get(id); if(videoInfo != null){ redis.hmset(key=redisKey,value=transformVideoToMap(videoInfo)); } } } 其他命令   hgetall key，返回hash key对应的所有field和value（On）\n  hvals key，返回hash key对应的所有field的key（On）\n  hkeys key，返回hash key 对应的所有field （On）\n  hsetnx key field value,设置hash key对应的field的value，如field已经存在，则失败（O1）\n  hinrcby key field intCounter，hash key对应的field的value自增intCount（O1）\n  hinrcbyfloat key field floatCount，hincrby浮点数（O1）\n  列表 键值结构 key-value（有序队列）\n可以从左右两端进行添加，弹出\n特点   有序\n  可以重复\n  左右两边插入弹出\n  API  rpush key v1 v2 \u0026hellip; vn,从列表右端插入值（1~n） （O1-On）   vn ... v3 v2 v1\n  linsert key before|after value newValue,在list指定的值前|后插入newValue（O1-On）\n  lpop key，从左边弹出一个item（O1）\n  rpop key，从右边弹出一个item（O1）\n  lrem kay count value，根据count的值，从列表中删除|count|个和value的值相等的项，count\u0026gt;0表示从左到右（On）\n  ltrim key start end，保留start-end索引范围的列表项（On）\n  lrange key start end ，获取列表指定索引范围的全部item，包含end（On）\n  lindex key index，获取列表指定索引的item（On）\n  llen key，获取列表长度（O1）\n  lset key index newValue，设置列表指定索引的项为newValue（On）\n  实战  时间轴功能  有你关注的人更新了微博：lpush\n时间轴是一个lrange的结果\n微博是一个个对象，可以存放在hashmap或者string中\nlpush中存储了对象中的关键uid，可以通过关键的uid，去取微博内容\n其他命令   blpop keys timeout,依次检查ksys，弹出第一个非空列表的头元素，当没有任何元素时，连接被阻塞，直到等待超时（timeout），或者发现可弹出元素为止（O1）\n  blpop keys timeout,依次检查ksys，弹出第一个非空列表的右边元素，当没有任何元素时，连接被阻塞，直到等待超时（timeout），或者发现可弹出元素为止（O1）\n  TIPS   LPUSH + LPOP = Stack，左入左出是栈\n  LPUSH + RPOP = Queue，左入右出是队列\n  LPUSH + LTRIM = Capped Collection，限制长度的列表\n  LPUSH + BRPOP = Message Queue，左入阻塞式右出是消息队列\n  集合 键值结构 key：string\nvalue：集合\n特点   无序\n  无重复\n  集合间操作\n  API   sadd key elements，向集合kay添加elements，返回添加成功数（O1）\n  srem key elements，将集合kay中的elements移除掉，返回移除成功数（O1）\n  scard key，返回集合大小（O1）\n  sismember key elements，判断elements是否在集合中（O1）\n  srandmenmber key count，从集合key中挑出count个元素，不会删掉这些元素（O1~On）\n  spop key ，从集合中随机弹出一个元素（O1）\n  smembers key，无序返回集合中的所有元素（On）\n  sscan key cursor count，增量式迭代从cursor开始迭代，返回count个结果。返回值是一个数组，第一个元素，指示了下一次迭代的游标，如果为0，完全迭代。第二个元素是迭代结果\n  实战   抽奖系统，把参与了这个抽奖的用户放进这个集合\n  赞，踩，转发，把参与了这个操作的用户放进这个新闻的集合中\n  tag，用户标签，可以把用户的标签放进集合中，也可以把用户放进这个标签对应的集合中，这两个是一个事务\n  集合运算API   sdiff key1 key2,差集\n  sinter key1 key2，交集\n  sunion key1 key2，并集\n  sdiff|sinter|sunion + store destkey,将运算结果保存在destkey中，下次就可以不用计算了\n  TIPS SADD = Tagging，可以用类做标签\nSPOP/SRANDMEMBER = Random item，可以用来做随机的场景\nSADD + SINTER = Social Graph，可以用来做社交的场景\n有序集合 键值结构 key：string\nvalue： score:value\n按照score进行排序\n特点 无重复元素\n按照score排序\nvalue中存储着element+score\nAPI   zadd key score element[score element\u0026hellip;]，添加score和element，score可以重复（OlogN）\n  zrem key elements，删除元素 (O1)\n  zscore key element，获取key中element对应的分数（O1）\n  zincrby key increScore element，为key中element对应的score加increScore（O1）\n  zcard key，返回key中的元素个数（O1）\n  zrange key start stop [WITHSCORES]，返回key中排序结果start~end的升序结果，是否和score一起输出（O log(N)+m,N:元素个数,m:end-start）\n  zrangebyscore key minScore maxScore [WITHSCORES],返回key中score在minScore~maxScore范围的结果（O log(N)+m,N:元素个数）\n  zcount key minScore maxScore，返回有序集合中，在指定分数范围内的个数 （O log(N)+m,N:元素个数）\n  zremrangebyrank key start end，删除指定排名内的升序元素（O log(N)+m,N:元素个数,m:end-start）\n  zremrangebyscore key minScore maxScore，删除指定分数范围内的升序元素（O log(N)+m,N:元素个数）\n  实战  排行榜  score可以是时间戳，销售数，点赞数\n其他API   zrevrank key，返回从高到低的排名 （OlogN）\n  zrevrange key start end [withscore]，从降序的结果中按照start~end返回结果，（O log(N)+m,N:元素个数,m:end-start）\n  zrevrangebyscore，从降序的结果中按照分数返回结果，（O log(N)+m,N:元素个数,m:end-start）\n  zinterstore destination numkeys key[key\u0026hellip;]，计算给定的一个或多个有序集的交集，其中给定 key 的数量必须以 numkeys 参数指定，并将该交集(结果集)储存到 destination 。默认结果集中某个成员的 score 值是所有给定集下该成员 score 值之和.（O(NK)+O(Mlog(M))， N 为给定 key 中基数最小的有序集， K 为给定有序集的数量， M 为结果集的基数。）\n  zunionstore destination numkeys key[key\u0026hellip;]，计算给定的一个或多个有序集的并集，其中给定 key 的数量必须以 numkeys 参数指定，并将该并集(结果集)储存到 destination 。默认结果集中某个成员的 score 值是所有给定集下该成员 score 值之 和 。（O(NK)+O(Mlog(M))， N 为给定 key 中基数最小的有序集， K 为给定有序集的数量， M 为结果集的基数。）\n ","permalink":"/zh-cn/posts/redis/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","series":["redis"],"tags":["redis"],"title":"Redis API及数据结构"},{"categories":["redis"],"content":"Redis Cluster 背景   并发量 \u0026lt;10万dps\n  数据量 单机内存\u0026lt;256G\n  带宽 网卡限制\n  解决方式   提高机器配置\n  分布式\n  数据分布 | 分布方式 | 特点 | 典型产品 |\n| \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026ndash; |\n| 哈希分布 | 数据分散度高数据分布业务无关无法顺序访问支持批量操作 | 一致性哈希MemcacheRedis Cluster缓存产品 |\n| 顺序分布 | 数据分散度易倾斜键值业务相关可顺序访问支持批量操作 | BigTableHBase |\n哈希分布  节点取余：hash(key)%nodes    客户端分片：哈希+取余\n  节点扩容：扩容时需要数据迁移\n  翻倍扩容：扩容时最好多倍扩容\n  一致性哈希  有一个token环，节点在token环上，会为每个key分配一个token，在依据token在环上顺时针寻找最近的节点\n  客户端分片：哈希+顺时针选择节点\n  节点伸缩：扩容时减少影响的范围\n  翻倍伸缩：保证最小迁移数据和保证负载均衡\n  虚拟槽分区   预设虚拟槽：每个槽映射一个数据子集，一般比节点数大\n  良好的哈希函数：CRC16\n  服务端管理节点，槽，数据：例如Redis Cluster\n  搭建集群 Redis Cluster架构   节点，很多节点，都负责读写\n  meet，使用raft协议，是互相通信的基础\n  指派槽，把节点指派槽，才能正常读写\n  复制，保证高可用\n  安装 配置安装 节点配置 port ${port} daemonize yes dir \u0026#34;path/to/run\u0026#34; dbdilename \u0026#34;dump-${port}.rdb\u0026#34; logfile \u0026#34;${port}.log\u0026#34; cluster-enabled \u0026lt;yes/no\u0026gt;: 使redis实例作为集群的一个节点 cluster-config-file nodes-${port}.conf: 集群配置文件 cluster-require-full-coverage no,部分节点不可用，依然提供服务 meet操作 cluster meet ip port\n当前节点开启meet\nredis-cli -h 127.1 -p 7000 cluster meet 127.1 7001 redis-cli -h 127.1 -p 7000 cluster meet 127.1 7002 redis-cli -h 127.1 -p 7000 cluster meet 127.1 7003 redis-cli -h 127.1 -p 7000 cluster meet 127.1 7004 redis-cli -h 127.1 -p 7000 cluster meet 127.1 7005 Cluster 配置详解   cluster-enabled \u0026lt;yes/no\u0026gt;: 使redis实例作为集群的一个节点\n  cluster-config-file nodes-${port}.conf: 集群配置文件\n  cluster-node-timeout \u0026lt;milliseconds\u0026gt;: 这是集群中的节点能够失联的最大时间，超过这个时间，该节点就会被认为故障。如果主节点超过这个时间还是不可达，则用它的从节点将启动故障迁移，升级成主节点。注意，任何一个节点在这个时间之内如果还是没有连上大部分的主节点，则此节点将停止接收任何请求。\n  cluster-slave-validity-factor \u0026lt;factor\u0026gt;: 如果设置成０，则无论从节点与主节点失联多久，从节点都会尝试升级成主节点。如果设置成正数，则cluster-node-timeout乘以cluster-slave-validity-factor得到的时间，是从节点与主节点失联后，此从节点数据有效的最长时间，超过这个时间，从节点不会启动故障迁移。假设cluster-node-timeout=5，cluster-slave-validity-factor=10，则如果从节点跟主节点失联超过50秒，此从节点不能成为主节点。注意，如果此参数配置为非0，将可能出现由于某主节点失联却没有从节点能顶上的情况，从而导致集群不能正常工作，在这种情况下，只有等到原来的主节点重新回归到集群，集群才恢复运作。\n  cluster-migration-barrier \u0026lt;count\u0026gt;:主节点需要的最小从节点数，只有达到这个数，主节点失败时，它从节点才会进行迁移。更详细介绍可以看本教程后面关于副本迁移到部分。\n  cluster-require-full-coverage \u0026lt;yes/no\u0026gt;:在部分key所在的节点不可用时，如果此参数设置为”yes”(默认值), 则整个集群停止接受操作；如果此参数设置为”no”，则集群依然为可达节点上的key提供读操作。\n  分配槽 cluster addslots slot [slot ...]\n分配槽，一共6个节点，三主三从：\nredis-cli -h 127.1 -p 7000 cluster addslots {0...5461} redis-cli -h 127.1 -p 7001 cluster addslots {5462...10922} redis-cli -h 127.1 -p 7002 cluster addslots {10923...16383} 使用脚本来分配槽\nstart=$1 end=$2 port=$3 for slot in `seq ${start} ${end}` do echo \u0026#34;slot:${slot}\u0026#34; redis-cli -p ${port} cluster addslots ${slot} done if [${end}==16383] then redis-cli -p ${port} cluster info fi 设置主从 cluster replicate node-id设置不会更改的node-id\n设置从节点去复制主节点\nredis-cli -h 127.1 -p 7003 cluster replicate ${node-id-7000} redis-cli -h 127.1 -p 7004 cluster replicate ${node-id-7001} redis-cli -h 127.1 -p 7005 cluster replicate ${node-id-7002} 使用脚本分配主从\na=$1 b=$2 c=$3 d=$4 master_arr=($(seq ${a} 1 ${b})) slave_arr=($(seq ${c} 1 ${d})) for index in `seq 0 $(( ${#master_arr[*]}-1))` do nodeid=`redis-cli -p ${slave_arr[index]} cluster nodes |grep ${master_arr[index]}` redis-cli -h 127.1 -p ${slave_arr[index]} cluster replicate ${nodeid:0:41} done 最好把主从端口配置在文件中，通过脚本读取运行\n工具安装 ruby环境安装  下载ruby  wget https://cache.ruby-lang.org/ruby/2.3/ruby-2.3.1.tar.gz\n 安装ruby  tar -xvf ruby-2.3.1.tar.gz ./configure -prefix=/usr/local/ruby make make install cd /usr/local/ruby cp bin/ruby /usr/local/bin  安装rubygem redis  wget http://rubygems.org/downloads/redis-3.3.0.gem gem install -l redis-3.3.0.gem gem list --check redis gem  安装redis-trib.rb  cp ${REDIS_HOME}/src/redis-trib.rb /usr/local/bin\n通过redis-trib搭建集群  配置开启redis节点  redis-server redis-8000.conf redis-server redis-8001.conf redis-server redis-8002.conf redis-server redis-8003.conf redis-server redis-8004.conf redis-server redis-8005.conf 一键开启集群  ./redis-trib.rb creat --replicas 1{每个master的slave数量} [ip：port...]{前面都是master，后面的都是slave}\n","permalink":"/zh-cn/posts/redis/rediscluster-1/","series":["redis"],"tags":["redis"],"title":"Redis Cluster"},{"categories":["redis"],"content":"集群伸缩 伸缩原理 伸：增加节点 缩：节点下线\n集群伸缩：槽和数据在节点之间的移动\n扩容集群  准备新节点    打开集群模式\n  配置和其他节点统一\n  启动后是孤立的节点\n  加入集群meet    在集群节点中配置：cluster meet 127.1 \u0026lt;newnodeport\u0026gt;\n  使用redis-trib.rb：\n  redis-trib.rb ad-node new_host:new_port existing_host:existing_port --slave --master_id \u0026lt;arg\u0026gt;{扩展参数是配置为从节点}\n  为它迁移槽和数据可以实现扩容\n  可以作为从节点负责故障转移\n  迁移槽和数据    1). 对目标节点发送cluster setslot \u0026lt;slot\u0026gt; importing \u0026lt;sourceNodeId\u0026gt;,让目标节点准备导入槽的数据\n  2). 对源节点发送cluster setslot \u0026lt;slot\u0026gt; migrating \u0026lt;targetNodeId\u0026gt;,让源节点准备迁出槽\n  3). 源节点循环执行cluster getkeysinslot \u0026lt;slot\u0026gt; \u0026lt;count\u0026gt;,每次获取count个属于槽的键\n  4). 在源节点上执行migrate \u0026lt;targetIp\u0026gt; \u0026lt;targetPort\u0026gt; key 0{对应数据库，master只有db0} \u0026lt;timeout\u0026gt;,死循环，知道所有的key迁移完成\n  5). 重复执行3)~4)知道槽下所有的key迁移到目标节点\n  6). 向集群中的所有主节点发送cluster setslot \u0026lt;slot\u0026gt; node \u0026lt;targetNode\tId\u0026gt;,通知槽已经重新分配给目标节点\n  伪代码：\n  def move_slot(source,target,slot): #目标节点准备导入槽 target.cluster(\u0026#34;setslot\u0026#34;,slot,\u0026#34;importing\u0026#34;,source,nodeID); #源节点准备导出槽 source.cluster(\u0026#34;setslot\u0026#34;,slot,\u0026#34;migrating\u0026#34;,target,nodeId); while true: #批量从源节点获取key keys = source.cluster(\u0026#34;getkeysinslot\u0026#34;,slot,pipeline_size) if keys.length == 0 #键列表为空，退出循环 break #批量迁移key到目标节点 source.call(\u0026#34;migrate\u0026#34;,target.host,target.port,\u0026#34;\u0026#34;,0,timeout,\u0026#34;keys\u0026#34;,[keys]) #向集群所有主节点通知槽slot被分配给目标节点 for node in nodes: if node.flag == \u0026#34;slave\u0026#34;: continue node.cluster(\u0026#34;setslot\u0026#34;,slot,\u0026#34;node\u0026#34;,target.nodeId)  在集群中添加两个节点7006，7007，7007 slaveof 7006  #生成配置 sed \u0026#39;s/7000/7006/g\u0026#39; redis-7000.conf \u0026gt; redis-7006.conf sed \u0026#39;s/7000/7007/g\u0026#39; redis-7000.conf \u0026gt; redis-7007.conf #启动孤立节点 redis-server redis-7006.conf redis-server redis-7007.conf #加入集群 redis-cli -p 7000 cluster meet 127.1 7006 redis-cli -p 7000 cluster meet 127.1 7007 #配置主从 redis-cli -p 7007 cluster replicate \u0026lt;7006.nodeId\u0026gt; #reshard redis-trib.rb reshard 127.1:7000 #输入迁移槽个数 #输入目标节点Id #选择all或者done，确定源node #是否继续 #查看分配的slot的结果 redis-cli -p 7000 cluster nodes |grep master 缩容集群  下线迁移槽   下线7006，7007  #添加节点时，7006从三个node上获取槽，因此槽分为三段 #迁移槽 redis-trib.rb reshard --from \u0026lt;7006.nodeId\u0026gt; --to \u0026lt;7000.nodeId\u0026gt; --slots \u0026lt;slotsNums\u0026gt; \u0026lt;127.1:7006\u0026gt;{在哪一个端口执行} #同意迁移计划 redis-trib.rb reshard --from \u0026lt;7006.nodeId\u0026gt; --to \u0026lt;7001.nodeId\u0026gt; --slots \u0026lt;slotsNums\u0026gt; \u0026lt;127.1:7006\u0026gt;{在哪一个端口执行} #同意迁移计划 redis-trib.rb reshard --from \u0026lt;7006.nodeId\u0026gt; --to \u0026lt;7002.nodeId\u0026gt; --slots \u0026lt;slotsNums\u0026gt; \u0026lt;127.1:7006\u0026gt;{在哪一个端口执行} #同意迁移计划 忘记节点   忘记7006，7007  #忘记节点,先下线从节点 redis-trib.rb del-node 127.1:7000 \u0026lt;7007.nodeId\u0026gt; #忘记节点,再下线主节点 redis-trib.rb del-node 127.1:7000 \u0026lt;7006.nodeId\u0026gt; ","permalink":"/zh-cn/posts/redis/rediscluster-2/","series":["redis"],"tags":["redis"],"title":"Redis Cluster"},{"categories":["redis"],"content":"RedisCluster 客户端使用 moved重定向   对任意节点发送键命令\n  节点会计算槽和对应节点确定这个键是否指向自身\n  如果指向自身，就执行命令，返回key所在的槽\n  否则就回复moved异常，客户端拿到这个moved后，重定向节点，重新发送命令\n  ASK重定向 解决槽迁移时客户端的查询问题\n  对源节点发送键命令\n  节点发现正在进行槽迁移，回复客户端ask转向\n  客户端对目标节点Asking，发送命令\n  目标节点返回响应结果\n  两者的区别   两者都是客户端重定向\n  moved：槽已经确定迁移\n  ask：槽还在迁移中\n  smart客户端 目标：追求性能（不能使用代理模式）\n  从集群中选取一个可运行节点，使用cluster slots 初始化槽和节点映射\n  将cluster slots的结果映射到本地，为每个节点都创建一个连接池\n  准备执行命令\n  执行命令   通过key哈希模16383，得到slot，通过本地映射得到节点，再通过连接池去连接\n  如果连接出错，可能槽迁移，也可能是连接异常，如果槽迁移，那么\n  我们随机访问一个活跃节点，节点会返回moved异常\n  我们得到槽迁移的结果，更新我们的slot和nodes的映射（确定槽迁移）\n  然后再去连接目标节点\n  如果命令发送多次未成功，显示异常Too many cluster redirection\n  jiedisCluster使用 Set\u0026lt;HostAndPort\u0026gt; nodeList = new HashSet\u0026lt;HostAndPort\u0026gt;(); nodeList.add(new HostAndPort(HOST1,PORT1)); nodeList.add(new HostAndPort(HOST2,PORT2)); nodeList.add(new HostAndPort(HOST3,PORT3)); nodeList.add(new HostAndPort(HOST4,PORT4)); nodeList.add(new HostAndPort(HOST5,PORT5)); nodeList.add(new HostAndPort(HOST6,PORT6)); JedisCluster redisCluster = new JedisCluster(nodeList,timeout,poolConfig); TIPS   单例：内置了所有节点的连接池，并可以用来做故障转移\n  无需手动借还连接池\n  合理设置commons-pool\n  整合spring //工厂  import redis.client.jedis.JedisCluster; public class JedisClusterFactory{ private JedisCluster jedisCluster; private List\u0026lt;String\u0026gt; hostPoetList; private int timeout; private Logger logger = LoggerFactory.getLogger(JedisClusterFactory.class) public void init(){ JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); Set\u0026lt;HostAndPort\u0026gt; nodeSet = new HashSet\u0026lt;HostAndPort\u0026gt;(); for(String hostPort:hostPortList){ String[] arr = hostPort.split(\u0026#34;:\u0026#34;); if(arr.length != 2){ continue; } nodeSet.add(new HostAndPort(arr[0],Integer.parseInt(arr[1]))); } try{ jedisCluster = new JedisCluster(nodeSet,timeout,jedisPoolConfig); }catch(Exception e){ logger.error(e.getMessage(),e); } } public void destroy(){ if(jedisCluster != null){ try{ jedisCluster.close(); }catch(IOException e){ logger.error(e.getMessage(),e); } } } public JedisCluster getJedisCluster(){ return jedisCluster; } public void setHostPortList(List\u0026lt;String\u0026gt; hostPortList){ this.hostPortList = hostPortList; } public void setTomeout(int timeout){ this.timeout = timeout; } } \u0026lt;bean id=\u0026#34;jedisClusterFactory\u0026#34; class=\u0026#34;path/to/factoryClass\u0026#34; init-method=\u0026#34;init\u0026#34; destory-method=\u0026#34;destory\u0026#34;\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;jedisCluster\u0026#34; factory-bean=\u0026#34;jedisClusterFactory\u0026#34; factory-method=\u0026#34;getJedisCluster\u0026#34;\u0026gt; \u0026lt;/bean\u0026gt; 多节点命令实现 伪代码\nMap\u0026lt;String,JedisPool\u0026gt; jedisPoolMap = jedisCluster.getClusterNodes(); for(Entry\u0026lt;String,JedisPool\u0026gt;entry:jedisPoolMap.entrySet()){ //获取每个节点的Jedis连接  Jedis.jedis = entry.getValue().getResource(); //只删除主节点数据  if(!isMater(jedis)){ continue; } //finally close  } Redis Cluster的故障转移 其他主节点对集群进行监控\n故障发现   通过ping/pong 消息实现故障发现，不需要sentinel\n  主观下线：某个节点认为另一个节点不可用\n  客观下线：当半数以上持有槽的主节点都标记为某节点主管下线\n  故障恢复   从节点资格检查\n1). 每个从节点坚检查与故障主节点的断线时间\n2). 超过cluster-node-timeout*cluster-slave-validity-factory就取消资格\n3). cluster-slave-validity-factory默认为10\n  准备选举时间\n1). 给偏移量最大的节点最长的选举时间\n2). 把最接近master节点的从节点的选举延迟时间设置为最短\n  选举投票\n1). 收集到master节点数/2+1票就可以替换主节点\n  替换主节点\n1). slaveof no one当前从节点取消复制变为主节点\n2). 执行clusterDelSlot撤销故障主节点负责的槽,并执行clusterAddSlot把这些槽分配给自己\n3). 向集群中广播自己的pong消息,表明自己已经替换了故障从节点\n  RedisCluster开发运维 集群完整性   cluster-require-full-converge默认为yes\n集群中16384个槽全部可用：保证集群完整性\n节点故障或者正在故障转移，集群下线(error)CLUSTERDOWN The cluster is down\n  大多数业务无法容忍，cluster-require-full-converge设置为no\n  带宽   消息发送频率：节点发现与其他节点最后通信时间超过cluster-node-timeout会直接发送ping消息\n  消息数据量:slots槽数组（2KB空间）和整个集群1/10的状态数据（10个节点状态数据约1kb）\n  节点部署的机器规模：集群分布的机器越多且每台机器划分的节点数越均匀，则集群内整体的可用带宽越高\n  优化   避免大集群：避免多业务使用一个集群，大业务可以多集群\n  cluster-node-timeout：和带宽和故障转移速度都有关，需要均衡\n  尽量均匀分配到多机器上，保证高可用和带宽\n  Pub/Sub广播  publish在集群中每个节点广播：加重带宽  优化  如果需要Pub/Sub，单独开启一套Redis Sentinel  集群倾斜 数据倾斜：内存在每个节点中分布不均   节点和槽分配不均\n1). redis-trib.rb info ip:port查看节点，槽，键值分布\n2). redis-trib.rb rebalance ip:port进行均衡\n  不同槽对应键值数量差异较大\n1). CRC16正常情况下比较均匀\n2). 可能存在hash_tag\n3). cluster countkeysinslot {slot}获取槽对应键值个数\n  包含bigkey\n1). 在从节点运行redis-cli --bigkeys\n2). 优化：优化数据结构\n  内存相关配置不一致（例如每个节点哈希优化不一致）\n1). hash-max-ziplist-value,set-max-intset-entries的配置\n2). 定期检查配置的一致性\n  客户端缓冲区大小\n  哈希表大小\n  请求倾斜：某些节点访问量很高   热点key：重要的key或则bigkey\n1). 避免bigkey\n2). 热键不要用hash_tag\n3). 当一致性需求不高时，可以使用本地缓存+MQ\n  读写分离   只读连接：集群模式的从节点不接受任何读写请求\n1). 在从节点get会重定向到负责槽的主节点\n2).readonly命令可以读：连接连接命令\n  读写分离：更加复杂\n1). 同样的问题：复制延迟，读取过期数据，从节点故障\n2). 修改客户端：cluster slaves {nodeId}\n3). 不建议使用\n  数据迁移   官方迁移工具：redis-trib.rb import --from ip:port{源节点} --copy ip:port{集群节点}\n1).只能从单机迁移到集群\n2).不支持在线迁移：source需要停写\n3).不支持断点续传\n4).单线程迁移：影响速度\n  在线迁移\n有一个中转站，这个中转站会伪装成slave节点去拿到全量更新数据\n1).redis-migrate-tool，唯品会\n2).redis-port，豌豆荚\n  集群vs单机   集群的限制\n1). key批量操作支持有限，mget，mset必须在一个slot\n2). key事务和lua支持有限：操作的key必须在一个节点\n3). key时数据库分区的最小粒度：不支持bigkey分区\n4). 不支持多个数据库：集群模式下只有一个db 0\n5). 复制只支持直接复制，不能更改复制的拓扑结构（树）减小压力\n  Redis Cluster：满足容量和性能的扩展性，很多业务不需要\n1). 客户端性能会降低\n2). 命令无法跨节点用：mget。keys，scan，flush，sinter等\n3).Lua和事务无法跨节点使用\n4).客户端维护复杂\n  Redis Sentinel：满足高可用\n  总结   Redis Cluster的分区规则\n  搭建集群的步骤\n  集群伸缩的步骤\n  smart客户端操作redis集群\n  集群自动故障转移\n  ","permalink":"/zh-cn/posts/redis/rediscluster-3/","series":["redis"],"tags":["redis"],"title":"Redis Cluster 3"},{"categories":["redis"],"content":"Redis Sentinel 主从复制的问题   手动故障转移\n  写能力和存储能力受限\n  Redis Sentinel架构   有多个Sentinel节点\n  不用来存储数据\n  多个节点判断master节点的故障，进行故障转移\n  保证高可用，即便一个Sentinel节点挂点也没事\n  客户端只会记录sentinel的地址（因为sentinel会进行故障转移，master节点地址不固定）\n  一套sentinel可以监控多套master-slave，利用master-name作为标识\n  Sentinel的故障转移   多个sentinel发现并确认master有问题\n  选举出一个sentinel作为领导\n  选出一个slave作为新的master\n  通知其余slave成为新的master的slave\n  通知客户端主从变化\n  等待老的master复活成为新的master的slave\n  安装与配置 主从配置：\nsed \u0026quot;s/6380/6381/g\u0026quot; redis-6380.conf \u0026gt; redis-6381.conf\n查看：\ncat redis-6381.conf|grep -v \u0026quot;#\u0026quot; |grep -v \u0026quot;^$\u0026quot;\nSentinel配置\nport ${port} dir \u0026#34;\u0026#34; logfile \u0026#34;${port}.log\u0026#34; sentinel monitor mastername 127.1 port{主节点端口} 2{故障发现个数} #判断失败时间 30000毫秒 sentinel down-after-milliseconds mastername 30000 #并发度 sentinel parallel-syncs mastername 1 sentinel failover-timeout mastername 180000 客户端与sentinel连接 高可用   服务端高可用\n  客户端高可用\n  实现原理   获取全部的sentinel节点\n  我需要给sentinel我想连接的mastername\n  遍历sentinel节点集合，获取一个可用的sentinel节点\n  通过APIget-master-addr-by-name来获取真正的master节点地址\n  通过role/role replication验证得到的master节点是否是真正的master\n  jedisAPI JedisSentinelPool sentinelPool = new JedisSentinelPool(masterName,sentinelSet,poolConfig,timeout); Jedis jedis = null; try{ jedis = redisSentinelPool.getResource(); }catch(Exception e){ logger.error(e.getMessage(),e); }finally{ if(jedis != null) jedis.close(); } redis-py from redis.sentinel import Sentinel sentinel = Sentinel([(\u0026#34;localhost\u0026#34;,26379),(\u0026#34;localhost\u0026#34;,26380),(\u0026#34;localhost\u0026#34;,26381)],socket_timeout=0.1) #获取主节点ip sentinel.discover_master(\u0026#39;mymaster\u0026#39;) #获取从节点ip sentinel.discover_slaves(\u0026#39;mymaster\u0026#39;) 如果你的Redis一直杀不死   检查是否开了守护进程\n  检测使用kill -9 能否杀死\n  关闭守护进程，利用/etc/init.d/redis-sentinel stop进行关闭\n  故障转移 from redis.sentinel import Sentinel as St import redis as rd import time st = St([(\u0026#34;localhost\u0026#34;,26379),(\u0026#34;localhost\u0026#34;,26379),(\u0026#34;localhost\u0026#34;,26379)],socket_timeout=0.1) key = \u0026#34;master\u0026#34; i = 0 while(True): try: masterhost,masterport = st.discover_master(\u0026#39;mymaster\u0026#39;) i +=1 time.sleep(1) client = rd.StrictRedis(host=masterhost,port=masterport) setResult = client.set(key,\u0026#34;value: %d\u0026#34;%i) time.sleep(1) if i%3==0: print(client.get(key)) except Exception as e: print(e) 运行这个程序后，kill -9 掉master\n查看脚本的输出，最后查看sentinel和各个server的日志\ntail -f redis-sentinel-26379.log\n我们可以看到，投票，重写配置，主从辅助，部分复制等等一系列的过程\nsentinel的定时任务  每10秒每个sentinel对master和slave执行info命令    发现slave节点\n  确定主从关系\n  每2秒每个sentinel通过master节点的channel交换信息（是不是把master作为一个频道，那如果master挂掉了怎么办）    通过__sentinel__:hello频道交换信息\n  交互对节点的看法和自身的信息\n  3.每1秒每个sentinel对其他sentinel和redis执行ping\n  心跳检测，失败判定依据\n  是故障检测的基础\n  主观下线 每个sentinel节点对Redis节点失败的偏见\nsentinel down-after-milliseconds mastername 30000{超过多久未收到回复}\n客观下线 所有sentinel节点对redis节点失败“达成共识”（超过quorum个统一，建议sentinel/2+1）\nsentinel monitor mastername ip port quorum{法定人数}\n故障转移 领导者选举   原因：只有一个sentinel节点完成故障转移\n  选举：通过sentinel is-master-down-by-addr 命令\n    这个命令会发出自己对master的主观判断，并且要求将自己设置为领导者\n  收到命令的sentinel如果没有同意其他sentinel发出的请求，就会同意这个请求，否则拒绝\n  如果sentinel节点超过sentinel集合半数且超过quorum数，那么它将成为领导者\n  如果此过程有多个sentinel节点成为了领导者，那么将等待一段时间重新进行选举\n  sentinel领导者节点实现故障转移   从slave节点中选出一个合适的节点作为新的master\n  对上面的slave节点执行slaveof no one命令让其成为master节点\n  向剩余的slave节点发送命令，让它们成为新master节点的slave节点，复制规则和parallel-syncs参数有关{快速复制还是顺序复制}\n  更新原来的master节点为slave，并对其保持关注，当其恢复后命令他去复制master\n  怎么选择合适的slave节点   选择slave-priority{slava优先级}最高的节点，如果存在返回，不存在继续\n  选择复制偏移量最大的slave节点{复制的最完整}，如果存在返回，不存在继续\n  选择runID最小的slave节点\n  TIPS 节点运维，节点的上下线  节点下线    机器性能不足\n  节点故障\n  机器故障，过保\n  sentinel failover \u0026lt;masterName\u0026gt;,让一个sentinel节点去完成故障转移\n  节点临时下线还是永久下线\n  节点上线    主节点上线，使用sentinel failover\n  从节点上线，slaveof，sentinel节点可以感知\n  sentinel上线，配置sentinel monitor mastername 127.1 port quorum\n  高可用读写分离  从节点的作用    是一个副本，高可用的基础\n  读写分离\n  依赖三个消息用于监控slave节点资源池    +switch-master：切换主节点（从节点晋升主节点）\n  +convet-to-slave：切换从节点（主节点降为从）\n  +sdown：主观下线\n  实际部署   在同一局域网不同物理机部署redis Sentinel节点\n  redis sentinel 的sentinel节点个数最好为奇数，quorum最好是（节点个数/2+1）\n  客户端初始化时连接的是sentinel节点集合，但是sentinel只是配置中心，不是代理模式\n  当客户端监控到switch-master时，会重新进行redis连接初始化\n  ","permalink":"/zh-cn/posts/redis/redissentinel/","series":["redis"],"tags":["redis"],"title":"Redis Sentinel"},{"categories":["redis"],"content":"Redis基础学习 Redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set \u0026ndash;有序集合)和hash（哈希类型）。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。\nRedis 是一个高性能的key-value数据库。 redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部 分场合可以对关系数据库起到很好的补充作用。它提供了Python，Ruby，Erlang，PHP客户端，使用很方便,Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。从盘可以有意无意的对数据进行写操作。由于完全实现了发布/订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。\n安装和基本命令 安装： Ubuntu18.04：sudo apt-get install redis-server\n安装redis后会自动安装redis-cli\n也可以安装图形工具\nsudo snap install redis-desktop-manager\n基本操作  检查Redis服务器系统进程  ps -aux |grep redis\n通过启动命令检查Redis服务器状态  netstat -nlt|grep 6379\n访问Redis  最简启动\nredis-server\n指定配置文件启动\nredis-server config/redis-6380.conf\n验证\nps -ef|grep redis\nnetstat -antpl | grep redis\nredis-cli -h ip -p port ping\n访问\nredis-cli -a euraxluo -h 127.1 -p 6379\n基本命令 0.keys* 时间复杂度是On\nkeys xx?\nkeys xx*\nkeys xx[x-x]*\n1.判断一个key是否存在 O1 exists key\n2.设置key的过期时间O1 expire key seconds#在seconds秒后过期\nttl key#查看key剩余的过期时间\npersist key#去掉key的过期时间\n查看过期时间\n127.1:6380\u0026gt; set k1 v1 OK 127.1:6380\u0026gt; expire k1 20 (integer) 1 127.1:6380\u0026gt; ttl k1 (integer) 14 127.1:6380\u0026gt; ttl k1 (integer) 1 127.1:6380\u0026gt; ttl k1 (integer) -2（-2表示key不存在，已经过期了） 去掉key过期时间\n127.1:6380\u0026gt; set k1 v1 OK 127.1:6380\u0026gt; ttl k1 (integer) -1 127.1:6380\u0026gt; expire k1 20 (integer) 1 127.1:6380\u0026gt; ttl k1 (integer) 18 127.1:6380\u0026gt; persist k1 (integer) 1 127.1:6380\u0026gt; ttl k1 (integer) -1(-1表示key存在，并且没有设置过期时间) 3.查看key的数据类型O1 type key\n4. 添加一条记录 set k1 \u0026#34;helloworld\u0026#34; get k1 5.添加一条数字记录 set k2 1 #让数字自增 incr k2 get k2 6.添加一个列表记录 #添加列表第一个元素 lpush k3 a #在最左边添加第二个元素 lpush k3 b #在最右边添加第三个元素 rpush k3 c #打印这个列表，按从左到右的顺序，规定起点和终点 lrange k3 0 3 7.添加一个哈希记录 #添加name hset k4 name \u0026#34;euraxluo\u0026#34; #添加email hset k4 email \u0026#34;euraxluo@qq.com\u0026#34; #打印key为name的记录的value hget k4 name #获取整个哈希表 hgetall k4 8.给哈希一次一次添加多个值 #一次添加多个k-v HMSET k5 username euraxluo password pwd age 21 #答应哈希表中，key为username，age对应的value HMGET k5 username age #打印完整的哈希表 HGETALL k5 9.删除记录 #查看所有的key列表 keys × #删除k1,k5 del k1 k5 10.其他设置 #使用密码 sudo vi /etc/redis/redis.conf #取消注释requirepass，设置密码为euraxluo requirepass euraxluo #设置远程访问，注释bind #bind 127.0.0.1 #重启redis sudo /etc/init.d/redis-server restart #使用密码，指定host来登录服务器 redis-cli -a euraxluo -h 127.1 python操作redis 参考博客![https://www.cnblogs.com/koka24/p/5841826.html]\nimport redis 连接数据库 try: r = redis.Redis(host=\u0026#39;127.0.0.1\u0026#39;,password=\u0026#39;euraxluo\u0026#39;,port=6379,db=0) r.keys() print(\u0026#34;connected success.\u0026#34;) except: print(\u0026#34;could not connect to redis.\u0026#34;) connected success.\r 通过连接池连接 try: pool = redis.ConnectionPool(host=\u0026#39;127.0.0.1\u0026#39;,password=\u0026#39;euraxluo\u0026#39;,port=6379,db=0) r = redis.Redis(connection_pool=pool) r.keys() print(\u0026#34;connected success.\u0026#34;) except: print(\u0026#34;could not connect to redis.\u0026#34;) connected success.\r 通过python操作redis #bytes to str def b2s(value): return bytes.decode(value) string操作 set(name, value, ex=None, px=None, nx=False, xx=False) \rex，过期时间（秒）\rpx，过期时间（毫秒）\rnx，如果设置为True，则只有name不存在时，当前set操作才执行,同setnx(name, value)\rxx，如果设置为True，则只有name存在时，当前set操作才执行\rr.set(\u0026#39;k2\u0026#39;,\u0026#39;10秒\u0026#39;,10,nx=True)#添加一个记录，过期时间为20秒，如果k2不存在，就执行这个操作 r.psetex(\u0026#39;k3\u0026#39;, 2000, \u0026#39;2000毫秒\u0026#39;)#设置过期时间为毫秒 r.setex(\u0026#39;k1\u0026#39;,2,\u0026#34;2s later\u0026#34;)#过期时间为秒 b2s(r.get(\u0026#39;k3\u0026#39;))#获取值 '2000毫秒'\r 批量添加记录：mset({key:value,*args});批量获取值：mget(key,*args) r.mset({\u0026#39;k7\u0026#39;:\u0026#39;value5\u0026#39;,\u0026#39;k8\u0026#39;:\u0026#39;value6\u0026#39;})#批量添加记录 r.mget(\u0026#39;k1\u0026#39;,\u0026#39;k2\u0026#39;,\u0026#39;k3\u0026#39;,\u0026#39;k4\u0026#39;,\u0026#39;k5\u0026#39;,\u0026#39;k6\u0026#39;,\u0026#39;k7\u0026#39;,\u0026#39;k8\u0026#39;)#批量获取值 [b'2s later',\rb'10\\xe7\\xa7\\x92',\rb'2000\\xe6\\xaf\\xab\\xe7\\xa7\\x92',\rNone,\rNone,\rNone,\rb'value5',\rb'value6']\r getset(name,value) 设置新值，打印旧值 r.getset(\u0026#39;k7\u0026#39;,\u0026#39;new\u0026#39;) b'value5'\r getrange(key, start, end) 根据字节获取子序列 r.getrange(\u0026#39;k8\u0026#39;,0,-2) b'value'\r setrange(name, offset, value) 修改字符串内容，从指定字符串索引开始向后替换，如果新值太长时，则向后添加 r.set(\u0026#34;name\u0026#34;,\u0026#34;zhangsan\u0026#34;) r.setrange(\u0026#34;name\u0026#34;,1,\u0026#34;z\u0026#34;) print(r.get(\u0026#34;name\u0026#34;)) #输出:zzangsan r.setrange(\u0026#34;name\u0026#34;,6,\u0026#34;zzzzzzz\u0026#34;) print(r.get(\u0026#34;name\u0026#34;)) #输出:zzangszzzzzzz b'zzangsan'\rb'zzangszzzzzzz'\r setbit(name, offset, value)对二进制表示位进行操作;getbit(name, offset) 获取name对应值的二进制中某位的值(0或1) \rname，redis的name\roffset，位的索引（将值对应的ASCII码变换成二进制后再进行索引）\rvalue，值只能是 1 或 0\rstr=\u0026#39;123\u0026#39; r.set(\u0026#39;k1\u0026#39;,str) for i in str: print(i,ord(i),bin(ord(i)))#1字符串，ascii码，ascii二进制表示 1 49 0b110001\r2 50 0b110010\r3 51 0b110011\r r.setbit(\u0026#39;k1\u0026#39;,6,1)#把第7位变成1 r.get(\u0026#39;k1\u0026#39;) b'323'\r r.getbit(\u0026#39;k1\u0026#39;,6) 1\r bitcount(key, start=None, end=None) 获取对应二进制中1的个数 \rkey:Redis的name\rstart:字节起始位置\rend:字节结束位置\rr.bitcount(\u0026#39;k1\u0026#39;,start=0,end=0) 4\r strlen(name) 返回name对应值的字节长度 r.set(\u0026#39;k2\u0026#39;,\u0026#34;飒飒\u0026#34;)#一个中文3个字节 r.strlen(\u0026#39;k2\u0026#39;) 6\r incr(self, name, amount=1)自增整数，incrbyfloat(self, name, amount=1.0)自增浮点数，decr(self, name, amount=1)自减整数 r.incr(\u0026#34;k1\u0026#34;,amount=2)#可以对str类型的整数进行自增 325\r r.set(\u0026#39;k2\u0026#39;,\u0026#39;123.1\u0026#39;) r.incrbyfloat(\u0026#39;k2\u0026#39;,amount=1.1)#可以对str类型的浮点数进行自增 #r.decrbyfloat(\u0026#39;k2\u0026#39;,amount=1.1) 没有这个东西 124.2\r r.decr(\u0026#39;k1\u0026#39;, amount=1) 324\r append(name,value) r.append(\u0026#34;k3\u0026#34;,\u0026#34;str\u0026#34;)#返回的是append后的value的长度 r.get(\u0026#39;k3\u0026#39;) b'2000\\xe6\\xaf\\xab\\xe7\\xa7\\x92str'\r HASH操作 redis中的Hash在内存中一个name对应一个dic来存储\nhset(name,key,value)在name对应的hash中设置一个k-v;hget(name,key);hgetall(name) r.hset(\u0026#39;h1\u0026#39;,\u0026#39;name\u0026#39;,\u0026#39;euraxluo\u0026#39;) r.hgetall(\u0026#39;h1\u0026#39;) {b'name': b'euraxluo'}\r hmset(name,mapping) 在name对应的hash中用dic来填充;hmget(name, keys, *args) 从hash中获取多个key值 dic={\u0026#34;name\u0026#34;:\u0026#34;euraxluo\u0026#34;,\u0026#34;age\u0026#34;:\u0026#34;13\u0026#34;} r.hmset(\u0026#39;h1\u0026#39;,dic) r.hgetall(\u0026#39;h1\u0026#39;) {b'name': b'euraxluo', b'age': b'13'}\r hlen(name)获取hash中键值对的个数、hkeys(name)获取hash中所有的key的值、hvals(name)获取hash中所有的value的值 r.hlen(\u0026#39;h1\u0026#39;) 2\r r.hkeys(\u0026#39;h1\u0026#39;) [b'name', b'age']\r r.hvals(\u0026#39;h1\u0026#39;) [b'euraxluo', b'13']\r hexists(name, key) 检查name对应的hash是否存在当前传入的key r.hexists(\u0026#39;h1\u0026#39;,\u0026#39;sex\u0026#39;) False\r hdel(name,*keys) 删除指定name对应的keys对应的k-v r.hdel(\u0026#39;h1\u0026#39;,\u0026#39;sex\u0026#39;) 0\r r.hdel(\u0026#39;h1\u0026#39;,\u0026#39;age\u0026#39;) 1\r hincrby(name, key, amount=1) 自增hash中key对应的值，不存在则创建key=amount(amount为整数) dic={\u0026#34;name\u0026#34;:\u0026#34;euraxluo\u0026#34;,\u0026#34;age\u0026#34;:\u0026#34;13\u0026#34;,\u0026#39;test\u0026#39;:\u0026#39;13.1\u0026#39;} r.hmset(\u0026#39;h2\u0026#39;,dic) r.hincrby(\u0026#39;h2\u0026#39;,\u0026#39;age\u0026#39;,amount=2) r.hgetall(\u0026#39;h2\u0026#39;) {b'name': b'euraxluo', b'age': b'15', b'test': b'13.1'}\r hincrbyfloat(name, key, amount=1.0) 自增hash中key对应的值，不存在则创建key=amount(amount为浮点数) r.hincrbyfloat(\u0026#39;h2\u0026#39;,\u0026#39;test\u0026#39;,amount=2.1) r.hgetall(\u0026#39;h2\u0026#39;) {b'name': b'euraxluo', b'age': b'15', b'test': b'15.2'}\r hscan(name, cursor=0, match=None, count=None) 增量式迭代获取，对于数据大的数据非常有用，hscan可以实现分片的获取数据，并非一次性将数据全部获取完，避免内存被撑爆\n\rname，redis的name\rcursor，游标（基于游标分批取获取数据）\rmatch，匹配指定key，默认None 表示所有的key\rcount，每次分片最少获取个数，默认None表示采用Redis的默认分片个数\rr.hscan(\u0026#39;h2\u0026#39;,cursor=1,match=\u0026#39;*e*\u0026#39;,count=2) (0, {b'name': b'euraxluo', b'age': b'15', b'test': b'15.2'})\r hscan_iter(name, match=None, count=None) 利用yield封装hscan创建生成器，实现分批去redis中获取数据\n\rmatch，匹配指定key，默认None 表示所有的key\rcount，每次分片最少获取个数，默认None表示采用Redis的默认分片个数\rfor i in r.hscan_iter(\u0026#39;h2\u0026#39;,match=\u0026#39;*e*\u0026#39;,count=2):print(i) (b'name', b'euraxluo')\r(b'age', b'15')\r(b'test', b'15.2')\r List操作 redis中的List在在内存中按照一个name对应一个List来存储。\nlpush(name,values)在name对应的list中添加元素，每个新的元素都添加到列表的最左边;rpush(name, values) 表示从右向左操作 r.lpush(\u0026#39;l1\u0026#39;,\u0026#39;a\u0026#39;) 2\r lpushx(name,value)在name对应的list中添加元素，只有name已经存在时，值添加到列表的最左边; rpushx(name, value) 表示从右向左操作 r.lpushx(\u0026#39;l1\u0026#39;,\u0026#39;b\u0026#39;) 3\r llen(name)name对应的list的元素个数 r.llen(\u0026#39;l1\u0026#39;) 3\r linsert(name, where, refvalue, value))在name对应的列表的某一个值前或后插入一个新值 \rname，redis的name\rwhere，BEFORE或AFTER\rrefvalue，标杆值，即：在它前后插入数据\rvalue，要插入的数据\rr.linsert(\u0026#39;l1\u0026#39;,\u0026#39;BEFORE\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c1\u0026#39;) r.linsert(\u0026#39;l1\u0026#39;,\u0026#39;AFTER\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c2\u0026#39;) 5\r lset(name, index, value)对name对应的list中的某一个索引位置重新赋值 \rname，redis的name\rindex，list的索引位置\rvalue，要设置的值\rr.lset(\u0026#39;l1\u0026#39;,\u0026#39;0\u0026#39;,\u0026#39;c\u0026#39;) r.lrange(\u0026#39;l1\u0026#39;,0,-1) [b'c', b'b', b'c2', b'a', b'c']\r lrem(name, num, value)在name对应的list中删除指定的值 \rname，redis的name\rvalue，要删除的值\rnum， num=0，删除列表中所有的指定值；\rnum=2,从前到后，删除2个；\rnum=-2,从后向前，删除2个\rr.lrem(\u0026#39;l1\u0026#39;,2,\u0026#39;c\u0026#39;) 2\r lpop(name)在name对应的列表的左侧获取第一个元素并在列表中移除，返回值则是第一个元素;rpop(name) 表示从右向左操作 r.lpop(\u0026#39;l1\u0026#39;) r.lrange(\u0026#39;l1\u0026#39;,0,-1) [b'c2', b'a']\r ltrim(name, start, end)在name对应的列表中移除没有在start-end索引之间的值 \rname，redis的name\rstart，索引的起始位置\rend，索引结束位置\rr.ltrim(\u0026#39;l1\u0026#39;,0,-2) r.lrange(\u0026#39;l1\u0026#39;,0,-1) [b'c2']\r rpoplpush(src, dst)从一个列表取出最右边的元素，同时将其添加至另一个列表的最左边 \rsrc，要取数据的列表的name\rdst，要添加数据的列表的name\rr.lpush(\u0026#39;l2\u0026#39;,\u0026#39;c\u0026#39;) r.rpop(\u0026#39;l1\u0026#39;) r.rpoplpush(\u0026#39;l2\u0026#39;,\u0026#39;l1\u0026#39;) r.lrange(\u0026#39;l1\u0026#39;,0,-1) [b'c']\r blpop(keys, timeout)将多个列表排列，按照从左到右去pop对应列表的元素;brpop(keys, timeout)，从右向左获取数据 \rkeys，redis的name的集合\rtimeout，超时时间，当元素所有列表的元素获取完之后，阻塞等待列表内有数据的时间（秒）, 0 表示永远阻塞\rr.lpush(\u0026#34;l3\u0026#34;, \u0026#39;11\u0026#39;, \u0026#39;22\u0026#39;, \u0026#39;33\u0026#39;) r.lpush(\u0026#34;l4\u0026#34;, \u0026#39;44\u0026#39;, \u0026#39;55\u0026#39;, \u0026#39;66\u0026#39;) r.brpop([\u0026#39;l3\u0026#39;,\u0026#39;l4\u0026#39;],timeout=1) (b'l3', b'33')\r lindex(name, index)在name对应的列表中根据索引获取列表元素 r.lindex(\u0026#39;l3\u0026#39;,1) b'22'\r 增量迭代 由于redis类库中没有提供对列表元素的增量迭代，如果想要循环name对应的列表的所有元素，那么就需要：\n 1、获取name对应的所有列表\n  2、循环列表\n 但是，如果列表非常大，那么就有可能在第一步时就将程序的内容撑爆，所有有必要自定义一个增量迭代的功能：\ndef list_iter(name): \u0026#34;\u0026#34;\u0026#34; 自定义redis列表增量迭代 :param name: redis中的name，即：迭代name对应的列表 :return: yield 返回 列表元素 \u0026#34;\u0026#34;\u0026#34; list_count = r.llen(name) for index in range(list_count): yield r.lindex(name, index) for item in list_iter(\u0026#39;l3\u0026#39;):print(item) b'33'\rb'22'\rb'11'\rb'33'\rb'22'\rb'11'\rb'33'\rb'22'\rb'11'\rb'33'\rb'22'\rb'11'\rb'33'\rb'22'\rb'11'\rb'33'\rb'22'\rb'11'\rb'33'\rb'22'\rb'11'\rb'33'\rb'22'\rb'11'\r Set操作，Set集合就是不允许重复的列表 sadd(name,values) name对应的集合中添加元素 r.sadd(\u0026#39;s2\u0026#39;,\u0026#34;value1\u0026#34;,\u0026#34;2sasa\u0026#34;,\u0026#34;2sasa\u0026#34;,\u0026#34;2ssss\u0026#34;) 1\r scard(name) 获取name对应的集合中元素个数 r.scard(\u0026#39;s1\u0026#39;) 0\r sdiff(keys, *args)在第一个name对应的集合中且不在其他name对应的集合的元素集合 r.sdiff(\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;)#s1对应的集合中且不在其他name对应的集合的元素集合 set()\r sdiffstore(dest, keys, *args)获取第一个name对应的集合中且不在其他name对应的集合，再将其新加入到dest对应的集合中 r.sdiffstore(\u0026#39;s3\u0026#39;,\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;) r.smembers(\u0026#39;s3\u0026#39;) set()\r sinter(keys, *args)获取多个name对应集合的并集 r.sinter(\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;) set()\r sinterstore(dest, keys, *args)获取多一个name对应集合的并集，再讲其加入到dest对应的集合中 r.sinterstore(\u0026#39;s4\u0026#39;,\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;) r.smembers(\u0026#39;s4\u0026#39;) set()\r sismember(name, value)检查value是否是name对应的集合的成员 r.sismember(\u0026#39;s1\u0026#39;,\u0026#39;value1\u0026#39;) False\r smembers(name)获取name对应的集合的所有成员 r.smembers(\u0026#39;s1\u0026#39;) set()\r smove(src, dst, value)将某个成员从一个集合中移动到另外一个集合 r.smove(\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;,\u0026#39;ssss\u0026#39;) r.smembers(\u0026#39;s2\u0026#39;) {b'2sasa', b'2ssss', b'ssss', b'value1'}\r spop(name)从集合的右侧（尾部）移除一个成员，并将其返回 r.spop(\u0026#39;s1\u0026#39;) r.smembers(\u0026#39;s1\u0026#39;) set()\r srandmember(name, numbers)从name对应的集合中随机获取 numbers 个元素 r.srandmember(\u0026#39;s2\u0026#39;,\u0026#39;2\u0026#39;) [b'2ssss', b'2sasa']\r srem(name, values)在name对应的集合中删除某些值 r.srem(\u0026#39;s2\u0026#39;,\u0026#39;2ssss\u0026#39;) r.smembers(\u0026#39;s2\u0026#39;) {b'2sasa', b'ssss', b'value1'}\r sunion(keys, *args)获取多一个name对应的集合的并集 r.sunion(\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;,\u0026#39;s3\u0026#39;) {b'2sasa', b'ssss', b'value1'}\r sunionstore(dest,keys, *args)获取多一个name对应的集合的并集，并将结果保存到dest对应的集合中 r.sunionstore(\u0026#39;d4\u0026#39;,\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;,\u0026#39;s3\u0026#39;) r.smembers(\u0026#39;d4\u0026#39;) {b'2sasa', b'ssss', b'value1'}\r sscan(name, cursor=0, match=None, count=None);sscan_iter(name, match=None, count=None)同字符串的操作，用于增量迭代分批获取元素，避免内存消耗太大 for i in r.sscan_iter(\u0026#39;s2\u0026#39;,match=\u0026#39;*v*\u0026#39;,count=2):print(i) b'value1'\r 有序集合，在集合的基础上，为每元素排序 元素的排序需要根据另外一个值来进行比较，所以，对于有序集合，每一个元素有两个值，即：值和分数，分数专门用来做排序。\nzadd(name, mapping, nn,nx)在name对应的有序集合中添加元素 \rzadd('zz', 'n1', 1, 'n2', 2)\r或\rzadd('zz', n1=11, n2=22)\rdic={\u0026#39;n1\u0026#39;:1,\u0026#39;n2\u0026#39;:2} r.zadd(\u0026#39;zz\u0026#39;,dic) 2\r zcard(name)获取name对应的有序集合元素的数量 r.zcard(\u0026#39;zz\u0026#39;) 2\r zcount(name, min, max)获取name对应的有序集合中分数 在 [min,max] 之间的个数 r.zcount(\u0026#39;zz\u0026#39;,0,1) 1\r zincrby(name, value, amount)自增name对应的有序集合的 name 对应的分数 r.zincrby(\u0026#39;zz\u0026#39;,value=\u0026#39;n3\u0026#39;,amount=1) 1.0\r zrange( name, start, end, desc=False, withscores=False, score_cast_func=float)按照索引范围获取 name对应的有序集合的元素 \rname，redis的name\rstart，有序集合索引起始位置（非分数）\rend，有序集合索引结束位置（非分数）\rdesc，排序规则，默认按照分数从小到大排序\rwithscores，是否获取元素的分数，默认只获取元素的值\rscore_cast_func，对分数进行数据转换的函数\rr.zrange(\u0026#39;zz\u0026#39;,0,-1,desc=True,withscores=True)#desc=true,排序规则从大到小 [(b'n2', 2.0), (b'n3', 1.0), (b'n1', 1.0)]\r zrevrange(name, start, end, withscores=False, score_cast_func=float) 从大到小排序 r.zrevrange(\u0026#39;zz\u0026#39;,0,-1,withscores=True) [(b'n2', 2.0), (b'n3', 1.0), (b'n1', 1.0)]\r zrangebyscore(name, min, max, start=None, num=None, withscores=False, score_cast_func=float 按照分数范围获取name对应的有序集合的元素 zrevrangebyscore(name, max, min, start=None, num=None, withscores=False) 从大到小排序 r.zrangebyscore(\u0026#39;zz\u0026#39;,1,2,withscores=True) [(b'n1', 1.0), (b'n3', 1.0), (b'n2', 2.0)]\r zrank(name, value) 获取某个值在 name对应的有序集合中的排行（从 0 开始）\nzrevrank(name, value)，从大到小排序 r.zrank(\u0026#39;zz\u0026#39;,\u0026#39;n3\u0026#39;)#n3最大 1\r zrangebylex(name, min, max, start=None, num=None) 当有序集合的所有成员都具有相同的分值时，有序集合的元素会根据成员的 值 （lexicographical ordering）来进行排序，而这个命令则可以返回给定的有序集合键 key 中， 元素的值介于 min 和 max 之间的成员\n对集合中的每个成员进行逐个字节的对比（byte-by-byte compare）， 并按照从低到高的顺序， 返回排序后的集合成员。 如果两个字符串有一部分内容是相同的话， 那么命令会认为较长的字符串比较短的字符串要大\n\rname，redis的name\rmin，左区间（值）。 + 表示正无限； - 表示负无限； ( 表示开区间； [ 则表示闭区间\rmin，右区间（值）\rstart，对结果进行分片处理，索引位置\rnum，对结果进行分片处理，索引后面的num个元素\rzrevrangebylex(name, max, min, start=None, num=None) 从大到小排序 dic={\u0026#39;aa\u0026#39;:0,\u0026#39;ba\u0026#39;:0,\u0026#39;ca\u0026#39;:0,\u0026#39;da\u0026#39;:0,\u0026#39;ea\u0026#39;:0,\u0026#39;fa\u0026#39;:0} r.zadd(\u0026#39;z1\u0026#39;,dic) r.zrangebylex(\u0026#39;z1\u0026#39;, \u0026#34;-\u0026#34;, \u0026#34;[fa]\u0026#34;) [b'aa', b'ba', b'ca', b'da', b'ea', b'fa']\r zrem(name, values) 删除name对应的有序集合中值是values的成员 r.zrem(\u0026#39;z1\u0026#39;, \u0026#39;fa\u0026#39;, \u0026#39;ea\u0026#39;) 2\r zremrangebyrank(name, min, max) 根据排行范围删除 r.zremrangebyrank(\u0026#39;zz\u0026#39;,0,1) 2\r zremrangebyscore(name, min, max)根据分数范围删除 r.zremrangebyscore(\u0026#39;z1\u0026#39;,0,3) 4\r zremrangebylex(name, min, max)根据值返回删除 ZREMRANGEBYLEX 删除名称按字典由低到高排序成员之间所有成员。\n不要在成员分数不同的有序集合中使用此命令, 因为它是基于分数一致的有序集合设计的,如果使用,会导致删除的结果不正确。\n待删除的有序集合中,分数最好相同,否则删除结果会不正常。\ndic={\u0026#39;aa\u0026#39;:0,\u0026#39;ba\u0026#39;:0,\u0026#39;ca\u0026#39;:0,\u0026#39;da\u0026#39;:0,\u0026#39;ea\u0026#39;:0,\u0026#39;fa\u0026#39;:0} r.zadd(\u0026#39;z2\u0026#39;,dic) r.zremrangebylex(\u0026#39;z2\u0026#39;,\u0026#39;[aa\u0026#39;,\u0026#39;(ea\u0026#39;) r.zrangebylex(\u0026#39;z2\u0026#39;,\u0026#39;-\u0026#39;,\u0026#39;+\u0026#39;) [b'ea', b'fa']\r zscore(name, value)获取name对应有序集合中 value 对应的分数 r.zscore(\u0026#39;z2\u0026#39;,value=\u0026#39;ea\u0026#39;) 0.0\r zinterstore(dest, keys, aggregate=None)获取两个有序集合的交集，如果遇到相同值不同分数，则按照aggregate进行操作 r.zinterstore(\u0026#39;z1\u0026#39;,\u0026#39;z2\u0026#39;,aggregate=\u0026#39;MAX\u0026#39;) 0\r zunionstore(dest, keys, aggregate=None)获取两个有序集合的并集，如果遇到相同值不同分数，则按照aggregate进行操作  aggregate的值为: SUM MIN MAX\n r.zinterstore(\u0026#39;z1\u0026#39;,\u0026#39;z2\u0026#39;,aggregate=\u0026#39;MAX\u0026#39;) 0\r zscan(name, cursor=0, match=None, count=None, score_cast_func=float) zscan_iter(name, match=None, count=None,score_cast_func=float) 同字符串相似，相较于字符串新增score_cast_func，用来对分数进行操作\n其他常用操作 delete(*names)根据name删除redis中的任意数据类型,返回值为删除的个数 r.delete(\u0026#34;k4\u0026#34;,\u0026#39;k2\u0026#39;,\u0026#39;k3\u0026#39;) 1\r exists(name)若 name 存在返回 1 ，否则返回 0 。 r.exists(\u0026#39;11\u0026#39;) 0\r keys(pattern='*')根据pattern获取redis的name \rKEYS * 匹配数据库中所有 key 。\rKEYS h?llo 匹配 hello ， hallo 和 hxllo 等。\rKEYS h*llo 匹配 hllo 和 heeeeello 等。\rKEYS h[ae]llo 匹配 hello 和 hallo ，但不匹配 hillo\rr.keys(\u0026#34;*\u0026#34;) [b'name',\rb'l3',\rb'k7',\rb's2',\rb'z2',\rb'z3',\rb'k1',\rb'h2',\rb'd4',\rb'l4',\rb'zz',\rb'l1',\rb'k8',\rb'h1',\rb'l2']\r expire(name ,time)为某个redis的某个name设置超时时间 r.expire(\u0026#39;name\u0026#39;,2) True\r rename(src, dst)对redis的name重命名为 r.rename(\u0026#39;zz\u0026#39;,\u0026#39;z3\u0026#39;) True\r move(name, db))将redis的某个值移动到指定的db下 print(r.hkeys(\u0026#39;h1\u0026#39;)) r.move(\u0026#39;h1\u0026#39;,1) r.hkeys(\u0026#39;h1\u0026#39;) [b'name']\r[b'name']\r randomkey()随机获取一个redis的name（不删除） r.randomkey() b'l3'\r type(name) 获取name对应值的类型 r.type(\u0026#39;d4\u0026#39;) b'set'\r scan(cursor=0, match=None, count=None) scan_iter(match=None, count=None) 同字符串操作，用于增量迭代获取key\n","permalink":"/zh-cn/posts/redis/redis%E5%9F%BA%E7%A1%80/","series":["redis"],"tags":["redis"],"title":"Redis基础学习"},{"categories":["redis"],"content":"Redis的主从复制 单机部署的问题   机器故障（高可用）\n  容量瓶颈（分布式）\n  QPS瓶颈（分布式）\n  主从复制的作用   为一个数据提供了副本\n  slave从master复制一个备份库\n  master可以有多个slave\n  一个slave只能有一个master\n  数据流向是单向的，由master\u0026ndash;\u0026gt;slave\n  扩展读性能，可以实现读写分离\n  主从复制实现 slaveof slaveof 127.1 6380\n取消复制\nslaveof no one\n配置 #配置这个redis服务复制ip:port这个redis作为他的slave slaveof ip port #只读,必须保证从和主的内容一致 slave-read-only yes 两种方式的比较 | 方式 | 命令 | 配置 |\n| \u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026ndash; |\n| 优点 | 无需重启 | 统一配置 |\n| 缺点 | 不便于管理 | 需要重启 |\n使用配置的方式实现主从复制，需要重启原来的redis服务器 config redis-cli -h 127.1 -p 6379 shutdown\nconfig ps -ef |grep redis-server\nxl 3963 1 0 3月09 ? 00:03:17 redis-server *:6380 xl 19626 18759 0 13:41 pts/0 00:00:00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn redis-server config redis-cli -h 127.1 -p 6380 shutdown\nconfig ps -ef |grep redis-server\nxl 19649 18759 0 13:41 pts/0 00:00:00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn redis-server config redis-server redis-6379.conf\nconfig redis-server redis-6380.conf\nconfig redis-cli -h 127.1 -p 6379 info replication\n\r# Replication\rrole:master\rconnected_slaves:0\rmaster_replid:8e2a95428f7fa32eb6936a052b31bcaee64d43d3\rmaster_replid2:0000000000000000000000000000000000000000\rmaster_repl_offset:0\rsecond_repl_offset:-1\rrepl_backlog_active:0\rrepl_backlog_size:1048576\rrepl_backlog_first_byte_offset:0\rrepl_backlog_histlen:0\rconfig redis-cli -h 127.1 -p 6380 info replication\n# Replication role:slave master_host:127.0.0.1 master_port:6380 master_link_status:down master_last_io_seconds_ago:-1 master_sync_in_progress:0 slave_repl_offset:1 master_link_down_since_seconds:1552282946 slave_priority:100 slave_read_only:1 connected_slaves:0 master_replid:231a9e1dffed58138ccdd5d7d48b85b332edf79b master_replid2:0000000000000000000000000000000000000000 master_repl_offset:0 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 查看run_id:redis-cli -p 6379 info server |grep run\n通过偏移量监控主从复制 redis-cli -p 6379 info replication\nmaster_repl_offset:偏移量\nslave0:ip=127.1,port=6379,state=online,offset=从库的偏移量，log=1\n 通过对两个偏移量的比对，可以检测主从复制的状态  全量复制 全量复制的开销   bgsave时间\n  RDB文件网络传输时间\n  从节点清空数据时间\n  从节点加载RDB时间\n  可能的AOF重写时间\n  全量复制的问题 网络不稳定时，丢包或者网络断开连接，数据丢失，这时候需要再进行全量复制，开销巨大\n部分复制 repl_back_buffer 默认为1mb，但是实际我们会设置的较大\n故障处理   故障不可避免\n  自动故障转移\n  slave故障  将读取客户端指向存活的其他slave  master故障   把写入客户端指向一个slave\n  更改这个slave：slaveof no one,恢复其写入能力\n  把其他的slave：slaveof new master,指向这个新的master\n  故障自动转移  sentinel实现自动故障转移  TPIS 读写分离   读写分离：读流量分摊到从节点\n  可能的问题\n    复制数据延迟（可以通过监控偏移量解决）\n  读到过期数据（操作key时才校验是否过期，定时采样校验是否过期）\n  从节点故障\n  主从配置不一致   maxmemory不一致：丢失数据\n  数据结构优化参数不一致(例如hash-max-ziplist-entries)：造成内存不一致\n  规避全量复制  第一次全量复制    第一次时不可避免\n  使用小主节点（减小maxmemory）\n  在低压，低峰时进行全量复制\n  节点运行ID不匹配    大多出现在主节点重启时（会使run_id变化）\n  利用故障转移，使用哨兵或者集群\n  复制缓冲区不足    网络中断时，却无法进行部分复制（repl_back_buffer过小）\n  可以通过增大缓冲区（配置rel_backlog_size）,大小可以通过网络增强计算（每秒写入dps*(故障排除-故障发生)再计算大小）\n  规避复制风暴  单主节点复制风暴    主节点重启后，多从节点请求全量复制\n可以更改复制拓扑，减轻主节点的复制压力，使用树形结构分散压力\n  单机器复制风暴    一个机器上全是master节点，当机器宕机时，压力会很大\n可以通过让其他slave作为新的master来解决，当然也可以使用哨兵或者集群\n  ","permalink":"/zh-cn/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","series":["redis"],"tags":["redis"],"title":"Redis的主从复制"},{"categories":["redis"],"content":"Redis的持久化 Redis持久化作用 什么是持久化 redis的所有数据保存在内存中，对数据的更新回异步的保存在磁盘中\n持久化方式 快照   MySQL Dump\n  Redis RDB\n  日志   MySQL Binlog\n  Hbase HLog\n  Redis AOF\n  RDB持久化 什么是RDB redis可以通过命令，把当前数据库的状态保为一个RDB文件（二进制）\n也可以通过命令把硬盘上的RDB载入到redis中\n同时RDB文件也是一个复制的媒介\n触发机制 save   通过save命令让redis生成rdb文件，生成成功返回‘OK’\n  同步命令，阻塞命令，会导致服务器阻塞\n  会替换老的rdb文件\n  复杂度On\n  bgsave   接收到bgsave后，redis利用linux的fork()命令产生一个子进程，让产生的子进程去生成RDB文件，返回‘Backgroud saving started’\n  fork()函数也是一阻塞命令，一般情况下很快\n  会替换老的rdb文件\n  复杂度On\n  save与bgsave比较 | 命令 | save | bgsave |\n| \u0026mdash;- | \u0026mdash;- | \u0026mdash;- |\n| io类型 |同步 | 异步 |\n| 是否阻塞 | 是 | 是 |\n| 时间复杂度 | On | On |\n| 优点 | 不会消耗额外内存 |不阻塞客户端命令 |\n| 缺点 | 阻塞客户端命令 |需要fork()，消耗内存 |\n自动生成快照 策略 满足以下三个条件就会触发创建RDB文件的行为（bgsave）\n  900 1chages\n  300 10chages\n  60 10000chages\n  缺点  生成快照的频率有些时候可能过高了（写量过高的情况）  配置 #自动策略，一般不配置，不使用自动生成快照 save 900 1 save 300 10 save 60 10000 #文件名，一般按照端口号区分 dbfilename dump-${port}.rdb #rdb,log,aof文件的位置，选择一个大内存的目录，或者需要按照端口进行分盘 dir ./ #如果bgsave出现错误是否立刻停止 stop-writes-on-bgsave-error yes #是否采用压缩格式 rdbcompression yes #是否进行校验和验证 rdbchecksum yes 注意   全量复制时，主数据库会自动生成RDB\n  debug reload，不清空数据库的重启\n  shutdown，关机时会自动生成rdb文件\n  耗时，耗性能\n  不可控，易丢失以前的数据（宕机与上一次dump之间的操作）\n  AOF持久化 什么是AOF   每执行一条命令，就会在AOF文件中追加写入\n  恢复时，把AOF文件载入执行\n  执行命令时，会把命令刷新到缓冲区，通过不同的策略，同步到AOF文件中\n  AOF的执行策略 always  每个命令都会从缓冲区fsync到AOF中  everysec   每一秒从缓冲区fsync到AOF中\n  可以保护硬盘\n  刷新频率可以配置\n  no  由操作系统决定什么时候fsync  三种策略比较 | 命令 | always | everysec | no |\n| \u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash; |\n| 优点 | 不丢失数据 | 每秒一次fsync | 不用管 |\n| 缺点 | IO开销大 | 丢失一秒数据 | 不可控 |\nAOF重写 策略   从内存中重写\n  会把一些过期的命令删除\n  会把一些可以化简的命令化简\n  会把一些等值的命令合并\n  优点   减少硬盘占用量\n  加快恢复速度\n  实现方式  bgrewriteaof   异步操作，主进程fork一个子进程，会从内存中完成AOF重写  AOF重写配置    auto-aof-rewrite-min-size，AOF文件重写需要的最小尺寸\n  auto-aof-rewrite-percentage，AOF文件增长率\n  AOF统计指标    aof_current_size,AOF当前尺寸\n  aof_base_size，AOF上次启动和重写的尺寸\n  同时满足以下两条公式    aof_current_size\u0026gt;auto-aof-rewrite-min-size\n  (aof_current_size-aof_base_size/aof_base_size)\u0026gt;auto-aof-rewrite-min-size\n  AOF配置 #是否打开aof appendonly yes #文件名字，使用端口进行区分 appendfilenam \u0026#34;appendonly-${port}.aof\u0026#34; #每秒aof appendfsync everysec #使用大的盘 dir /bigdiskpath #是否进行append操作，是否允许丢失数据(在重写期间关闭append操作) no-appendfsync-on-rewrite yes #增长率 auto-aof-rewrite-percentage 100 #最小尺寸 auto-aof-rewrite-min-size 64mb #在加载时是否忽略文件错误 aof-load-truncated yes conf文件内容\nhead *.aof#查看文件头部 *2#有两个指令 $6#下一行有6个字节 SELECT#指令 $1#下一行有1个字节 0#select 0 ，选择0号数据库 $3 set $5 hello RDB和AOF的抉择 RDB,AOF比较 | 命令 | RDB | AOF |\n| \u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; |\n| 启动优先级 | 低 | 高 |\n| 体积 | 小 | 大 |\n| 恢复速度 | 快 | 慢 |\n| 数据安全性 | 丢数据 | 根据策略决定 |\n| 轻重 | 重 | 轻 |\nRDB最佳策略   关掉RDB\n  集中管理\n  主从库，从库打开，密度不要太大\n  AOF最佳策略   开：缓存还是存储，根据功能决定是否需要这个功能\n  AOF重写集中管理\n  everysec\n  最佳策略   小分片\n  根据缓存或者存储决定是否需要这个功能\n  监控：硬盘，内存，负载，网络\n  足够的内存\n  持久化的常见问题 fork操作的问题   是一个同步操作\n  与内存量息息相关；内存越大，耗时越长（也与机器类型有关，虚拟机，物理机）\n  info：latest_fork_usec\n  改善fork   优先使用物理机或者高效支持fork操作的虚拟化技术\n  控制Redis实例最大可用内存：maxmemory\n  合理配置Linux内存分配策略，让机器确保有足够的内存再fork：vm.overcommit_memory=1（默认为0，会导致内存不够时，fork阻塞）\n  降低fork频率，放宽AOF重写自动触发时机，避免不必要的全量复制（全量复制会bgsave）\n  子进程外开销和优化  CPU    开销：RDB和AOF文件生成，属于CPU密集型\n  优化：不做CPU绑定，不和CPU密集型应用部署，单机部署时，保证不进行大量的rdb和aof文件生成\n  内存    开销：fork内存开销，copy-on-write\n  优化：单机部署时，不做大量的重写；在主进程io少时去做fork；关闭大内存分配echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enable\n  硬盘    开销：AOF，RDB文件写入，可以结合iostat，iotop分析\n  优化：不要和高硬盘负载服务部署在一起（存储服务，消息队列）；根据写入量决定磁盘的类型（ssd）；单机多实例持久化文件目录可以考虑分盘；no-appendfsync-on-rewrite = yes\n  AOF追加阻塞 在AOF从缓冲区刷盘时，会启动一个线程来完成这个事，主线程会监控同步时间，如果同步时间超过2秒，即刷盘操作2秒还没有完成，主线程就会阻塞，直到刷盘完成\n问题   主进程不能阻塞\n  刷盘时可能不止丢失1秒的数据\n  定位   看日志，会出现（disk is busy?）提示\n  info Persistence，可以通过aof_delayed_fsync:nums,查看出现这种情况的次数\n  优化   不要和高硬盘负载服务部署在一起（存储服务，消息队列）\n  根据写入量决定磁盘的类型（ssd）\n  单机多实例持久化文件目录可以考虑分盘\n  no-appendfsync-on-rewrite = yes\n  ","permalink":"/zh-cn/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96%E7%AD%96%E7%95%A5/","series":["redis"],"tags":["redis"],"title":"Redis的持久化"},{"categories":["redis"],"content":"Redis高级特性初识 慢查询 客户端请求的生命周期   客户端发送命令\n  入队列\n  执行命令（慢查询在这一阶段）\n  返回客户端\n  （客户端超时，不一定是慢查询，慢查询只是客户端超时的一个可能）\n配置   slowlog-max-len，固定长度\n  slowlog-log-slower-than，慢查询阈值（单位微秒）\n=0，记录所有命令\n\u0026lt;0，不记录任何命令\n  #1. 第一次开启配置 config get slowlog-max-len = 128 config get slowlog-log-slower-than = 10000 #2. 修改默认配置重启 #3. 动态配置 config set slowlog-max-len = 128 config set slowlog-log-slower-than = 10000 API 慢查询会把命令放在内存中\n  slowlog get [n]：获取慢查询队列\n  slowlog len ：获取慢查询队列长度\n  slowlog reset：清空慢查询队列\n  定期持久化查询\n  TIPS   slowlog-max-len 不要设置的过大，默认为10ms，通常设置为1ms\n  slowlog-log-slower-than 不要设置过小，通常设置为1000左右\n  理解命令生命周期\n  pipeline 流水线 n次通信时间=n次命令时间+n次网络时间\n使用pipeline：1次网络+n次命令\n客户端实现 maven:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.0\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;jar\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 没有使用pipeline\nJedis jedis = new Jedis(\u0026#39;127.1\u0026#39;,6379); for(int i=0;i\u0026lt;10000;i++){ jedis.hset(\u0026#34;hashkey:\u0026#34;+i,\u0026#34;field\u0026#34;+i,\u0026#34;value\u0026#34;+i); } 使用pipeline\nJedis jedis = new Jedis(\u0026#39;127.1\u0026#39;,6379); for(int i=0;i\u0026lt;100;i++){ Pipeline pipeline = jedis.pipelined(); for(int j=i*100;j\u0026lt;(i+1)*100;j++){ pipeline.hset(\u0026#34;hashkey:\u0026#34;+i,\u0026#34;field\u0026#34;+i,\u0026#34;value\u0026#34;+i); } pipeline.syncAndRetuenAll(); } 与原生M操作对比 M操作是原子的，而pipeline命令在队列中会被拆分为很多子命令，不是原子的\nTIPS   注意每次pipeline携带数据量\n  pipeline每次只能作用在一个redis节点上\n  M操作与pipeline的区别\n  发布订阅 角色   发布者\n  订阅者\n  频道\n  通信模型   发布者向一个频道发布消息\n  订阅者可以订阅多个频道\n  订阅者不能收到他订阅之前的消息\n  API   pushlish channel message，返回订阅者个数\n  subscribe [channel] ,订阅一个或多个\n  unsubscribe [channel] ,取消一个或多个订阅\n  psubscribe [pattern] ，订阅指定的模式\n  punsubscribe [pattern],退订指定的模式\n  pubsub channels，列出至少有一个订阅者的频道\n  pubsub numsub [channel\u0026hellip;]，列出给定频道的订阅者数量\n  发布订阅与消息队列   发布订阅会让所有的客户端都受到消息\n  消息队列通过阻塞和list达到让多个客户端收到队列中的不同内容\n  消息队列类似于抢红包\n  BitMap 因为redis可以直接操作位\nAPI   setbit key offset value，给位图指定索引设置值,返回offset之前的值（不要突然在很小的位图上做很大的偏移量）\n  getbit key offset，获取位图指定索引的值\n  bitcount key [start end]，获取位图指定范围（start到end，单位为字节，如果不指定就是获取全部）位值为1的个数\n  bitop op destkey key [key\u0026hellip;]，做多个Bitmap的and(交)，or(并)，not(非)，xor(异或)操作并将结果保存在destkey中\n  bitpos key targetBit [start] [end]，计算位图指定范围start~end，单位为字节，如果不指定就是获取全部，第一个偏移量对应的值等于targetBit的位置\n  实战  独立用户统计   假设1亿总用户， 5千万独立用户用户  如果userid是整形，则使用set实现存储需要 32*50000000=200MB\nBitMap：1*1亿=12.5MB\n 如果只有10万独立用户  如果userid是整形，则使用set实现存储需要 32*100000=4MB\nBitMap：1*1亿=12.5MB\nTIPS   type=string，最大512MB，可能需要拆分\n  注意setbit偏移量，可能有很大的耗时\n  位图不是绝对的好，需要在合适的场景使用合适的数据结构\n  HyperLogLog   基于HypeLogLog算法：可以在极小的空间完成独立数量统计\n  本质还是字符串\n  API   pfadd key element [element\u0026hellip;]，向hyperloglog添加元素\n  pfcount key [key\u0026hellip;]，计算hyperloglog的独立总数\n  pfmerge destkey sourcekey [sourcekey\u0026hellip;],合并多个hyperloglog\n  实战 添加百万独立用户\nelements=\u0026#34;\u0026#34; key=\u0026#34;2019_03_09:users\u0026#34; for i in `seq 1 1000000` do elements=\u0026#34;${elements}uuid-\u0026#34;${i} if [[$((i%1000)) == 0]] then redis-cli pfadd ${key} ${ellements} elements=\u0026#34;\u0026#34; fi done 内存消耗为15kb\nTIPS   是否能容忍错误？（错误率 0.81%）\n  是否需要单条数据？（不能）\n  是否需要很小的内存解决问题？\n  GEO GEO是什么 GEO（地理信息定位）：存储经纬度，计算两地距离，范围计算\n实战 需要计算两地距离，以及需要存储用户的位置的场景\nAPI   geo key longitude latitude member [longitude latitude member\u0026hellip;]，增加地理位置信息（经纬度，名称）\n  geopos key member [member \u0026hellip;]，通过名称获取地理位置信息\n  geodist key member1 menber2 [m/km/mi(英里)/ft(尺)],获取两个地理位置的距离\n  georadius key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [ASC|DESC] [COUNT count]  ,获取指定位置范围内的地理位置的信息集合(O(N+logM)， 其中 N 为指定半径范围内的位置元素数量， 而 M 则是被返回位置元素的数量) 代码示例\n  redis\u0026gt; GEORADIUS Sicily 15 37 200 km WITHDIST WITHCOORD 1) 1) \u0026#34;Palermo\u0026#34; 2) \u0026#34;190.4424\u0026#34; 3) 1) \u0026#34;13.361389338970184\u0026#34; 2) \u0026#34;38.115556395496299\u0026#34; 2) 1) \u0026#34;Catania\u0026#34; 2) \u0026#34;56.4413\u0026#34; 3) 1) \u0026#34;15.087267458438873\u0026#34; 2) \u0026#34;37.50266842333162\u0026#34; TIPS   since 3.2+\n  type geoKey = zset\n  没有删除API,可以使用zrem key member\n  ","permalink":"/zh-cn/posts/redis/redis%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/","series":["redis"],"tags":["redis"],"title":"Redis高级特性初识别"},{"categories":["ROS"],"content":"利用enve使用在ros中使用python3 因为ros的python有很多依赖需要使用C，python3的支持不太好。我们可以让当前的环境变量依然是python2，为ros创建一个py3的enve来给它使用\n查看版本： pip -V pip3 -V python -V python3 -V 我的pip和python都是py2.7的\n接下来在你的工作空间中创建enve\nmkdir -p catkin_ws/src cd catkin_ws pip3 install virtualenv #先安装 virtualenv -p /usr/bin/python3 venv#创建一个名为enve的python3环境 source venv/bin/activate #激活enve #创建成功，你应该会看到shell的变化，你可以在这里试一下pip和python，会发现已经变成python3了。 deactivate #关闭enve SLAM 同时定位建模 移动机器人的主要任务：定位，建模，路径规划\nslam 建模工具包： Gmapping，Karto，Heotor，Gartographer\nROS支持的定位工具包： 自适应蒙特卡罗定位：AMCL\n导航工具包集 Navigation：Local，Global\nGlobal：Dijkstra，A×\nLocal;DWA\nSLAM中的MAP： 本质也是一个msg\nTopic：/map\nType：nav_msgs/OccupancyGrid(栅格地图)\nGmapping Topic 输入：base到odom的tf， /scan\n输出：\n定位信息：map_frame\u0026gt;odom的tf消息\nmapping:topic -/map _msg\nKarto topic 输入和Gmapping一样\n输出：map_frame -\u0026gt;odom\nNavigation matepkg ","permalink":"/zh-cn/posts/ros/ros%E5%9F%BA%E7%A1%80/","series":["ROS"],"tags":["ROS"],"title":"ROS基础学习1"},{"categories":["ROS"],"content":"ROS 工作空间:组织和管理功能包的文件夹 catkin workspace\n build (cmake,catkin缓存中间件)\n  src(package 源代码)\n   package1(是catkin编译的基本单元)\n    package2\n    folder\n     package3\n      package3\n    devel(目标文件)\n   头文件\n    动态连接库\n    静态连接库\n    可执行文件\n  catkin(编译工具) catkin ROS定制的编译构建系统\n是对CMake的扩展\n常用命令:\ncatkin_make:  初始化,建立工作空间\n eg:\nmkdir -p ~/catkin_ws/src cd ~/catkin_ws/ catkin_make  编译\n eg:\ncd ~/catkin_ws #回到工作空间 catkin_make source ~/catkin/devel/setup.bash #编译完成后需要使用source进行刷新 package 功能包 是ROS软件的基本组织形式(一个个package)\ncatkin编译的基本单元\n一个package可以包含多个节点(可执行文件),但是至少必须含有CMakeLists.txt和package.XML才能认为这是一个pkg\nCMakeLists.txt 规定了catkin编译的规则(源文件,依賴項，目標文件)\neg:\ncmake_mininum_required() #指定catkin的最低版本 project() #指定軟件包的name find_package() #指定編譯時需要的依賴項 add_message_files()/add_service_files()/add_action_files()#添加消息文件/服務文件/動作文件 generate_message() #指定catkin信息給編譯系統生成cmake文件 add_library()/add_executable() #指定生成庫文件，可執行文件 target_link_libraries() #指定可執行文件鏈接那些庫 catkin_add_gtest() #添加單元測試 install() #生成可安裝目標 如果編譯過程中出現問題，一般都是這個文件的原因\npackage.XML 包的自我描述：定义了package的属性,包名,版本号,作者,依賴等\n\u0026lt;package\u0026gt;\u0026lt;!--root--\u0026gt; \u0026lt;name\u0026gt;\u0026lt;!--包名--\u0026gt; \u0026lt;version\u0026gt;\u0026lt;!--版本号--\u0026gt; \u0026lt;description\u0026gt;\u0026lt;!--包描述--\u0026gt; \u0026lt;maintainer\u0026gt;\u0026lt;!--维护者--\u0026gt; \u0026lt;licsense\u0026gt;\u0026lt;!--软件许可--\u0026gt; \u0026lt;buildtool_depend\u0026gt;\u0026lt;!--编译工具--\u0026gt; \u0026lt;build_depend\u0026gt;\u0026lt;!--编译时的依賴--\u0026gt; \u0026lt;run_depend\u0026gt;\u0026lt;!--运行时的依賴--\u0026gt; \u0026lt;/package\u0026gt; 你也可能会看到manifest.xml,这是rosbuild编译系统使用的信息清單,类似catkin的package.XML\n代码文件: 源文件src(.cpp/python module),頭文件include(.h),腳本scripts(.sh/.py) 自定義通信格式：消息msg(.msg),服務srv(.srv),動作action(*.action) lauch文件(*.lauch):使多个可执行文件一起运行 配置文件:config(*.yaml) 这样一来,我们的package目录结构就变成了: package\n CMakeList.txt\n  package.XML\n  script\n     .py/.sh\n   include\n     *.h\n   src\n     *.cpp/python modulel\n   msg\n     *.msg\n   srv\n     *.srv\n   action\n     *.action\n   lauch\n     *.lauch\n   config\n     *.yaml\n  ros文件系统 常用操作:\nrospack 查找某个pkg的地址\nrospack find pkg_name\n列出本地全部的pkg\nrospack list\nroscd 跳转到pkg的路径下\nroscd pkg_name\nrosls 列举某个pkg下的文件信息\nrosls pkg_name\nrosed 编辑pkg下的文件\nrosed pkg_name file_name\ncatkin_create_pkg 创建一个pkg\ncatkin_create_pkg \u0026lt;pkg_name\u0026gt; [deps]\ndeps指的是这个pkg需要安装哪些依賴\nrosdep 安裝某個pkg所需要的依賴\nrosdep install [pkg_name]\n主要给下载的pkg安装所需要的依賴\n例子： #下載tree sudo apt insall tree #建立一個帶src的文件目錄 mkdir -p catkin_ws/src #cd 到workspace cd catkin_ws/ #tree查看文件結構 tree #初始化 catkin_make #显示1級目录 tree -L 1 #cd到src cd src #新建一个pkg catkin_create_pkg test1 #查看文件结构 tree #在建立pkg时制定依賴(cpp依賴,py依賴,通信依賴,导航依賴) catkin_create_pkg test2 roscpp rospy std_msgs nav_msgs 最后,我们的文件目录是:\ncatkin_ws\n build\n  devel\n  src\n   CMakeList.txt\n    test1\n     CMakeList.txt\n      package.XML\n     test2\n     CMakeList.txt\n      include\n             test2\n       package.xml\n      src\n   对于外部克隆下载的文件: #cd 到工作空间 cd ~/catkin_ws/src #下载或者克隆 git clone ``` cd ~/catkin_ws #安装依賴 rosdep install [pkg_name] #编译 catkin_make #刷新环境(一般选择在配置文件中加入这句话) source ~/catkin_ws/devel/setup.bash 最后一句如果:echo \u0026quot;source ~/catkin_ws/devel/setup.bash\u0026quot; \u0026gt;\u0026gt; ~/.bashrc\n这样,我们每次打开一个新的终端,就会刷新一下source\nmetapackage ros官网称作stack(软件包集),其实指的是自己没有很多内容,大量依賴了其他的包的(link包?)\n主要的一些metapackage:\nnavigation:导航相关\nmoveit:控制机械臂\nimage_pipeline:图像获取,处理\nvision_opencv:ROS与openCV交互的功能包集\nturtlebot:turtlebot机器人相关的包\npr2_robot:pr2机器人驱动功能包集\nROS通信架构 master 节点管理器,管理node之间的通信\n每个节点node启动时都需要向master注册\nnode1\u0026ndash;注册\u0026ndash;\u0026gt;master\u0026mdash;-\u0026gt;node2\n我们在启动ROS时:\n 先启动master:  roscore\n可以启动master(节点管理器),rosout(日志输出),parameter server(参数服务器)\n启动node的一些相关命令:  启动node\nrosrun [pkg_name] [node_name]\n列出当前运行的node的详细信息\nrosnode info [node_name]\n结束运行node:\nrosrun kill [node_name]\n多个node需要启动时:\n使用roslaunch,可以同时启动master和多个node\nroslaunch [pkg_name] [file_name.launch]\n其中file_name.launch的写法如下:\n\u0026lt;launch\u0026gt; \u0026lt;node\u0026gt;\u0026lt;!--需要启动的node及其参数--\u0026gt; \u0026lt;include\u0026gt;\u0026lt;!--包含其他launch文件--\u0026gt; \u0026lt;machine\u0026gt;\u0026lt;!--指定运行的機器--\u0026gt; \u0026lt;env_loader\u0026gt;\u0026lt;!--设置环境变量--\u0026gt; \u0026lt;param\u0026gt;\u0026lt;!--定义参数到参数服务器--\u0026gt; \u0026lt;arg\u0026gt;\u0026lt;!--定义参数传到launch文件中--\u0026gt; \u0026lt;remap\u0026gt;\u0026lt;!--设置参数映射--\u0026gt; \u0026lt;group\u0026gt;\u0026lt;!--设置命名空间--\u0026gt; \u0026lt;/launch\u0026gt; eg:roslaunch pr2_bingup pr2.launch\n通信方式 Topic(主题) ROS中的異步通信方式\nnode之间通过publish-subscribe通信\nnodeA\u0026ndash;发\u0026ndash;\u0026gt; /Topic \u0026ndash;订阅\u0026ndash;\u0026gt; nodeB\neg:\nnode1(camera)\n /camera-rgb\n  /camera-depth\n  这些节点的msg都通过publish上传到topic\n   node2\n diplay\n  从topic订阅\n node3\n image_proless\n  从topic订阅\n 总结  異步通信  通過使用publish()方法,直接发送到topic\n多對多通信  可以发送多个msg到topic\n也可以有多个node从topic上订阅消息\ntopic通信有严格的格式要求,即Message(是topic内容要求的数据类型,定义在*.msg中)   你可以把message看作一种数据类型,也就是一个对象,publish则时操作这种数据对象的一个类\n msg 基本的msg包括:\nbool,int8,int16,int32,int64,uint,float32,float64,string,time,duration,header,array[],array[C]\nmsg是一个类或者说结构体,例如/camera_rgb的msg格式\n\rstd_msgs/Header header\ruint32 seq\rtime stamp\rstring frame_id\ruint32 height\ruint32 width\rstring encoding\ruint8 is_bigendian\ruint32 step\ruint8[] data\rrostopic list 列出当前的全部topic\nrostopic info /topic_name 显示某个topic的属性信息\nrostopic echo /topic_name 显示某个topic的内容\nrostopic pub /topic_name\u0026hellip; 向topic发送内容\nrosmsg list 列出系统上所有的msg\nrosmag show /msg_name 显示某个msg内容\n 如果两个node,在运行时会占用大量的资源,并且不是每一刻都需要对进行通信,使用service更好\n Service(服务) ROS中的同步通信方式(阻塞等待reply)\nNode之間可以通過request-reply的方式通信\nNodeA(Client)\u0026ndash;Req\u0026ndash;\u0026gt;|\u0026lt;\u0026ndash;Reply\u0026ndash; /Service \u0026lt;===\u0026gt;NodeB(Server)\nservice通信方式使用的通信格式是srv\n定义在*.srv中,和msg类似\neg:\n my_pkg/srv/DetectHuman.srv  \rbool start_detect#请求的格式\r---\rmy_pkg/HumanPose[] pose_data #返回的是一个坐标数组\rmy_pkg/msg/HumanPose.msg(里面嵌套了一个msg)  \rstd_msgs/Header header\rstring uuid\rint32 number_of_joints\rmy_pkg/JointPose[] joint_data\rmy_pkg/msg/JointPose.msg  \rstring joint_name\rgeometry_msgs/Pose pose\rfloat32 Confidence\rrosserice list 列出当前所有活跃的service\nrosserice info /service_name 显示某个service的属性信息\nrosserice call /service_name args 调用某个service,args是参数\nrossrv list 列出系统上所有的srv\nrossrv show srv_name 显示出某个srv内容\nParameter Service(参数服务器) 用于存储各种不常改变的参数,配置,以字典的形式存储,可以用命令行,launch,node来读取\nrosparam list 列出所有参数\nrosparam get param_key 显示出某个参数的值\nrosparam set param_key 设置某个参数的值\nrosparam dump file_name 保存参数到文件\nrosparam load file_name 从文件读取参数\nrosparam delete param_key 删除参数\nAction(动作) 一种问答通信机制，带有连续反馈，可以在任务过程中终止运行，基于ROS的消息机制实现\n类似service,带有状态反馈的通信方式\n通常用在长时间,可抢占(可打断)的任务中\n同理action时Action通信使用的数据格式,定义在*.action中\neg:/action/DoDishes.action(分为三部分)\n#Define the goal (client发出) uint32 dishwasher_id #Specify which dishwasher we want to use --- #Define the result (只回答一次,server发出) uint32 total_dishes_cleaned --- #Define a feedback message (实时回传多次,server发出) float32 percent_complete 举一个洗碗机的例子:\nClient\u0026ndash;goal(洗碗机的Id)\u0026ndash;\u0026gt;Server\nServer\u0026ndash;feedback(洗碗的进度)\u0026ndash;\u0026gt;Client\nServer\u0026ndash;result(洗碗的数量,时间)\u0026ndash;\u0026gt;Client\n常用的API   goal:发布任务目标\n  cancel:请求取消任务\n  status:通知客户端当前的状态\n  feedback:周期反馈任务运行的监控数据\n  result:向客户端发送任务的执行结果，只发布一次\n  ROS常用的工具 仿真工具: Gazebo,CV-rep,Carsim 调试,可视化工具:Rviz,rqt Rviz(The Robot Visualization tool) rqt 是一个可视化工具,常用的工具有:\nrqt_graph(查看通信结构,msg的流向) rqt_plot(曲线绘制的工具,可以看到,信息中的数据的变化) rqt_console(查看日志) 命令行工具:rostopic,rosbag\u0026hellip; rosrun :可以运行node rosbag:可以记录和回放数据流 使用方法:\n/topic1 | /topic2\u0026ndash;\u0026gt;record\u0026ndash;\u0026gt;*.bag文件\u0026ndash;\u0026gt;play\u0026ndash;\u0026gt; /topic1 | /topic2\nrosbag record [topic-names] 记录某些topic到bag中\nrosbag record - a(a=all) 记录全部的topic\nrosbag play [bag-files] 回放topic\neg:\nrosbag record /camera/rgb/image_raw roscore rosbag play *.bag(bag-files) rostopic list #查看回放有哪一些topic rostopic info /camera/rgb/image_raw #查看回放中的这个topic rosrun image_view image_view image:=/camera/rgb/image_raw #run这个节点,查看回放的图像 专用工具:Moveit(机械臂) Client Library 提供ROS编程的库(roscpp,rospy,roslisp等),类似接口,但是在API的基础上进行了封装\n","permalink":"/zh-cn/posts/ros/ros%E5%85%A5%E9%97%A8/","series":["ROS"],"tags":["ROS"],"title":"ROS基础学习2"},{"categories":["Shell"],"content":"shell 基础 在终端输入:sh进入脚本界面\nhelloworld 编辑内容\n\r#!/bin/bash\recho \u0026quot;hello world!\u0026quot;\r保存退出:\nw ~/helloworld.sh\n运行:\n\rchmod +x ~/helloworld.sh\rcd ~\r./helloworld.sh\r执行结果:\nhello world!\n分析: 第一行中#!是一个约定的标记,告诉系统脚本需要使用什么解释器来执行,即使用哪一种shell\n这种在第一行指定了解释器信息的方式,需要让脚本作为可执行程序执行\n还有第二种运行方式,即作为解释器参数,这时,第一行的解释器信息,失效\neg:python test.py\nshell 变量 显式赋值:\na=\u0026quot;abc\u0026quot;\n用语句:\nfor file in `ls /etc/` 或者\nfor file in $(ls /etc)\n使用变量: 使用一个定义过的变量:\nfile=\u0026#34;test\u0026#34; echo $file echo ${file} 花括弧是为了帮助解释器识别变量的边界:\nfor skill in Ada Coffe Action java;do echo \u0026#34;I am good at ${skill}Script\u0026#34; done 只读变量 使用readonly :\n#!/bin/bash myUrl=\u0026#39;http://euraxluo.github.io\u0026#39; readonly myUrl 删除变量 unset:\nunset variable_name\n变量被删除后不能再次使用,unset 命令不能删除只读变量\n#!/bin/sh myUrl=\u0026#34;http://euraxluo.github.io\u0026#34; myname=\u0026#34;Euraxluo\u0026#34; readonle myname unset myname unset myUrl echo $myUrl echo $myname 字符串: 单引号 单引号字符串的限制：\n 单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；\n  单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。\n str='this is a string'\n双引号 双引号的优点：\n 双引号里可以有变量\n  双引号里可以出现转义字符\n your_name=\u0026#39;euraxluo\u0026#39; str=\u0026#34;Hello, I know you are \\\u0026#34;$your_name\\\u0026#34;! \\n\u0026#34; echo -e $str 拼接字符串 mynam=\u0026#34;euraxluo\u0026#34; str1=\u0026#34;hello \u0026#34;word\u0026#34; ! from \u0026#34;$myname str2=\u0026#34;hello word ! from $myname\u0026#34; echo $str1 echo $str2 str1=\u0026#39;hello \u0026#39;word\u0026#39; ! from \u0026#39;$myname str2=\u0026#39;hello word ! from $myname\u0026#39; echo $str1 echo $str2 获取字符串长度 在变量名前加#\nstring=\u0026#34;abc\u0026#34; echo ${#string} 提取子字符串 截取字符变量的前5位 expr substr “$a” 1 8\necho $a|cut -c1-8\nstring=\u0026#34;hello world euraxluo\u0026#34; #1 echo `expr substr \u0026#34;$string\u0026#34; 1 5` #2 echo $string | cut -c1-5 按指定的字符串截取 从左向右截取最后一个string后的字符串\n${varible##*string}\n从左向右截取第一个string后的字符串\n${varible#*string}\n从右向左截取最后一个string后的字符串\n${varible%%string*}\n从右向左截取第一个string后的字符串\n${varible%string*}\n“*”只是一个通配符可以不要\nstring=\u0026#34;hello world euraxluo\u0026#34; #1 echo ${string##*ld} #2 echo ${string#*l} #3 echo ${string%%w*} #4 echo ${string%wo*} 查找子字符串 查找r u 的位置:\nstring=\u0026#34;hello world euraxluo\u0026#34; echo `expr index \u0026#34;$string\u0026#34; ru` shell数组 bash支持一维数组（不支持多维数组），并且没有限定数组的大小\n定义数组 数组名=(值1 值2 ... 值n)\neg:\nvalues=( value1 value2 value3 ) echo $values echo ${value[1]} 读取数组 通过下标读取\n${数组名[下标]}\n读取全部元素\necho ${数组名[@]}\n获取数组的长度 # 取得数组元素的个数 length=${#array_name[@]} # 或者 length=${#array_name[*]} # 取得数组单个元素的长度 lengthn=${#array_name[n]} 注释: 单行注释:\n在每行开头加上#\n多行注释:\n 1:\n \r每一行加个#符号太费力了，可以把这一段要注释的代码用一对花括号括起来，定义成一个函数，没有地方调用这个函数，这块代码就不会执行，达到了和注释一样的效果。\r 2:\n :\u0026lt;\u0026lt;EOF 注释内容... 注释内容... 注释内容... EOF 或者\n:\u0026lt;\u0026lt;\u0026#39; 注释内容... 注释内容... 注释内容... \u0026#39; 自动复制脚本\n#!/bin/sh #\t`find /home/euraxluo/Documents/工作报告/bags -mmin +1240 -exec rm -f () \\;` 这是删除21h前的 #\tdf 查看硬盘地址，我的是/run/media/euraxluo/72c7944d-f7e1-4cb9-a431-6b0285044d79/ #\t/home/euraxluo/Documents/工作报告/bags 是我的 bag存放地址 if [ ! -d \u0026#34;/run/media/euraxluo/72c7944d-f7e1-4cb9-a431-6b0285044d79\u0026#34; ];then echo \u0026#34;硬盘还没插\u0026#34; else echo \u0026#34;删除一天前拷贝过来的文件\u0026#34; `find /home/euraxluo/Documents/工作报告/bags -mtime 1 -exec rm -f {} \\;` echo \u0026#34;硬盘插入，自动拷贝中！\u0026#34; for var in `cd /run/media/euraxluo/72c7944d-f7e1-4cb9-a431-6b0285044d79/ \u0026amp;\u0026amp; ls *.bag` do strcp=\u0026#34;cd /run/media/euraxluo/72c7944d-f7e1-4cb9-a431-6b0285044d79/ \u0026amp;\u0026amp; cp -i $var/home/euraxluo/Documents/工作报告/bags/${var##*/}\u0026#34; `awk \u0026#34;BEGIN { cmd=\\\u0026#34;$strcp\\\u0026#34;; print \u0026#34;n\u0026#34; | cmd; }\u0026#34;` done echo \u0026#34;拷贝完成\u0026#34; `cd /home/euraxluo/Documents/工作报告/bags` fi 批量修改文件后缀的shell\n\r#!/bin/bash\r# -*- coding: UTF-8 -*-\roldext=\u0026quot;apng\u0026quot;\rnewext=\u0026quot;png\u0026quot;\rdir=$(eval pwd)\rfor file in $(ls $dir | grep .$oldext)\rdo\rname=$(ls $file | cut -d. -f1)\rmv $file ${name}.$newext\rdone\recho \u0026quot;change apng=====\u0026gt;png done!\u0026quot;\r","permalink":"/zh-cn/posts/shell/shell%E5%9F%BA%E7%A1%80/","series":["Shell"],"tags":["Shell"],"title":"Shell 基础"},{"categories":["Shell"],"content":"shell进阶  破壳漏洞\nenv x='() { :;}; echo shellshocked' bash –c \u0026quot;echo test\u0026quot;检查,如果输出了两行,那么需要升级bash的版本\n  解释器的类型\n    系统中的shells使用cat /etc/shells查看:\n/bin/sh /bin/dash /bin/bash /bin/rbash /usr/bin/tmux /usr/bin/screen /bin/zsh /usr/bin/zsh   设置解释器的类型 #!/bin/bash在文件的开头使用,内核会根据\u0026quot;#!\u0026ldquo;后的解释器来确定该用那个程序解释这个脚本中的内容\n  脚本的编辑   vim帮助我们编辑脚本  我的vimrc内容\n1 set tabstop=4 2 set shiftwidth=4 3 set expandtab 4 set number 5 autocmd BufNewFile *.py,*.cc,*.sh,*.java exec \u0026#34;:call SetTitle()\u0026#34; 6 func SetTitle() 7 if expand(\u0026#34;%:e\u0026#34;) == \u0026#39;sh\u0026#39; 8 call setline(1,\u0026#34;#!/bin/bash\u0026#34;) 9 call setline(2,\u0026#34;# Author: Euraxluo\u0026#34;) 10 call setline(3,\u0026#34;# Email: Euraxluo@outlook.com\u0026#34;) 11 call setline(4,\u0026#34;# Time:\u0026#34; .strftime(\u0026#34;%F %T\u0026#34;)) 12 call setline(5,\u0026#34;# Description: \u0026#34;) 13 call append(line(\u0026#34;.\u0026#34;), \u0026#34;\\# File Name: \u0026#34;.expand(\u0026#34;%\u0026#34;)) 14 endif 15 autocmd BufNewFile * normal G 16 endfunc  脚本的执行\nsh/bash scripts.sh chown +x ./scripts.sh \u0026amp;\u0026amp; ./scripts.sh   source scripts.sh . scripts.sh cat oldboyedu.sh |bash # 效率较低\n\r其中`source` 和`.` 都是在当前的shell中执行一个文件中的命令\r而`sh`会新建一个进程去执行一个文件中的命令\rsh和bash的关系:\r```bash\rwhich sh\r\u0026gt; /bin/sh\rll /bin/sh\r\u0026gt; lrwxrwxrwx 1 root root 4 Jul 25 21:47 /bin/sh -\u0026gt; bash\r变量    环境变量\nenv/declare/set/export -p 这四个命令 输出的结果有些不同\n配置文件的读取顺序:\n① /etc/profile\n② ~/.bash_profile\n③ ~/.bashrc\n④ /etc/bashrc\n  普通变量\n  a=1 b=\u0026#39;1\u0026#39; c=\u0026#34;1\u0026#34; a=1 echo \u0026#34;$a\u0026#34; \u0026gt; 1 echo \u0026#34;${b}\u0026#34; \u0026gt; 1 echo \u0026#34;$c\u0026#34; \u0026gt; 1 连续普通字符串内容赋值给变量，不管用什么引号或者不用引号，它的内容是什么，打印变量就输出什么\n  位置变量\n         $0 获取当前执行shell脚本的文件名,执行时带路径,则包括路径   $n 获取当前执行shell脚本的第n个参数,n:1\u0026hellip;9,如果n大于9用大括号括起来{10}   $# 获取当前执行的shell脚本后面接的参数的个数   $*/$@ 获取当前shell的所有传参的参数   \u0026ldquo;$*\u0026rdquo; 将所有的参数视为单个字符串   \u0026ldquo;$@\u0026rdquo; 将所有的参数视为不同的独立字符,多用于传递参数    #./test.sh 1s asa 2 3 4 5 6 set -v #用于调试 set -x test(){ mm=$1 echo $mm } echo $* + echo 1s asa 2 3 4 5 6 1s asa 2 3 4 5 6 test $* + test 1s asa 2 3 4 5 6 + mm=1s echo \u0026#34;$*\u0026#34; + echo \u0026#39;1s asa 2 3 4 5 6\u0026#39; 1s asa 2 3 4 5 6 test \u0026#34;$*\u0026#34; + test \u0026#39;1s asa 2 3 4 5 6\u0026#39; + mm=\u0026#39;1s asa 2 3 4 5 6\u0026#39; + echo 1s asa 2 3 4 5 6 1s asa 2 3 4 5 6 echo $@ + echo 1s asa 2 3 4 5 6 1s asa 2 3 4 5 6 echo \u0026#34;$@\u0026#34; + echo 1s asa 2 3 4 5 6 1s asa 2 3 4 5 6 test \u0026#34;$@\u0026#34; + test 1s asa 2 3 4 5 6 + mm=1s   进程状态变量\n         $? 获取上一个指令的执行状态返回值(0成功,非零为失败)   $$ 获取当前执行的shell脚本的PID   $! 获取上一个后台工作的进程的PID   $_ 获取在此之前执行的命令或脚本的最后一个参数      export命令\n说明:\n  在当前shell窗口及子shell窗口生效\n  在新开的shell窗口不会生效，生效需要写入配置文件\n    反引号赋值\ntime=`data` echo $time \u0026gt; Fri Jan 3 21:44:04 CST 2020   TIPS\n  变量名通常要大写。\n  变量可以在自身的Shell及子Shell中使用。\n  常用export来定义环境变量。\n  执行env默认可以显示所有的环境变量名称及对应的值。\n  输出时用“$变量名”，取消时用“unset变量名*”。\n  书写crond定时任务时要注意，脚本要用到的环境变量最好先在所执行的Shell脚本中重新定义。\n  如果希望环境变量永久生效，则可以将其放在用户环境变量文件或全局环境变量文件里。\n  只有在变量的值中有空格时,才需要使用引号,单引号和双引号的区别在于是否能解析特殊符号\n  如果内容是纯数字简单连续的字符(不喊空格)时,可以不使用引号\n  没有特殊情况时,字符串一律使用双引号定义赋值\n  当变量中的内容需要原样输出时,使用单引号\n  希望变量的内容是命令的解析结果时,要使用反引号或者$()把命令括起来在赋值\n    变量子串   说明     表达式 说明     ${v} 返回变量$v的内容   ${#v} 返回$v的长度   ${v:offset} 返回在变量${v}中，从位置offset之后开始提取子串到结尾   ${v:offset:lenght} 在变量${v}中，从位置offset之后开始提取长度为length的子串   ${v#word} 从变量${v}开头开始删除最短匹配的word子串   ${v##word} 从变量${v}开头开始删除最长匹配的word子串   ${v%word} 从变量${v}结尾开始删除最短匹配的word子串   ${v%%word} 从变量${v}结尾开始删除最长匹配的word子串   ${parameter/pattem/string} 使用string代替第一个匹配的pattern   ${parameter//pattem/string} 使用string代替所有匹配的pattern    范例\n# ${v:offset:lenght} mm=0123456 echo ${mm:1:0} \u0026gt; echo ${mm:1:1} \u0026gt; 1 echo ${mm:1:2} \u0026gt; 12 echo ${mm:1:-1} \u0026gt; 12345 # ## 与 #  file=/dir1/dir2/dir3/my.file.txt \u0026gt; file=/dir1/dir2/dir3/my.file.txt echo ${file#*/} \u0026gt; dir1/dir2/dir3/my.file.txt echo ${file##*/} \u0026gt; my.file.txt echo ${file#*.} \u0026gt; file.txt echo ${file##*.} \u0026gt; txt # %% 与 % echo ${file%/*} \u0026gt; /dir1/dir2/dir3 echo ${file%%/*} \u0026gt; echo ${file%.*} \u0026gt; /dir1/dir2/dir3/my.file echo ${file%%.*} \u0026gt; /dir1/dir2/dir3/my # // 与 / echo ${file/dir/path} \u0026gt; /path1/dir2/dir3/my.file.txt echo ${file//dir/path} \u0026gt; /path1/path2/path3/my.file.txt # // split 字符串 list=1,2,3,4,5 echo ${list//,/ } \u0026gt; 1 2 3 4 5 array=(${list//,/ }) echo \u0026#34;${array[*]}\u0026#34; \u0026gt; 1 2 3 4 5  特殊扩展变量\n说明\n   表达式 说明     ${v:+word} (v != \u0026lsquo;') ?word :   ${v:-word} (v != \u0026lsquo;') ? :word   ${v:?word} (v != \u0026lsquo;') ? :(word;exit -1)   ${v:=word} (v != \u0026lsquo;') ? :(word;v=word)   ${v-word} (v not exist) ?word :v      条件表达式\n   文件判断     常用文件测试操作符 说明     -d文件，d的全拼为directory 文件存在且为目录则为真，即测试表达式成立   -f文件，f的全拼为file 文件存在且为普通文件则为真，即测试表达式成立   -e文件，e的全拼为exist 文件存在则为真，即测试表达式成立。注意区别于“-f”，-e不辨别是目录还是文件   -r文件，r的全拼为read 文件存在且可读则为真，即测试表达式成立   -s文件，s的全拼为size 文件存在且文件大小不为0则为真，即测试表达式成立   -w文件，w的全拼为write 文件存在且可写则为真，即测试表达式成立   -x文件，x的全拼为executable 文件存在且可执行则为真，即测试表达式成立   -L文件，L的全拼为link 文件存在且为链接文件则为真，即测试表达式成立   fl -nt f2，nt 的全拼为 newer than 文件fl比文件f2新则为真，即测试表达式成立。根据文件的修改时间来计算   fl -ot f2，ot 的全拼为 older than 文件fl比文件f2旧则为真，即测试表达式成立。根据文件的修改时间来计算     字符串判断     常用字符串测试操作符 说明     -n \u0026ldquo;字符串\u0026rdquo; 若字符串的长度不为0,则为真，即测试表达式成立，n可以理解为no zero   -Z \u0026ldquo;字符串\u0026rdquo; 若字符串的长度为0,则为真，即测试表达式成立，z可以理解为zero的缩写   \u0026ldquo;串1\u0026rdquo;== \u0026ldquo;串2\u0026rdquo; 若字符串1等于字符串2,则为真，即测试表达式成立，可使用\u0026rdquo;==\u0026ldquo;代替\u0026rdquo;=\u0026quot;   \u0026ldquo;串1\u0026rdquo;!= \u0026ldquo;串*2\u0026rdquo; 若字符串1不等于字符串2,则为真，即测试表达式成立，但不能用\u0026quot;!==\u0026ldquo;代替\u0026rdquo;!=\u0026quot;   1.对于字符串的测试，一定要将字符串加双引号之后再进行比较。 2.空格非空      整数判断\n   在**[]**以及**test**中使用的比较符号 在**(())**和**[[]]**中使用的比较符号 说明     -eq ==/= 相等，全拼为equal   -ne != 不相等，全拼为not equal   -gt \u0026gt; 大于，全拼为greater than   -ge \u0026gt;= 大于等于，全拼为greater equal   -lt \u0026lt; 小于，全拼为丨ess than   -le \u0026lt;= 小于等于，全拼为less equal      逻辑符号\n   在**[]**和**test**中使用的操作符 说明 在**[[]]**和**(())**中使用的操作符 说明     -a [ 条件A -a 条件B ]A与B都要成立，整个表达式才成立 \u0026amp;\u0026amp; and，与，两端都为真，则结果为真   -o [ 条件A -o 条件B]A与B都不成立，整个表达式才不成立 || or，或，两端有一个为真，则结果为真   ！ 非 ! not，非，两端相反，则结果为真      if条件语句  file=$1 if [ -d $file ] then echo \u0026#34;$fileis a dir\u0026#34; elif [ -f $file ] then echo \u0026#34;$fileis a file\u0026#34; else echo \u0026#34;end\u0026#34; fi  case条件语句\n# . ./test.sh -a 1 -b 2 -c 3 -d 4 -1 # \u0026gt; # 2 # 3 # 4 # e p(){ str=$1 echo \u0026#34;$1\u0026#34; } main(){ while getopts \u0026#34;🅰️b:c:d:e:\u0026#34; OPT do case $OPT in a) p $OPTARG;; b) p $OPTARG;; c) p $OPTARG;; d) p $OPTARG;; e) p $OPTARG;; :) p $OPTARG;; ?) p $OPTARG;; esac done } main \u0026#34;$@\u0026#34;   for循环\n    列表for循环\n# . ./test.sh 1 2 3  # 1 lenght: 1 # 13 lenght: 2 # 43 lenght: 2 # 4 lenght: 1 # 0 lenght: 1 # 5 lenght: 1 array=(1 13 43 4 0 5) main(){ for i in ${array[*]} do echo \u0026#34;$ilenght: ${#i}\u0026#34; done } main \u0026#34;$@\u0026#34;   不带列表for循环\n# . ./test.sh 1 2 3  # 1 # 2 # 3 # 1 # 2 # 3 for i do echo $i done ## 效果等同于: for i in $* do echo $i done   C风格for循环\narray=(1 13 43 4 0 5) for((i=0;i\u0026lt;${#array[@]};i++)) do echo ${array[$i]} done    while循环\n#while :创建守护进程 #临时监听81端口,达到服务器的效果 # nc -l 81 while true do echo \u0026#34;ok\u0026#34;|nc -l 81 done   文件读取\n    迭代获取文件的每一行\n#1 while read line do echo $line done \u0026lt; $1 #2 cat $1| while read line do echo $line done #3 exec \u0026lt; $1 while read line do echo $line done   迭代获取每一个单词\nline=\u0026#34;sasa sas as as asas\u0026#34; array=($line) for word in ${array[@]}; do echo $word; done   迭代获取每一个字符\nword=\u0026#34;wordwordword\u0026#34; for ((i=0;i\u0026lt;${#word};i++)) do echo ${word:$i:1} done   统计文章的行数和词数,字节数\nexec \u0026lt; $1 lines=1 total_words=0 bytes=0 while read line do echo \u0026#34;$lines:\u0026#34;$line words=1 array=($line) for word in ${array[@]}; do echo \u0026#34;$words:\u0026#34;$word; for ((i=0;i\u0026lt;${#word};i++)) do echo ${word:$i:1}; done ((words++)) ((total_words+=words)) done ((bytes+=${#line})) ((lines++)) done echo \u0026#34;lines:$lines;total_words:$total_words;bytes:$bytes(with out \u0026#39; |\\r|\\n\u0026#39;)\u0026#34;   分割字符串转为数组    使用{str//,/ }处理\nstr=\u0026#34;1,2,3,4,5\u0026#34; arr=(${str//,/}) echo ${arr[@]}   使用tr\nstr=\u0026#34;1,2,3,4,5\u0026#34; arr=(`echo $str | tr \u0026#39;,\u0026#39; \u0026#39; \u0026#39;`) echo ${arr[@]}   awk\nstr=\u0026#34;1,2,3,4,5\u0026#34; arr=($(echo $str|awk \u0026#39;BEGIN{FS=\u0026#34;,\u0026#34;;OFS=\u0026#34; \u0026#34;}{print $1,$2,$3,$4,$5}\u0026#39;)) echo ${arr[@]}   IFS\nstr=\u0026#34;1,2,3,4,5\u0026#34; IFS=\u0026#34;,\u0026#34; arr=(str) echo ${str[@]}   array    定义数组arr=(001 002 003)\n  定义数组arr=([1]=321 [3]=ewq)\n  命令执行结果赋值`\ndir=(`ls`) dir=($(ls))   数组长度${#arr[@]}\n  获取所有元素${arr[@]}\n  获取所有的下标${!arr[@]}\n  根据索引(下标)获取元素${arr[1]}\n  遍历数组 for i in ${arr[@]};do echo $i;done\n  遍历数组for i in ${!arr[@]};do echo ${arr[$i]};done\n  遍历数组\nfor i in `eval echo {1..${#arr[@]}}`;do echo ${arr[$i]};done   增加元素arr[3]=004\n  修改元素arr[3]=005\n  删除元素unset arr[2]\n  map   定义mapdeclare -A map=([key1]=value1 [key2]=value2 [key3]=value3) 获取所有元素${map[@]} 获取所有keys${!map[@]} 根据key获取value${map[key1]} 修改元素map[key1]=\u0026quot;new value\u0026quot; 遍历mapfor i in ${!map[@]};do echo ${map[$i]};done  ","permalink":"/zh-cn/posts/shell/shell%E8%BF%9B%E9%98%B6%E4%B8%8E%E6%80%BB%E7%BB%93/","series":["Shell"],"tags":["Shell"],"title":"Shell 进阶"},{"categories":["redis"],"content":"Redis的特点 速度快   使用内存\n  使用C语言\n  单线程\n  持久化  对数据的更新，异步保存到磁盘上  多种数据结构   strings/Blobs/Bitmaps\n  Hash Tables\n  Linked Lists\n  Sets\n  Sorted Sets\n  BitMaps\n  HyperLogLog(超小内存唯一值计数)\n  GEO\n  多语言支持 功能丰富   发布topic\n  支持lua脚本\n  支持简单的事务\n  支持pipeline\n  高可用，分布式 Redis初识   缓存\n  计数器\n  消息队列系统\n  排行榜\n  实时系统\n  社交队列\n  Redis 可执行文件介绍   redis-server：redis服务器\n  redis-cli：rdis命令行服务端\n  redis-benchmark：性能测试\n  redis-check-aof： aof修复工具\n  redis-check-dump：rdb文件检查工具\n  redis-sentinel：sentinel服务器\n  启动方式 最简启动 启动\nredis-server\n验证\nps -ef|grep redis\nnetstat -antpl | grep redis\nredis-cli -h ip -p port ping\n配置启动 daemonsize:是否以守护进程的方式启动\nport:redis对外端口号\nlogfile:redis系统日志\ndir:redis工作目录\n#redis是单进程，但是一般电脑是多线程的，所以我们可以开多个redis进程，通过不同的端口来访问 mkdir -p /home/redis/config cp /etc/redis/redis.conf /home/redis/config/redis.conf #查看修改配置 cd /home/redis/conf cat redis.conf|grep -v \u0026#34;#\u0026#34; |grep -v \u0026#34;^$\u0026#34; \u0026gt; redis-6380.conf 配置说明 INCLUDES 　多个人进行开发维护，需要多个配置文件，可以在此通过 include /path/to/local.conf 配置进来，而原本的 redis.conf 配置文件是一个汇总。\n　注意，如果此配置写在redis.conf 文件的开头，那么后面的配置会覆盖引入文件的配置，如果想以引入文件的配置为主，那么需要将 include 配置写在 redis.conf 文件的末尾。\n　MODULES 通过 loadmodule path/to/my_module.so引入自定义模块\nNETWORK 　①、bind:绑定redis服务器网卡IP，默认为127.0.0.1,即本地回环地址。这样的话，访问redis服务只能通过本机的客户端连接，而无法通过远程连接。如果bind选项为空的话，那会接受所有来自于可用网络接口的连接。\n　②、port：指定redis运行的端口，默认是6379。由于Redis是单线程模型，因此单机开多个Redis进程的时候会修改端口。\n　③、timeout：设置客户端连接时的超时时间，单位为秒。当客户端在这段时间内没有发出任何指令，那么关闭该连接。默认值为0，表示不关闭。\n　④、tcp-keepalive ：单位是秒，表示将周期性的使用SO_KEEPALIVE检测客户端是否还处于健康状态，避免服务器一直阻塞，官方给出的建议值是300s，如果设置为0，则不会周期性的检测。\n　GENERAL 　①、daemonize:设置为yes表示指定Redis以守护进程的方式启动（后台启动）。默认值为 no\n　②、pidfile:配置PID文件路径，当redis作为守护进程运行的时候，它会把 pid 默认写到 /var/redis/run/redis_6379.pid 文件里面\n　③、loglevel ：定义日志级别。默认值为notice，有如下4种取值：\n　debug（记录大量日志信息，适用于开发、测试阶段）\n　verbose（较多日志信息）\n　notice（适量日志信息，使用于生产环境）\n　warning（仅有部分重要、关键信息才会被记录）\n　④、logfile ：配置log文件地址,默认打印在命令行终端的窗口上\n　⑤、databases：设置数据库的数目。默认的数据库是DB 0 ，可以在每个连接上使用select \u0026lt;dbid\u0026gt; 命令选择一个不同的数据库，dbid是一个介于0到databases - 1 之间的数值。默认值是16.\n　SNAPSHOTTING 　这里的配置主要用来做持久化操作。\n　　①、save：这里是用来配置触发 Redis的持久化条件，也就是什么时候将内存中的数据保存到硬盘。默认如下配置：\nsave 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存\nsave 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存\nsave 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存\n　当然如果你只是用Redis的缓存功能，不需要持久化，那么你可以注释掉所有的 save 行来停用保存功能。可以直接一个空字符串来实现停用：save \u0026quot;\u0026quot;\n　②、stop-writes-on-bgsave-error ：默认值为yes。当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据。这会让用户意识到数据没有正确持久化到磁盘上，否则没有人会注意到灾难（disaster）发生了。如果Redis重启了，那么又可以重新开始接收数据了\n　③、rdbcompression ；默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。\n　④、rdbchecksum ：默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。\n　⑤、dbfilename ：设置快照的文件名，默认是 dump.rdb\n　⑥、dir：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。使用上面的 dbfilename 作为保存的文件名。\nREPLICATION 　①、slave-serve-stale-data：默认值为yes。当一个 slave 与 master 失去联系，或者复制正在进行的时候，slave 可能会有两种表现：\n　1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，或者数据可能是空的在第一次同步的时候\n　2) 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，slave 都将返回一个 \u0026ldquo;SYNC with master in progress\u0026rdquo; 的错误\n　②、slave-read-only：配置Redis的Slave实例是否接受写操作，即Slave是否为只读Redis。默认值为yes。\n　③、repl-diskless-sync：主从数据复制是否使用无硬盘复制功能。默认值为no。\n　④、repl-diskless-sync-delay：当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。 这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段 时间以期更多的从站到达。延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动。默认值为5。\n　⑤、repl-disable-tcp-nodelay：同步之后是否禁用从站上的TCP_NODELAY 如果你选择yes，redis会使用较少量的TCP包和带宽向从站发送数据。但这会导致在从站增加一点数据的延时。 Linux内核默认配置情况下最多40毫秒的延时。如果选择no，从站的数据延时不会那么多，但备份需要的带宽相对较多。默认情况下我们将潜在因素优化，但在高负载情况下或者在主从站都跳的情况下，把它切换为yes是个好主意。默认值为no。\nSECURITY 　①、rename-command：命令重命名，对于一些危险命令例如：\n　flushdb（清空数据库）\n　flushall（清空所有记录）\n　config（客户端连接后可配置服务器）\n　keys（客户端连接后可查看所有存在的键）\n　作为服务端redis-server，常常需要禁用以上命令来使得服务器更加安全，禁用的具体做法是是：\nrename-command FLUSHALL \u0026quot;\u0026quot;\n也可以保留命令但是不能轻易使用，重命名这个命令即可：\nrename-command FLUSHALL abcdefg\n　这样，重启服务器后则需要使用新命令来执行操作，否则服务器会报错unknown command。\nCLIENTS 　①、maxclients ：设置客户端最大并发连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件。 描述符数-32（redis server自身会使用一些），如果设置 maxclients为0 。表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息\nMEMORY MANAGEMENT 　①、maxmemory：设置客户端最大并发连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件。描述符数-32（redis server自身会使用一些），如果设置 maxclients为0 。表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息。\n　②、maxmemory-policy ：当内存使用达到最大值时，redis使用的清楚策略。有以下几种可以选择：\n　1）volatile-lru 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used )\n　2）allkeys-lru 利用LRU算法移除任何key\n　3）volatile-random 移除设置过过期时间的随机key\n　4）allkeys-random 移除随机ke\n　5）volatile-ttl 移除即将过期的key(minor TTL)\n　6）noeviction noeviction 不移除任何key，只是返回一个写错误 ，默认选项\n　③、maxmemory-samples ：LRU 和 minimal TTL 算法都不是精准的算法，但是相对精确的算法(为了节省内存)。随意你可以选择样本大小进行检，redis默认选择3个样本进行检测，你可以通过maxmemory-samples进行设置样本数。\nAPPEND ONLY MODE 　①、appendonly：默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式， 可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入appendonly.aof文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。默认值为no。\n　②、appendfilename ：aof文件名，默认是\u0026quot;appendonly.aof\u0026quot;\n　③、appendfsync：aof持久化策略的配置；no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快；always表示每次写入都执行fsync，以保证数据同步到磁盘；everysec表示每秒执行一次fsync，可能会导致丢失这1s数据\n　④、no-appendfsync-on-rewrite：在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。 设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。默认值为no。\n　⑤、auto-aof-rewrite-percentage：默认值为100。aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。\n　⑥、auto-aof-rewrite-min-size：64mb。设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写。\n　⑦、aof-load-truncated：aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项，出现这种现象 redis宕机或者异常终止不会造成尾部不完整现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。默认值为 yes。\nLUA SCRIPTING 　①、lua-time-limit：一个lua脚本执行的最大时间，单位为ms。默认值为5000.\nREDIS CLUSTER 　①、cluster-enabled：集群开关，默认是不开启集群模式。\n　②、cluster-config-file：集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。 这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件。请确保与实例运行的系统中配置文件名称不冲突。默认配置为nodes-6379.conf。\n　③、cluster-node-timeout ：可以配置值为15000。节点互连超时的阀值，集群节点超时毫秒数\n　④、cluster-slave-validity-factor ：可以配置值为10。在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了， 导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period 如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移\n　⑤、cluster-migration-barrier ：可以配置值为1。master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。\n　⑥、cluster-require-full-coverage：默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。 设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致。\n","permalink":"/zh-cn/posts/redis/redis%E9%85%8D%E7%BD%AE/","series":["redis"],"tags":["redis"],"title":"Redis基础配置"},{"categories":["TensorFlow"],"content":"TensorFlow 基础 计算密集型(tensorflow) cpu计算\nio密集型(Django,Scrapy) http请求\n线性回归回顾  准备好特征和lable  y = x*0.7+0.8\n2.建模.随机初始化一个权重w,一个偏置b\ny_predict = wx+b\n求损失函数  less化损失函数\n(y-y_predict)^2/x.shape[0]\n4.梯度下降优化损失函数,我们需要查阅tensorflowAPI,制定合适的eta\n变量作用域 tf.variable_scope\n让变量显示可观测  收集变量    tf.summary.scalar(name='',tensor) #收集单值变量,name是变量名,tensor为值\n  tf.summary.histogram(name='',tensor) #收集高纬度的变量参数\n  tf.summary.image(name='',tensor) #收集输入的图片张量能显示图片\n  合并变量写入事件文件    merged = tf.summary.merge_all()\n  summary = sess.run(merged) #每次迭代都需要运行\n  FileWriter.add_summary(summary,i) #表示第几次的值\n  模型的保存和加载 tf.train.Save(var_list = None,max_to_keep = 5)\n var_list:指定将要保存和还原的变量.他可以作为一个dict或一个列表传递\n  max_to_keep:指示要保留的最近检查点文件的最大数量.创建新文件时,会删除较旧文件,默认为5,即保留最近的5个检查点文件\n 定义命令行参数   先定义有哪些参数需要在运行时指定\n  程序中获取定义命令行参数\n  使用时 python *.py --name=参数 [--DEFINE_name=参数]\n  import os import tensorflow as tf #定义参数的名字,默认值,说明 tf.app.flags.DEFINE_integer(\u0026#34;max_step\u0026#34;,100,\u0026#34;模型的训练步数\u0026#34;) tf.app.flags.DEFINE_string(\u0026#34;model_dir\u0026#34;,\u0026#34;\u0026#34;,\u0026#34;模型文件的加载路径\u0026#34;) #定义获取命令行参数的名字 FLAGS = tf.app.flags.FLAGS def mylg(): g3 = tf.get_default_graph() with tf.variable_scope(\u0026#34;data\u0026#34;): # 准备特征和lablel x = tf.random_normal([1000,1],mean=1.75,stddev=0.5,name=\u0026#34;X_data\u0026#34;) y = tf.matmul(x,[[0.7]]) + 0.8#举证相乘必须是二维的 with tf.variable_scope(\u0026#34;model\u0026#34;): # 设置模型 w = tf.Variable(tf.random_normal([1,1],mean=0.0,stddev=1.0),name=\u0026#34;w\u0026#34;,trainable=True) #trainable设置这个变量是否变化 b = tf.Variable(0.5,name=\u0026#39;b\u0026#39;) y_predict = tf.matmul(x,w) + b with tf.variable_scope(\u0026#34;loss\u0026#34;): #写损失函数 loss = tf.reduce_mean(tf.square(y-y_predict)) with tf.variable_scope(\u0026#34;train\u0026#34;): train = tf.train.GradientDescentOptimizer(0.01).minimize(loss) #1. 收集tensor tf.summary.scalar(\u0026#34;loss\u0026#34;,loss) tf.summary.histogram(\u0026#39;weight\u0026#39;,w) tf.summary.histogram(\u0026#39;bias\u0026#39;,b) #2. 合并变量 merged = tf.summary.merge_all() #初始化变量 init = tf.global_variables_initializer() #定义一个保存模型的实例 saver = tf.train.Saver() with tf.Session(graph=g3) as sess: sess.run(init) filewriter = tf.summary.FileWriter(\u0026#39;/home/python/jupyter/TensorFlow\u0026#39;,graph=g3) #加载模型 if os.path.exists(FLAGS.model_dir+\u0026#34;/checkpoint\u0026#34;): saver.restore(sess,FLAGS.model_dir+\u0026#34;/model\u0026#34;) for i in range(FLAGS.max_step): sess.run(train) summary = sess.run(merged) filewriter.add_summary(summary,i) if i%20==0: print(\u0026#34;第%d次优化的参数权重为%f,偏置为%f\u0026#34;%(i,w.eval(),b.eval())) if i%200==0: saver.save(sess,FLAGS.model_dir+\u0026#34;/model\u0026#34;)#保存模型 mylg() graph图 创建一张图包含了一组op和tensor,上下文环境\n没创建一个图就会包含一个内存地址\n一个Session运行一张图 tf.InteractiveSession()#开启Session一个上下文环境\ng = tf.Graph() with g.as_default(): c = tf.constant(11.0) a = tf.constant(5.0) b = tf.constant(6.0) sum1 = tf.add(a,b) mul = tf.multiply(a,b) g2 = tf.get_default_graph() #config=tf.ConfigProto(log_device_placement=True) 可以查看运行在那些cpu with tf.Session(graph=g2,config=tf.ConfigProto(log_device_placement=True)) as sess: print(sess.run(sum1))## run()方法 print(sess.run([a,b])) print(sum1.eval()) 重载 默认会把运算符重载为op\nd = tf.constant(1.0) e = 11.0 sum2 = d+e with tf.Session() as sess: print(sess.run(sum2))## run()方法 实时的提供数据进行训练 在程序执行时,不确定输入的shape\nplaceholder #占位符\nplt = tf.placeholder(tf.float32,[None,3])#样本数不固定,三列 print(plt)#打印这个张量 #使用 with tf.Session() as sess: print(sess.run(plt,feed_dict={plt:[[1,2,3],[4,5,6]]}))## run()方法 张量的动态形状和静态形状 Numpy:把原来的数据通过reshape直接改变\n 静态形状：  创建一个张量，初始化状态的形状：\ntf.Tensor.get_shape:获取静态形状\rtf.Tensor.set_shape():更新Tensor对象的静态形状\r  动态形状:  一种描述原始张量在执行过程中的一种形状(动态变化)\ntf.reshape:创建一个具有不同形状的新张量\r plt.set_shape([3,3])#把plt的shape从[?,3]变成[3,3] with tf.Session() as sess: print(sess.run(plt,feed_dict={plt:[[1,2,3],[4,5,6],[7,8,9]]}))## run()方法 变量 变量也是一种op,是一种特殊的张量,能够进行持久化,他的值就是张量,默认被训练\nvar = tf.Variable(tf.random_normal([2,3],mean=0.0,stddev=1.0))#均值为0,标准差为1 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) print(sess.run(var)) Tensorboard  数据序列化-\u0026gt;events文件  TensorBoard通过读取TensorFlow的事件文件来运行\n 生成文件:  tf.summary.FileWriter(\u0026lsquo;dir-path\u0026rsquo;,graph=g?)\n返回一个filewriter\n 开启:  tensorboard \u0026ndash;logdir='/dir-path'\nd = tf.constant(1.0) e = tf.constant(1.0) sum2 = d+e var = tf.Variable(tf.random_normal([2,3],mean=0.0,stddev=1.0))#均值为0,标准差为1 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) print(sess.run(var)) print(sess.run(sum2))## run()方法 filewriter = tf.summary.FileWriter(\u0026#39;/home/python/jupyter/TensorFlow\u0026#39;,graph=sess.graph) 文件读取 队列与队列管理器  在训练样本的时候,希望数据有序读取   tf.FIFOQueue(capacity,dtypes,name=\u0026lsquo;fifo_queue\u0026rsquo;) 先进先出队列,按顺序出队列\n   capacity:整数,可能存储在此队列中的元素数量的上限\n  dtypes:DType对象列表,长度dtypes必须等于每个队列元素中的张量数,dtype的元素形状,决定了后面进队元素的形状\n   tf.RandomShuffleQueue 随机出队列\n 异步读取,队列管理器  tf.train.QueueRunner(queue,enqueue_ops=None)创建一个QueueRunner\n 线程协调器,实现一个简单的机制来协调一组线程的终止  tf.train.Coordinator()\n   request_stop()\n  should_stop()检查是否要求停止\n  join(threads = None,stop_grace_period_secs=120)\n  读取文件的流程 1.构建文件队列 将输出字符串到管道队列中\n tf.train.string_input_producer(string_tensor,shuffle = True)\n   string_tensor 含有文件名的1阶张量\n  num_epochs 过几遍数据,默认无线过数据\n  return:具有输出字符串的队列\n  2.构造文件阅读器,读取队列内容(都是用read(file_queue)这个方法,从文件中读取指定数量内容)  tf.TextLineReader(阅读文本文件csv,默认按行读取)\n  tf.FixedLengthRecordReader(record_bytes):读取每个记录是固定数量的二进制文件\n  record_bytes:整形,指定每次读取的字节数   tf.TFRecordReader: 读取TFRecords文件\n 3.读取每个队列文件的每一个样本  tf.decode_csv(records,record_defaults=None,field_delim=None,name=None)\n   将csv转换为张量,与tf.TextLineReader搭配使用\n  records:tensor型字符串,每个字符串是csv中的记录行\n  field_delim:默认分隔符\u0026quot;,\u0026quot;\n  record_defauts:参数决定所得每一列张量的类型,并设置一个值,在输入字符串中缺少使用默认值\n   tf.decode_raw(bytes,out_type,little_endian=None,name=None)\n 将字节转换为一个数字向量表示,字节为一字符类型的张量,二进制读取为uint8\n4.批处理 tf.train.batch([sentence],batch_size=30,num_threads=1,capacity=30)\n​\nimport tensorflow as tf import os def myqueu(): # 1. 定义队列 Q = tf.FIFOQueue(1000,tf.float32) # 2. 定义子线程操作 var = tf.Variable(0.0) data = tf.assign_add(var,tf.constant(1.0)) enq = Q.enqueue(data) # 3. 定义队列管理器,指定线程数 qr = tf.train.QueueRunner(Q,enqueue_ops=[enq]*4) #初始化变量 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) #开启线程协调管理器 coord = tf.train.Coordinator() threads = qr.create_threads(sess,coord=coord,start=True) for i in range(300): print(sess.run(Q.dequeue())) coord.request_stop() coord.join(threads) def convread(filelist): # 1.构造队列 file_queue = tf.train.string_input_producer(filelist) # 2.构造阅读器 reader = tf.TextLineReader() key, value = reader.read(file_queue) # 3.对每一行解码 records = [[\u0026#34; \u0026#34;],]#以字符串读取每一行,默认值是\u0026#34; \u0026#34; sentence = tf.decode_csv(value,record_defaults=records) #开启批处理 sentence_batch = tf.train.batch([sentence],batch_size=30,num_threads=1,capacity=30) return sentence#返回句子 if __name__ == \u0026#34;__main__\u0026#34;: #构造文件列表 file_name = os.listdir(\u0026#34;../data/\u0026#34;) filelist = [os.path.join(\u0026#34;../data/\u0026#34;,file) for file in file_name] #读取文件 sentence_batch = convread(filelist) #开启会话 with tf.Session() as sess: #定义一个线程协调器 coord = tf.train.Coordinator() #开启读取文件的线程 threads = tf.train.start_queue_runners(sess,coord=coord) print(sess.run(sentence_batch)) #回收子线程 coord.request_stop() coord.join(threads) ","permalink":"/zh-cn/posts/tensorflow/tensorflow%E5%9F%BA%E7%A1%80/","series":["TensorFlow"],"tags":["TensorFlow"],"title":"TensorFlow 基础"},{"categories":["TensorFlow"],"content":"TensorFlow 线性回归 TensorFlow是一个编程系统,使用图(graphs)来表示计算任务,图(graphs)中的节点称之为op(operation),一个op获得0个或者多个Tensor,执行计算,产生0个或者多个Tensor.Tensor看做是一个n维的数组或者列表.图必须在会话Session里被启动\n##基本概念\n  使用图(graphs)来表示计算任务\n  在被称为会话(Session)的上下文(context)中执行图\n  使用张量(tensor)表示数据\n  通过变量(Vatria)维护状态\n  使用feed和fetch可以为任意的操作赋值或者从中获取数据\n  张量(Tensor)\n在TensorFlow中,张量的维度被描述为\u0026quot;阶\u0026quot;,但是,张量的阶和矩阵的阶并不是同一个概念,张量的阶,是张量维度的一个数量的描述\n  x=3\t#零阶张量:纯量 v=[1.,2.,3.]\t#一阶张量:向量 t=[[1,2,3],[4,5,6]]\t#二阶张量:矩阵 m=[[[1],[2],[3]],[[4],[5],[6]],[[7],[8],[9]]]\t#三阶张量:立方体   图(Graph)\n代表模型的数据流,由ops和tensor组成.其中op是操作,也就是节点,而tensor是数据流,也就是边\n算法会表示为计算图(computational graphs),也称之为数据流图.我们把计算图看作为一种有向图,张量就是通过各种操作在有向图中流动\n  会话(Session)\n在TensorFlow中,要想启动一个图的前提是要创建一个会话(Session),TensorFlow的所有对图的操作,都必须放在会话中进行\n  基础使用: op和Session import tensorflow as tf #创建两个常量op c1 = tf.constant([[1,2]]) c2 = tf.constant([[2],[1]]) #创建一个矩阵乘法op matmulop = tf.matmul(c1,c2) print(matmulop) Tensor(\u0026quot;MatMul:0\u0026quot;, shape=(1, 1), dtype=int32)\r #定义一个会话,启动图 sess = tf.Session() #调用sess的run方法来运行矩阵乘法op #run(matmulop)触发了图中的3个op result = sess.run(matmulop) print(result) sess.close() [[4]]\r #利用with省去这个麻烦 with tf.Session() as sess: #调用sess的run方法执行矩阵乘法op result = sess.run(matmulop) print(result) [[4]]\r 变量 #添加一个变量op x = tf.Variable([1,2]) #添加一个常量op c = tf.constant([2,1]) #增加一个减法op sub = tf.subtract(x,c)#x-c #增加一个加法op add = tf.add(x,sub)#x+(x-c) #初始化所有变量 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) print(sess.run(sub)) print(sess.run(add)) [-1 1]\r[0 3]\r 实现迭代自增 #创建一个变量初始化为0 state = tf.Variable(0,name=\u0026#39;cont\u0026#39;) #创建一个让state加1的op new_state = tf.add(state,1) #赋值op update = tf.assign(state,new_state)#把new_state的值给到state \u0026#39;\u0026#39;\u0026#39; tf.assign(ref, value, validate_shape=None, use_locking=None, name=None) 函数完成了将value赋值给ref的作用。 注意: 1. ref 必须是tf.Variable创建的tensor，如果ref=tf.constant()会报错！ 2. shape（value）==shape（ref） \u0026#39;\u0026#39;\u0026#39; #变量初始化op init = tf.global_variables_initializer() #使用Session运行这些op with tf.Session() as sess: sess.run(init) for _ in range(6): print(sess.run(state)) sess.run(update) 0\r1\r2\r3\r4\r5\r Fetch 同时运行多个op,得到他们的结果 def session_run(*args): #初始化所有变量 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) #调用sess的run方法执行矩阵乘法op result = sess.run(args) print(result,end=\u0026#39; \u0026#39;) with tf.Session() as sess: sess.run(init) result = sess.run([new_state,update]) print(\u0026#39;feed:\u0026#39;,result) with tf.Session() as sess: sess.run(init) print(\u0026#39;not fetch\u0026#39;,end=\u0026#39;: [\u0026#39;) print(sess.run(state),end=\u0026#39;,\u0026#39;) print(sess.run(update),end=\u0026#39;]\\n\u0026#39;) print(\u0026#39;session_run\u0026#39;,end=\u0026#39;: \u0026#39;) session_run(new_state,update)#达到了和fetch一样的效果 feed: [1, 1]\rnot fetch: [0,1]\rsession_run: (1, 1)  Feed #创建两个32位浮点型的占位符op placeholder1 = tf.placeholder(tf.float32) placeholder2 = tf.placeholder(tf.float32) feed_output = tf.multiply(placeholder1,placeholder2) with tf.Session() as sess: result=sess.run(feed_output,feed_dict={placeholder1:[8.],placeholder2:[9.1]}) print(result) [72.8]\r demo import tensorflow as tf import numpy as np #使用numpy生成特征和真实值 X = np.random.rand(100) y = X*0.1 + 0.2 #创建两个op变量,用来构造一个线性模型 b = tf.Variable(0.) w = tf.Variable(0.) predic = w*X+b #设置我们的代价函数(均方差) loss = tf.reduce_mean(tf.square(y - predic)) #定义我们的优化器(梯度下降) gd_optimizer = tf.train.GradientDescentOptimizer(0.2)#学习率 #创建一个op,用来最小化代价函数 train = gd_optimizer.minimize(loss) #初始化变量 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) for step in range(200): sess.run(train) if step%20 == 0: print(step,sess.run([w,b])) 0 [0.055094976, 0.10045407]\r20 [0.10424501, 0.19765908]\r40 [0.10235276, 0.1987026]\r60 [0.101303995, 0.19928093]\r80 [0.10072273, 0.19960146]\r100 [0.10040057, 0.19977911]\r120 [0.10022201, 0.19987758]\r140 [0.10012304, 0.19993214]\r160 [0.1000682, 0.19996239]\r180 [0.1000378, 0.19997916]\r ","permalink":"/zh-cn/posts/tensorflow/tensorflow%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","series":["TensorFlow"],"tags":["TensorFlow"],"title":"TensorFlow 线性回归"},{"categories":["NLP"],"content":"word2vec !(http://www.cnblogs.com/neopenx/p/4571996.html)(是个巨佬) !(https://blog.csdn.net/itplus/article/details/37969817)\n概率语言模型 概率语言模型 预测字符串概率,考虑动机,考虑计算方式\n  Unigram models(一元文法统计模型)\n  N-gram 语言模型(N元模型\n  N元模型 $P( w1,w2,\u0026hellip;,w_m) = i\u0026hellip;m(*) P(w_i|w1,\u0026hellip;,w_(i-1)) = i\u0026hellip;m(*) P(w_i|w_(i-n+1),\u0026hellip;,w_(i-1))$\n注: n大于3时基本无法处理,参数空间太大.另外它不能表示词与词之间的关联性\n神经概率语言模型 在论文《A neural probabilistic language model》中提出的一种模型.该模型的重要工具是词向量\n词向量: 对词典D中的任意词w,指定一个固定长度的实值向量$v(w)\\in R^m$v(w)就称为w的词向量,m为词向量的长度\n概述 训练样本: (Context(w),w) 包括前n-1个词分别的向量,假定每个词向量大小m\n投影层： (n-1)*m 首尾拼接起来的大向量\n输出: 输出是一棵二叉树,它以语料中出现过的词当做叶子节点.以各词在语料中的出现次数当做权值垢找出来的Huffman树\ny_w = (y_w1,y_w2,y_w3,\u0026hellip;y_wN,)\n表示上下文为Context(w)时,下一个词恰好为词典中的第i个词的概率\n归一化: $$p(w|Context(w)) = \\frac{e^{yw,iw}}{\\sum^{N}_{i=1}e^{yw,iw} }$$\n哈弗曼树 最优二叉树,节点会有权重,指示词的常用频次\n使用哈弗曼树\n把高频词放在距离根节点近的地方,在测试时,我们每次预测每一层的正概率和负概率\nCBOW 根据上下文的词语预测当前词语的出现概率的模型\n$$L = \\sum_{w\\in c}logp(w|Context(w))$$\n词向量=哈弗曼编码,经过不断地训练,哈弗曼编码不断改变\n权重参数=通过每层的概率计算,最终指向这个词会有一个似然函数,其中的某个参数,就是sigmod函数中的theta\n对最终的似然函数求最大==\u0026gt;最大化问题\u0026ndash;\u0026gt;梯度上升\nNegative Sampling 为了解决,树空间过大\n思想:\n  保证频次越高的词,越容易被采样出来\n  不使用哈弗曼树进行预测,使用负采样,降低计算复杂度\n  Skip-gram seq2seq seq2seq是一个Encoder-Decoder结构的网络,它的输入是一个序列,输出也是一个序列\n  Encoder中将一个可变长度的信号序列变为固定长度的向量表达\n  Decoder将这个固定长度的向量变成可变长度的目标的信号序列\n  输入序列和输出序列的长度是可变的\n  可以用于翻译,聊天机器人,句法分析,文本摘要\n  encoder 过程   取得输入的文本,进行enbedding\n  传入到LSTM中进行训练\n  记录状态,并输出当前cell的结果\n  依次循环,得到最终结果\n  decoder过程   在encoder最后一个时间步长的隐藏层之后输入到decoder的第一份cell里\n  通过激活函数得到候选的文本\n  筛选出可能性最大的文本作为下一个时间步长的输入\n  依次输入,得到目标\n  注意力机制 注意力机制是在序列到序列模型中用于注意编码器状态的最常用方法,它同时还可用于回顾序列模型的过去状态\n 注意力机制不仅能用来处理编码器或前面的隐藏层,它同样还能用来获得其他特征的分布  为什么需要注意力机制   减小处理高纬度输入数据的计算负担,通过结构化的选取输入的子集,降低数据维度\n  让任务处理系统更专注于找到输入数据中显著的与当前输出相关的有用信息.从而提高输出的质量\n  Attention模型的最终目的是帮助类似编解码器这样的框架,跟好的学到多种内容模态的相互关系,从而更好的表示这些信息,克服其无法解释从而很难设计的缺陷\n  聊天机器人根据对话的产生方式   基于检索的模型\n  基于生成式的模型\n  基于检索的模型   在数据库中存储问答对\n  使用语句匹配的形式查找答案\n  答案相对固定,且很少出现语法错误\n  不会出现新的语句\n  基于生成式模型   不依赖预先设定的问答库\n  通常基于机器翻译技术\n  需要大量的语料进行训练\n  Encoder-Decoder模式\n  混合模式   兼具检索模式和生成模式\n  检索模式产生候选数据集\n  生成模式产生最终答案\n   我们的系统架构 ","permalink":"/zh-cn/posts/nlp/chatbot%E6%A8%A1%E5%9E%8B/","series":["NLP"],"tags":["NLP"],"title":"ChatBot模型基础"},{"categories":["NLP"],"content":"语料处理流程 语料收集 \u0026gt; 语料清洗 \u0026gt; 句子向量编码化 \u0026gt; 语料问答对构建 \u0026gt; 语料的模型保存 \u0026gt; 结束 语料收集   聊天记录\n  电影对话\n  台词片断\n  语料清洗  要清洗的内容\n   多余的空格\n  不正规的符号\n  多余的字符,英文\n   清洗的方法\n   正则化\n  切分\n  好坏语句判断\n  语料问答对的构建  问答对的处理和拆分  句子向量的编码化   原始文本不能直接训练\n  将句子转化为向量\n  将向量转换为句子\n  语料模型的保存   使用pickle来保存模型\n  生成pkl格式\n  利用pkl格式进行语料的训练\n  最后通过深度模型过后打包成restful\n  实操 收集语料: 收集了200M的电影台词作为语料\nM 你/没/事/吧/？/ M 是/的/，/我/没/事/ M 来/吧/，/我/在/做/早/餐/ M 好/的/ E M C/h/l/o/e/./ M J/a/c/k/!/ M 没/事/吧/?/ M 发/生/什/么/了/?/ M 杀/死/知/道/你/还/活/着/的/人/?/ M 我/不/知/道/,/ M 现/在/,/ /我/要/进/入/C/T/U/的/档/案/ M 秘/密/的 M 我/没/电/脑/不/行/ M 在/加/州/工/学/院/有/个/研/究/处/ M 我/们/能/进/去/ M 那/是/谁/?/ 语料清洗 # 语料清洗 ##合并和切分,去掉不常用的符号 def make_split(line): if re.match(r\u0026#39;.*([，···?!\\.,!？])$\u0026#39;, \u0026#39;\u0026#39;.join(line)): return [] return [\u0026#39;, \u0026#39;] ##筛选出好句子和坏句子,判断英文和数字是不是太多了 def good_line(line): if len(re.findall(r\u0026#39;[a-zA-Z0-9]\u0026#39;, \u0026#39;\u0026#39;.join(line))) \u0026gt; 2: return False return True ##替换掉多余的字符 def regular(sen): sen = re.sub(r\u0026#39;\\.{3,100}\u0026#39;, \u0026#39;···\u0026#39;, sen) sen = re.sub(r\u0026#39;···{2,100}\u0026#39;, \u0026#39;···\u0026#39;, sen) sen = re.sub(r\u0026#39;[,]{1,100}\u0026#39;, \u0026#39;，\u0026#39;, sen) sen = re.sub(r\u0026#39;[\\.]{1,100}\u0026#39;, \u0026#39;。\u0026#39;, sen) sen = re.sub(r\u0026#39;[\\?]{1,100}\u0026#39;, \u0026#39;？\u0026#39;, sen) sen = re.sub(r\u0026#39;[!]{1,100}\u0026#39;, \u0026#39;！\u0026#39;, sen) return sen 问答对的构建 #解压文件 print(\u0026#39;extract lines\u0026#39;)#dgk_shooter_min fp = open(\u0026#39;test.conv\u0026#39;, \u0026#39;r\u0026#39;, errors=\u0026#39;ignore\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) #去掉M空格,和斜杠,丢弃,无效的句子 groups = [] group = [] for line in tqdm(fp): if line.startswith(\u0026#39;M \u0026#39;): #表示这一行是句子,需要处理 line = line.replace(\u0026#39;\\n\u0026#39;, \u0026#39;\u0026#39;) if \u0026#39;/\u0026#39; in line:#如果这一行有\u0026#39;/\u0026#39;,我们就从第二个字符开始以\u0026#39;/\u0026#39;切分 line = line[2:].split(\u0026#39;/\u0026#39;) else: line = list(line[2:]) line = line[:-1] group.append(list(regular(\u0026#39;\u0026#39;.join(line)))) else: if group: groups.append(group) group = [] if group: groups.append(group) group = [] print(\u0026#39;extract group\u0026#39;) # 定义问答对 x_data = [] y_data = [] for group in tqdm(groups):#tqdm可以显示进度 for i, line in enumerate(group): #把他化为枚举类 last_line = None if i \u0026gt; 0:#表示最少有两行 last_line = group[i-1] if not good_line(last_line): last_line = None next_line = None if i \u0026lt; len(group) - 1: next_line = group[i+1] if not good_line(next_line): next_line = None next_next_line = None if i \u0026lt; len(group) - 2: next_next_line = group[i + 2] if not good_line(next_next_line): next_next_line = None if next_line: x_data.append(line) y_data.append(next_line) if last_line and next_line: x_data.append(last_line + make_split(last_line) + line) y_data.append(next_line) if next_line and next_next_line: x_data.append(line) y_data.append(next_line + make_split(next_line) + next_next_line) print(len(x_data), len(y_data)) 句子向量的编码化 # 把句子进行编码化 class WordSequence(object): # 字典定义 PAD_TAG = \u0026#39;\u0026lt;pad\u0026gt;\u0026#39; #填充标签 UNK_TAG = \u0026#39;\u0026lt;unk\u0026gt;\u0026#39; #未知标签 START_TAG = \u0026#39;\u0026lt;s\u0026gt;\u0026#39; #开始标记 END_TAG = \u0026#39;\u0026lt;/S\u0026gt;\u0026#39; #结束标记 PAD = 0 UNK = 1 START = 2 END = 3 def __init__(self): self.fited = False #是否训练 self.dict = {WordSequence.PAD_TAG: WordSequence.PAD, WordSequence.UNK_TAG: WordSequence.UNK, WordSequence.START_TAG: WordSequence.START, WordSequence.END_TAG: WordSequence.END} # 编码转换 def to_index(self, word): #word 2 index assert self.fited, \u0026#39;WordSequence尚未进行fit操作\u0026#39; if word in self.dict: return self.dict[word] return WordSequence.UNK def to_word(self, index): #index 2 word assert self.fited, \u0026#39;WordSequence尚未进行fit操作\u0026#39; for k, v in self.dict.items(): if v == index: return k return WordSequence.UNK_TAG def size(self): assert self.fited, \u0026#39;WordSequence尚未进行fit操作\u0026#39; return len(self.dict) + 1 def __len__(self): # 返回字典长度 return self.size() # 训练函数 def fit(self, sentences, min_count=5, max_count=None, max_features=None): assert not self.fited, \u0026#39;WordSequence只能fit一次\u0026#39; count = {} for sentence in sentences: arr = list(sentence) for a in arr: if a not in count: count[a] = 0 count[a] += 1 if min_count is not None: count = {k: v for k, v in count.items() if v \u0026gt;= min_count} if max_count is not None: count = {k: v for k, v in count.items() if v \u0026lt;= max_count} self.dict = {WordSequence.PAD_TAG: WordSequence.PAD, WordSequence.UNK_TAG: WordSequence.UNK, WordSequence.START_TAG: WordSequence.START, WordSequence.END_TAG: WordSequence.END} if isinstance(max_features, int): count = sorted(list(count.items()), key=lambda x: x[1])#排序,找到最大特征的数目 if max_features is not None and len(count) \u0026gt; max_features: count = count[-int(max_features):] for w, _ in count: self.dict[w] = len(self.dict) else: for w in sorted(count.keys()): self.dict[w] = len(self.dict) self.fited = True #把句子编码化 def transform(self, sentence, max_len=None): assert self.fited, \u0026#39;WordSequence尚未进行fit操作\u0026#39; if max_len is not None: r = [self.PAD] * max_len else: r = [self.PAD] * len(sentence) for index, a in enumerate(sentence): if max_len is not None and index \u0026gt;= len(r): break r[index] = self.to_index(a) return np.array(r) # 把句子解码 def inverse_transform(self, indices, ignore_pad=False, ignore_unk=False, ignore_start=False, ignore_end=False): ret = [] for i in indices: word = self.to_word(i) if word == WordSequence.PAD_TAG and ignore_pad: continue if word == WordSequence.UNK_TAG and ignore_unk: continue if word == WordSequence.START_TAG and ignore_start: continue if word == WordSequence.END_TAG and ignore_end: continue ret.append(word) return ret 效果:\nws = WordSequence() ws.fit([ [\u0026#39;你\u0026#39;, \u0026#39;好\u0026#39;, \u0026#39;啊\u0026#39;], [\u0026#39;你\u0026#39;, \u0026#39;好\u0026#39;, \u0026#39;哦\u0026#39;] ]) indice = ws.transform([\u0026#39;我\u0026#39;, \u0026#39;们\u0026#39;, \u0026#39;好\u0026#39;]) print(indice) back = ws.inverse_transform(indice,ignore_pad=True,ignore_unk=False,ignore_start=True,ignore_end=True) print(back) output:\n\r[1 1 1]\r['\u0026lt;unk\u0026gt;', '\u0026lt;unk\u0026gt;', '\u0026lt;unk\u0026gt;']\r语料模型的训练和保存 def dump(x_data, y_data): from word_sequence import WordSequence # 生成pkl文件备用 data = list(zip(x_data, y_data)) data = [ (x, y) for x, y in data if limit \u0026gt; len(x) \u0026gt;= x_limit and limit \u0026gt; len(y) \u0026gt;= y_limit ] x_data, y_data = zip(*data) ## 训练以及词向量模型保存 ws_input = WordSequence() ws_input.fit(x_data + y_data) print(\u0026#39;dump\u0026#39;) pickle.dump((x_data, y_data), open(\u0026#39;chatbot_test.pkl\u0026#39;, \u0026#39;wb\u0026#39;)) pickle.dump(ws_input, open(\u0026#39;ws_test.pkl\u0026#39;, \u0026#39;wb\u0026#39;)) print(\u0026#39;done\u0026#39;) ","permalink":"/zh-cn/posts/nlp/%E8%AF%AD%E6%96%99%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/","series":["NLP"],"tags":["NLP"],"title":"语料处理基础"},{"categories":["Flask"],"content":"Flask 学习 入门： 最小的Flask 程序 from flask import Flask # 导入flask app = Flask(__name__)#使用单一的模块（如本例），你应该使用 __name__ @app.route(\u0026#39;/hello\u0026#39;) #route()装饰器 什么样子的URL能触发我们的函数 def hello_word(): return \u0026#39;Hello Word!\u0026#39;#返回我们想在浏览器中显示的内容 if __name__ == \u0026#39;__main__\u0026#39;: #确保服务器只会在该脚本被 Python 解释器直接执行的时候才会运行，而不是作为模块导入的时候 #app.run()#让app这个应用在本地服务器运行起来 #app.run(host=\u0026#39;0.0.0.0\u0026#39;) #监听所有的公网IP app.debug = True app.run()#q启动调试器 模板渲染 Jinja2模板引擎文档\nfrom flask import Flask # 导入flask from flask import render_template #使用Jinja2的模版渲染 app = Flask(__name__)#使用单一的模块（如本例），你应该使用 __name__ @app.route(\u0026#39;/hello\u0026#39;) #route()装饰器 什么样子的URL能触发我们的函数 def hello_word(): return render_template(\u0026#34;hello.html\u0026#34;)#返回的模板文件（需要放在当前目录的templates文件夹内） if __name__ == \u0026#39;__main__\u0026#39;: #确保服务器只会在该脚本被 Python 解释器直接执行的时候才会运行，而不是作为模块导入的时候 #app.run()#让app这个应用在本地服务器运行起来 #app.run(host=\u0026#39;0.0.0.0\u0026#39;) #监听所有的公网IP app.debug = True app.run()#q启动调试器 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello Template\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello World!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 变量规则 URL的变量部分：\u0026lt;variable_name\u0026gt;\n规则可以用 \u0026lt;converter:variable_name\u0026gt;指定一个可选的转换器。这里有一些不错的例子:\n@app.route(\u0026#39;/user/\u0026lt;username\u0026gt;\u0026#39;) def show_user_profile(username): # show the user profile for that user return \u0026#39;User %s\u0026#39; % username @app.route(\u0026#39;/post/\u0026lt;int:post_id\u0026gt;\u0026#39;) def show_post(post_id): # show the post with the given id, the id is an integer return \u0026#39;Post %d\u0026#39; % post_id 转换器的类型\nint ： 接受整数\nfloat ：同int，但是接受浮点数\npath ：和默认的相似，但也接受浮点数\nURL规范 以这两个规则为例:\n@app.route(\u0026#39;/projects/\u0026#39;) def projects(): return \u0026#39;The project page\u0026#39; @app.route(\u0026#39;/about\u0026#39;) def about(): return \u0026#39;The about page\u0026#39; 第一种情况中，指向 projects 的规范 URL 尾端有一个斜线。这种感觉很像在文件系统中的文件夹。访问一个结尾不带斜线的 URL 会被 Flask 重定向到带斜线的规范 URL 去。\n第二种情况的 URL 结尾不带斜线，类似 UNIX-like 系统下的文件的路径名。访问结尾带斜线的 URL 会产生一个 404 “Not Found” 错误。\n在遗忘尾斜线时，允许关联的 URL 接任工作，与 Apache 和其它的服务器的行为一样。此外，也保证了 URL 的唯一，有助于避免搜索引擎索引同一个页面两次。\n结论：使用不带尾斜线的url 构造URL 使用url_for() 来给指定的函数构造 URL\n优点  URL 构建会转义特殊字符和 Unicode 数据\n  如果你的应用不位于 URL 的根路径（比如，在 /myapplication 下，而不是 / ）， url_for() 会妥善处理这个问题\n  反向构建通常比硬编码的描述性更好。更重要的是，它允许你一次性修改 URL， 而不是到处边找边改\n 例子：\nfrom flask import Flask, url_for app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def index(): pass @app.route(\u0026#39;/login\u0026#39;) def login(): pass @app.route(\u0026#39;/user/\u0026lt;username\u0026gt;\u0026#39;) def profile(username): pass with app.test_request_context(): \u0026#39;\u0026#39;\u0026#39;test_request_context:即使我们正在通过 Python 的 shell 进行交互，它依然会告诉 Flask 要表现为正在处理一个请求\u0026#39;\u0026#39;\u0026#39; print url_for(\u0026#39;index\u0026#39;) print url_for(\u0026#39;login\u0026#39;) print url_for(\u0026#39;login\u0026#39;, next=\u0026#39;/\u0026#39;) print url_for(\u0026#39;profile\u0026#39;, username=\u0026#39;John Doe\u0026#39;) 输出：\n\r/\r/login\r/login?next=%2F\r/user/John%20Doe\rHTTP方法： 默认情况下，路由只回应 GET 请求，route() 装饰器传递 methods 参数可以改变这个行为\n例子：\nfrom flask import Flask # 导入flask from flask import render_template #使用Jinja2的模版渲染 from flask import request,redirect,url_for app = Flask(__name__) @app.route(\u0026#39;/login\u0026#39;, methods=[\u0026#39;POST\u0026#39;,\u0026#39;GET\u0026#39;]) def login(): error = None if request.method == \u0026#39;POST\u0026#39;: if request.form[\u0026#39;username\u0026#39;]==\u0026#39;admin\u0026#39; and request.form[\u0026#39;password\u0026#39;]==\u0026#39;root\u0026#39;: return redirect(url_for(\u0026#39;home\u0026#39;,username=request.form[\u0026#39;username\u0026#39;])) else: error = \u0026#39;Invalid username/password\u0026#39; return render_template(\u0026#39;login.html\u0026#39;, error=error,username=request.form[\u0026#39;username\u0026#39;]) @app.route(\u0026#39;/home\u0026#39;) def home(): return render_template(\u0026#39;home.html\u0026#39;, username=request.args.get(\u0026#39;username\u0026#39;)) if __name__ == \u0026#39;__main__\u0026#39;: #确保服务器只会在该脚本被 Python 解释器直接执行的时候才会运行，而不是作为模块导入的时候 #app.run()#让app这个应用在本地服务器运行起来 #app.run(host=\u0026#39;0.0.0.0\u0026#39;) #监听所有的公网IP app.debug = True app.run()#q启动调试器 /login.html文件:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;login\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form style=\u0026#34;margin:20px;\u0026#34; method=\u0026#34;post\u0026#34; action=\u0026#34;/login\u0026#34;\u0026gt; username:\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34; id=\u0026#34;name\u0026#34;\u0026gt; \u0026lt;br\u0026gt; password:\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34; id=\u0026#34;pwd\u0026#34;\u0026gt; \u0026lt;br\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34; id=\u0026#34;loginBtn\u0026#34;\u0026gt;login\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; {% if error %} {% if username %} \u0026lt;h1 style=\u0026#34;color:red\u0026#34;\u0026gt;Dear {{ username }}:{{ error }}!\u0026lt;/h1\u0026gt; {% endif %} {% endif %} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; home主页：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;home\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;wlcome {{username}} , this is home\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 解析  render_template ： 将请求定位到模板文件上，处理模板文件后，将结果作为请求的响应返回\n  redirect：将请求的响应重定向到新的url上。当登录成功后，重定向到 home页面\n  url_for：根据参数生成url\n  request对象包含了所有的请求信息，通过它可获取所需要的请求信息:\n  app.route增加了methods参数，指明该url支持的http请求方式，默认是get方式。/login即作为get，也作为post的请求目标\n 自定义错误处理程序 定制错误页面， @errorhandle装饰器\nfrom flask import Flask # 导入flask from flask import render_template #使用Jinja2的模版渲染 from flask import request,redirect,url_for app = Flask(__name__) @app.route(\u0026#39;/index\u0026#39;) #route()装饰器 什么样子的URL能触发我们的函数 def index(): return render_template(\u0026#34;index.html\u0026#34;) @app.errorhandler(404) def not_found_error(error): return render_template(\u0026#39;404.html\u0026#39;), 404 @app.errorhandler(404) def not_found(error): resp = make_response(render_template(\u0026#39;404.html\u0026#39;), 404) resp.headers[\u0026#39;X-Something\u0026#39;] = \u0026#39;A value\u0026#39; return resp @app.errorhandler(500) def internal_error(error): return render_template(\u0026#39;500.html\u0026#39;), 500 if __name__ == \u0026#39;__main__\u0026#39;: #确保服务器只会在该脚本被 Python 解释器直接执行的时候才会运行，而不是作为模块导入的时候 #app.run()#让app这个应用在本地服务器运行起来 #app.run(host=\u0026#39;0.0.0.0\u0026#39;) #监听所有的公网IP app.debug = True app.run()#q启动调试器 静态文件 只要在你的包中或是模块的所在目录中创建一个名为 static 的文件夹，在应用中使用 /static 即可访问CSS 和 JavaScript 静态文件\nurl_for('static', filename='style.css')\nflask的线程安全 环境局部变量 一个请求传入，Web 服务器决定生成一个新线程（ 或者别的什么东西，只要这个底层的对象可以胜任并发系统，而不仅仅是线程）。 当 Flask 开始它内部的请求处理时，它认定当前线程是活动的环境，并绑定当前的应用和 WSGI 环境到那个环境上（线程）。它的实现很巧妙，能保证一个应用调用另一个应用时不会出现问题。\n如果我们需要左自动化测试：\n创建一个请求对象并且把它绑定到环境中：用 test_request_context() 环境管理器。结合 with 声明.绑定一个测试请求\nfrom flask import request with app.test_request_context(\u0026#39;/hello\u0026#39;, method=\u0026#39;POST\u0026#39;): # now you can do something with the request until the # end of the with block, such as basic assertions: assert request.path == \u0026#39;/hello\u0026#39; assert request.method == \u0026#39;POST\u0026#39; 或者传递整个WSGI环境给request_context() \nfrom flask import request with app.request_context(environ): assert request.method == \u0026#39;POST\u0026#39; Request的常用操作 导入from flask import request\n通过 [method]属性来访问不同的HTTP请求\n通过:attr:~flask.request.form 属性来访问表单数据() POST 或 PUT 请求提交的数据)\n通过args属性访问url中提交的参数\nsearchword = request.args.get('q', '')\nothers 当访问 form 属性中的不存在的键会发生什么？会抛出一个特殊的 KeyError 异常。你可以像捕获标准的 KeyError 一样来捕获它，推荐用 get 来访问 URL 参数或捕获 KeyError\n文件上传   在html的表单中设置enctype=\u0026quot;multipart/form-data\u0026quot;\n  通过请求对象的 files 属性访问文件的临时存储，它是一个标准的 Python file 对象，但它还有一个 save() 方法，允许你把文件保存到服务器的文件系统上\n  3. filename 属性：上传前文件在客户端的文件名，这个值是可以伪造的\n例子：把客户端上传的文件按照上传前的文件名保存在服务器上\nfrom flask import request from werkzeug import secure_filename @app.route(\u0026#39;/upload\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def upload_file(): if request.method == \u0026#39;POST\u0026#39;: f = request.files[\u0026#39;the_file\u0026#39;] f.save(\u0026#39;/var/www/uploads/\u0026#39; + secure_filename(f.filename)) Cookies 通过 cookies 属性来访问 Cookies，用响应对象的 set_cookie 方法来设置 Cookies\n读取Cookies：\nfrom flask import request @app.route(\u0026#39;/\u0026#39;) def index(): username = request.cookies.get(\u0026#39;username\u0026#39;) # use cookies.get(key) instead of cookies[key] to not get a # KeyError if the cookie is missing. 存储Cookies\nfrom flask import make_response @app.route(\u0026#39;/\u0026#39;) def index(): resp = make_response(render_template(...)) \u0026#39;\u0026#39;\u0026#39; Cookies 是设置在resp对象上的。由于通常视图函数只是返回字符串，之后 Flask 将字符串转换为响应对象。如果你要显式地转换，你可以使用 make_response() 函数然后再进行修改。 \u0026#39;\u0026#39;\u0026#39; resp.set_cookie(\u0026#39;username\u0026#39;, \u0026#39;the username\u0026#39;) return resp Session 允许你在不同请求间存储特定用户的信息，是在 Cookies 的基础上实现的，并且对 Cookies 进行密钥签名。这意味着用户可以查看你 Cookie 的内容，但却不能修改它，除非用户知道签名的密钥\nfrom flask import Flask, session, redirect, url_for, escape, request app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def index(): if \u0026#39;username\u0026#39; in session: return \u0026#39;Logged in as %s\u0026#39; % escape(session[\u0026#39;username\u0026#39;]) return \u0026#39;You are not logged in\u0026#39; @app.route(\u0026#39;/login\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def login(): if request.method == \u0026#39;POST\u0026#39;: session[\u0026#39;username\u0026#39;] = request.form[\u0026#39;username\u0026#39;] return redirect(url_for(\u0026#39;index\u0026#39;)) return \u0026#39;\u0026#39;\u0026#39; \u0026lt;form action=\u0026#34;\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;p\u0026gt;\u0026lt;input type=text name=username\u0026gt; \u0026lt;p\u0026gt;\u0026lt;input type=submit value=Login\u0026gt; \u0026lt;/form\u0026gt; \u0026#39;\u0026#39;\u0026#39; @app.route(\u0026#39;/logout\u0026#39;) def logout(): # remove the username from the session if it\u0026#39;s there session.pop(\u0026#39;username\u0026#39;, None) return redirect(url_for(\u0026#39;index\u0026#39;)) # set the secret key. keep this really secret: app.secret_key = \u0026#39;A0Zr98j/3yX R~XHH!jmN]LWX/,?RT\u0026#39; 强壮的密钥\nimport os os.urandom(24) 响应对象 视图函数的返回值会被自动转换为一个响应对象。如果返回值是一个字符串， 它被转换为该字符串为主体的、状态码为 200 OK的 、 MIME 类型是 text/html 的响应对象。\n Flask 把返回值转换为响应对象的逻辑是这样：\n   如果返回的是一个合法的响应对象，它会从视图直接返回。\n  如果返回的是一个字符串，响应对象会用字符串数据和默认参数创建。\n  如果返回的是一个元组，且元组中的元素可以提供额外的信息。这样的元组必须是 (response, status, headers) 的形式，且至少包含一个元素。 status 值会覆盖状态代码， headers 可以是一个列表或字典，作为额外的消息标头值。\n  如果上述条件均不满足， Flask 会假设返回值是一个合法的 WSGI 应用程序，并转换为一个请求对象。\n  例子可以看之前的错误页面的内容\nlogger 服务器错误，但要让代码继续运行，你需要日志\napp.logger.debug(\u0026#39;A value for debugging\u0026#39;) app.logger.warning(\u0026#39;A warning occurred (%dapples)\u0026#39;, 42) app.logger.error(\u0026#39;An error occurred\u0026#39;) ","permalink":"/zh-cn/posts/python/flask%E5%85%A5%E9%97%A8/","series":["Flask"],"tags":["python","Flask"],"title":"Flask入门"},{"categories":["ROS"],"content":"Ubuntu18.04安装ROS 源配置: \rsudo sh -c '. /etc/lsb-release \u0026amp;\u0026amp; echo \u0026quot;deb \u0026lt;http://mirrors.ustc.edu.cn/ros/ubuntu/\u0026gt; $DISTRIB_CODENAME main\u0026quot; \u0026gt; /etc/apt/sources.list.d/ros-latest.list'\r更新: sudo apt-get update\n添加密匙: sudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-key 421C365BD9FF1F717815A3895523BAEEB01FA116\n和官网步骤一样: sudo apt-get install ros-melodic-desktop-full\nsudo rosdep init\n报错: 由于py版本导致,网上说切换为python2.7,我失败了\n\rTraceback (most recent call last): File \u0026quot;/usr/bin/rosdep\u0026quot;, line 3, in \u0026lt;module\u0026gt; from rosdep2.main import rosdep_mainModuleNotFoundError: No module named 'rosdep2'\r重头戏来了: sudo apt-get install python3-catkin-pkg\n sudo apt-get install python3-rosinstall python3-rosinstall-generator python3-wstool build-essential\n再次运行: sudo rosdep init\nrosdep update\n感觉没问题? echo \u0026quot;source /opt/ros/melodic/setup.bash\u0026quot; \u0026gt;\u0026gt; ~/.bashrc\nsource ~/.bashrc\n报错: \r没有找到 /opt/ros/melodic/setup.bash\r强行来: roscore\n报错: \rCommand 'roscore' not found, but can be installed with:\rsudo apt install python-roslaunch\r输入\nsudo apt install python-roslaunch\n发现无法定位包?\n输入sudo apt-get update后再试,无效\u0026hellip;..\n给出的依賴要求python-roslib，可是我在安裝python3-*的指令時看到已经安好了,错误不在这里\n怎么办阿\u0026hellip;\ncd 到 /opt/ros/melodic/ cd /opt/ros/melodic/\nls -l\n发现没有sh脚本????!!!!\nsudo apt-get install ros-melodic-desktop\n我太机智了!\ncd 进去再看,有了!\nOK source ~/.bashrc 成功了\n安装完成,进行验证:roscore 报错: \rraise DistributionNotFound(req, requirers)pkg_resources.DistributionNotFound: The 'rospkg==1.1.7' distribution was not found and is required by the application\r???我最熟悉的python包报错!简单!\npip install rospkg\n看到whl下载的进度,成了\nroscore\n","permalink":"/zh-cn/posts/ros/ros%E5%AE%89%E8%A3%85/","series":["ROS"],"tags":["ROS"],"title":"Ubuntu18.04安装ROS"},{"categories":["java"],"content":"jdbc  JAVA Database Connectivity java 数据库连接\n  为什么会出现JDBC   SUN公司提供的一种数据库访问规则、规范, 由于数据库种类较多，并且java语言使用比较广泛，sun公司就提供了一种规范，让其他的数据库提供商去实现底层的访问规则。 我们的java程序只要使用sun公司提供的jdbc驱动即可。\n jdbc是一种接口规范\n优势:\n  简单\n  快捷\n  移植性\n  框架(在jdbc的基础上开发更好的框架)\n  jdbc Manager的上层JDBC API负责与java Application通信,JDBC Driver API 负责与具体的数据库通信(由数据库厂商开发和提供)\nAPI介绍: Driver:接口,定义了各个驱动程序都必须要实现的功能\nDriverManager:Driver的管理类\n用户通过Class.forname(DriverName)可以向DriverManager注册一个驱动程序,然后使用getConnection来建立物理连接,基于物理连接没使用SQL语句\neg:\nClass.forName(JDBC_DRIVER); conn= DriverManager.getConnection(DB_URL,USER,PASS); //DB_URL:链接,USER:用户名,PASS:密码  //例如  conn= DriverManager.getConnection(\u0026#34;jdbc:mysql://127.0.0.1:3306/test\u0026#34; ,USER,PASS); //jdbc:mysql://ip:端口/数据库名;协议:子协议:主机ip:端口/数据库  常用的3种格式  mysql  jdbc:mysql://\u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;/database\noracle  jdbc:oracle:thin:@\u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;:database\nsqlserver  jdbc:microsoft:sqlserver://\u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;;DatabaseName=database\nConnection 常用方法   Statement对象\n 创建(其实是一个sql语句的容器  ​\tStatement stmt = conn.createStatement();\n使用(使用Statement对象执行sql语句,返回结果为ResultSet/int):  ​\tResultSet rs = stmt.executeQuery(\u0026quot;select userName from user\u0026quot;)\n​\t查询结果是一个ResultSet对象\n  ResultSet对象(Statement对象的查询结果)\n  rs.next():将光标移动到下一行(默认在第一行)\n  rs.previous():将光标移动到上一行\n  rs.absolute():将光标定位到某一行\n  rs.beforeFirst():直接将光标定位到第一行的前一行\n  rs.afterLast():直接将光标移动到最后一行\n  rs.getString(ColumnName/Index):通过列名或者列序号取值\n  rs.getInt(ColumnName/Index):通过列名或者列序号取值\n  rs.getObject(ColumnName/Index):通过列名或者列序号取值\n    异常捕获 sql会抛出SQLException异常,我们通过捕获这个来处理异常\n构建步骤   装在驱动程序\n  建立数据库连接\n  执行SQL语句\n  获取执行结果\n  清理环境\n  eg:\npackage com.bean; import java.sql.*; public class Testjdbc { static final String JDBC_DRIVER = \u0026#34;com.mysql.jdbc.Driver\u0026#34;; static final String DB_URL = \u0026#34;jdbc:mysql://localhost/test\u0026#34;; static final String USER = \u0026#34;euraxluo\u0026#34;; static final String PASSWORD = \u0026#34;1234\u0026#34;; public static void test() throws ClassNotFoundException{ Connection conn = null; Statement stmt = null; ResultSet rs = null; //1.装载驱动程序  Class.forName(JDBC_DRIVER); //2.建立数据库物理连接  try { conn = DriverManager.getConnection(DB_URL,USER,PASSWORD); //3.创建statement容器,执行sql语句  stmt = conn.createStatement(); rs = stmt.executeQuery(\u0026#34;select * from user\u0026#34;); //4.获取执行结果  while(rs.next()){ System.out.println(rs.getString(\u0026#34;id\u0026#34;)+\u0026#34;:\u0026#34;+rs.getString(\u0026#34;userName\u0026#34;)); } } catch (SQLException e) { //异常处理  e.printStackTrace(); } finally { //关闭连接,清理环境  try { if(conn != null) conn.close(); if(stmt != null) stmt.close(); if(rs != null) rs.close(); } catch (SQLException e) { e.printStackTrace(); } } } public static void main(String[] args) throws ClassNotFoundException{ test(); } } JDBC 工具类\n 资源释放工作的整合  public class JDBCUtil { public static void release(Connection conn,PreparedStatement ptmt,ResultSet rs){ close(rs); close(conn); close(ptmt); } public static void close(ResultSet rs){ try { if(rs != null) rs.close(); } catch (SQLException e) { e.printStackTrace(); }finally { rs = null; } } public static void close(PreparedStatement ptmt){ try { if(ptmt != null) ptmt.close(); } catch (SQLException e) { e.printStackTrace(); }finally { ptmt = null; } } public static void close(Statement st) { try { if (st != null) st.close(); } catch (SQLException e) { e.printStackTrace(); } finally { st = null; } } private static void close(Connection conn){ try { if(conn != null) conn.close(); } catch (SQLException e) { e.printStackTrace(); }finally { conn = null; } } }  驱动防二次注册\nDriverManager.registerDriver(new com.mysql.jdbc.Driver());\nDriver 这个类里面有静态代码块java.sql.DriverManager.registerDriver(new Driver());，一上来就执行了，所以等同于我们注册了两次驱动。 其实没这个必要的。\n//静态代码块 \u0026mdash;\u0026gt; 类加载了，就执行。\n 最后形成以下代码即可。\r   ​\n Class.forName(\u0026quot;com.mysql.jdbc.Driver\u0026quot;);\t 也可把我们的数据库驱动的装载放到公共类中  public static Connection getSConn(){ Connection conn = null; try { conn = DriverManager.getConnection(DB_URL2,USER2,PASSWORD); } catch (SQLException e) { e.printStackTrace(); } return conn; } public static Connection getLConn(){ Connection conn = null; try { conn = DriverManager.getConnection(DB_URL,USER,PASSWORD); } catch (SQLException e) { e.printStackTrace(); } return conn; }  创建 properties\n 在src底下声明一个文件 jdbc.properties ，里面的内容吐下：    \rJDBC_DRIVER = com.mysql.jdbc.Driver\rJDBC_DRIVER2 = com.mysql.cj.jdbc.Driver\rDB_URL = jdbc:mysql://localhost/test\rDB_URL2 = jdbc:mysql://192.168.23.1:3306/test?serverTimezone=GMT\rUSER = euraxluo\rUSER2 = root\rPASSWORD = 1234\rFTLE_URL = IOTEST.txt\r 在工具类里面，使用静态代码块，读取属性\nstatic{\n try {\r//1. 创建一个属性配置对象\rProperties properties = new Properties();\r//InputStream is = new FileInputStream(\u0026quot;jdbc.properties\u0026quot;); //对应文件位于工程根目录\r   ​\n //使用类加载器，去读取src底下的资源文件。 后面在servlet //对应文件位于src目录底下\rInputStream is = JDBCUtil.class.getClassLoader().getResourceAsStream(\u0026quot;jdbc.properties\u0026quot;);\r//导入输入流。\rproperties.load(is);\r ​\n //读取属性\rdriverClass = properties.getProperty(\u0026quot;driverClass\u0026quot;);\rurl = properties.getProperty(\u0026quot;url\u0026quot;);\rname = properties.getProperty(\u0026quot;name\u0026quot;);\rpassword = properties.getProperty(\u0026quot;password\u0026quot;);\r ​\n } catch (Exception e) {\re.printStackTrace();\r}\r}\r ​\n我们在文档中可以看到一句话,就是说Class.forName(),驱动加载,jdbc4中自动帮我们完成了这一步骤  ","permalink":"/zh-cn/posts/java/jdbc1/","series":["JDBC"],"tags":["JDBC"],"title":"JDBC1"},{"categories":["java"],"content":"业务场景1  过滤条件比较弱,一次读出多条记录 读取数据库表中的所有记录 海量数据读取  这些都容易产生内存溢出,为了不使得内存溢出,我们采用游标的方式\n游标:提供一种客户端读取部分服务器端结果集的机制 一个批次的大小为:Fetch Size\n游标的使用  开启游标,DB_URL的处理(加上useCursorFetch=true)  eg:\njdbc:mysql://\u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;/\u0026lt;database\u0026gt;?useCursorFetch=true\n 使用PreparedStatement接口\nPreparedStatement接口继承自Statement接口,我们可以使用PreparedStatement替代Statement\n  这个接口要求创建时就要传入sql语句,但是这个sql语句,参数格式化.即过滤条件用问号表示,后续再用PreparedStatement.setString()和PreparedStatement.setInt()来设置过滤条件.还可以使用PreparedStatement.setFetchSize()设置游标的大小.即每次从数据库服务端取回记录的数量\neg:\n//使用prepareStatement()接口  ptmt = conn.prepareStatement(\u0026#34;select * from user\u0026#34;); ptmt.setFetchSize(1); rs = ptmt.executeQuery(); 业务场景2  读取的记录字段太大(例如博文)  也是会造成内存溢出,即使读取的记录很少\n流方式 把大字段按照二进制流的方式,分成多个区间,每次只读取一个区间的内容\n流方式的使用   利用ResultSet.getBinaryStream();获取对象流\n  生成一个外部文件,把对象流采用边读边写的方式写入文件\n  eg:\nwhile(rs2.next()){ //5.获取对象流  InputStream in = rs1.getBinaryStream(\u0026#34;userName\u0026#34;); //6.将对象流写入文件  File f = new File(FTLE_URL); OutputStream out = null; try { out = new FileOutputStream(f); int temp = 0; while((temp = in.read()) != -1){//边读边写  out.write(temp); System.out.println(rs2.getString(\u0026#34;id\u0026#34;)+\u0026#34;:\u0026#34;+rs2.getString(\u0026#34;userName\u0026#34;)); System.out.println(\u0026#34;---rs2--\u0026#34;); } in.close(); out.close(); } catch (IOException e) { e.printStackTrace(); } } 业务场景3  大量数据插入操作  数据的插入操作太慢了\n批处理 一次操作多个SQL语句\n利用Statement的addBatch(),实现批处理 addBatch():把多个sql打包成一个Batch()\nexecuteBatch():执行一个Batch\nclearnBatch():清除Batch(),下次使用\neg:\nstmt = conn.createStatement(); for (String item:users){ stmt.addBatch(\u0026#34;insert into user(id,userName) values(\u0026#34;+item.id+\u0026#34;,\u0026#34;+item.user+\u0026#34;)\u0026#34;); } stmt.excuteBatch(); stmt.clearBatch(); 业务场景4  乱码  ###　编码，字符集\n  你需要先查看数据库的内部编码\n  编码优先级\nServer\u0026lt;Database\u0026lt;Table\u0026lt;column;\n  jdbc编码设置\n  `DB_URL = DB_URL+\u0026ldquo;characterEncoding=utf8\u0026rdquo;\n","permalink":"/zh-cn/posts/java/jdbc2/","series":["JDBC"],"tags":["JDBC"],"title":"JDBC2"},{"categories":["java"],"content":"1. execute,executeQuery,executeUdate的区别 JDBCTM中Statement接口提供的execute,executeQuery,executeUdate之间的区别:\n  executeQuery:\n用于产生单个结果集的语句,例如SELECT语句,使用最多的方法\n  executeUpdate:\n用于执行INSERT,UPDATE,DELETE语句以及DDL语言,返回值是一个整数,指示受影响的行\n  execute:\n用于执行返回多个结果集,多个更新技术或者两者皆有的语句\n  2. SQL注入 防范措施:\n  使用动态封装的方式会导致SQL注入的风险,我们应该使用prepareStatement提供的参数化SQL\n  严格的数据库权限管理\n 仅给web应用访问数据库的最小权限\n  避免Drop table等权限\n   封装数据库错误\n 不要直接将后端数据库异常信息暴露给用户\n  对后端遗产信息进行必要的封装,避免用户直接看到后端异常\n   机密信息禁止明文存储\n 涉密信息需要加密处理\n  使用AES_ENCRYPT/AES_DECRYPT加密和解密\n   事务:{是并发控制的基本单位,指作为单个逻辑工作单位执行的一系列操作,而这些逻辑工作单元需要满足ACID特性} ACID:原子性,一致性,隔离性,持久性\njdbc事务控制 connection:\n .setAutoCommit('false')开启事务\n  .commit()事务执行结束提交事务\n  .rollback()回滚到事务开始之前的状态\n eg:\ntry{ conn = JDCBUtil.getConnection; conn.setAutoCommit(false); /** *sql语句 * conn.commit(); }catch(){ //如果出错,事务回滚  conn.rollback(); } 事务并发执行   脏读:读取一个事务未提交的更新\n  不可重复读:一个失误读取到另一个事务的更新,两次读取的结果包含的行记录的值不一样\n  幻读:两次读取的结果包含的行记录不一样\n  事务隔离级别   读未提交{允许脏读}\n  读提交{不允许脏读,允许重复读}\n  重复读{不允许不可重复读,可以幻读}\n  串行化{严格的并发控制}{如果有一个连接的隔离级别设置为了串行化 ，那么谁先打开了事务， 谁就有了先执行的权利， 谁后打开事务，谁就只能得着，等前面的那个事务，提交或者回滚后，才能执行。 但是这种隔离级别一般比较少用。 容易造成性能上的问题。 效率比较低。}\n  例子   查看隔离级别:select @@tx_isolation\n  设置隔离级别为读未更新:set session transaction isolation level read uncommitted;\n  开启事务:start transaction\n  按效率划分,从高到低:\n   读未更新\u0026gt;读已提交\u0026gt;可重复读\u0026gt;可串行化\n 按拦截成都,从高到低   可串行化 \u0026gt; 可重复读 \u0026gt; 读已提交 \u0026gt; 读未提交\n 默认隔离级别:   mySql:可重复读\n  Oracle:读已提交\n 在JDBC中使用事务  Connection\n .getTranactionlsolation()获取事务隔离级别\n  .setTransactionlsolation设置事务隔离级别\n ##　死锁\nMySql中的锁: |已有锁\\预加锁|X{排它锁}|S{共享锁}|\n|:\u0026ndash;:|:\u0026ndash;:|:\u0026ndash;:|\n|X|冲突|冲突|\n|S|冲突|兼容|\n加锁方式  外部加锁:   由应用程序添加,锁依赖关系较容易分析\n  共享锁:select * from table lock in share mode\n  排它锁:select * from table for update{解决丢失更新}\n 内部加锁   为了实现ACID特性,由数据库系统内部自动添加\n  加锁规则繁琐,与SQL执行计划,事务隔离级别,表索引结构有关\n  SQL持有锁的情况\n快照读\n Innodb实现了多版本控制(MVCC),支持不加锁快照读\n  Select * from table where\n  能够保证同一个Select结果集是一致的\n  不能够保证同一个事务内部,Select语句和其他语句的数据一致性,如果业务需要,应该通过外部显式加锁\n   分析死锁的原因,排查出死锁的SQL\nshow engine innodb status\n会反馈出发生死锁是等待的SQL\n  ","permalink":"/zh-cn/posts/java/jdbc3/","series":["JDBC"],"tags":["JDBC"],"title":"JDBC3"},{"categories":["java"],"content":"jsp  Java Server Page\n  什么是jsp   从用户角度看待 ，就是是一个网页 ， 从程序员角度看待 ， 其实是一个java类， 它继承了servlet，所以可以直接说jsp 就是一个Servlet.\n  为什么会有jsp?   html 多数情况下用来显示静态内容 ， 一成不变的。 但是有时候我们需要在网页上显示一些动态数据， 比如： 查询所有的学生信息， 根据姓名去查询具体某个学生。 这些动作都需要去查询数据库，然后在网页上显示。 html是不支持写java代码 ， jsp里面可以写java代码。\n java服务器页面\n jsp = html+java+JSP tag   处理流程：浏览器客户端向服务器发起请求，请求对应的jsp文件。然后jsp容器载入jsp文件，并且把jsp文件转化为Servlet(只是简单的把jsp文件改写为servlet语句)，然后jsp容器把servlet编译为可执行的class，然后把请求交给servlet容器，然后web组件就会调用servlet容器，载入对应的servlet实例。在执行时，会产生html页面，嵌入到response中返回给浏览器\n ###　jsp与servlet比较\n１.\t侧重点\n​\tjsp侧重于视图\n​\tservlet侧重于逻辑\n２.\tjsp有一些内置对象\n３.\t本质jsp其实是servlet的一种简化\n###　jsp基本语法\n jsp声明  \u0026lt;%! int a,b,c; %\u0026gt;\njsp表达式(表达式元素中可以包含任何符合java语言规范的表达式，但是不能使用分号来结束)  \u0026lt;%= 表达式%\u0026gt;\neg：输出日期\u0026lt;p\u0026gt;Today's date:\u0026lt;% = (new java.util.Date()).toLocaleString()%\u0026gt;\u0026lt;/p\u0026gt;\njsp脚本(可以包含任意量的java语句,变量,方法或者表达式)  \u0026lt;% 代码片段 %\u0026gt;\neg:打印ip\u0026lt;% out.println(\u0026quot;Your IP:\u0026quot;+request.getRemoteAddr()); %\u0026gt;\njsp注释  \u0026lt;-- 这部分是jsp注释 --\u0026gt;\n jsp指令\n  page指令(定义页面的依赖属性,比如脚本语言,error页面,缓存需求)\n  include指令(把其他文件包含到这个jsp中)\n  taglib指令(引入自定义的标签库,并且可以指定前缀)\n    jsp内置对象\n  request:HttpServletRequest类的实例\n  response:HttpServletResponse类的实例\n  out:PrintWriter类的实例\n  session:HttpSession类的实例\n  application:ServletContext类的实例\n  config:ServletConfig类的实例\n  page:类似于java类中的this关键字\n  pageContext:PageContext类的实例,提供对JSP页面所有对象以及命名空间的访问\n  Exception:EXception类的对象,代表发生错误的jsp页面中对应的异常对象\n    jsp指令 1) page指令  表明jsp页面中可以写java代码\n  contentType   其实即使说这个文件是什么类型，告诉浏览器我是什么内容类型，以及使用什么编码\tcontentType=\u0026quot;text/html; charset=UTF-8\u0026quot;\n `text/html MIMEType 这是一个文本，html网页`\r   pageEncoding jsp内容编码\n  extends 用于指定jsp翻译成java文件后，继承的父类是谁，一般不用改。\n  import 导包使用的，一般不用手写。\n  session\n   值可选的有true or false .\n  用于控制在这个jsp页面里面，能够直接使用session对象。\n  具体的区别是，请看翻译后的java文件 如果该值是true , 那么在代码里面会有getSession（）的调用，如果是false : 那么就不会有该方法调用，也就是没有session对象了。在页面上自然也就不能使用session了。\n  errorPage   指的是错误的页面， 值需要给错误的页面路径\n  isErrorPage   上面的errorPage 用于指定错误的时候跑到哪一个页面去。 那么这个isErroPage , 就是声明某一个页面到底是不是错误的页面。\n 2) include指令  包含另外一个jsp的内容进来。\n \u0026lt;%@ include file=\u0026quot;other02.jsp\u0026quot;%\u0026gt;\n 背后细节:   把另外一个页面的所有内容拿过来一起输出。 所有的标签元素都包含进来。\n 3) taglib指令 \u0026lt;%@ taglib prefix=\u0026quot;\u0026quot; uri=\u0026quot;\u0026quot;%\u0026gt;\n​\turi: 标签库路径\n​\tprefix : 标签库的别名\n​\nJSP 动作标签 \u0026lt;jsp:include page=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/jsp:include\u0026gt;\r\u0026lt;jsp:param value=\u0026quot;\u0026quot; name=\u0026quot;\u0026quot;/\u0026gt;\r\u0026lt;jsp:forward page=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/jsp:forward\u0026gt;\rjsp:include \u0026lt;jsp:include page=\u0026quot;other02.jsp\u0026quot;\u0026gt;\u0026lt;/jsp:include\u0026gt;\n 包含指定的页面， 这里是动态包含。 也就是不把包含的页面所有元素标签全部拿过来输出，而是把它的运行结果拿过来。\n jsp:forward \u0026lt;jsp:forward page=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/jsp:forward\u0026gt;\n 前往哪一个页面。\n \u0026lt;% //请求转发\rrequest.getRequestDispatcher(\u0026quot;other02.jsp\u0026quot;).forward(request, response);\r%\u0026gt;\tjsp:param  意思是： 在包含某个页面的时候，或者在跳转某个页面的时候，加入这个参数。\n \u0026lt;jsp:forward page=\u0026quot;other02.jsp\u0026quot;\u0026gt;\r\u0026lt;jsp:param value=\u0026quot;beijing\u0026quot; name=\u0026quot;address\u0026quot;/\u0026gt;\r\u0026lt;/jsp:forward\u0026gt;\r在other02.jsp中获取参数\r\u0026lt;br\u0026gt;收到的参数是：\u0026lt;br\u0026gt;\r\u0026lt;%= request.getParameter(\u0026quot;address\u0026quot;)%\u0026gt;\rJSP内置对象  所谓内置对象，就是我们可以直接在jsp页面中使用这些对象。 不用创建。\n   pageContext\n  request\n  session\n  application\n  以上4个是作用域对象 ,\n作用域  表示这些对象可以存值，他们的取值范围有限定。 setAttribute 和 getAttribute\n 使用作用域来存储数据\u0026lt;br\u0026gt;\r\u0026lt;%\rpageContext.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;page\u0026quot;);\rrequest.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;request\u0026quot;);\rsession.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;session\u0026quot;);\rapplication.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;application\u0026quot;);\r%\u0026gt;\r取出四个作用域中的值\u0026lt;br\u0026gt;\r\u0026lt;%=pageContext.getAttribute(\u0026quot;name\u0026quot;)%\u0026gt;\r\u0026lt;%=request.getAttribute(\u0026quot;name\u0026quot;)%\u0026gt;\r\u0026lt;%=session.getAttribute(\u0026quot;name\u0026quot;)%\u0026gt;\r\u0026lt;%=application.getAttribute(\u0026quot;name\u0026quot;)%\u0026gt;\r作用域范围大小：\npageContext -- request --- session -- application  四个作用域的区别  pageContext 【PageContext】   作用域仅限于当前的页面。\n  还可以获取到其他八个内置对象。\n  request 【HttpServletRequest】   作用域仅限于一次请求， 只要服务器对该请求做出了响应。 这个域中存的值就没有了。\n  session 【HttpSession】   作用域限于一次会话（多次请求与响应） 当中。\n  application 【ServletContext】   整个工程都可以访问， 服务器关闭后就不能访问了。\n 如何使用 1. 取出4个作用域中存放的值。 \u0026lt;%\rpageContext.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;page\u0026quot;);\rrequest.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;request\u0026quot;);\rsession.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;session\u0026quot;);\rapplication.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;application\u0026quot;);\r%\u0026gt;\r按普通手段取值\n\u0026lt;%= pageContext.getAttribute(\u0026quot;name\u0026quot;)%\u0026gt;\r\u0026lt;%= request.getAttribute(\u0026quot;name\u0026quot;)%\u0026gt;\r\u0026lt;%= session.getAttribute(\u0026quot;name\u0026quot;)%\u0026gt;\r\u0026lt;%= application.getAttribute(\u0026quot;name\u0026quot;)%\u0026gt;\r使用EL表达式取出作用域中的值\n${ pageScope.name }\r${ requestScope.name }\r${ sessionScope.name }\r${ applicationScope.name }\r如果域中所存的是数组  \u0026lt;%=String [] a = {\u0026quot;aa\u0026quot;,\u0026quot;bb\u0026quot;,\u0026quot;cc\u0026quot;,\u0026quot;dd\u0026quot;};\rpageContext.setAttribute(\u0026quot;array\u0026quot;, a);\r%\u0026gt;\r 使用EL表达式取出作用域中数组的值\n ${array[0] } , ${array[1] },${array[2] },${array[3] }\n如果域中锁存的是集合  \u0026lt;br\u0026gt;-------------Map数据----------------\u0026lt;br\u0026gt;\r\u0026lt;%\tMap map = new HashMap();\rmap.put(\u0026quot;name\u0026quot;, \u0026quot;zhangsna\u0026quot;);\rmap.put(\u0026quot;age\u0026quot;,18);\rmap.put(\u0026quot;address\u0026quot;,\u0026quot;北京..\u0026quot;);\rmap.put(\u0026quot;address.aa\u0026quot;,\u0026quot;深圳..\u0026quot;);\rpageContext.setAttribute(\u0026quot;map\u0026quot;, map);\r%\u0026gt;\r 使用EL表达式取出作用域中集合的值\n ${li[0] } , ${li[1] },${li[2] },${li[3] }\n取出Map集合的值  \u0026lt;%\rMap map = new HashMap();\rmap.put(\u0026quot;name\u0026quot;, \u0026quot;zhangsna\u0026quot;);\rmap.put(\u0026quot;age\u0026quot;,18);\rmap.put(\u0026quot;address\u0026quot;,\u0026quot;北京..\u0026quot;);\rmap.put(\u0026quot;address.aa\u0026quot;,\u0026quot;深圳..\u0026quot;);\rpageContext.setAttribute(\u0026quot;map\u0026quot;, map);\r%\u0026gt;\r 使用EL表达式取出作用域中Map的值 ${map.name } , ${map.age } , ${map.address } , ${map[\u0026quot;address.aa\u0026quot;] }\n取值细节：  存值(从域中取值,先存)  \u0026lt;%//pageContext.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;zhangsan\u0026quot;);\rsession.setAttribute(\u0026quot;name\u0026quot;, \u0026quot;lisi...\u0026quot;);\r%\u0026gt;\r\u0026lt;br\u0026gt;直接指定说了，到这个作用域里面去找这个name\u0026lt;br\u0026gt;\r${ pageScope.name } \u0026lt;br\u0026gt;//先从page里面找，没有去request找，去session，去application \u0026lt;br\u0026gt;\r${ name }\r\u0026lt;br\u0026gt;指定从session中取值\u0026lt;br\u0026gt;\r${ sessionScope.name } 取值方式   如果这份值是有下标的，那么直接使用[]\n \u0026lt;%\tString [] array = {\u0026quot;aa\u0026quot;,\u0026quot;bb\u0026quot;,\u0026quot;cc\u0026quot;}\rsession.setAttribute(\u0026quot;array\u0026quot;,array);\r%\u0026gt;\r${ array[1] } --\u0026gt; 这里array说的是attribute的name  如果没有下标， 直接使用 .的方式去取\n \u0026lt;%\tUser user = new User(\u0026quot;zhangsan\u0026quot;,18);\rsession.setAttribute(\u0026quot;u\u0026quot;, user);\r%\u0026gt;\r${ u.name } , ${ u.age } ##　EL表达式\n 是为了简化咱们的jsp代码，具体一点就是为了简化在jsp里面写的那些java代码。\n  写法格式  ${表达式 }\n 如果从作用域中取值，会先从小的作用域开始取，如果没有，就往下一个作用域取。 一直把四个作用域取完都没有， 就没有显示。\n ###　EL表达式 的11个内置对象。\n｀${ 对象名.成员 }｀\n-　pageContext\n作用域相关对象\n  pageScope\n  requestScope\n  sessionScope\n  applicationScope\n  头信息相关对象\n  header\n  headerValues\n  参数信息相关对象\n  param\n  paramValues\n  cookie\n  全局初始化参数\n initParam  JSTL  全称 ： JSP Standard Tag Library jsp标准标签库\n  简化jsp的代码编写。 替换 \u0026lt;%%\u0026gt; 写法。 一般与EL表达式配合\n 怎么使用   导入jar文件到工程的WebContent/Web-Inf/lib jstl.jar standard.jar\n  在jsp页面上，使用taglib 指令，来引入标签库\n  注意： 如果想支持 EL表达式，那么引入的标签库必须选择1.1的版本，1.0的版本不支持EL表达式。\n\u0026lt;%@ taglib prefix=\u0026quot;c\u0026quot; uri=\u0026quot;http://java.sun.com/jsp/jstl/core\u0026quot; %\u0026gt;\n  常用标签 \u0026lt;c:set\u0026gt;\u0026lt;/c:set\u0026gt;\r\u0026lt;c:if test=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/c:if\u0026gt;\r\u0026lt;c:forEach\u0026gt;\u0026lt;/c:forEach\u0026gt;\r c:set  \u0026lt;!-- 声明一个对象name,对象的值 zhangsan,存储到了page(默认),指定是session --\u0026gt;\r\u0026lt;c:set var=\u0026quot;name\u0026quot; value=\u0026quot;zhangsan\u0026quot; scope=\u0026quot;session\u0026quot;\u0026gt;\u0026lt;/c:set\u0026gt;\r${sessionScope.name }\r c:if   判断test里面的表达式是否满足，如果满足，就执行c:if标签中的输出 ， c:if 是没有else的。\n \u0026lt;c:set var=\u0026quot;age\u0026quot; value=\u0026quot;18\u0026quot; \u0026gt;\u0026lt;/c:set\u0026gt;\r\u0026lt;c:if test=\u0026quot;${ age \u0026gt; 26 }\u0026quot;\u0026gt;\r年龄大于了26岁...\u0026lt;/c:if\u0026gt;\r\u0026lt;c:if test=\u0026quot;${ age \u0026lt;= 26 }\u0026quot;\u0026gt;\r年龄小于了26岁...\u0026lt;/c:if\u0026gt;\r------------------------------\r\u0026lt;!--定义一个变量名 flag 去接收前面表达式的值，然后存在session域中--\u0026gt;\r\u0026lt;c:if test=\u0026quot;${ age \u0026gt; 26 }\u0026quot; var=\u0026quot;flag\u0026quot; scope=\u0026quot;session\u0026quot;\u0026gt;\r年龄大于了26岁...\u0026lt;/c:if\u0026gt;\r c:forEach  \u0026lt;!--从1 开始遍历到10,得到的结果,赋值给i,并且会存储到page域中,step,增幅为2--\u0026gt;\r\u0026lt;c:forEach begin=\u0026quot;1\u0026quot; end=\u0026quot;10\u0026quot; var=\u0026quot;i\u0026quot; step=\u0026quot;2\u0026quot;\u0026gt;\r${i}\u0026lt;/c:forEach\u0026gt;\r-----------------------------------------------\r\u0026lt;!--items : 表示遍历哪一个对象，注意，这里必须写EL表达式。 var: 遍历出来的每一个元素用user 去接收。 --\u0026gt;\r\u0026lt;c:forEach var=\u0026quot;user\u0026quot; items=\u0026quot;${list }\u0026quot;\u0026gt;\r${user.name } ----${user.age }\r\u0026lt;/c:forEach\u0026gt;\r总结：  JSP   三大指令\n page\rinclude\rtaglib\r  三个动作标签\n \u0026lt;jsp:include\u0026gt;\r\u0026lt;jsp:forward\u0026gt;\r\u0026lt;jsp:param\u0026gt;\r  九个内置对象\n   四个作用域\n  pageContext\rrequest\rsession\rapplication\rout\rexception\rresponse\rpage\rconfig\r EL  ${ 表达式 }\n 取4个作用域中的值\n ${ name }\r  有11个内置对象。\n pageContext\npageScope\nrequestScope\nsessionScope\napplicationScope\nheader\nheaderValues\nparam\nparamValues\ncookie\ninitParam\nJSTL   使用1.1的版本， 支持EL表达式， 1.0不支持EL表达式\n  拷贝jar包， 通过taglib 去引入标签库\n \u0026lt;c:set\u0026gt;\n\u0026lt;c:if\u0026gt;\n\u0026lt;c:forEach\u0026gt;\neg:\n\u0026lt;%@ taglib prefix=\u0026quot;c\u0026quot; uri=\u0026quot;http://java.sun.com/jsp/jstl/core\u0026quot; %\u0026gt;\r\u0026lt;%@ taglib prefix=\u0026quot;fn\u0026quot; uri=\u0026quot;http://java.sun.com/jsp/jstl/functions\u0026quot; %\u0026gt;\r\u0026lt;td\u0026gt;\r\u0026lt;!--fn:contains(stu.hobby,'游泳')-\u0026gt;boolean 用于确定一个字符串是否包含指定的子串--\u0026gt;\r\u0026lt;input \u0026lt;c:if test=\u0026quot;${fn:contains(stu.hobby,'游泳')}\u0026quot;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026quot;checkbox\u0026quot; name=\u0026quot;hobby\u0026quot; value=\u0026quot;游泳\u0026quot;\u0026gt;游泳\r\u0026lt;input \u0026lt;c:if test=\u0026quot;${fn:contains(stu.hobby,'篮球')}\u0026quot;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026quot;checkbox\u0026quot; name=\u0026quot;hobby\u0026quot; value=\u0026quot;篮球\u0026quot;\u0026gt;篮球\r\u0026lt;input \u0026lt;c:if test=\u0026quot;${fn:contains(stu.hobby,'足球')}\u0026quot;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026quot;checkbox\u0026quot; name=\u0026quot;hobby\u0026quot; value=\u0026quot;足球\u0026quot;\u0026gt;足球\r\u0026lt;input \u0026lt;c:if test=\u0026quot;${fn:contains(stu.hobby,'看书')}\u0026quot;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026quot;checkbox\u0026quot; name=\u0026quot;hobby\u0026quot; value=\u0026quot;看书\u0026quot;\u0026gt;看书\r\u0026lt;input \u0026lt;c:if test=\u0026quot;${fn:contains(stu.hobby,'写字')}\u0026quot;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026quot;checkbox\u0026quot; name=\u0026quot;hobby\u0026quot; value=\u0026quot;写字\u0026quot;\u0026gt;写字\r\u0026lt;/td\u0026gt;\rJSP开发模式 开发模式一:\njavaBean +JSP\n在jsp里面直接写java代码,维护起来比较困难.并且jsp的页面代码会面的臃肿\n开发模式二:\nServlet+javaBean+JSP\n使用的MVC模式:\nM:model 模型层 封装数据,显示数据javaBean java类 EJB\nV:View 视图层 jsp 专注于显示\nC:Controller 控制层 Servlet 接受页面请求,找模型层去处理,然后响应数据给视图层\njavaEE:\n 客户端\n  Web层 Servlet/jsp 对应MVC模式的Controller和Vew\n  业务逻辑层 javaBean 对应Model\n  数据访问层 Dao 对应Mode\n 实战 学生信息管理\n与以往(我写过的)的mvc有点区别,在dao与Servlet中增加了Service(业务层)层\n 好处：\n   Dao只针对单一的逻辑，对数据进行操作\n    service是业务层\n    业务:分页,应该把这个事给业务处理层\n       需求分析\n   先写 login.jsp , 并且搭配一个LoginServlet 去获取登录信息。\n  创建用户表， 里面只要有id , username 和 password\n  创建UserDao, 定义登录的方法\n  /** * 该dao定义了对用户表的访问规则 */ public interface UserDao { /** * 这里简单就返回一个Boolean类型， 成功或者失败即可。 * 但是开发的时候，登录的方法，一旦成功。这里应该返回该用户的个人信息 * @param userName * @param password * @return true : 登录成功， false : 登录失败。 */ boolean login(String userName , String password); } 创建UserDaoImpl , 实现刚才定义的登录方法。  public class UserDaoImpl implements UserDao { @Override public boolean login(String userName , String password) { Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { //1. 得到连接对象  conn = JDBCUtil.getConn(); String sql = \u0026#34;select * from t_user where username=? and password=?\u0026#34;; //2. 创建ps对象  ps = conn.prepareStatement(sql); ps.setString(1, userName); ps.setString(2, password); //3. 开始执行。  rs = ps.executeQuery(); //如果能够成功移到下一条记录，那么表明有这个用户。  return rs.next(); } catch (SQLException e) { e.printStackTrace(); }finally { JDBCUtil.release(conn, ps, rs); } return false; } }  在LoginServlet里面访问UserDao， 判断登录结果。 以区分对待\n  创建stu_list.jsp , 让登录成功的时候跳转过去。\n  创建学生表 ， 里面字段随意。\n  定义学生的Dao . StuDao\n  public interface StuDao { /** * 查询出来所有的学生信息 * @return List集合 */ List\u0026lt;Student\u0026gt; findAll(); } 对上面定义的StuDao 做出实现 StuDaoImpl  public class StuDaoImpl implements StuDao { @Override public List\u0026lt;Student\u0026gt; findAll() { List\u0026lt;Student\u0026gt; list = new ArrayList\u0026lt;Student\u0026gt;(); Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { //1. 得到连接对象  conn = JDBCUtil.getConn(); String sql = \u0026#34;select * from t_stu\u0026#34;; ps = conn.prepareStatement(sql); rs = ps.executeQuery(); //数据多了，用对象装， 对象也多了呢？ 用集合装。  while(rs.next()){ //10 次 ，10个学生  Student stu = new Student(); stu.setId(rs.getInt(\u0026#34;id\u0026#34;)); stu.setAge(rs.getInt(\u0026#34;age\u0026#34;)); stu.setName(rs.getString(\u0026#34;name\u0026#34;)); stu.setGender(rs.getString(\u0026#34;gender\u0026#34;)); stu.setAddress(rs.getString(\u0026#34;address\u0026#34;)); list.add(stu); } } catch (SQLException e) { e.printStackTrace(); }finally { JDBCUtil.release(conn, ps, rs); } return list; } }  在登录成功的时候，完成三件事情。\n  查询所有的学生\n 把这个所有的学生集合存储到作用域中。\n  跳转到stu_list.jsp\n    protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //提交的数据有可能有中文， 怎么处理。  request.setCharacterEncoding(\u0026#34;UTF-8\u0026#34;); response.setContentType(\u0026#34;text/html;charset=utf-8\u0026#34;); //1. 获取客户端提交的信息  String userName = request.getParameter(\u0026#34;username\u0026#34;); String password = request.getParameter(\u0026#34;password\u0026#34;); //2. 去访问dao ， 看看是否满足登录。  UserDao dao = new UserDaoImpl(); boolean isSuccess = dao.login(userName, password); //3. 针对dao的返回结果，做出响应  if(isSuccess){ //response.getWriter().write(\u0026#34;登录成功.\u0026#34;);  //1. 查询出来所有的学生信息。  StuDao stuDao = new StuDaoImpl(); List\u0026lt;Student\u0026gt; list = stuDao.findAll(); //2. 先把这个集合存到作用域中。  request.getSession().setAttribute(\u0026#34;list\u0026#34;, list); //2. 重定向  response.sendRedirect(\u0026#34;stu_list.jsp\u0026#34;); }else{ response.getWriter().write(\u0026#34;用户名或者密码错误！\u0026#34;); } } 在stu_list.jsp中，取出域中的集合，然后使用c标签 去遍历集合。  \u0026lt;table border=\u0026quot;1\u0026quot; width=\u0026quot;700\u0026quot;\u0026gt;\r\u0026lt;tr align=\u0026quot;center\u0026quot;\u0026gt;\r\u0026lt;td\u0026gt;编号\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;姓名\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;年龄\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;性别\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;住址\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;操作\u0026lt;/td\u0026gt;\r\u0026lt;/tr\u0026gt;\r\u0026lt;c:forEach items=\u0026quot;${list }\u0026quot; var=\u0026quot;stu\u0026quot;\u0026gt;\r\u0026lt;tr align=\u0026quot;center\u0026quot;\u0026gt;\r\u0026lt;td\u0026gt;${stu.id }\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;${stu.name }\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;${stu.age }\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;${stu.gender }\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;${stu.address }\u0026lt;/td\u0026gt;\r\u0026lt;td\u0026gt;\u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;更新\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt;删除\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt;\r\u0026lt;/tr\u0026gt;\r\u0026lt;/c:forEach\u0026gt;\r\u0026lt;/table\u0026gt;\r 查询的细节:\n1). 查询出来的数据先放在作用域\n2). 在页面跳转时,应该判断,跳转的页面或者逻辑层能否有能力处理数据\n3). 模糊查询\nString sql = \u0026#34;select * from stu where 1=1 \u0026#34;;//为了保留where  List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;();//把参数放在list中  //判断有没有姓名， 如果有，就组拼到sql语句里面  if(!TextUtils.isEmpty(sname)){ sql = sql + \u0026#34; and sname like ?\u0026#34;; list.add(\u0026#34;%\u0026#34;+sname+\u0026#34;%\u0026#34;); } //判断有没有性别，有的话，就组拼到sql语句里面。  if(!TextUtils.isEmpty(sgender)){ sql = sql + \u0026#34; and gender = ?\u0026#34;; list.add(sgender); }   分页的拓展  物理分页(真分页)\n 优点:内存中的数据量不会太大\n缺点:对数据库访问频繁\n 逻辑分页\n 一口气把所有数据全部查询出来,然后放在浏览器内存中\n优点:访问速度快\n缺点:如果数据量大,内存溢出\n物理分页: sql:select * from stu limit 5 offset 2 select * from stu 2,5 显示5条,偏移2两条 ","permalink":"/zh-cn/posts/java/jsp%E5%AD%A6%E4%B9%A0/","series":["JSP"],"tags":["JSP"],"title":"JSP"},{"categories":["Linux"],"content":"Linux基础 文件基本属性 ll/ls -l 显示一个文件的属性以及文件所属的用户组\neg: [root@www /]# ls -l total 64 dr-xr-xr-x 2 root root 4096 Dec 14 2012 bin dr-xr-xr-x 4 root root 4096 Apr 19 2012 boot …… bin 以d开头,表示这是一个目录\n\r当为[-]是文件\r当为[l]表示为link file\r当为[b]表示为可以进行存取的接口设备\r当为[c]表示为串行端口设备\r接下来以3个为一组,且均为[rwx]的组合,位置次序不变\n[r]表示可读,[w]可写,[x]可执行,如果没有这个权限,就会用[-]代替.\n\r第0位确定文件类型.\r第1-3位确定属主（该文件的所有者）拥有该文件的权限\r第4-6位确定属组（所有者的同组用户）拥有该文件的权限\r第7-9位确定其他用户拥有该文件的权限\r属主:对文件具有所有权的用户\n属组:用户按组分类,一个用户属于一个或者多个组\n所以,文件按照[文件所有者|所有者同组用户|所有着不同组用户]来规定访问权限\n对于root用户,权限对他无效\n2. 更改属性 chgrp [-R] 属组名 文件名 更改文件属组\nsudo chgrp name test\nchown [-R] 属主名 : 属组名 文件名 更改文件属主,也可以同时修改文件属组\nsudo chown 770:euraxluo test\nchmod [-R] xyz 文件或者目录  r:4\n w:2\nx:1\n xyz:\n x = owner = rwx = 4+2+1\ny = group = rwx = 4+2+1\nz = others = rwx = 4+2+1\neg:\nsudo chmod 670 test\n使用符号类型改变文件权限 | | | | | |\n| :\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| chmod | u=user | +(加入) | r | 文件或者文件名 |\n| | g=group | - (减少) | w | |\n| | o=others | =(设定) | x | |\n| | a=all | | | |\n所以刚刚我们的代码也可以是\nsudo chmod u=rw,g=rwx,o= test\n文件目录的处理 ls [-adl] 目录名: -a:全部文件\n-d:列出目录本身\n-l:详细列出\nls -al ~\ncd 切换目录 cd ~ :回到xxx@www的/xxx下(家目录)\ncd .. 返回上一级\ncd ./xxx 使用相对路径切换\npwd [-P] (显示当前所在的目录) -P:针对联接档,可以显示出真的路径\nmkdir [-mp] 目录名: 创建新的目录\n-m: 配置文件的权限\n-p:你就可以使用 xxx/xxx/xxx的方式创建目录\neg:\nmkdir -m 440 -p test1/test2\nrmdir [-p] 目录名 删除空的目录\n-p:连同上级的空目录也删除\neg:\n$ rmdir -p test1/test2/test3/test4 $ ls -l 总用量 4 drwxrwxr-x 5 euraxluo euraxluo 4096 1月 15 11:14 \u0026#39;Tencent Files\u0026#39; -r--r--r-- 1 770 euraxluo 0 1月 17 15:06 test cp [-adfilprsu] source destination -i:destination已经存在,先询问\n-r:force ,目标已经存在,强制覆盖\n-p:连同文件的属性一起copy过去\n-d:若source是一个连接档(link file),就copy连接档\n-r:递归copy,用于copy目录\n-a:-all=-pdr\n-u:若 destination 比 source 旧才覆盖 destination\n-s:复制成为符号连结档 (symbolic link)，亦即(link)文件；\n-l:不是copy文件本身,而是copy连接档\neg:\n$ cp -sf test test1 $ cat test1 test $ ls -l total 8 drwxrwxr-x 5 euraxluo euraxluo 4096 1月 15 11:14 \u0026#39;Tencent Files\u0026#39; -rwxrwxrwx 1 770 euraxluo 5 1月 17 16:09 test lrwxrwxrwx 1 euraxluo euraxluo 4 1月 17 16:17 test1 -\u0026gt; test sudo apt-get install -f 安装上一个错误 scp [文件名][路径] 拷贝到远程 eg:\nscp test xxx@ip:拷贝到home\nrm [-fir] 文件或目录 -f:force 强制删除\n-i:会询问一下\n-r:递归删除\ncat [-bnT] 从第一行开始显示文件内容\n-b:列出行号\n-n:列出列号\n-T:打印tap\ntac [-bnT] 从最后一行显示\n-b:列出行号\n-n:列出列号\n-T:打印tap\nnl [-bnw] 显示的时候,输出行号\n -b ：指定行号指定的方式，主要有两种：\n -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n)；\n-b t ：如果有空行，空的那一行不要列出行号(默认值)；\n -n ：列出行号表示的方法，主要有三种：\n -n ln ：行号在荧幕的最左方显示；\n-n rn ：行号在自己栏位的最右方显示，且不加 0 ；\n-n rz ：行号在自己栏位的最右方显示，且加 0 ；\n -w ：行号栏位的占用的位数。\n more 一页一页显示\nless 和more一样,并且可以向前翻页\nhead [-n] 显示头几行\n-n:number\ntail [-n] 显示尾行\n-n:number\nman {命令} 查看命令的文档\nlinux 链接 1.硬连接\n硬连接指通过索引节点来进行连接,两个文件具有完全一样的地位\n删除原始文件,硬链接文件不受影响\n主要用于关键文件的保护\n2.软连接\n软链接文件类似于 Windows 的快捷方式,保存的是原始文件的位置信息.\n删除原始文件,软链接文件无效\n文件系統的索引 在 Linux 的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在 Linux 中，多个文件名指向同一索引节点是存在的.硬连接通过索引实现\n用户管理 useradd [-cdgsu] 用户名 添加新的用户:\n-c comment\n-d 目录 指定用户主目录，若目录不存在,使用-m选项，来创建。\n-g 用户组 指定用户所属的用户组。\n-G 用户组，用户组 指定用户所属的附加组。\n-s Shell文件 指定用户的登录Shell。\n-u 用户号 指定用户号，同时-o，则可以使用其他用户的标识号\neg:\n$ useradd –d /usr/test -m test\nuserdel [-r] 用户名 删除账号\n-r:同时删除用户的主目录\nusermod [-cdmGusol] 用户名 参数与useradd一样\n-l:制定新的用户名,就是更改名字\npasswd [-ludf] 用户名 修改用户的pwd\n-l:锁定口令，即禁用账号。\n-u:口令解锁。\n-d: 使账号无口令。\n-f: 强迫用户下次登录时修改口令。\n用户组管理 groupadd [-go] 用户组 -g:指定新用戶組的GID\n-o:一般和-g一起使用，表示新的用戶組可以和別人相同\ngroupdel 用户组 刪除一個用戶組\ngroupmod [-gon] 用戶組 -g:设置GID\n-o:与groupadd相同\n-n:更名\nnewgrp [目标用户组名] 用户可以在登录后，使用命令newgrp切换到其他用户组\neg:$ newgrp root\n用户标识号  是一个整数，系统内部用它来标识用户。\n  一般情况下它与用户名是一一对应的。如果几个用户名对应的用户标识号是一样的，系统内部将把它们视为同一个用户，但是它们可以有不同的口令、不同的主目录以及不同的登录Shell等。\n  0是超级用户root的标识号，1～99由系统保留，作为管理账号，普通用户的标识号从100开始。在Linux系统中，这个界限是500。\n /etc/shadow  /etc/shadow中的记录行与/etc/passwd中的一一对应，它由pwconv命令根据/etc/passwd中的数据自动产生\n 它的文件格式与/etc/passwd类似，由若干个字段组成，字段之间用\u0026quot;:\u0026ldquo;隔开。这些字段是：\n登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志\n磁盘管理 df [-ahikHTm] 目录或用户名 -a:all,列出全部\n-k:用kb显示\n-m:用mb显示\n-h:自己显示\n-H:用M=1000k来显示\n-T:显示文件系统的分区名\n-i:用inode(索引节点)的数量显示\ndu [-ahskm] 目录或用户名 参数和df一样\n-s:列出总量,不列出占用容量\n-S:不包括子目录的总计\nfdisk [-l] 磁盘名 输出各装置的分区\nmkfs [-t] 装置文件名 格式化这个分区\neg:格式化为fat32\n$ mkfs.fat -F32 /dev/sda1\nmount [-t 文件系统] [-L Label名] [-o 额外选项] [-n] 装置文件名 挂载点 挂載分區\neg:mount /dev/sda1 /mnt/boot/EFI\nunmount [-fn] 装置文件名|挂载点 卸载分区\n-f:強制卸載\n-n:不升級/etc/mtab的情況下卸载\nVI/VIM 下载: sudo apt-get install vim\n命令模式 \r刚刚启动时,或者在输入模式下`ESC`,进入命令模式.\ri:插入,进入输入模式\rI:到行首插入\ra:附加\rA:到行尾附加\rs:删除字符并插入\rS:删除行并插入\rx:删除当前光标所在的字符\rr:替换当前光标所在的字符字符\rR:替换模式:会把当前和后面的字符都替换\re|E:跳到这个词的末尾一个字符上\rw|E:跳到下一个词的开头一个字符上\ro:在这字符前分段\rO:在这字符后分段\rY:拷贝行\rp:在这字符后粘贴行\rP:在这字符前粘贴行\r(\u0026gt;\u0026lt;^v:表示方向键)\rd 动作:删除的范围\reg:\rd l|\u0026gt;:删除这个字符\rd h|\u0026lt;:删除这个字符前面的字符\rd k|^:删除这个字符所在行和上一行\rd j|v:删除这个字符所在行和下一行\rd H:删除屏幕顶行到这个字符\rd L:删除屏幕尾行到这个字符\rD:从这字符一直删除到行尾\r\u0026gt;:缩进\r\u0026lt;:反缩进\r:切换到底线模式\r(:跳转到句首\r):跳转到句尾巴\r{:跳转到段首\r}:跳转到段尾\rV:让这一行高亮\r输入模式 iI,aA,sS,RC进入\n  字符按键以及Shift组合，输入字符\n  ENTER，回车键，换行\n  BACK SPACE，退格键，删除光标前一个字符\n  DEL，删除键，删除光标后一个字符\n  方向键，在文本中移动光标\n  HOME/END，移动光标到行首/行尾\n  Page Up/Page Down，上/下翻页\n  Insert，切换光标为输入/替换模式，光标将变成竖线/下划线\n  ESC，退出输入模式，切换到命令模式\n  底线模式 :w(保存)\n:q(退出)\n:q!(不保存退出)\n:e f(打開文件f)\n:h(幫助)\n:new(新建文件 in vim)\n詳見：問題： vim使用很不熟悉\n","permalink":"/zh-cn/posts/shell/linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/","series":["Linux"],"tags":["Linux"],"title":"Linux基础"},{"categories":["Java"],"content":"MyBatis   一个ORM框架,(不直接建立java对象到关系数据库表数据的映射,而是建立对对象的操作方法到SQL的映射)支持自定义SQL,存储过程和高级映射的持久化框架\n  使用XML或者注解配置\n  能够映射基本数据元素,接口,Java对象到数据库\n  ORM(Object/Relation Mapping) 作用:持久化类与数据库表之间的映射关系,让我们对持久化对象的操作自动转换成对关系数据库操作\n通过映射,我们把关系数据库中的每一行都映射为对象,数据库的每一列就映射成了对象的属性\n##　三层架构：\n１.\t接口层(数据查询接口,数据新增接口,数据更新接口,数据删除接口,获取配置接口)\n２.\t数据处理层(参数映射,SQL解析,SQL执行,结果映射)\n３.\t基础支撑层(连接管理，事务管理，配置加载，缓存处理)\n工作流机制:   根据XM(xml中定义了连接的地址,以及对象和SQL的映射和关系)L或者注解加载SQL语句,参数映射,结果映射到内存\n  应用程序调用API传入参数和SQL ID\n  MyBatis 自动生成SQL语句完成数据库访问,转换执行结构返回应用程序\n  例如,完成一个数据库查询  加载配置文件   应用配置文件\n  关联映射文件\n sqlSession   生成SqlSessionFactory\n  获取SqlSession\n 执行查询   Session 执行SQL\n ","permalink":"/zh-cn/posts/java/mbatis%E5%9F%BA%E7%A1%80/","series":["MyBatis"],"tags":["MyBatis"],"title":"MyBatis"},{"categories":["Python"],"content":"Python构建开源软件 python的构建工具setup.py的应用场景 一般在安装python模块的时候,我们会使用pip install 模块名进行在线安装,会安装依赖包,或者python setup.py install通过源码在本地安装,不会安装依赖包\n在做一个开源项目的时候遇到了一些问题: 我的程序需要用到python的Redis等模块,以及自己写的入口文件run.py,怎么实现可以在服务器上方便的发布,也就是说,可以让依赖和自己写的程序一起安装,同时将自己写的模块变成一个可执行文件\n###　setup.py\n示例以及注释:\nfrom setuptools import setup, find_packages setup( name = \u0026#34;proxy-pool\u0026#34;, #包名 version = \u0026#34;1.0.0\u0026#34;, #版本 keywords = (\u0026#34;poxypool\u0026#34;, \u0026#34;redis\u0026#34;),#关键词列表 description = \u0026#34;test version proxy pool\u0026#34;, #程序的简单介绍 long_description = \u0026#34;A proxy pool project modified from Germey/ProxyPool\u0026#34;, #程序的详细介绍 url = \u0026#34;https://github.com/Euraxluo/ProxyPool\u0026#34;, #程序的官网  download_url = \u0026#34;https://github.com/Euraxluo/ProxyPool.git\u0026#34; #程序的下载地址 author = \u0026#34;Euraxluo\u0026#34;, #作者 author_email = \u0026#34;euraxluo@qq.com\u0026#34;, #程序作者的邮箱 #maintainer 维护者 #maintainer_email 维护者的邮箱地址 packages=[ \u0026#39;proxy-pool\u0026#39; ], py_modules = [\u0026#39;run\u0026#39;],#需要打包的python文件列表 include_package_data = True, platforms = \u0026#34;any\u0026#34;, #程序适用的软件平台列表 install_requires = [#需要安装的依赖包 \u0026#39;aiohttp\u0026#39;, \u0026#39;requests\u0026#39;, \u0026#39;flask\u0026#39;, \u0026#39;redis\u0026#39;, \u0026#39;pyquery\u0026#39; ], entry_points = { #动态发现服务和插件 \u0026#39;console_scripts\u0026#39;: [ #指定命令行工具的名称 \u0026#39;test = test.help:main\u0026#39; #工具包名=程序入口 ] }, license = \u0026#34;apache 2.0\u0026#34;, #程序的授权信息 zip_safe=False,#安装为文件夹还时打包为egg文件 classifiers = [#程序所属的分类列表 \u0026#39;Environment :: Console\u0026#39;, \u0026#39;Programming Language :: Python :: 3.6\u0026#39;, \u0026#39;Programming Language :: Python :: Implementation :: CPython\u0026#39; ] #data_files 打包时需要打包的数据文件,如图片,配置文件等 #package_dir = {\u0026#39;\u0026#39;:\u0026#39;lib\u0026#39;},#表示root pkg的模块都在lib目录中 # requires 定义依赖哪些模块 # provides定义可以为哪些模块提供依赖 #scripts = [],#安装时需要执行的脚本列表 #packages = find_packages(exclude=[\u0026#39;*.tests\u0026#39;]), #需要处理的包目录,可以手动增加手动增加packages参数很容易，刚刚我们用到了这个函数，它默认在和setup.py同一目录下搜索各个含有 __init__.py的包。其实我们可以将包统一放在一个src目录中，另外，这个包内可能还有aaa.txt文件和data数据文件夹,也可以使用exclude排除一些特定的包 ) requirement python项目中必须包含一个 requirements.txt 文件，用于记录所有依赖包及其精确的版本号。以便新环境部署\n示例:\n\raiohttp\u0026gt;=1.3.3\rFlask\u0026gt;=0.11.1\rredis\u0026gt;=2.10.5\rrequests\u0026gt;=2.13.0\rpyquery\u0026gt;=1.2.17\r生成:\npip freeze \u0026gt; requirements.txt\n也可以直接pip freeze查看列表\n安装:\n可以使用pip安装requeirments.txt的依赖:\npip install -r requirements.txt\nLICENSE文件的生成 在开源仓库中选择create files,取名为LICENSE,会让你选择开源协议,最后选好后创建文件即可\nlisence文件也可以用来对项目进行限制和控制\n##　.gitignore\n一般来说每个Git项目中都需要一个“.gitignore”文件，这个文件的作用就是告诉Git哪些文件不需要添加到版本管理中\n添加规则\n例子：\n*.vscode\r*.pyc\r*.db\rvenv\rbuild/ #忽略build/目录下的所有文件\r/.idea #仅仅忽略项目根目录下的.idea文件\r如果我们要排除某些文件呢？\n过滤规则\n加一个｀!｀，比如我们需要排除掉/mtk/文件夹中的/mtk/test.txt\n\r/mtk/\r!/mtk/test.txt\r.travis.yml yaml语法的写出来的配置文件，用来描述如何持续构建，支持各种语言，各种系统环境\n示例:\nlanguage: python python: - \u0026#34;3.6\u0026#34; services: - redis-server script: - python3 setup.py install - cd tests - python3 test_api.py - python3 test_db.py - python3 test_schedule.py python 命名规范 文件名 全小写,可使用下划线\n包 应该是简短的、小写的名字。如果下划线可以改善可读性可以加入。如mypackage。\n模块 与包的规范同。如mymodule。\n类 总是使用首字母大写单词串。如MyClass。内部类可以使用额外的前导下划线。\n函数\u0026amp;方法 函数名应该为小写，可以用下划线风格单词以增加可读性。如：myfunction，my_example_function。\n注意：混合大小写仅被允许用于这种风格已经占据优势的时候，以便保持向后兼容。\n函数和方法的参数\n总使用“self”作为实例方法的第一个参数。总使用“cls”作为类方法的第一个参数。\n如果一个函数的参数名称和保留的关键字冲突，通常使用一个后缀下划线好于使用缩写或奇怪的拼写。\n全局变量 对于from M import *导入语句，如果想阻止导入模块内的全局变量可以使用旧有的规范，在全局变量上加一个前导的下划线。\n注意:应避免使用全局变量\n变量 变量名全部小写，由下划线连接各个单词。如color = WHITE，this_is_a_variable = 1\n注意：\n1.不论是类成员变量还是全局变量，均不使用 m 或 g 前缀。\n2.私有类成员使用单一下划线前缀标识，多定义公开成员，少定义私有成员。\n3.变量名不应带有类型信息，因为Python是动态类型语言。如 iValue、names_list、dict_obj 等都是不好的命名。\n常量 常量名所有字母大写，由下划线连接各个单词如MAX_OVERFLOW，TOTAL。\n异常 以“Error”作为后缀。\n缩写 命名应当尽量使用全拼写的单词，缩写的情况有如下两种：\n1.常用的缩写，如XML、ID等，在命名时也应只大写首字母，如XmlParser。\n2.命名中含有长单词，对某个单词进行缩写。这时应使用约定成俗的缩写方式。\n例如：\nfunction 缩写为 fn\ntext 缩写为 txt\nobject 缩写为 obj\ncount 缩写为 cnt\nnumber 缩写为 num，等。\n前导后缀下划线\n一个前导下划线：表示非公有。\n一个后缀下划线：避免关键字冲突。\n两个前导下划线：当命名一个类属性引起名称冲突时使用。\n两个前导和后缀下划线：“魔”（有特殊用图）对象或者属性，例如__init__或者__file__。绝对不要创造这样的名字，而只是使用它们。\n注意：关于下划线的使用存在一些争议。\n特定命名方式 主要是指 xxx 形式的系统保留字命名法。项目中也可以使用这种命名，它的意义在于这种形式的变量是只读的，这种形式的类成员函数尽量不要重载。如\nclass Base(object):\ndef init(self, id, parent = None):\nself.id = id\nself.parent = parent\ndef message(self, msgid):\n","permalink":"/zh-cn/posts/python/python%E6%9E%84%E5%BB%BA%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6/","series":["Python"],"tags":["Python"],"title":"Python构建开源项目"},{"categories":["读书笔记"],"content":"Unix/Linux 编程實踐教程 ##　什麼是系統編程\n系统资源  处理器  程序由指令构成,处理器是执行指令的硬件设备,一个系统中可能有多个处理器,内核可以安排一个程序何时开始开始执行,暂时停止,恢复执行,终止执行\n输入输出  程序中所有的输入输出都必须流经内核,集中处理,保证了系统的正确性,安全性,有效性\n进程管理  每个程序执行都必须有自己的资源,内核可以新建进程,中止进程,进程调度\n内存  程序必须被装载到内存中才能运行,内核可以对进程进行管理,在程序需要的时候给程序分配内存,当程序不需要时,回收内存,还可以保证内存不被其他进程非法访问.\n设备  各种设备的操作方式不相同,通过内核,可以屏蔽這種差异,使我们对设备的操作简单统一\n计时器  程序的工作和时间有关,内核可以通过系统调用向应用程序提供计时器服务\n进程间通信  内核可以让进程之间进行通信\n网络  内核可以让不同主机上的不同进程进行通信\nbc:Unix计算器,可以接受逆波兰表达式 通过他的与处理器dc,转换为逆波兰表达式,通过pip给dc\n和web服务类似,web服务器作为預处理器,浏览器作为前端显示\nmore: more filename,分页显示file内容\ncommand | more:分页显示command命令\nmore \u0026lt; filename:分页+重定向\n自己写一个more\n//more command  #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;stdlib.h\u0026gt; #define PAGELEN 24  #define LINELEN 512  void do_more(FILE* ); int see_more(FILE*,int ); int sum_size = 0; int main(int ac,char *av[]) { FILE* fp; if(ac == 1) do_more(stdin); else while(--ac) { if((fp = fopen(*++av,\u0026#34;r\u0026#34;)) != NULL) { fseek(fp,0L,SEEK_END); /*利用fseek函数将指针定位在文件结尾的位置*/ sum_size=ftell(fp); /*利用ftell函数返回指针相对于文件开头的位置，以字节计算*/ printf(\u0026#34;\\nthe type of file is : %d\\n\u0026#34;,sum_size); /*进行输出文件总大小*/ fseek(fp,0L,SEEK_SET); /*将fp设置文件开始的位置*/ do_more(fp); fclose(fp); } else exit(1); } return 0; } void do_more(FILE* fp) { /* read PAGELEN lines, then call see_more() for further instructions */ char line[LINELEN]; int num_of_lines = 0; int see_more(FILE*,int),reply; FILE* fp_tty; fp_tty = fopen(\u0026#34;/dev/tty\u0026#34;,\u0026#34;r\u0026#34;); if(fp_tty == NULL) exit(1); while(fgets(line, LINELEN,fp)) { if(num_of_lines == PAGELEN) { int cur_size=ftell(fp); /*利用ftell函数返回指针相对于文件开头的位置，以字节计算*/ int per= (int)100* cur_size/sum_size; //计算当前占用比例。  reply =see_more(fp_tty,per); if(reply == 0 ) break; num_of_lines -= reply; } if(fputs(line,stdout) == EOF) exit(1); num_of_lines++; } } int see_more(FILE* cmd,int per) { /* print message, wait for response, return # of lines to advance q means no, space means yes CRmeans one line */ int c; system(\u0026#34;stty -icanon\u0026#34;);//关闭缓冲区，输入字符无需回车直接接受  printf(\u0026#34;\\033[7m more?##%d##\\033[m\u0026#34;,per); //实现反白  while((c=getc(cmd))!=EOF) { if(c == \u0026#39;q\u0026#39;) return 0; if(c == \u0026#39; \u0026#39;) return PAGELEN; if(c == \u0026#39;\\n\u0026#39;) return 1; } } who 查看有哪些用户在使用这台电脑\n自己写一个who:\n需要的步骤:\n#直接运行,了解大致的功能 who #查看文档 man who #可以看到,大致放在utmp这个文件中 #根据关键词查看帮助 man -k utmp #结果可以看到在帮助手册的第3节 man 3 utmp #结果中,可以知道这是一个数据结构,定义在某个.h文件中 #从文件中读取数据结构 man -k file | egrep read #于是我们找到了read(),进去看如何调用 #顺便,他还介绍了close()和open() #思路: #从utmp中读取我们需要的信息,循环输出 #关于怎么输出时间 man -k time | egrep transform #结果你应该可以看到ctime man 3 ctime ## 开始写吧: who:\n#include\u0026lt;stdlib.h\u0026gt; #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;utmp.h\u0026gt; #include\u0026lt;fcntl.h\u0026gt; #include\u0026lt;unistd.h\u0026gt; #include\u0026lt;time.h\u0026gt; #define SHOWHOST  #define USER_PROCESS 7  void showtime(long); void show_info(struct utmp * utbufp){ if(utbufp-\u0026gt;ut_type != USER_PROCESS) return; printf(\u0026#34;%-8.8s\u0026#34;,utbufp-\u0026gt;ut_name); printf(\u0026#34; \u0026#34;); printf(\u0026#34;%-8.8s\u0026#34;,utbufp-\u0026gt;ut_line); printf(\u0026#34; \u0026#34;); showtime(utbufp-\u0026gt;ut_time); #ifdef SHOWHOST  if(utbufp-\u0026gt;ut_host[0] != \u0026#39;\\0\u0026#39;) printf(\u0026#34;(%s)\u0026#34;,utbufp-\u0026gt;ut_host); #endif  printf(\u0026#34;\\n\u0026#34;);\t} void showtime(long timeval){ char *cp; cp = ctime(\u0026amp;timeval); printf(\u0026#34;%12.12s\u0026#34;,cp+4); } int main(){ struct\tutmp current_record; int utmpfd; int reclen = sizeof(current_record); if((utmpfd = open(UTMP_FILE,O_RDONLY)) == -1){ perror(UTMP_FILE); exit(1);} while (read(utmpfd,\u0026amp;current_record,reclen) == reclen) show_info(\u0026amp;current_record); close(utmpfd); return 0; } #使用缓冲区的who\n#include\u0026lt;stdlib.h\u0026gt; #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;utmp.h\u0026gt; #include\u0026lt;fcntl.h\u0026gt; #include\u0026lt;unistd.h\u0026gt; #include\u0026lt;time.h\u0026gt; #define SHOWHOST  #define USER_PROCESS 7  #define NRECS 16  #define NULLUT ((struct utmp*)NULL)  #define UTSIZE (sizeof(struct utmp))  static char utmpbuf[NRECS * UTSIZE]; static NULLUT () void showtime(long); void show_info(struct utmp * utbufp){ if(utbufp-\u0026gt;ut_type != USER_PROCESS) return; printf(\u0026#34;%-8.8s\u0026#34;,utbufp-\u0026gt;ut_name); printf(\u0026#34; \u0026#34;); printf(\u0026#34;%-8.8s\u0026#34;,utbufp-\u0026gt;ut_line); printf(\u0026#34; \u0026#34;); showtime(utbufp-\u0026gt;ut_time); #ifdef SHOWHOST  if(utbufp-\u0026gt;ut_host[0] != \u0026#39;\\0\u0026#39;) printf(\u0026#34;(%s)\u0026#34;,utbufp-\u0026gt;ut_host); #endif  printf(\u0026#34;\\n\u0026#34;);\t} void showtime(long timeval){ char *cp; cp = ctime(\u0026amp;timeval); printf(\u0026#34;%12.12s\u0026#34;,cp+4); } int main(){ struct\tutmp current_record; int utmpfd; int reclen = sizeof(current_record); if((utmpfd = open(UTMP_FILE,O_RDONLY)) == -1){ perror(UTMP_FILE); exit(1);} while (read(utmpfd,\u0026amp;current_record,reclen) == reclen) show_info(\u0026amp;current_record); close(utmpfd); return 0; } cp cp命令把源文件复制到目标文件，如果目标文件不存在，就创建这个命令，如果已经存在就覆盖\n创建和重写文件：\n系统调用函数creat：\nint fd = creat(char *filename,mode_t mode)\nmode:如果内核成功创建了file，则把mode设置为许可位\n系统调用函数write：\nssize_t result = write(int fd,void *buf,size_t amt)\n提高文件i/o效率的方法：使用缓冲 系统调用是需要时间的：\n当这个程序去调用read时，read的代码在内核中。\n系统调用开销大的原因：\n内核和程序之间不只是会传输数据，还会在root模和用户模式之间来回切换\n","permalink":"/zh-cn/posts/shell/linux%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/","series":["读书笔记"],"tags":["读书笔记"],"title":"Unix/Linux编程实践1"},{"categories":["爬虫"],"content":"前记：   爬虫：使用任何技术手段，批量获取网站信息的一种方式。关键在于批量。\n  反爬虫：使用任何技术手段，阻止别人批量获取自己网站信息的一种方式。关键也在于批量。\n  误伤：在反爬虫的过程中，错误的将普通用户识别为爬虫。误伤率高的反爬虫策略，效果再好也不能用。\n  拦截：成功地阻止爬虫访问。这里会有拦截率的概念。通常来说，拦截率越高的反爬虫策略，误伤的可能性就越高。因此需要做个权衡。\n  资源：机器成本与人力成本的总和。\n  url 管理器：管理待抓取url集合和已抓取url集合 个人：set(),python的set()可以自动去重\n大量带爬取url：关系数据库mysql\n互联网公司：缓存数据库(高性能)\n网页下载器： 1.urllib2：python官方基础模块（py2.7） 下载方法：\n1.直接下载\nimport urllib2 response = urllib2.urlopen(url)#直接下载 print response.getcode()#获取状态码 cont = response.read()#读取内容 2.伪装和密码\nimport urllib2 request = urllib2.Request(url)#创建request对象 request.add_data(\u0026#39;a\u0026#39;,\u0026#39;l\u0026#39;)#添加数据，a-l,诸如账号密码 request.add_header(\u0026#39;User-Agent\u0026#39;,\u0026#39;Mozilla/5.0\u0026#39;)#添加http的header，用于伪装 response = urllib2.urlopen(request)#发送请求获取结果 cont = response.read()#读取内容 3.复杂情景（加套子）\nHTTPCookie用户登录情景/Proxy代理信息/HTTPS加密信息/Readirect防止URL互相跳转\nimport urllib2,cookielib cj = cookielib.CookieJar()#创建cookie容器 opener = urllib2.builb_opener(urllib2.HTTPCookieProcessor(cj))#httpcookie用户登陆 urllib2.intall_opener(opener)#给urllib2安装opener response = urllib2.urlopen(url)#使用带有cookie的urllib2爬取网页 2.urllib.request:(py3) 2.1 request.urlopen方法： urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)    urlopen无法判断数据的encoding，所以返回的是bytes对象。一般会对返回的数据进行decode。\n  url参数，可以是一个string，或者一个Request对象。\n  data一定是bytes对象，传递给服务器的数据，或者为None。目前只有HTTP requests会使用data，提供data时会是一个post请求，如若没有data，那就是get请求。data在使用前需要使用urllib.parse.urlencode()函数转换成流数据\n  urlopen方法：   read() , readline() ,readlines() , fileno() , close() ：对HTTPResponse类型数据进行操作\n  info()：返回HTTPMessage对象，表示远程服务器返回的头信息\n  getcode()：返回Http状态码。如果是http请求，200请求成功完成;404网址未找到\n  geturl()：返回请求的url\n  eg: from urllib import request req = request.urlopen(\u0026#39;http://euraxluo.cn\u0026#39;) print(req.read().decode())#read()方法是读取返回数据内容，decode是转换返回数据的bytes格式为str  2.2 urllib.request.Reques： urllib.request.Request(url, data=None, headers={},origin_req_host=None, unverifiable=False, method=None)\neg: import urllib.request req=urllib.request.Request(\u0026#39;http://euraxluo.cn\u0026#39;) with urllib.request.urlopen(req) as response: page=response.read(300).decode(\u0026#39;utf-8\u0026#39;)#我们获取的数据一般是ascii的，decode成utf-8. print(page) 2.3 用来包装头部的数据：  User-Agent ：这个头部可以携带如下几条信息：浏览器名和版本号、操作系统名和版本号、默认语言  百度图片\r“Baiduspider-image+(+http://www.baidu.com/search/spider.htm)”\r百度最新UA如下：\rPC：\rMozilla/5.0 (compatible; Baiduspider-render/2.0; +http://www.baidu.com/search/spider.html)\r移动：\rMozilla/5.0 (iPhone; CPU iPhone OS 9_1 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Version/9.0 Mobile/13B143 Safari/601.1 (compatible; Baiduspider-render/2.0; +http://www.baidu.com/search/spider.html)\r360搜索\rMozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0);\r360网站安全检测\r360spider (http://webscan.360.cn)\rGoogle\r“Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)”\rGoogle图片搜索\r“Googlebot-Image/1.0”\rAdwords移动网络\r“AdsBot-Google-Mobile (+http://www.google.com/mobile/adsbot.html) Mozilla (iPhone; U; CPU iPhone OS 3 0 like Mac OS X) AppleWebKit (KHTML, like Gecko) Mobile Safari”\r微软 bing，必应\r“Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)”\r腾讯搜搜\r“Sosospider+(+http://help.soso.com/webspider.htm)”\r搜搜图片\r“Sosoimagespider+(+http://help.soso.com/soso-image-spider.htm)”\r雅虎英文\r“Mozilla/5.0 (compatible; Yahoo! Slurp; http://help.yahoo.com/help/us/ysearch/slurp)”\r雅虎中国\r“Mozilla/5.0 (compatible; Yahoo! Slurp China; http://misc.yahoo.com.cn/help.html)”\r搜狗图片\r“http://pic.sogou.com” “Sogou Pic Spider/3.0(+http://www.sogou.com/docs/help/webmasters.htm#07)”\r搜狗\r“Sogou web spider/4.0(+http://www.sogou.com/docs/help/webmasters.htm#07)”\r网易有道\r“Mozilla/5.0 (compatible; YoudaoBot/1.0; http://www.youdao.com/help/webmaster/spider/; )”\r瑞典 Speedy Spider\r“Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) Speedy Spider (http://www.entireweb.com/about/search_tech/speedy_spider/)”\r俄罗斯 yandex\r“Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots)”\r宜搜 EasouSpider\rMozilla/5.0 (compatible; EasouSpider; +http://www.easou.com/search/spider.html)\r华为赛门铁克蜘蛛\r“HuaweiSymantecSpider/1.0+DSE-support@huaweisymantec.com+(compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR ; http://www.huaweisymantec.com/cn/IRL/spider)”\r华为赛门铁克科技有限公司网页信誉分析系统的一个页面爬取程序，其作用是用于爬取互联网网页并进行信誉分析，从而检查该网站上的是否含有恶意代码。\r七牛镜像蜘蛛\rqiniu-imgstg-spider-1.0\r监控宝\r“Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; JianKongBao Monitor 1.1)”\rDNSPod监控\rDNSPod-Monitor/2.0\r  Referer：可以用来防止盗链，有一些网站图片显示来源http://*.com，就是检查Referer来鉴定的\n  Connection：表示连接状态，记录Session的状态\n  \r#urllib.request.Request(url, data=None, headers={}, method=None)\r#使用request（）来包装请求，再通过urlopen（）获取页面。\r2.4 Post数据  urlopen()的data参数默认为None，当data参数不为空的时候，urlopen（）提交方式为Post  urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)\n`\nurlencode（）主要作用就是将url附上要提交的数据。\n Post的数据必须是bytes或者iterable of bytes，不能是str，因此需要进行encode（）编码  page = request.urlopen(req, data=data).read()\n当然，也可以把data的数据封装在urlopen（）参数中\ndata = {'first': 'true',}\ndata = parse.urlencode(data).encode('utf-8')\n eg:  import urllib.parse as up import urllib.request as ur url = \u0026#39;http://www.uustv.com/\u0026#39; values = {\u0026#39;word\u0026#39;: \u0026#39;Euraxluo\u0026#39;,\u0026#39;sizes\u0026#39;: \u0026#39;60\u0026#39;,\u0026#39;fonts\u0026#39;: \u0026#39;jfcs.ttf\u0026#39;,\u0026#39;fontcolor\u0026#39;: \u0026#39;#000000\u0026#39;}#Post的数据 data = up.urlencode(values)#编码 data = data.encode(\u0026#39;ascii\u0026#39;)#解码,server,只接受ascii数据 req = ur.Request(url,data) with ur.urlopen(req) as response: page = response.read().decode(\u0026#39;utf-8\u0026#39;) #我们获取的数据一般是ascii的，decode成utf-8. print(page) 使用代理  当需要抓取的网站设置了访问限制，这时就需要用到代理来抓取数据  urllib.request.ProxyHandler(proxies=None)\n eg:  proxy = urllib.request.ProxyHandler({\u0026#39;http\u0026#39;: \u0026#39;ip\u0026#39;}) # 设置proxy opener = urllib.request.build_opener(proxy) # 挂载opener urllib.request.install_opener(opener) # 安装opener data = urllib.parse.urlencode(data).encode(\u0026#39;utf-8\u0026#39;)#下载 ","permalink":"/zh-cn/posts/crawler/%E7%88%AC%E8%99%AB%E5%88%9D%E7%BA%A71/","series":["Pathon"],"tags":["爬虫","Pathon"],"title":"爬虫学习1"},{"categories":["爬虫"],"content":"Requests库 发送请求 方法： r=requests.get(\u0026#39;http://httpbin.org/get\u0026#39;)#get r = requests.post(\u0026#34;http://httpbin.org/post\u0026#34;)#post r = requests.put(\u0026#34;http://httpbin.org/put\u0026#34;)#put r = requests.delete(\u0026#34;http://httpbin.org/delete\u0026#34;)#delect r = requests.head(\u0026#34;http://httpbin.org/get\u0026#34;)#head r = requests.options(\u0026#34;http://httpbin.org/get\u0026#34;)#options eg import requests r = requests.get(url=\u0026#39;http://www.euraxluo.cn\u0026#39;) # 最基本的GET请求 print(r.status_code) # 内置的状态码查询对象 #状态码非200视为出错 httpbin响应状态码  eg:404 r = requests.get(\u0026#39;http://httpbin.org/status/404\u0026#39;) print(r.status_code)#404 error_info = r.raise_for_status()#Response.raise_for_status()抛出异常 带参数的url请求： #向url传递参数 r = requests.get(url=\u0026#39;http://dict.baidu.com/s\u0026#39;, params={\u0026#39;wd\u0026#39;: \u0026#39;python\u0026#39;})#带参数的GET请求 #当你不知道你的编码类型时 r.encoding = r.apparent_encoding#获取编码类型 print(r.text)#返回解码后的数据 注： 若有图片 r.content 返回bytes数据\neg：r.content r = requests.get(url=\u0026#39;http://music.baidu.com\u0026#39;)#实测，没啥区别 html=r.content #html_doc=str(html,\u0026#39;utf-8\u0026#39;) html_doc=html.decode(\u0026#34;utf-8\u0026#34;,\u0026#34;ignore\u0026#34;) print(html_doc) 响应内容 不同的内容处理方式 Json：request.json() 二进制：一般用于图片 from PIL import Image from io import BytesIO m = request.content#未解码内容 i = Image.open(m)#用二进制数据创建图片 text:可以自动解码。用的最多 import requests r=requests.get(\u0026#39;https://euraxluo.cn\u0026#39;) r.text#已经经过自动解码 编码问题： 1. if req.encoding == \u0026#39;ISO-8859-1\u0026#39;: encodings = requests.utils.get_encodings_from_content(req.text) if encodings: encoding = encodings[0] else: encoding = req.apparent_encoding # encode_content = req.content.decode(encoding, \u0026#39;replace\u0026#39;).encode(\u0026#39;utf-8\u0026#39;, \u0026#39;replace\u0026#39;) global encode_content encode_content = req.content.decode(encoding, \u0026#39;replace\u0026#39;) #如果设置为replace，则会用?取代非法字符； 2. try: r = requests.get(url,timeout = 30) r.raise_for_status() r.encoding = r.apparent_encoding return r.text except: print(\u0026#34;error\u0026#34;) 定制headers headers必须是string，bytestring,Unicode url=\u0026#39;https://euraluo.cn\u0026#39; headers={\u0026#39;user-agent\u0026#39;:\u0026#39;my-app/0.0.1\u0026#39;}#UA r=requests.get(url,headers=headers) POST POST表单 多个元素使用同一key的时候可以将dict替换成元祖列表，\n可以将data=替换成json=，传入json对象。\npayload={\u0026#39;key1\u0026#39;:\u0026#39;value1\u0026#39;,\u0026#39;key2\u0026#39;:\u0026#39;value2\u0026#39;} r=requests.post(\u0026#39;http://httpbin.org/post\u0026#39;, data=payload) POST文件 url = \u0026#39;http://httpbin.org/post\u0026#39; files={\u0026#39;file\u0026#39;:open(\u0026#39;report.xls\u0026#39;,\u0026#39;rb\u0026#39;)}#使用二进制模式打开文件。 r=requests.post(url,files=files) Cookie 访问cookie r.cookies['cookie_name']\n发送cookie到服务器 cookies=dict(cookies_are='workding')\nr.requests.get(url,cookies=cookies)\neg: #Cookie的返回对象为RequestsCookieJar，类似于字典，适合跨域名路径使用。 jar=requests.cookies.RequestsCookieJar() jar.set(\u0026#39;tasty_cookie\u0026#39;, \u0026#39;yum\u0026#39;, domain=\u0026#39;httpbin.org\u0026#39;, path=\u0026#39;/cookies\u0026#39;) jar.set(\u0026#39;gross_cookie\u0026#39;, \u0026#39;blech\u0026#39;, domain=\u0026#39;httpbin.org\u0026#39;, path=\u0026#39;/elsewhere\u0026#39;) url = \u0026#39;http://httpbin.org/cookies\u0026#39; r = requests.get(url, cookies=jar) r.text#打印出cookie 会话 使用grt()时，先构建Request对象，发送请求；再返回Response对象，包含服务器返回的所有信息 ag: #会话也可用来为请求方法提供缺省数据 s=requests.Session() s.auth=(\u0026#39;user\u0026#39;,\u0026#39;pass\u0026#39;) s.headers.update({\u0026#39;x-test\u0026#39;:\u0026#39;true\u0026#39;}) #x-test和x-test2都会发送出去 s.get(\u0026#39;http://httpbin.org/headers\u0026#39;, headers={\u0026#39;x-test2\u0026#39;:\u0026#39;true\u0026#39;}) print(s) SSL证书验证 如果设置为False，会忽略对SSL证书的验证。\nrequests.get('https://github.com', verify=True)\nSSL验证默认开始，如果验证失败，会抛出SSLErro\n代理 通过代理爬取\nimport requests proxies = {\u0026#34;http\u0026#34;: \u0026#34;171.38.24.164:8132\u0026#34;} r=requests.get(\u0026#34;http://ip.chinaz.com/getip.aspx\u0026#34;, ,proxies=proxies) print(r.text) ","permalink":"/zh-cn/posts/crawler/%E7%88%AC%E8%99%AB%E5%88%9D%E7%BA%A72/","series":["Pathon"],"tags":["爬虫","Pathon"],"title":"爬虫学习2"},{"categories":["爬虫"],"content":"代理 获取代理ip import requests import bs4 from bs4 import BeautifulSoup User_Agent = \u0026#39;Mozilla/5.0 (Windows NT 6.3; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0\u0026#39; header = {} header[\u0026#39;User-Agent\u0026#39;] = User_Agent url = \u0026#39;http://www.xicidaili.com/nn/1\u0026#39; r = requests.get(url,headers=header) res = r.text soup = BeautifulSoup(res,\u0026#34;html.parser\u0026#34;) ips = soup.findAll(\u0026#39;tr\u0026#39;) f = open(\u0026#34;./ip_proy/ip\u0026#34;,\u0026#34;w\u0026#34;) for x in range(1,len(ips)): ip = ips[x]#一行 tds = ip.findAll(\u0026#34;td\u0026#34;) line = \u0026#34;%s:%s;%s\u0026#34; % (tds[1].contents[0],tds[2].contents[0],tds[5].contents[0])+\u0026#34;\\n\u0026#34; ip_temp = tds[2].contents[0]+\u0026#34;\\t\u0026#34;+tds[3].contents[0]+\u0026#34;\\n\u0026#34; f.write(line) print(line) 验证能否连接 #Unicode gbk import socket import re import sys import requests #socket.setdefaulttimeout(3)#全局延时 #f2 = open(\u0026#34;./ip_proy/run_ip\u0026#34;, \u0026#34;w\u0026#34;) f = open(\u0026#34;./ip_proy/ip\u0026#34;) lines = f.readlines() proxys = [] for i in range(0,len(lines)): ip = lines[i].strip(\u0026#34;\\n\u0026#34;).split(\u0026#34;\\t\u0026#34;) ip_line = re.split(r\u0026#34;[.:;]\u0026#34;,ip[0])#re.split分割 proxy_host = \u0026#34;http://\u0026#34;+ip_line[0]+\u0026#34;.\u0026#34;+ip_line[1]+\u0026#34;.\u0026#34;+ip_line[2]+\u0026#34;.\u0026#34;+ip_line[3]+\u0026#34;:\u0026#34;+ip_line[4] proxy_temp = {\u0026#34;http\u0026#34;:proxy_host} proxys.append(proxy_temp) url = \u0026#34;http://ip.chinaz.com/getip.aspx\u0026#34; for proxy in proxys: try: res = requests.get(url,proxies=proxy,timeout=30) res.encoding = res.apparent_encoding res = res.text print(proxy) print(res+\u0026#34;\\n\u0026#34;) \u0026#39;\u0026#39;\u0026#39;#hava a bug for values in proxy.values(): print(values) f2.write(str(values)+\u0026#34;\\n\u0026#34;) \u0026#39;\u0026#39;\u0026#39; except: print(proxy) print(\u0026#34;times out\\n\u0026#34;) f.close() #f2.close() sys.exit() 网页解析器 正则表达式 html.parser BeautifulSoup lxml 网页解析方法： 结构化解析-DOM树\nBeautifulSoup(最常用) BeautifulSoup解析器： |解析器|使用方法|条件|\n|\u0026mdash;|\u0026mdash;|\u0026mdash;|\n|bs4的html解析器|BeautifulSoup(html,\u0026lsquo;html.parser\u0026rsquo;)|安装bs4|\n|lxml的html解析器|BeautifulSoup(html,\u0026lsquo;lxml\u0026rsquo;)|pip install lxml|\n|lxml的xml解析器|BeautifulSoup(html,\u0026lsquo;xml\u0026rsquo;)|pip install lxml|\n|html5lib的解析器|BeautifulSoup(html,\u0026lsquo;html5lib\u0026rsquo;)|pip install html5lib|\n基本元素 |基本元素|说明|\n|\u0026mdash;|\u0026mdash;|\n|tag|标签,\u0026lt;\u0026gt;开头，\u0026lt;/\u0026gt;结尾|\n|name|标签的名字，,\u0026lt;tag\u0026gt;.name|\n|attrs|标签的属性，\u0026lt;tag\u0026gt;.attrs|\n|NavigableString|String,\u0026lt;tag\u0026gt;.String|\n|Comment|标签内字符串的注释部分，Comment类型|\n搜索节点(html中的标签) find_all(name,attrs,recursive,string)\nname:对标签名称的检索字符串\nattrs:对标签属性值的检索字符串,可棕注属性栓索\nrecursive:是否对子孙全部检索,默以True\nstring:\u0026lt;\u0026gt;..\u0026lt;/\u0026gt;中字符串区域的检索字符串\neg: import bs4 from bs4 import BeautifulSoup import re html = \u0026#34;\u0026lt;body\u0026gt;\u0026lt;a href=\u0026#39;./test/123.txt\u0026#39;\u0026gt;hjhkj\u0026lt;/a\u0026gt; \u0026lt;div class=\u0026#39;test\u0026#39;\u0026gt;fdfdfd\u0026lt;div class=\u0026#39;test\u0026#39;\u0026gt;fdfdfd\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/body\u0026gt;\u0026#34; soup = BeautifulSoup(html,\u0026#34;html.parser\u0026#34;) #查找所有标签为a，链接为./test/123.txt形式的节点 m = soup.find_all(\u0026#39;a\u0026#39;,href=re.compile(r\u0026#39;./test/(.*).txt\u0026#39;))# (另一种写法\\d+\\) #查找所有标签为div，class为test，文字为fdfdfd的节点 m=soup.find_all(\u0026#39;div\u0026#39;,class_=\u0026#39;test\u0026#39;,string = \u0026#39;fdfdfd\u0026#39;) m = soup.div(class_=\u0026#39;test\u0026#39;,string = \u0026#39;fdfdfd\u0026#39;) soup.div.attrs#tag的attrs soup.div.parent.name#tag的父亲节点的名字 m = soup.a.string#String #显示： m = soup.prettify()#友好度+1 print(m) ###标签树的遍历\n上行遍历\n|属性|说明|\n|\u0026mdash;|\u0026mdash;|\n|.parent|节点的父亲标签|\n|.parents|节点父辈的迭代，用来遍历父辈节点|\n下行遍历\n|属性|说明|\n|\u0026mdash;|\u0026mdash;|\n|.contents|tag的子节点列表|\n|.children|子结点的迭代，用于循环儿子节点|\n|.descendants|子孙节点的迭代，循环遍历所有子孙节点|\n平行遍历\n|属性|说明|\n|\u0026mdash;|\u0026mdash;|\n|.next_sibling|返回下一个平行节点的tag|\n|.previous_sibling|分返回上一个平行节点|\n|.next_siblings|迭代类型，返回后续所有平行节点|\n|.previous_siblings|迭代类型，返回前序所有平行节点|\n​ 总结：扩展方法：又是实例(网上找的) # coding:utf-8 from bs4 import BeautifulSoup import re html_doc = \u0026#34;\u0026#34;\u0026#34; #定义一个长字符串，存储html代码,\u0026#39;\u0026#39;\u0026#39;可以保留格式 \u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;The Dormouse\u0026#39;s story\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p class=\u0026#34;title\u0026#34;\u0026gt;\u0026lt;b\u0026gt;The Dormouse\u0026#39;s story\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026#34;story\u0026#34;\u0026gt;Once upon a time there were three little sisters; and their names were \u0026lt;a href=\u0026#34;http://example.com/elsie\u0026#34; class=\u0026#34;sister\u0026#34; id=\u0026#34;link1\u0026#34;\u0026gt;Elsie\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;http://example.com/lacie\u0026#34; class=\u0026#34;sister\u0026#34; id=\u0026#34;link2\u0026#34;\u0026gt;Lacie\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;http://example.com/tillie\u0026#34; class=\u0026#34;sister\u0026#34; id=\u0026#34;link3\u0026#34;\u0026gt;Tillie\u0026lt;/a\u0026gt;; and they lived at the bottom of a well.\u0026lt;/p\u0026gt; http://example.com/lacie \u0026lt;p class=\u0026#34;story\u0026#34;\u0026gt;...\u0026lt;/p\u0026gt; \u0026#34;\u0026#34;\u0026#34; soup = BeautifulSoup(html_doc, \u0026#39;html.parser\u0026#39;)#传入的html字符串；使用的解析器；编码方式 print(soup.prettify())#按照标准的缩进格式输出获取的soup内容 #提取所有的连接出来 links = soup.find_all(\u0026#39;a\u0026#39;) for link in links: print(link.name, link[\u0026#39;href\u0026#39;], link[\u0026#39;class\u0026#39;], link.get_text()) #获取lacie连接 link_node = soup.find(\u0026#39;a\u0026#39;, href=\u0026#39;http://example.com/lacie\u0026#39;) print(link_node.name, link_node[\u0026#39;href\u0026#39;], link_node.get_text()) #用强大的 正则匹配 link_node = soup.find(\u0026#39;a\u0026#39;, href=re.compile(r\u0026#34;ill\u0026#34;)) print(link_node.name, link_node[\u0026#39;href\u0026#39;], link_node.get_text()) #获取P标签 p_node = soup.find(\u0026#39;p\u0026#39;, class_=re.compile(r\u0026#34;ti\u0026#34;)) print(p_node.name, p_node[\u0026#39;class\u0026#39;], p_node.get_text()) #抓取暗链接 link_node = soup.find_all(style=\u0026#39;display:none;\u0026#39;) print(link_node) #选择器 soup.select(\u0026#39;title\u0026#39;)#选择title标签 soup.select(\u0026#39;p nth-of-type(3)\u0026#39;) #通过tag标签逐层查找 soup.select(\u0026#39;body a\u0026#39;)#查找body标签下面的a标签 #找到某个tag标签下的直接子标签： soup.select(\u0026#39;head\u0026gt;title\u0026#39;) #通过id来查找： soup.select(\u0026#39;#link1\u0026#39;) #通过class来查找： soup.select(\u0026#39;.story\u0026#39;) soup.select(\u0026#39;[class~=story]\u0026#39;) #通过是否存在某个属性来查找： soup.select(\u0026#39;a[href]\u0026#39;) #通过属性的值来查找： soup.select(\u0026#39;a[href=\u0026#34;http://example.com/lacie]\u0026#39;) 正则RE 特殊字符：(使用r\u0026rsquo;string\u0026rsquo;定义字符) \u0026#39;.\u0026#39;，#点号，在默认模式中，匹配任何一个字符，除了新的行newline。如果DOTALL标记指定了，那么还可以匹配newline。 \u0026#39;^\u0026#39;，#匹配字符串的开始 \u0026#39;$\u0026#39;，#匹配字符串的结束。比如foo匹配foo或者foobar，但是foo$只能匹配到foo。 \u0026#39;*\u0026#39;，#匹配0个或者多个字符，比如ab*，可以匹配a，ab，abbbb等 \u0026#39;+\u0026#39;，#匹配1个或者多个字符，比如ab+，可以匹配ab，或者abbbb \u0026#39;?\u0026#39;，#匹配0或者1个字符，比如ab?只能匹配a或者ab。 \u0026#39;*？+\u0026#39;，#贪婪模式的，会尽可能多的匹配字符， \u0026#39;*？+\u0026#39;,#在后面加上一个？则会变为非贪婪模式，尽可能匹配少的字符。 #我们一般用非贪婪模式。 #m,n表示匹配的数量，如果不指定m或者n，则表示没有上限，下限不能低于0个 \u0026#39;{m}\u0026#39;,#指定匹配的数量，比如a{6}表示将匹配6个a字符，而不是5个，准确匹配。 \u0026#39;{m,n}\u0026#39;,#匹配在m~n个字符之间，包含m和n，比如a{3,5}将匹配3-5个a字符，一般会取上限来匹配。 \u0026#39;{m,n}?\u0026#39;,#非贪婪模式的匹配，尽可能匹配少，取下限m来匹配。 \u0026#39;[]\u0026#39;,#用于创造一个字符的集合，字符可以单独出现或者使用0-9，a-z这种格式。 比如： 1.[amk]会匹配a，m或者k字符。[a-z]将会匹配a-z之间的任何一个字符。[0-5][0-9]匹配从00-59的所有字符。 2.如果在[]中包含一个特殊字符的集合，比如[(+*)]，这些特殊字符将会失去其特殊含义，只匹配字面意义，\u0026#39;(\u0026#39;\u0026#39;)\u0026#39;\u0026#39;+\u0026#39;\u0026#39;*\u0026#39;。 3.如果在[]的开始有一个\u0026#39;^\u0026#39;，比如[^5]，将会匹配任何一个不是5的字符。 \u0026#39;|\u0026#39;,#A|B，AB是任意的RE表达式，可以匹配A或者B \u0026#39;(...)\u0026#39;,#括号内的表达式将作为分组，从表达式左边开始每遇到一个分组的左括号，编号+1。分组表达式作为一个整体，可以后接数量词。 比如: 1.(abc){2}匹配abcabc，a(123|456)c匹配a456c或者a123c。 \u0026#39;(?P\u0026lt;name\u0026gt;...)\u0026#39;，#分组，除了原有的编号外，指定一个额外的别名，比如：(?P\u0026lt;id\u0026gt;abc){2}，可以匹配abcabc，通过.\u0026#39;id\u0026#39;来访问。 \u0026#39;\\\u0026lt;number\u0026gt;\u0026#39;，#引用编号为\u0026lt;number\u0026gt;的分组匹配到的字符串。比如(\\d)abc\\1，可以匹配1abc1，或者5abc5 \u0026#39;(?P=name)\u0026#39;,#引用别名为\u0026lt;name\u0026gt;的分组匹配到的字符串，比如(?P\u0026lt;id\u0026gt;\\d)abc(?P=id),可以匹配1abc1，5abc5等。 \u0026#39;\\d\u0026#39;,#表示数字，0-9之间的一个，比如a\\dc,可以匹配a1c; \u0026#39;\\D\u0026#39;,#表示非数字，也可以用[^\\d]来代替， \u0026#39;\\s\u0026#39;，#表示空白字符 \u0026#39;\\S\u0026#39;，#表示非空白字符 \u0026#39;\\w\u0026#39;,#表示单词字符，[A-Za-z0-9_] \u0026#39;\\W\u0026#39;，#表示非单词字符。 \u0026#39;\\A\u0026#39;,#仅匹配字符串的开头，\\Aabc可以匹配abc。 \u0026#39;\\Z\u0026#39;,#仅匹配字符串结尾，abc\\Z,匹配abc 方法： 1re.findall(pattern,string) 对string中所有符合pattern规则的进行匹配\n2re.compile(pattern,flag=0) 返回一个对象的模式，用法：re.compile(pattern,flag=0).findall(string)\npattern为正则字符串\nflag，匹配模式,以下可选\n\rre.I #忽略大小写\rre.M #多行模式\rre.S #点任意匹配，\rre.L #\rre.U\rre.X #详细模式，这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释\r3re.match(pattern, string, flags=0) match方法会从要匹配的string的开头开始，尝试匹配pattern，一直向后，如果遇到无法匹配的字符，就返回None，如果匹配未结束已经到达string的末尾也会返回None，表示匹配失败。匹配成功会返回True，以及匹配到的内容的group,非完全匹配，完全匹配需要在表达式末尾加上'$'\neg: pattern=re.compile(r\u0026#39;hello\u0026#39;) result1=re.match(pattern,\u0026#39;hello\u0026#39;) result2=re.match(pattern,\u0026#39;helloo world\u0026#39;) result3=re.match(pattern,\u0026#39;helo world\u0026#39;) result4=re.match(pattern,\u0026#39;hello world\u0026#39;) if result1: print(result1.group()) else: print(\u0026#39;1匹配失败!\u0026#39;) if result2: print(result2.group()) else: print(\u0026#39;2匹配失败!\u0026#39;) if result3: print(result3.group()) else: print(\u0026#39;3匹配失败!\u0026#39;) if result4: print(result4.group()) else: print(\u0026#39;4匹配失败!\u0026#39;) m=re.match(r\u0026#39;(\\w+) (\\w+)(?P\u0026lt;sign\u0026gt;.*)\u0026#39;,\u0026#39;hello world!\u0026#39;)#单词+空格+单词+任意字符 print(m.string)#获取匹配时使用的文本 print(m.re)#获取匹配时使用的pattern对象 print(m.pos)#文本中开始搜索的位置 print(m.endpos)#返回结束搜索的位置 print(m.lastindex)#最后一个被捕获的分组在文本中的索引 print(m.lastgroup)#最后一个最捕获的分组的别名 print(m.group())#获得一个或多个分组截获的字符串，如果指定多个参数，将会以元祖形式返回 print(m.group(1,2))#指定多个参数 print(m.groups())#以元组形式返回所有分组截获的字符串 print(m.groupdict())#返回具有别名的组的别名为Key，字符串为value的字典，不包含别名的组不统计 print(m.start(2))#返回指定的组截获的子串在string中的起始索引 print(m.end(2))#返回指定的组在string中的结束索引 print(m.span(2))#返回(start(group),end(group)) 4re.search(pattern, string, flags=0) 类似与match方法，但是match会检测re是不是在string的开始位置就能够匹配到，而search会扫描整个string来匹配。match方法只有在0位置匹配成功的话才会返回，如果不是开始i位置，即使后面由匹配，也会返回None。\neg: pattern=re.compile(r\u0026#39;world\u0026#39;) match=re.search(pattern,\u0026#39;hello world!\u0026#39;) if match: print(match.group() 5re.split(pattern, string, maxsplit=0, flags=0) 将string按照匹配的子串分割后返回列表，maxsplit参数指定最大分割次数，不指定的话会全部分割。\neg: pattern=re.compile(r\u0026#39;\\d+\u0026#39;) split=re.split(pattern,\u0026#39;one1two2three3four4\u0026#39;) print(split) 6re.findall(pattern, string, flags=0) 搜索string，以列表的形式返回全部能匹配的子串。\neg: pattern = re.compile(r\u0026#39;\\d+\u0026#39;) print(re.findall(pattern,\u0026#39;one1two23three3four4\u0026#39;)) 7re.finditer(pattern, string, flags=0) 搜索string，返回一个顺序访问每一个匹配结果的迭代器\neg: pattern=re.compile(r\u0026#39;\\d+\u0026#39;) for m in re.finditer(pattern,\u0026#39;one1two23three3four4\u0026#39;): print(m.group()) 8re.sub(pattern, repl, string, count=0, flags=0) 使用repl替换string中的每一个匹配的子串后返回替换的字符串。\nrepl可以是一个方法，这个方法应该只接受一个match对象作为参数，并且返回一个字符串用于替换。\ncount可以指定最多替换次数，不指定的话就全部替换。\neg: pattern=re.compile(r\u0026#39;(\\w+) (\\w+)\u0026#39;) string=\u0026#39;i say, hello world!\u0026#39; print(re.sub(pattern,r\u0026#39;\\2 \\1\u0026#39;,string)) def func(m): return m.group(1).title()+\u0026#39; \u0026#39;+m.group(2).title() print(re.sub(pattern,func,string)) ","permalink":"/zh-cn/posts/crawler/%E7%88%AC%E8%99%AB%E5%88%9D%E7%BA%A73/","series":["Pathon"],"tags":["爬虫","Pathon"],"title":"爬虫学习3"},{"categories":["爬虫"],"content":"PyQuery 初始化 %%html \u0026lt;div id = \u0026#34;container\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;list\u0026#34;\u0026gt; \u0026lt;li class = \u0026#34;item-0\u0026#34;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-1\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link2.html\u0026#34;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-0 active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link3.html\u0026#34; style=\u0026#34;color:black;\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;bold\u0026#34;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-1 active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link4.html\u0026#34;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-0\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link5.html\u0026#34;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; 字符串初始化 html = \u0026#39;\u0026#39;\u0026#39; \u0026lt;div id = \u0026#34;container\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;list\u0026#34;\u0026gt; \u0026lt;li class = \u0026#34;item-0\u0026#34;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-1\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link2.html\u0026#34;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-0 active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link3.html\u0026#34; style=\u0026#34;color:black;\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;bold\u0026#34;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-1 active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link4.html\u0026#34;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-0\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link5.html\u0026#34;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026#39;\u0026#39;\u0026#39; from pyquery import PyQuery as pq doc = pq(html) print(doc(\u0026#34;li\u0026#34;)) \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r ​\nURL初始化 doc = pq(url=\u0026#34;http://www.baidu.com\u0026#34;) print(doc(\u0026#34;head\u0026#34;).text().encode(\u0026#39;iso8859-1\u0026#39;).decode(\u0026#39;utf8\u0026#39;)) 百度一下，你就知道\r 文件初始化 doc = pq(filename = \u0026#34;test.html\u0026#34;) print(doc(\u0026#34;li\u0026#34;)) \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r ​\ncss选择器 doc = pq(html) print(doc(\u0026#34;#container .list li\u0026#34;)) \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r ​\n查找元素 doc = pq(html) items = doc(\u0026#34;.list\u0026#34;) print(type(items)) print(items) print(\u0026#34;------------------\u0026#34;) lis = items.find(\u0026#34;li\u0026#34;) print(type(lis)) print(lis) \u0026lt;class 'pyquery.pyquery.PyQuery'\u0026gt;\r\u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;/ul\u0026gt;\r------------------\r\u0026lt;class 'pyquery.pyquery.PyQuery'\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r ​\n子元素 lis1 = items.children() print(lis1) print(\u0026#34;------------------\u0026#34;) lis2 = items.children(\u0026#34;.active\u0026#34;) print(lis2) \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r------------------\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r ​\n父级元素 parent = items.children().parent() print(parent) \u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;/ul\u0026gt;\r ​\nparents =items.children().parents() print(parents) print(\u0026#34;------------------\u0026#34;) print(parents(\u0026#34;.list\u0026#34;)) \u0026lt;div id=\u0026quot;container\u0026quot;\u0026gt;\r\u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;/ul\u0026gt;\r\u0026lt;/div\u0026gt;\u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;/ul\u0026gt;\r------------------\r\u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;/ul\u0026gt;\r\u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;/ul\u0026gt;\r ​\n兄弟元素 third = doc(\u0026#34;.list .item-0.active\u0026#34;) print(third) print(\u0026#34;----------\u0026#34;) brothers = third.siblings() print(brothers) \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r----------\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r ​\n遍历 doc = pq(html) lis = doc(\u0026#34;li\u0026#34;).items() print(type(lis)) for li in lis: print(li) print(\u0026#34;---\u0026#34;) \u0026lt;class 'generator'\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt;\r---\r\u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r---\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r---\r\u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r---\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r---\r 获取信息 获取属性 doc = pq(html) a = doc(\u0026#34;.item-0.active a\u0026#34;) print(a) print(\u0026#34;---\u0026#34;) print(a.attr(\u0026#34;style\u0026#34;)) print(\u0026#34;---\u0026#34;) print(a.attr.href) \u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\r---\rcolor:black;\r---\rlink3.html\r 获取文本 texts = doc.items() for text in texts: print(text.text()) frist item\rsecond item\rthird item\rfourth item\rfifth item\r 获取html a = doc(\u0026#34;.item-0.active a\u0026#34;) print(a) print(\u0026#34;---\u0026#34;) print(a.html()) \u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\r---\r\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\r addClass,removeClass doc = pq(html) li = doc(\u0026#34;.item-0.active\u0026#34;) print(li) li.removeClass(\u0026#39;active\u0026#39;) print(li) li.addClass(\u0026#39;active\u0026#39;) print(li) \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r ​\nattr,css doc = pq(html) li = doc(\u0026#34;.item-0.active\u0026#34;) print(li) li.attr(\u0026#39;name\u0026#39;,\u0026#39;link\u0026#39;) print(li) li(\u0026#34;a\u0026#34;).css(\u0026#39;font-size\u0026#39;,\u0026#39;14px\u0026#39;) print(li) \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot; name=\u0026quot;link\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r\u0026lt;li class=\u0026quot;item-0 active\u0026quot; name=\u0026quot;link\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black; font-size: 14px\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\r ​\nremove doc =pq(html) li = doc(\u0026#34;li\u0026#34;) print(li.text()) li.find(\u0026#39;a\u0026#39;).remove() print(li.text()) frist item second item third item fourth item fifth item\rfrist item  API  %%html \u0026lt;pre style=\u0026#34;line-height: 1.25; white-space: pre;\u0026#34;\u0026gt; \\ SORRY / \\ / \\ This page does / ] not exist yet. [ ,\u0026#39;| ] [ / | ]___ ___[ ,\u0026#39; | ] ]\\ /[ [ |: | ] ] \\ / [ [ |: | ] ] ] [ [ [ |: | ] ] ]__ __[ [ [ |: | ] ] ] ]\\ _ /[ [ [ [ |: | ] ] ] ] (#) [ [ [ [ :====\u0026#39; ] ] ]_].nHn.[_[ [ [ ] ] ] HHHHH. [ [ [ ] ] / `HH(\u0026#34;N \\ [ [ ]__]/ HHH \u0026#34; \\[__[ ] NNN [ ] N/\u0026#34; [ ] N H [ / N \\ / q, \\ / \\ \u0026lt;/pre\u0026gt; 伪类选择器 doc = pq(html) li = doc(\u0026#34;li:first-child\u0026#34;) print(li.text()) li = doc(\u0026#34;li:last-child\u0026#34;) print(li.text()) li = doc(\u0026#34;li:nth-child(2)\u0026#34;) print(li.text()) li = doc(\u0026#34;li:nth-child(3n)\u0026#34;) print(li.text()) li = doc(\u0026#34;li:gt(3)\u0026#34;)#取第5个,即第4个以后,第四个下标为3 print(li.text()) li = doc(\u0026#34;li:contains(second)\u0026#34;)#搜索文本 print(li.text()) frist item\rfifth item\rsecond item\rthird item\rfifth item\rsecond item\r css选择器  ","permalink":"/zh-cn/posts/python/pyquerystudy/","series":["Pathon"],"tags":["爬虫","Pathon"],"title":"爬虫学习4"},{"categories":["读书笔记"],"content":"数组 线性表(每个线性表上的数据最多只有前和后两个方向):数组,链表,队列,栈 非线性表(数据之间并不是简单的前后关系):二叉树,堆,图\n数组:数组( Array )是一种线性表数据结构。它用一组连续的内存空间,来存储一组具有相同类型的数据。 数组的特点:连续的内存空间和相同类型的数据 优点:\n  随机访问:利用寻址公式对元素进行访问:\na[i]_address = base_address + i * data_type_size\n  数组的查找操作时间复杂度不是O(1),即便是排好的数组,用二分查找,时间复杂度也是O(logn);正确的说法\n数组支持随机访问,根据下标随机访问的时间复杂度为O(1)\n  缺点:\n  低效的插入和删除\n 插入:最好O(1),最坏O(n)  数组若无序,插入新的元素时,可以将第 K 个位置元素移动到数组末尾,把新的元素,插入到第 k 个位置,此处复杂度为O(1)\n删除:最好O(1),最坏O(n)  多次删除集中在一起,提高删除效率,记录下已经被删除的数据,每次的删除操作并不是搬移数据,只是记录数据已经被删除,当数组没有更多的存储空间时,再触发一次真正的删除操作。即 JVM 标记清除垃圾回收算法。\n  标记 - 清除算法\n标记 - 清除算法在垃圾收集时会先标记出需要回收的对象,标记完成后统一回收所有被标记的对象。清除之后会产生大量不连续的内存碎片。标记 - 整理垃圾回收算法在标记完成之后让所有存活的对象都向一端移动,然后直接清理掉边界以外的内存\n  访问越界\n数组越界在 C 语言中是一种未决行为,并没有规定数组访问越界时编译器应该如何处理。因为,访问数组的本质就是访问一段连续内存,只要数组通过偏移计算得到的内存地址是可用的,那么程序就可能不会报任何错误\n  容器能否完全替代数组(ArrayList,vector)\n  相比于数组, java 中的 ArrayList 封装了数组的很多细节(插入删除时数据的迁移工作),并支持动态扩容。一旦超过存储容量,扩容时比较耗时,因为涉及到内存申请和数据搬移。\n  Java ArrayList 无法存储基本类型,比如 int 、 long ,需要封装为 Integer 、 Long 类,而Autoboxing 、 Unboxing 则有一定的性能消耗,所以如果特别关注性能,或者希望使用基本类型,就可以选用数组。\n  如果数据大小事先已知,并且对数据的操作非常简单,用不到 ArrayList 提供的大部分方法,也可以直接使用数组。\n  当要表示多维数组时,用数组往往会更加直观。比如 Object[][]array ;而用容器的话则需要这样定义: ArrayList\u0026lt;ArrayList \u0026gt; array 。\n  总结:对于业务开发,直接使用容器就足够了,省时省力。毕竟损耗一丢丢性能,完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发,比如开发网络框架,性能的优化需要做到极致,这个时候数组就会优于容器,成为首选     为什么数组下标从0开始\n下标从内存来看,就是偏移量.如果用1开始计数.array[k]的内存地址为:a[k]_address = base_address + (k-1)*type_size;可以看出,多了一个减法运算,数组作为非常基础的数据结构,通过下标随机访问数组元素又是其非常基础的编程操作,效率的优化就要尽可能做到极致。所以为了减少一次减法操作,数组选择了从 0 开始号,而不是从 1开始。(python下标可以为任何整数)\n  ","permalink":"/zh-cn/posts/algorithm/%E6%95%B0%E7%BB%84/","series":["读书笔记"],"tags":["数据结构"],"title":"数组"},{"categories":["git"],"content":"Git 学习笔记 cd相对路径 cd 什么都不加 回到用户的家目录下 cd ~ 回到root目录下 cd .. 进入上一级目录\ncd - 返回上一次目录\ncd . 当前目录\n创建和删除目录 创建目录mkdir mkdir=make directory\nmkdir dirname 创建目录\nmkdir -p /etc/dirname/test/ 级联创建目录\nmkdir -pv /etc/dirname/test/ 加上v可以看到创建的过程\n删除目录rmdir rmdir=remove directory\nrmdir dirname 可 删除空目录（下面无目录和文件）\n删除文件 rm = remove命令 rmdir -p 可级联删除一串目录，但是是从最开始的目录删起。比较危险，慎用\nrm /tmp/ww/2/3/1.txt 会提示是否删除1.txt\nrm -f /tmp/ww/2/3/1.txt 强制删除，不给提示\nrm -r 级联删除目录，但是会提示是否删除，直接rm不能删目录\nrm -rf 直接级联强制删除\nrm -rfv 加上v显示删除过程\n更新仓库 //在github上创建项目  $ git clone https://github/xx账号/xx项目.git//克隆到本地  //编辑项目  $ git add .//(将改动添加到暂存区)  $ git commit –m”提交说明” //  $ git push origin master//将本地更改推送到远程master分支  实例：\ngit clone https://github.com/Euraxluo/-.git  //我更改了一个文件的名字  cd ./-//选中我的文件目录  git add *.py//选中我要更新的文件  git commit -m \u0026#34;rename\u0026#34;//提交说明  git push -u origin master//推送  //这时，由于我的项目地址是https,而不是git，要求更新  //我打算更改路径  如图\ngit push -u origin master//重新提交  最后成功结果如图\n注： 1.提交：\ngit add -A //提交所有变化  git add -u //提交被修改(modified)和被删除(deleted)文件，不包括新文件(new)  git add . //提交新文件(new)和被修改(modified)文件，不包括被删除(deleted)文件  2.删除：\n$ git rm 我的文件//删除文件  $ git rm -r 我的文件夹//删除文件夹  $ git rm -h//git rm [\u0026lt;选项\u0026gt;] [--] \u0026lt;文件\u0026gt;...  -n, --dry-run 演习 -q, --quiet 不列出删除的文件 --cached 只从索引区删除 -f, --force 忽略文件更新状态检查 -r 允许递归删除 --ignore-unmatch 即使没有匹配，也以零状态退出 创建仓库 $ makdir ~/hello-world //创建一个项目hello-world  $ cd~/hello-world //打开这个项目  $ git init //初始化  $ touch README $ git add README //更新README文件  $ git commit-m \u0026#39;first commit\u0026#39;//提交更新，并注释信息  $ git remote add origin git@.:.git//连接远程github项目  $ git push -u origin master //将本地项目更新到github项目上去  删除仓库 git branch//显示所有的本地分支  结果：* master ls -a//找到目录下的.git  结果：./ ../ .git rm -rf .git//删除操作  结果：.git 被删除，本地库删除成功 查看分支并切换 # 查看远程分支 git branch -a # 新建一个分支 git checkout -b \u0026lt;new branch name\u0026gt; # 查看本地分支 git branch # 分支切换 git checkout version 查看当前的远程库 #不带参数，列出已经存在的远程分支 git remote #列出详细信息，在每一个名字后面列出其远程url #此时， -v 选项(译注:此为 –verbose 的简写,取首字母),显示对应的克隆地址 git remote -v | --verbose 暂存修改 git stash 把不想提交的修改暂存起来\ngit stash apply 取回暂存修改\ngit 文件过大 在频繁增删改、commit之后，.git文件会出现过大的情况。这个时候如何彻底清理以前的历史版本（也就是说只保留当前版本，不可能再回滚了） 方法是首先建立一个分支，然后将master版本给删除，再将当前分支重命名为master，再强制push到远程仓库即可。 具体步骤：\n第一步： `git checkout --orphan latest_branch` 第二步：添加所有文件 `git add -A` 第三步：提交更改 `git commit -am \u0026#34;commit message\u0026#34;` 注意这里commit message是你提交的修改说明 第四步：删除分支 `git branch -D master` 第五步：将当前分支重命名 `git branch -m master` 最后：强制更新存储库 `git push -f origin master` 就此完成。 要注意尽量不要往git上提交二进制文件，二进制文件是不按diff保存的，即使提交了也不要每次改一点然后再提交一遍。\n一：常规办法 1.删除无用的分支\ngit branch -d \u0026lt;branch_name\u0026gt; 2.删除无用的tag\ngit tag -d \u0026lt;tag_name\u0026gt; 3.清理本地版本库\ngit gc --prune=now 二：高级办法 注意高级办法会导致push冲突，需要强制提交，其他人pull也会遇到冲突，建议重新克隆.\n1.完全重建版本库\nrm -rf .git\rgit init\rgit add .\rgit commit -m \u0026quot;first commit\u0026quot;\rgit remote add origin \u0026lt;your_github_repo_url\u0026gt;\rgit push -f -u origin master\r2.有选择性的合并历史提交\ngit rebase -i \u0026lt;first_commit\u0026gt; 会进入一个如下所示的文件\npick ba07c7d add bootstrap theme and format import\rpick 7d905b8 add newline at file last line\rpick 037313c fn up_first_char rename to caps\rpick 34e647e add fn of \u0026amp;\u0026amp; use for index.jsp\rpick 0175f03 rename common include\rpick 7f3f665 update group name \u0026amp;\u0026amp; update config\r将想合并的提交的pick改成s，如\npick ba07c7d add bootstrap theme and format import\rpick 7d905b8 add newline at file last line\rpick 037313c fn up_first_char rename to caps\rs 34e647e add fn of \u0026amp;\u0026amp; use for index.jsp\rpick 0175f03 rename common include\rpick 7f3f665 update group name \u0026amp;\u0026amp; update config\r这样第四个提交就会合并进入第三个提交。 等合并完提交之后再运行\ngit push -f\rgit gc --prune=now\r三.其他方法\n  dh -d 1 -h 查看哪个目录最大，确认是git目录\n  git rev-list --objects --all | grep \u0026quot;$(git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -5 | awk '{print$1}')\u0026quot; 查看占用空间最大的5个文件\n  重写commit，删除大文件git filter-branch --force --index-filter 'git rm -rf --cached --ignore-unmatch big-file.jar' --prune-empty --tag-name-filter cat -- --all big-file.jar 换成之前查询出来的大文件名\n  git push origin master --force以强制覆盖的方式推送repo\n  清理空间\nrm -rf .git/refs/original/\rgit reflog expire --expire=now --all\rgit gc --prune=now\r  合并分支 创建与合并分支 阅读: 10868325\n 在版本回退 里，你已经知道，每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。\n一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点：\n每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长。\n当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上：\n你看，Git创建一个分支很快，因为除了增加一个dev指针，改改HEAD的指向，工作区的文件都没有任何变化！\n不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变：\n假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并：\n所以Git合并分支也很快！就改改指针，工作区内容也不变！\n合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支：\n真是太神奇了，你看得出来有些提交是通过分支完成的吗？\n下面开始实战。\n首先，我们创建dev分支，然后切换到dev分支：\n$ git checkout -b dev\rSwitched to a new branch 'dev'\rgit checkout命令加上-b参数表示创建并切换，相当于以下两条命令：\n$ git branch dev\r$ git checkout dev\rSwitched to branch 'dev'\r然后，用git branch命令查看当前分支：\n$ git branch\r* dev\rmaster\rgit branch命令会列出所有分支，当前分支前面会标一个*号。\n然后，我们就可以在dev分支上正常提交，比如对readme.txt做个修改，加上一行：\nCreating a new branch is quick.\r然后提交：\n$ git add readme.txt $ git commit -m \u0026quot;branch test\u0026quot;\r[dev b17d20e] branch test\r1 file changed, 1 insertion(+)\r现在，dev分支的工作完成，我们就可以切换回master分支：\n$ git checkout master\rSwitched to branch 'master'\r切换回master分支后，再查看一个readme.txt文件，刚才添加的内容不见了！因为那个提交是在dev分支上，而master分支此刻的提交点并没有变：\n现在，我们把dev分支的工作成果合并到master分支上：\n$ git merge dev\rUpdating d46f35e..b17d20e\rFast-forward\rreadme.txt | 1 +\r1 file changed, 1 insertion(+)\rgit merge命令用于合并指定分支到当前分支。合并后，再查看readme.txt的内容，就可以看到，和dev分支的最新提交是完全一样的。\n注意到上面的Fast-forward信息，Git告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。\n当然，也不是每次合并都能Fast-forward，我们后面会讲其他方式的合并。\n合并完成后，就可以放心地删除dev分支了：\n$ git branch -d dev\rDeleted branch dev (was b17d20e).\r删除后，查看branch，就只剩下master分支了：\n$ git branch\r* master\r因为创建、合并和删除分支非常快，所以Git鼓励你使用分支完成某个任务，合并后再删掉分支，这和直接在master分支上工作效果是一样的，但过程更安全。\n合并分支相关小结 查看分支：git branch\n创建分支：git branch \u0026lt;name\u0026gt;\n切换分支：git checkout \u0026lt;name\u0026gt;\n创建+切换分支：git checkout -b \u0026lt;name\u0026gt;\n合并某分支到当前分支：git merge \u0026lt;name\u0026gt; 如果遇到报错$ git checkout dev\rwarning: refname 'dev' is ambiguous. 需要查看是否有同名指针: git show-ref --heads --tags 然后选择需要的指针合并\n删除分支：git branch -d \u0026lt;name\u0026gt;\n","permalink":"/zh-cn/posts/reading/git%E5%AD%A6%E4%B9%A0/","series":["git"],"tags":["git"],"title":"Git学习笔记"},{"categories":null,"content":"BIO (block io) 同步阻塞IO\n线程池:伪异步IO,实际上也是同步阻塞IO\nNIO(同步非阻塞)\nselector会主动轮询,与客户端建立通信(channel)\n每一个server会有一个selector\nAIO(异步非阻塞)\n当客户端通知我(回调),我再去连接\n单线程模式:所有的IO操作都由同一个NIO线程处理\n主线程组,从单线程模型\n主从线程组模型,具有一个主线程族和从线程组,主线程组去建立channel,从线程组会去进行处理\n","permalink":"/zh-cn/posts/note/bio-block-io-%E5%90%8C%E6%AD%A5%E9%98%BB%E5%A1%9Eio/","series":null,"tags":null,"title":""},{"categories":null,"content":"C++ 小记 CMAKE  工程构建工具  简单的使用  文件名大小写敏感 语法  cmake_minimum_required(VERSION 2.8)#设置cmake的版本 set(CMAKE_BUILD_TYPE Debug )#设置为debug模式 #项目名 PROJECT(HELLO)#设置某文件夹为头文件 include_directories(\u0026#34;include\u0026#34;)#设置一个头文件，把hello.cpp编译为libfile add_library(libfile src/hello.cpp)SET(SRC_LIST “fu nc.c”)#设置可执行二进制文件的输出路径和库的输出路径 SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin) SET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib)ADD_EXECUTABLE(hello main.c;func.c;$\\{RC_LIST\\}) target_link_libraries(hello libfile)#链接一个lib #设置编译的源文件在编译当前目录的bin下 ADD_SUBDIRECTORY (src bin)#修改为 SUBDIRS(src) 结果放在src中 #安装 DESTDIR= \tinstall: mkdir -p $(DESTDIR)/usr/bin \tinstall -m 755 hello $(DESTDIR)/usr/bin 更像一个工程 Hello\r- src\r- CMakeLists.txt\r- build #进去此目录进行外部编译 =》 cmake .. \u0026amp; make - CMakeLists.txt\rproject(hello)add_executable(hello hello.c)set(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin)set(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib)map和set 底层使用的是红黑树\n查找是使用二分搜索（红黑树保有顺序性）\n各种操作都是nlog\nunordered_map,unordered_set 底层都是哈希表\n不保有顺序性，但是查找操作是O1\n","permalink":"/zh-cn/posts/note/c++-%E5%B0%8F%E8%AE%B0/","series":null,"tags":null,"title":""},{"categories":null,"content":"stream 编程\nimport java.util.function.Consumer; import java.util.stream.Collectors; import java.util.stream.IntStream; import java.util.stream.Stream; Consumer\u0026lt;String\u0026gt; P = System.out::println;//消费者 // P.andThen(P.andThen(P)).accept(2);  /** * 流的创建 */ List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); //从集合创建流  list.stream(); list.parallelStream(); //从数组创建  Arrays.stream(new int[]{2,3,5}); // P.accept(Arrays.stream(new int[]{2,3,5}).map(x-\u0026gt;x+1).sum());  //创建数字流  IntStream.of(1,2,3); IntStream.rangeClosed(1,10); //从random创建一个无限流  new Random().ints().limit(10); //自己产生流  Stream.generate(()-\u0026gt;new Random().nextInt()).limit(20); // P.accept(Stream.generate(()-\u0026gt;new Random().nextInt()).limit(20).findAny().toString());  /** * 中间操作 */ //filter操作  Stream.of(msg.split(\u0026#34; \u0026#34;)).filter(s-\u0026gt;s.length()\u0026gt;1).forEach(P); //flatMap :将流中的属性提取出来作为流  //这里需要装箱,s.chars()返回IntStream,不是Stream的子类  Stream.of(msg.split(\u0026#34; \u0026#34;)).flatMap(s-\u0026gt;s.chars().boxed()).forEach(i-\u0026gt;System.out.println((char)i.intValue())); //limit  new Random().ints().filter(x-\u0026gt;x\u0026gt;10\u0026amp;\u0026amp;x\u0026lt;1000).limit(10).forEach(System.out::println); //peek,用于debug  Stream.of(msg.split(\u0026#34; \u0026#34;)).peek(System.out::println).forEach(P); /** * 终止操作 */ P.accept(\u0026#34;----终止操作----\u0026#34;); //foreach Order 用于在并行流中排序  Stream.of(msg.split(\u0026#34; \u0026#34;)).parallel().forEach(P); Stream.of(msg.split(\u0026#34; \u0026#34;)).parallel().forEachOrdered(P); //收集器  List\u0026lt;String\u0026gt; slist = Stream.of(msg.split(\u0026#34; \u0026#34;)).collect(Collectors.toList()); System.out.println(slist); //reduce 有个初始值 .orElse(\u0026#34;\u0026#34;):空判断  String s = Stream.of(msg.split(\u0026#34; \u0026#34;)).reduce(\u0026#34;\u0026#34;,(s1,s2)-\u0026gt;s1+\u0026#34;|\u0026#34;+s2); // 计算所有单词总长度  Integer reduce = Stream.of(msg.split(\u0026#34; \u0026#34;)).map(x -\u0026gt; x.length()).reduce(0, (x1, x2) -\u0026gt; x1 + x2); P.accept(s); P.accept(reduce.toString()); //max  Optional\u0026lt;String\u0026gt; max = Stream.of(msg.split(\u0026#34; \u0026#34;)).max((x1, x2) -\u0026gt; x1.length() - x2.length()); P.accept(max.get()); 异步Servlet 异步是针对后端来说,这样可以让我们后端提高吞吐量\n@WebServlet(asyncSupported = true,urlPatterns = {\u0026#34;/AsyncServlet\u0026#34;}) public class AsyncServlet extends HttpServlet{ protected void doGet(HttpServletRequest req,HttpServletResponse res){ //开启异步  AsyncContext asyncCtx = req.startAAsync(); //使用线程  CompletableFuture.runAsync(()-\u0026gt;doing(asyncCtx,asyncCtx.getRequest(),asyncCtx.getResponse()); } private void doing(AsyncContext asyncCtx,HttpServletRequest req,HttpServletResponse res){ //异步线程中会进行一些耗时操作  TimeUmtil.SECONDS.sleep(5); res.getWriter().append(\u0026#34;done\u0026#34;); //业务处理完毕,通知线程结束  asyncCtx.complete(); } } reactor = jdk8 stream + jdk9 reactor stream @RestController\r@Slf4j\rpublic class TestController {\r@GetMapping(\u0026quot;/1\u0026quot;)\rprivate String get1(){\rlog.info(\u0026quot;get1 start\u0026quot;);\rString res = createStr();\rlog.info(\u0026quot;get1 end\u0026quot;);\rreturn \u0026quot;getMapping\u0026quot;;\r}\rprivate String createStr() {\r//睡5秒\rtry {\rTimeUnit.SECONDS.sleep(5);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\rreturn \u0026quot;createStr\u0026quot;;\r}\r@GetMapping(\u0026quot;/2\u0026quot;)\rprivate Mono\u0026lt;String\u0026gt; get2(){\rlog.info(\u0026quot;get2 start\u0026quot;);\rMono\u0026lt;String\u0026gt; res = Mono.fromSupplier(()-\u0026gt;createStr());\rlog.info(\u0026quot;get2 end\u0026quot;);\rreturn res;\r}\r}\r","permalink":"/zh-cn/posts/note/consumerstring-p-system.outprintln%E6%B6%88%E8%B4%B9%E8%80%85/","series":null,"tags":null,"title":""},{"categories":null,"content":"C语言小计 Unix C   内核-》系统调用-》shell/共用函数库-》应用程序\n  系统调用和库函数\n  库函数会调用系统调用来实现自己的算法\n  公用函数库构建在系统调用之上，应用程序既可以使公用函数库，也可以使用系统调用\n    口令文件：/etc/passwd 字段结构：\n登录名：加密口令：UID：GID：注释字段：起始目录：sell\n  文件系统：\n /是root目录 /和空字符不能出现在文件名字中，斜线用来分隔开构成路径名的各文件名，空字符用来终止一个路径名 工作目录：每个进程都有一个工作目录，所有的相对路径名都从工作目录开始解释，进程可以使用chdir()更改工作目录,以/开始的路径名是绝对路径名 登陆时工作目录设置为起始目录，从口令文件中取得    输入输出\n 不带缓冲区的io：open,read,write,lseek,close stdout \u0026gt; file可以把标准输出或者符号左边的字符重定向到文件    进程\n  每个进程都有一个pid，pid_t保证可以用long保存\n  进程控制：fork,waitpid,exec(exec函数有很多变体)\n  signal，用于通知进程发生了某种情况；进程会：\n  忽略信号\n  按系统默认方式处理\n  提供一个函数，信号捕捉（类似错误处理？）\n      时间值\n 用户cpu时间：执行用户指令所用的时间 系统cpu时间：该进程执行内核程序经历的时间 时钟时间：进程运行的时间总量 CPU时间 = time_t + clock_t 问题：若日历时间放在带符号的32位int中，哪一年会溢出？怎么扩展    文件IO（不带缓冲的IO）   不带缓冲：指的是每个read和write都调用系统调用，这些函数不是ISO C的组成部分\n  幻数：没来由的，不利于维护的数字，最好define\n define STDIN_FILENO 0 define STDOUT_FILENO 1 define STDERR_FILENO 3    open(path，oflag),oflag常量很多，说明了文件的打开描述\n  openat(path，oflag),oflag常量很多，说明了文件的打开描述\n  creat(path,mode)mode指示文件访问权限\n  close(int fd)关闭一个文件的同时还会释放该进程加在这个文件上的所有记录锁\n  off_t/-1 = lseek(int fd,off_t offset,int whence)偏移量设置函数\n whence == SEEK_SET,off_t = begin()+offset,文首绝对偏移量 whence == SEEK_CUR,off_t = off_t + offset,相对当前位置偏移 whence == SEEK_END,off_t = end() + offset,文尾相对位置偏移    od -c file查看文件的实际内容,-c以字符方式\n  ssize_t read(int fd,void *buf,size_t nbytes)从文件中中读取数据，void *通用指针\n  shell提供一种方法，从标准输入上打开一个文件用于读，在标准输出上创建/重写一个文件。因此很多程序可以不必打开输出和输入文件\n  预读技术：检测到正在顺序读取时，系统试图读入比应用所要求的更多数据\n  ioctl(int fd,int request,...):io杂物箱\n很多的设备的驱动程序可以自定义自己的一组ioctl\n  /dev/fd\n这个目录的目录项时0,1,2，这些等效于/dev/stdin,/dev/stdout,/dev/stderr，打开/dev/fd/n等效于复制描述符\n  文件共享 数据结构   记录表：每个进程在进程表中都有一个记录项，记录项中包含一个文件描述符\na. 文件描述标志（close_no_exec）\nb. 指向一个文件表项的指针\n  内核为所有的打开文件都维持一张文件表\na. 文件状态标志（r,w,a,async）\nb. 当前文件偏移量\nc. 指向该文件v节点的指针\n  每个打开文件或设备都有一个v节点结构\n  原子操作   追加，在打开文件时设置O_APPEND标志，使得内核在每次写操作之前，都会将文件的当前偏移量设置到文件尾端处\n  pwrite()/pread(int fd,void *buf,size_t nbytes,off_t offset)相当于调用lseek后调用read\n 调用pread时，无法中断其定位和读操作 不更新当前文件的偏移量    dup()/dup2(int fd,int fd2)复制文件描述符，相当于调用了close(fd2),fcntl(fd,F_DUPFD,fd2)\n  延迟写：数据-》缓冲区-》queue-》disk 为了保证实际文件系统与缓冲区中内容的一致性，Unix系统提供了sync，fsync，fdatasync\n fsync(int fd):只对fd起作用，并且会更新文件的属性，并且等待写操作结束才返回 fdatasync(int fd)：和fsync类似，但是只影响文件的数据部分，不更新文件的数据部分 void sync(void)：将修改过的快缓冲区排入写队列，马上返回，并不等待实际写磁盘操作结束  fchtl(int fd,int cmd)  复制一个已有的文件描述符 获取/设置文件描述符标志 获取/设置文件状态标志 获取/设置异步IO所有权 获取/设置记录锁  文件中的空洞 普通文件会包含空洞，是由于所设置的偏移量超过了文件的尾端，并写入了某些数据后造成的\n ls -l file:可以查看文件的大小  文件和目录 stat函数   stat(pathname,buf):返回与此命名文件有关的信息结构\n  fstat(fd,buf)：获得已在描述符fd上打开文件的信息结构\n  lstat(pathname,buf)：当命名文件是一个是一个符号链接时，返回链接文件的有关信息，而不是由该符号链接引用的文件的信息\n  fstatat(fd,pathname,buf,flag)为一个相对于当前打开目录(fd指示)的路径名返回文件统计信息\n  文件类型：stat结构的st_mode  普通文件：普通文件内容的解释是由处理该文件的应用程序进行  二进制可执行文件除外，遵循一种标准化的格式   目录文件：包含了其他文件的名字以及指向这些文件信息的指针  对一目录文件具有读权限的任一进程都可以读该目录的内容 只有内核可以直接写目录文件 进程只有通过特定的函数才能更改目录   块特殊文件（block）：提供对设备带缓冲的，每次访问以固定长度为单位进行 字符特殊文件（character）;提供对设备不带缓冲的访问  系统中的设备要么是字符特殊文件，要么是块特殊文件   FIFO:用于进程之间的通信，也叫管道 套接字：用于进程间的网络通信 符号链接:指向另一个文件 消息队列：进程间通信对象(IPC) 信号量:进程间通信对象(IPC) 共享存储对象:进程间通信对象(IPC)  用户id和组id    实际用户ID实际组ID 我们实际上是谁     有效组ID有效组ID附属组ID 用于文件访问权限的检查   保存的设置用户ID保存的设置组ID 由exec函数保存    每个文件都有一个所有者和组所有者，所有者由stat结构中的st_uid指定，组所有者则由st_gid指定\n文件的访问权限  为了在一个目录中创建一个新文件，必须对改目录具有写权限和执行权限 为了在open()函数中对一个文件指定O_TRUNC标志，必须对该文件具有写权限 为了删除以恶搞现有的文件，必须对包含该文件的目录具有写权限和执行权限，对该文件本身不需要读和写权限 如果用7个exec函数中的任意一个执行某个文件，都必须对该文件具有执行权限，该文件还必须是一个普通文件 在使用open和creat创建一个文件时，新文件的用户ID设置为进程的有效用户ID  权限测试 当open函数打开一个文件时，内核以进程的有效ID和有效组ID为基础执行其访问权限测试。\n  access(pathname,mode)\n  faccessat(fd,pathname,mode,flag),计算相对于打开目录(fd指示)的pathname\nmode: R_OK,W_OK,X_OK\n  权限  umask(mode_t cmask)  000 任何用户可以读文件 002 阻止其他用户写入文件 027 阻止同组成员写入你的文件，以及其他用户的rwx权限   chmod(pathname,mode)更改指定文件的权限 fchmod(fd,mode)针对打开的文件进行操作 fchmodat(fd,pathname,made,flag)，fd为AT_FDCWD时和chmod一致，flag改变fchmodat的行为 chmod函数更新的是i节点最近一次被更改的时间，ls -l 列出来的是文件最后被修改的时间 fchown,fchownat,lchown,chown(pathname,owner,group)可用于更改文件的用户ID和组ID  文件和目录处理  truncate/ftruncate(fd,off_t length);截断函数，将一个现有的文件长度截断为length，如果之前该文件以前的长度大于length，则langth、以外的数据就不能再访问。如果以前的长度小于length，文件长度将增加。 link/linkat(efd,existingpath,nfd,*newpath,flag),创建newpath，引用existingpath，如果newpath已经存在，则返回出错。 renameat/rename(oldname,newname);如果oldname是指文件，为此文件重命名。link文件的话，重命名此文件，不是链接的文件 futimens,utimes,utimensat(fd,path,times,flag)修改一个文件的访问和修改时间 mkdirat，mkdir(fd,pathname,mode):这两个函数创建一个新的空目录，所指定的文件的访问权限mode由进程的文件模式创建屏蔽字修改 rmdir(const char*pathname)删除一个空目录，空目录是只包含.和..两项的目录 对某目录具有访问权限的任意用户都可以读该目录，但是，为了防止文件系统产生混乱，只有内核才能写目录。一个目录的的写权限位和执行权限决定了在该目录能否创建新文件以及删除文件，但是不代表可以写目录 DIR *fdopendir(int fd)表示可以把打开文件描述符转换成目录处理函数需要的DIR结构  标准I/O库   标准输入流，标准输出流，标准错误流。一个进程预定义了3个流，并且可以自动的被进程所使用\n  缓冲\n  全缓冲：填满标准I/O缓冲区后才进行实际I/O操作，一般用于驻留在磁盘上的文件\n在一个流上第一次执行I/O操作时，I/O函数通常调用malloc函数获得需要的缓冲区\nflush:冲洗，标准I/O缓冲区的写操作，当填满一个缓冲区时，I/O例程会自动的冲洗\n  行缓冲：当在输入和输出中遇到换行符时，标准I/O执行I/O操作，当流涉及一个终端时，通常使用行缓冲\n限制:缓冲区的长度固定的，所以有时没有遇到换行符，也会进行I/O操作\n  不带缓冲：标准错误流通常不带缓冲，使得他们的错误可以尽快显示出来\n    setbuf(fp,buf)打开或或关闭缓冲机制，开启后一般为全缓冲\n  setvbuf(fp,buf,mode,size)通过设置mode精确的说明所需的缓冲类型\n  fflush(fp)，强制冲洗一个流\n  FILE *fopen(pathname,type,)打开路径名为pathname的一个文件\n  FILE *freopen(pathname,type,fp)重定向流，在一个指定的流上打开文件，若流已经打开，则先关闭\n  fdopen(fd,type)获取一个已有的文件描述符，并使一个标准I/O流与该描述符相结合，此函数常用于由管道创建和网络通信函数返回的描述符\n  当以读和写类型打开一个文件时，如果中间没有fflush，fseek，fsetpos或rewind，那么在输出的后面不能直接跟随输入\n  以读和写打开一个文件时，当中间没有fseek,fsetpos,rewind,或者一个输入操作没有到达文件尾端，则在输入操作之后不能直接跟随输出\n  读和写流\n 每次一个字符的I/O，getc,fgetc,getchar一次读或者写一个字符，如果流是带缓冲的，则标准I/O函数处理所有的缓冲 每次一行的I/O，fgets,fputs,每行以一个换行符终止，当调用fgets时，应说明能处理的最大行 direct I/O，fread,fwrite每次I/O操作读或写某种数量的对象，每个对象具有指定的长度，常用于读写二进制文件 压送回流，ungetc(int c,FILE fp),压送回流的字符又可以    ","permalink":"/zh-cn/posts/note/c%E8%AF%AD%E8%A8%80%E5%B0%8F%E8%AE%A1/","series":null,"tags":null,"title":""},{"categories":null,"content":"go 语言\n1.go程序是使用packag来进行组织的，只有package中名为main的包可以包含main函数\n2.一个可执行程序有且仅有一个main包\n3.同通过import关键字导入其他非main包\n4.通过const关键字进行常量的定义\n5.在函数体外部使用var关键字进行全局变量的申明与赋值\n6.通过type关键字进行struct或者interface的申明\n7.通过func关键字进行函数的申明\n8.函数名(常量，变量，类型，接口，结构)首字母小写即为private，大写即为public\n","permalink":"/zh-cn/posts/note/go-%E8%AF%AD%E8%A8%80/","series":null,"tags":null,"title":""},{"categories":null,"content":"java跨平台 实现java跨平台只需要在相应的平台安装对应的虚拟机，我们就可以使用统一的接口进行开发。\njava通过不同的系统，不同的版本，不同的位数，来屏蔽不同的系统指令集的差异，对外提供统一的接口\njava中int数据占几个字节   java中有几种基本数据类型？8种\n基本类型：byte 二进制位数：8 包装类：java.lang.Byte 最小值：Byte.MIN_VALUE=-128 最大值：Byte.MAX_VALUE=127 基本类型：short 二进制位数：16 包装类：java.lang.Short 最小值：Short.MIN_VALUE=-32768 最大值：Short.MAX_VALUE=32767 基本类型：int 二进制位数：32 包装类：java.lang.Integer 最小值：Integer.MIN_VALUE=-2147483648 最大值：Integer.MAX_VALUE=2147483647 基本类型：long 二进制位数：64 包装类：java.lang.Long 最小值：Long.MIN_VALUE=-9223372036854775808 最大值：Long.MAX_VALUE=9223372036854775807 基本类型：float 二进制位数：32 包装类：java.lang.Float 最小值：Float.MIN_VALUE=1.4E-45 最大值：Float.MAX_VALUE=3.4028235E38 基本类型：double 二进制位数：64 包装类：java.lang.Double 最小值：Double.MIN_VALUE=4.9E-324 最大值：Double.MAX_VALUE=1.7976931348623157E308 基本类型：char 二进制位数：16 包装类：java.lang.Character 最小值：Character.MIN_VALUE=0 最大值：Character.MAX_VALUE=65535 面向对象的特征 封装 将对象封装成一个高度自洽相对封闭的个体，对象状态(属性)由这个对象自己的行为(方法)来读取和改变\n抽象 抽象就是找出一些事物的相似和共性之处，然后把他们抽象为类\n继承 把这个已经存在的类所定义的内容作为自己的内容，并可以加入若干新的内容，或修改原来的方法使之更适合特殊的需要\n多态 指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用只有在程序运行时才确定\n  ","permalink":"/zh-cn/posts/note/java%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/","series":null,"tags":null,"title":""},{"categories":null,"content":"Make My LIsp NAME lispluo 一个用 Python 实现的 Lisp 解释器 根据教程项目 https://github.com/kanaka/mal 进行实现及测试。 教程中文翻译 https://github.com/Windfarer/mal-zh\n1. 准备 1） 选择的python编写解释器 2） fork，克隆项目，修改配置 IMPLS = ... lispluo ...\r...\rlispluo_STEP_TO_PROG = lispluo/$($(1)).luo\r3) 写入run脚本： #!/bin/bash\rexec pyhton3 $(dirname $0)/${STEP:-stepA_mal}.luo \u0026quot;${@}\u0026quot; #使用pyhton3来构建新语言的编译器\r步骤 0: The REPL 读取求值打印循环(Read-Eval-Print Loop) step0_repl\n这个步骤基本上仅创建了你解释器的框架。\n在 quux/ 目录下创建 step0_repl.qx 文件。 添加 4 个函数 READ,EVAL,PRINT 以及 rep(read-eval-print)。READ,EVAL 和 PRINT 基本上是个假的实现，它只是返回它们的第一个参数（如果你的目标语言是静态类型的话，是一个字符串），rep 按顺序调用它们，将前一个的返回值传递给下一个。 添加一个主循环，让它循环打印提示符(提示符必须是\u0026quot;user\u0026gt; \u0026ldquo;才能通过测试)，读取一行用户输入，对于那一行输出调用rep函数，然后将结果打印出来。当你发送EOF的时候(通常是按 Ctrl-D)，它应该退出。 如果你使用一个编译型语言（静态编译「ahead-of-time」，而不是即时编译「just-in-time」），那么在你的目录下创建一个 Makefile（或者适当的项目定义文件）。 现在是时候运行你的第一部分测试了。它们将检查你的程序的输入和事实是否可以被测试所捕获。在目录顶层运行如下命令：\nmake \u0026ldquo;test^quux^step0\u0026rdquo; 将 step0_repl.qx 和 Makefile 添加并提交到 git 仓库中。\n恭喜你！你已经完成了 make-a-lisp 的第一个步骤。\n可选的任务： 为你的解释器的 REPL 增加整行编辑和命令历史功能。许多语言已经提供了支持行编辑的库/模块。另外一个选项是，如果你用的语言支持用 FFI (foreign function interface 外来函数接口)来直接加载调用 GNU readline, editline 或 linenoise 库。将行编辑接口代码写在 readline.qx 文件中。\n步骤 1: Read and Print 读取和打印 step1_read_print\n这个步骤中，你需要让你的解释器 “读取”(read) 用户输入的字符串，并把它解析为一种内部的树形数据结构（AST，抽象语法树），然后将这个数据结构 “打印”(print) 成字符串。\n在非 Lisp 类语言中，这个步骤（叫作“词法分析和语法分析”）将会是编译器/解释器中最复杂的部分之一。而在 Lisp 中，你想要的这种数据的结构与程序员写的代码的结构基本上是一致的（Homoiconicity，同像性）。\n举个例子，如果字符串是 \u0026ldquo;(+ 2 (* 3 4))\u0026rdquo; 那么读取 (read) 函数将把它解析为这样的树形结构：\n List\r/ | \\\r/ | \\\r/ | \\\r Sym:+ Int:2 List / | / | / | Sym:* Int:3 Int:4 每个左括号和与它匹配的右括号 (在 lisp 中叫 S-表达式\u0026quot;sexpr\u0026rdquo;) 成为树中的一个节点，而其他的一切都成为了树中的叶子节点。\n如果你能找到一份你目标语言的 JSON encoder/decoder 的实现代码，那么你就可以通过借鉴和修改它来搞定本步骤中 75% 的任务。\n这一节余下的部分假设你没有从 JSON encoder/decoder 起步，而是使用了一个 Perl 兼容的正则表达式 (PCRE) 库/模块。的确，你可以采用简单的字符串操作来实现这个功能，但那样更复杂。make 和 ps(postscript) 和 Haskell 的实现中有一些不使用正则表达式实现 reader 的例子。\n复制 step0_repl.qx 并重命名为 step1_read_print.qx。 新建一个 reader.qx 文件来保存与 reader 有关的函数。 如果你的目标语言有面向对象 (OOP) 的特性，那么下一步是在 reader.qx 中创建一个简单的有状态的 Reader 对象。这个对象用来保存 tokens 和 position。Reader 对象需要有两个方法：next 和 peek。next 返回当前位置 (position) 的 token，并且增大 position。而 peek 只是返回当前位置的 token。 在 reader.qx 中增加一个 read_str 函数。这个函数需要调用 tokenize 获得 token 列表，然后使用这些 token 来创建一个新的 Reader 实例。然后它调用 read_form 来处理这个 Reader 实例。 在 reader.qx 中增加一个 tokenize 函数。这个函数接受一个字符串参数，并且将返回一个数组 / 列表，里面包含了所有的 token(或者叫字符串，string）。下面的正则表达式 (PCRE) 能够匹配所有的 mal 的 token。 [\\s,](~@|[[]{}()'~^@]|\u0026quot;(?:\\\\.|[^\\\\\u0026quot;])*\u0026quot;?|;.*|[^\\s\\[\\]{}('\u0026quot;,;)]) 在括号中，每一个被下列六种正则表达式匹配到的字符串，将创建出一个新的 token\n[\\s,]*: 匹配任意个数的空格或逗号。它不是捕获对象，因此它会被忽略掉，不会标记化(not tokenized)\n~@: 捕获两个特殊字符的组合 ~@，会被标记化(tokenized)\n[[]{}()'~^@]: 捕获 []{}()'~^@ 这些字符中任意一个，会被标记化(tokenized)\n\u0026ldquo;(?:\\.|[^\\\u0026quot;])*\u0026rdquo;?: 捕获由双引号开头，并到下一个双引号结束之间的内容，如果中间出现双引号，且双引号前面有反斜杠，则将它们也包括在捕获的内容中，直到下一个双引号。会被标记化(tokenized)。也会匹配缺少第二个双引号的字符串，这种情况下解释器应该报错。\n;.*: 捕获由分号 ; 开头的任意序列，会被标记化(tokenized)\n[^\\s[]{}('\u0026quot;`,;)]*: 捕获一系列由零个或更多个非特殊字符组成的序列(如，symbol, 数字,\u0026ldquo;true\u0026rdquo;,\u0026ldquo;false\u0026quot;以及\u0026quot;nil\u0026rdquo;)\n在 reader.qx 文件中增加一个 read_form 函数，这个函数要读取(peek) Reader 对象的第一个 token，然后对 token 的第一个字符做条件判断。如果第一个字符是左括号，则使用 read_list 函数处理这个 Reader 对象。否则使用 read_atom 函数处理 Reader 对象。read_form 的返回值是一个 mal 数据类型。如果你的目标语言是静态类型语言，那么你要想办法让 read_form 函数能够返回出不同的类型或者子类型。举例来说，如果你用的是一门面向对象的语言，那么你可以在最顶层中定义 MalType(在 types.qx 中)，随后你的其他 mal 数据结构就可以继承它了。 MalList 类型（也是继承自 MalType）将由一个包含其他 MalType 对象的数组/列表构成。如果你用的语言是动态类型的，那么只需要返回一个包含其他 MalType 对象的数组/列表即可\n在 reader.qx 中新增一个 read_list 函数。这个函数将对 Reader 对象反复调用 read_form 函数，直到遇到个 \u0026lsquo;)\u0026rsquo; 字符(如果在')' 之前遇到了 EOF，那就说明出错了)。它把调用结果收集到一个 List 类型中。如果你的语言中不存在能够存储多个 mal 数据类型的值的顺序数据类型，那么你需要自己实现一个（在 types.qx 中实现）。注意 read_list 函数反复调用的是 read_form，而不是 read_atom 函数。这种在 read_list 与 read_form 之间的递归定义可以能够让列表中包含列表。\n在 reader.qx 中新增一个 read_atom 函数。函数将会解析 token 的内容，并返回合适的纯（简单，非复合的）数据类型。最开始，你可以只实现数字类型（整型 integer）和 symbol。这能使你继续后面的一些步骤，在随后再继续实现其他的一些类型: nil, true, false 和 string。这些保留的 mal 类型: 关键字(keyword), 向量(vector), 哈希表(hash-map) 和 原子(atom) 在步骤 9 之前都不需要实现（但可以在本步骤到步骤 9 之间的任意时间点实现）。还有，符号(symbol) 类型只是一个由单独的字符串名字构成的对象（有些语言已经有 symbol 类型了）。\n创建一个名为 printer.qx 的文件。这个文件包含一个叫 pr_str 的函数，它的功能与 read_str 正好相反：输入一个 mal 数据结构，返回出它的字符串形式。但是 pr_str 的功能很简单，它只是对于输入对象的一个 switch 条件语句：\nsymbol: 返回 symbol 的字符串名字 number: 将数字作为一个字符串返回 list: 对于列表中的每一个元素调用 pr_str，然后将结果使用空格分隔，把它们拼接在一起，最后在最外面加上括号 修改 step1_read_print.qx 中的 READ 函数，让它调用 reader.read_str，并且 PRINT 函数调用 printer.pr_str。EVAL 函数继续直接返回输入的东西，但是如今返回值的类型应当是 mal 数据类型了。\n现在你已经实现了足够多的东西，可以开始测试你的代码了。你可以手工测试一些简单的输入：\n123 -\u0026gt; 123 123 -\u0026gt; 123 abc -\u0026gt; abc abc -\u0026gt; abc (123 456) -\u0026gt; (123 456) (123 456 789) -\u0026gt; (123 456 789) (+ 2 (* 3 4) ) -\u0026gt; (+ 2 (* 3 4)) 为了验证你的代码不只是去掉了多余的空格（并且没有失败），你可以 instrument 你的 reader.qx 中的函数。\n当你已经通过了上述的简单手工测试，就可以运行步骤 1 的测试了。到最顶层的目录，执行下面的命令：\nmake \u0026ldquo;test^quux^step1\u0026rdquo; 修复所有与 symbol, number 和 list 有关的失败测试。\n你现在已经完成了最困难的步骤之一。从这儿开始就是下山的路了，剩下的步骤可能更简单，并且每个步骤会逐渐让你有更多的收获。\n可推迟的任务: 为你的 reader 和 printer 函数增加其他的基础类型的支持: string, nil, true, 和 false. 这些类型在步骤 4 的时候就是必需的了。在读取一个字符串之后，要进行下列的转换：一个反斜杠后面跟着双引号的时候 \u0026quot;，需要把它们翻译为一个普通的双引号 \u0026ldquo;，反斜杠后跟着 n 的时候 \\n 需要翻译为换行，一个反斜杠后面跟着另一个双引号的时候 \\，需要把它们翻译为一个单引号 \\。为了能正确的打印字符串（为了步骤 4 中的字符串函数），pr_str 函数需要另一个叫作 print_readably 的参数。当这个参数为 true 的时候，双引号、换行符和反斜杠会被翻译为它们被打印出来的表现形式（与 reader 的逻辑正好相反）。主程序中的 PRINT 函数应该在调用 pr_str 时将 print_readably 设置为 true。 为 reader 函数增加更多的错误检查，确保括号都能够正确匹配。在主循环中捕获并打印这些错误信息。如果你的语言中没有 try/catch 风格的冒泡式异常处理功能，那么你需要在代码中加上一个显式的异常处理，并且跳过错误，不要让程序崩溃掉。 为 reader 加上宏 (macros) 支持。这能够在读取阶段时将某些形式转换为其他形式。在 tests/step1_read_print.mal 中可以找到需要支持哪种宏的形式（它们只是对 token 流的简单转换） 支持其他几种 mal 数据类型: keyword, vector, hash-map. 关键字 (keyword): keyword 是由冒号开头的 token。keyword 只能存储为有特殊 unicode 前缀的字符串，像 0x29E (或字符 0xff/127, 如果目标语言没有很好的 unicode 支持的话) printer 会把带这个前缀的字符串转换回关键字表示。这能够让在大多数语言中使用关键字作为哈希表的键变得很容易。你也可以将关键字存储为一种唯一数据类型，但你要确定它们可以作为哈希表的键使用（这可能需要一种类似的前缀）。 向量 (vector): 向量可以使用与列表相同的底层类型实现，只要有一种能够记录它们之间区别的机制就行。你可以通过在开头和结尾的 token 上加上参数，从而做到使用同一个 reader 函数操作列表和向量的功能。 哈希表 (hash-map): 哈希表是一种关系型数据结构，它将字符串映射到其他 mal 类型的值上。如果你将关键字实现为带前缀的的字符串，那么你只需要一种原生的关系数据结构，只要它支持以字符串作为键就可以了。Clojure 支持把任何值作为哈希表的键，但在 mal 的基础功能中只需要支持把字符串作为键即可。因为将哈希表表示为键和值的交替序列，你可能可以用读取列表和向量的 reader 函数来处理哈希表，只需要用参数来标示它的开头和结尾 token 即可。奇数位置的 token 作为键，而偶数位置的 token 作为值。 为你的 reader 增加对注释的支持。tokenizer 应该忽略由 \u0026ldquo;;\u0026rdquo; 开头的 token。你的 reader_str 函数需要正确的处理 tokenizer 不返回任何值的情况。最简单的办法是返回 nil 这个 mal 类型的值。一个更加简明的（在这种情况下不打印 nil）方式是抛出一个特殊的异常，使主循环直接在循环的开头跳过循环，从而不调用 rep。\n步骤 2: Eval 求值 step2_eval\n在步骤 1 中，你的 mal 解释器基本上只有验证输入然后去除输出结果中多余空格的功能。在本步骤中，你将会为你的解释器增加 evaluator (EVAL) 的功能，从而把它改成一个简单的计算器。\n比较步骤 1 和步骤 2 的伪代码，可以对本步骤中将要做的修改有简要的了解：\ndiff -urp ../process/step1_read_print.txt ../process/step2_eval.txt 将 step1_read_print.qx 复制为 step2_eval.qx 定义一个简单的初始化 REPL 环境。这个环境是一个关联数据结构，将符号 (或符号名 symbol names) 映射为数学运算函数。例如，在 python 中，这个环境应该看起来是这个样子的： repl_env = {'+': lambda a,b: a+b, \u0026lsquo;-': lambda a,b: a-b, \u0026lsquo;': lambda a,b: ab, \u0026lsquo;/': lambda a,b: int(a/b)} 修改 rep 函数，将这个 REPL 环境作为调用 EVAL 函数时的第二个参数。 创建一个新函数 eval_ast，它将接受 ast(mal 数据类型)和一个关系数据结构（上文中的环境）。eval_ast 函数对 ast 的类型进行下列匹配，并做出相应处理： symbol: 在环境结构中查找符号，返回对应的值，或在值不存在时报错 list: 返回对于列表中的每个元素 EVAL 调用得到的结果所组成的列表 否则直接返回原 ast 值 修改 EVAL 函数，检查它的第一个参数 ast 是不是一个列表。 ast 不是列表: 返回对它调用 eval_ast 得到的结果 ast 是一个空的列表: 原封不动地返回 ast ast 是一个列表: 对它调用 eval_ast 得到一个新的求值后的列表。取求值结果列表的第一项，将它作为函数调用，以求值结果列表的余下项作为参数传入，返回求值的结果。 如果你的目标语言不支持可变长度参数（例如，variadic, vararg, splats, apply），那么你需要将整个参数的列表作为一个单独的参数，然后在每个 mal 函数中再将它切分为一个个独立的值。这样做虽然比较闹心，但还是可以凑合用的。\n调用或执行一个列表并返回某些新的东西，这样的过程在 Lisp 中被称为 \u0026ldquo;apply\u0026rdquo;(应用) 步骤。\n用这些表达式来进行测试：\n(+ 2 3) -\u0026gt; 5 (+ 2 (* 3 4)) -\u0026gt; 14 你最可能遇到的挑战是，如何正确地以一个参数列表作为参数调用函数引用。\n现在，回到顶层目录，执行步骤 2 的测试，并修复错误。\nmake \u0026ldquo;test^quux^step2\u0026rdquo; 现在你拥有了一个简单的前缀表达式计算器。\n可推迟的任务： eval_ast 应该对向量和哈希表中的元素进行求值。在 eval_ast 函数中加入下列条件判断： 如果 ast 是一个向量: 返回对于向量中的每个元素 EVAL 调用得到的结果所组成的向量 如果 ast 是一个哈希表: 返回一个新的哈希表，它的键是从原哈希表中来的键，值是对于原哈希表中的键所对应的值调用 EVAL 得到的结果。\n步骤 3: Environments 环境 step3_env\n在步骤 2 中我们已经实现了 REPL 环境 (repl_env)，在这个环境中可以存储和查找基本的算数运算函数。在本步骤中，你将会为解释器增加创建新环境 (let*) 和修改已存在的环境 (def!) 的功能。\nLisp 的环境是一个关系数据结构，它将符号 (即键) 映射到值上。但是 Lisp 环境还有一个很重要的额外功能：它们可以引用 (refer) 另一个环境 (外层的环境)。在环境中进行查找时，如果当前环境中没有要找的符号，那么将在外层环境中继续查找，持续进行这个过程，直到找到符号，或者外层的环境是 nil(在整个链中的最外层)为止。\n比较步骤 2 和步骤 3 的伪代码，可以对本步骤中将要做的修改有简要的了解：\ndiff -urp ../process/step2_eval.txt ../process/step3_env.txt 将 step2_eval.qx 复制为 step3_env.qx 创建 env.qx，在里面写和环境有关的定义 定义一个 Env 对象，在实例化时需要传入一个 outer 参数，它本身有一个的关系型数据结构的属性 data，在实例化的时候是空的。 为 Env 对象定义下列三个方法： set: 接受一个符号作为键，一个 mal 类型对象作为值，并将它们装入 data 结构中 find: 接受一个符号的键参数，如果当前环境中找到了这个键，那么返回环境。如果没有找到，并且外层环境不是 nil，那么在外层环境中（递归）调用 find get: 接受一个符号的键参数，并且用 find 方法来找到这个键对应的环境，并且返回匹配到的值。如果没有在外层环境的链中没有找到这个键，则抛出一个 \u0026ldquo;not found\u0026rdquo;（未找到）错误 更新 step3_env.qx，使用新的 Env 类型来创建 repl_env (它的 outer 参数设置为 nil)，并且使用 set 方法将算数运算函数加入到环境中 修改 eval_ast，对 env 参数调用 get 方法 修改 EVAL 函数的 apply 的部分，对于列表的第一个元素进行条件判断: symbol \u0026ldquo;def!\u0026quot;: 调用当前环境（EVAL 的第二个，名为 env 的参数）的 set 方法，使用未求值的第一个参数（列表的第二个元素）作为符号键，并且将已求值的第二个参数作为值 symbol \u0026ldquo;let*\u0026quot;: 以当前环境作为 outer，创建一个新的环境，并将第一个参数作为\u0026quot;let*\u0026ldquo;环境中新的 binding 列表。取 binding 列表的第二个元素，以新 \u0026ldquo;let*\u0026rdquo; 环境作为求值环境调用EVAL，然后在 \u0026ldquo;let*\u0026rdquo; 环境上调用set，以 binding 列表第一个元素作为键，以求值后的第二个元素作为值。对于 binding 列表中的每个奇/偶对重复进行上述过程。要特别注意的是，在列表前面的 binding，可以被后面的 binding 引用。最终，原始 let* 形式的第二个参数 (即第三个元素) 使用新的 \u0026ldquo;let*\u0026rdquo; 环境进行求值，结果作为新的 \u0026ldquo;let*\u0026rdquo; 的结果返回。 (新的 let 环境在结束后被丢弃) 否则: 对于 list 调用 eval_ast，并像前面一样，将第一个元素应用到余下的元素上。 def! 和 let* 是 Lisp 中的 \u0026ldquo;special\u0026rdquo; (特例)（或叫“特殊 atom”），意思是它们是语言级别的特性，并且更特别，list 中余下的元素（参数）可能会被求值（或根本不被求值），与默认的应用情况——list中的所有元素都在第一个元素被调用到之前，已经求值完毕——不同。以 \u0026ldquo;special\u0026rdquo; 作为第一个元素的列表被称为 \u0026ldquo;special forms\u0026rdquo;。它们很特殊，因为它们遵守特殊的求值规则。\n尝试一些简单的环境测试：\n(def! a 6) -\u0026gt; 6 a -\u0026gt; 6 (def! b (+ a 2)) -\u0026gt; 8 (+ a b) -\u0026gt; 14 (let* (c 2) c) -\u0026gt; 2 回到目录的最顶层，运行步骤 3 的测试，并修复错误。\nmake \u0026ldquo;test^quux^step3\u0026rdquo;\n步骤 4: If Fn Do step4_if_fn_do\n在步骤 3 中，你为解释器增加了环境，和用来操作环境的特殊形式。在本步骤中，你将为 REPL 的默认环境增加三种新的特殊形式 (if, fn* 和 do) 以及几种核心函数。新的结构如下：\nfn* 特殊形式是用户创建自定义函数的方式。在一些 Lisp 语言中，这个特殊的形式叫 \u0026ldquo;lambda\u0026rdquo;。\n比较步骤 3 和步骤 4 的伪代码，可以对本步骤中将要做的修改有简要的了解：\ndiff -urp ../process/step3_env.txt ../process/step4_if_fn_do.txt 将 step3_env.qx 复制为 step4_if_fn_do.qx。 如果你还没有实现 reader 和 printer 对 nil, true 和 false 的支持，那么你需要在本步骤中实现。 修改环境的构建器 / 初始化器，让它接受两个新的参数: binds 和 exprs。将 binds 列表中每个元素 (符号) 绑定(set) 到 exprs 列表中对应的元素上。 在 printer.px 中增加对打印函数值的支持。像 # 之类的字符串字面值够用了。 为 EVAL 实现下列特殊形式： do: 使用 eval_ast 对列表的所有元素进行求值，并返回最后一个元素的求值结果。 if: 对第一个参数进行求值（即第二个元素），如果结果不是 nil 或 false，则求值第二个参数（即第三个元素），并返回它的结果。否则，求值第三个参数（第四个元素）并返回执行结果。如果条件是 false 并且没有第三个参数，则返回 nil。 fn*: 返回一个新的函数闭包。闭包的 body 中包含如下内容： 创建一个新的环境，以 env (外层作用域) 作为 outer 参数，第一个参数（即外层作用域的 ast 的第二个列表元素）作为 binds 参数，闭包的参数作为 exprs 的参数。 对于第二个参数（即外层作用域的 ast 的第三个列表元素）调用 EVAL，使用新的环境。将结果作为闭包的返回值。 如果你的目标语言不支持闭包，那么你需要使用某种在关闭时可以保存值的结构或者对象保存如下的东西：ast 列表的第一个和第二个参数（函数参数列表和函数体），以及当前环境 env。在这种情况下，你的原生函数需要用相同的方式进行封装。可能你也需要在 EVAL 的 apply 部分有一个用来调用对象/结构的函数/方法。\n测试你已经实现的基础部分：\n(fn* [a] a) -\u0026gt; #((fn* [a] a) 7) -\u0026gt; 7\n((fn* [a] (+ a 1)) 10) -\u0026gt; 11\n((fn* [a b] (+ a b)) 2 3) -\u0026gt; 5\n增加一个新的文件 core.qx，并定义一个叫 ns(namespace)的关系数据结构，将 symbol 映射为函数。将算数运算函数定义放在这个函数里。\n修改 step4_if_fn_do.qx，让它读取 core.ns 结构，并将每个 symbol / 函数加入 (set) 到 REPL 环境中(repl_env)。\n将下列函数加入到 core.ns 中：\nprn: 对于第一个参数调用 pr_str，print_readably 参数设置为 true，将结果打印到屏幕，并返回 nil。注意，完整版本的 prn 函数在下面 “可推迟的任务” 一节中。 list: 接受参数并将它们返回为一个列表。 list?: 如果参数是一个列表，返回 true，否则返回 false。 empty?: 将第一个参数当作一个列表处理，如果这个列表是空的，则返回 true，如果里面有元素，返回 false。 count: 将第一个参数当作一个列表处理，并返回列表包括元素的个数。 =: 对比前两个参数，如果它们是相同的类型并且值也相同，那么返回 true。在比较两个列表的时候，两个列表中的每两个对应元素都要进行比较，如果它们都相同，返回 true，否则返回 false。 \u0026lt;, \u0026lt;=, \u0026gt; 和 \u0026gt;=: 将前两个参数作为数字，并且进行数学比较，返回 true 或 false。 回到目录顶层，运行步骤 4 的测试。步骤 4 有大量的测试用例，但是所有的不涉及到字符串的非可选测试，都需要通过。\nmake \u0026ldquo;test^quux^step4\u0026rdquo; 你的 mal 实现已经开始像一门真正的语言了。你有了流程控制，判断，带词法作用域的用户定义函数，副作用（如果你实现了字符串函数）等。但是我们的小解释器还没有达到 Lisp-ness 的程度。后续的步骤将使你的小玩具改造成为一个全功能的语言。\n可推迟的步骤: 实现 Clojure 风格的可变函数参数。修改环境的构造器/初始化器，在 binds 列表中遇到 \u0026ldquo;\u0026amp;\u0026rdquo; 符号的时候，列表中这个 \u0026ldquo;\u0026amp;\u0026rdquo; 符号后面的元素将绑定到 \u0026ldquo;exprs\u0026rdquo; 列表中余下的还未绑定的部分上。 定义一个 not 函数，给 mal 自己用。在 step4_if_fn_do.qx 中以 \u0026ldquo;(def! not (fn* (a) (if a false true)))\u0026rdquo; 为参数调用 rep 函数。 在 core.qx 中实现字符串函数。你需要为 reader 和 printer 实现字符串支持（步骤 1 中的可推迟的步骤）。每一个字符串函数接受若干个 mal 类型的值，打印它们 (pr_str) 并将它们组装成一个新的字符串。 pr-str：对于每个参数调用 pr_str，将 print_readably 参数设置为 true，用 \u0026quot; \u0026ldquo;把结果连接起来，返回字符串。 str: 对于每个参数调用 pr_str，将 print_readably 参数设置为 false，用 \u0026quot;\u0026rdquo; (空字符) 把结果连接起来，返回新字符串。 prn: 对于每个参数调用 pr_str，将 print_readably 参数设置为 true，用 \u0026quot; \u0026quot; 把结果连接起来，把新字符串打印到屏幕上，并返回 nil。 println: 对于每个参数调用 pr_str，将 print_readably 参数设置为 false，用 \u0026quot; \u0026quot; 把结果连接起来，把新字符串打印到屏幕上，并返回 nil。\n步骤 5: 尾调用优化 step5_tco\n在步骤 4 中，你增加了特殊的形式 do, if 和 fn* 并且定义了一些核心函数。在本步骤中你将实现一个 Lisp 的特性，叫作尾调用优化 (TCO)。也叫“尾递归” 或“尾调用”。\n你在 EVAL 中已经定义的一些形式最终会回调进入 EVAL 中。对于这些以调用 EVAL 作为在返回之前做的最后一件事情（尾调用）的形式，你将直接回到过程的开头循环执行，而不是再一次调用它。这个做法的优点是能够避免在调用栈里增加更多的栈帧。这在 Lisp 语言中特别重要，因为它们倾向于用递归代替迭代作为控制结构。（虽然有些 Lisp 的方言中有迭代，例如 Common Lisp）有了尾调用优化，递归可以有像迭代一样的调用栈的效率。\n比较步骤 4 和步骤 5 的伪代码，可以对本步骤中将要做的修改有简要的了解：\ndiff -urp ../process/step4_if_fn_do.txt ../process/step5_tco.txt 将 step4_if_fn_do.qx 复制为 step5_tco.qx 在 EVAL 所有代码的外层增加一个循环（如 while true） 修改下列的形式，增加对尾调用递归支持： let*: 移除最后对 ast 第二个参数（即第三个列表元素）的 EVAL 调用，将 env（即 EVAL 第二个参数传入的局部变量）的值设置为新的let环境， 将ast（即 EVAL 第一个参数传入的局部变量）的值设置为 ast 的第二个参数。回到循环开头继续执行（不返回）。 do: 修改 eval_ast 调用，让它求值所有的参数，除了最后一个参数（第二个列表元素以及后续的元素，但不包括最后一个元素）将 ast 设置为 ast 最后一个元素。回到循环开头继续执行（env 保持不变） if: 继续求值条件，但不是求值 true 或 false 分支，而是将 ast 设置为被选中分支的未求值的量。回到循环开头继续执行（env 保持不变） 特殊形式 fn* 的返回值现在要变成一个对象 / 结构，它应该有一些属性，以便 EVAL 对 mal 函数进行尾调用优化。这些属性是： ast: ast 的第二个参数（即第三个列表元素），相当于函数的 body。 params: ast 的第一个参数（第二个列表元素），相当于函数的参数名。 env: 当前 EVAL 函数的 env 参数的值。 fn: 原始的函数值（换句话说，就是步骤 4 中 fn* 所返回的东西）。注意这是一个可推迟的任务，在步骤 9 的时候 map 和 apply 才需要用到它。如果在后面的步骤 6 中你选择不推迟 atoms/swap! 的实现的话，那么也需要先实现它。 EVAL 默认的 \u0026ldquo;apply/invoke\u0026rdquo; 条件分支现在必须改为可以处理由 fn* 形式返回的新对象/结构体。继续对 ast 调用 eval_ast. 第一个元素是 f。 根据 f 不同的类型做对应的处理: 常规函数 (不是使用 fn* 定义的): 像原来 (步骤 4) 一样apply/invoke。 * fn* 值: 将 f 的 ast 属性赋值给 ast。创建一个新环境，以 f 的 env 和 params 属性作为 outer 和 binds 参数，以余下的 ast 参数 (列表第二个到最后一个元素)作为 exprs 参数。将新环境赋值给 env，回到循环的开头继续执行。 执行一下上一步骤中的手工测试，确保你没有因为加入了尾调用优化而破坏了什么东西。\n现在回到目录顶层，运行步骤 5 的测试。\nmake \u0026ldquo;test^quux^step5\u0026rdquo; 看一下步骤 5 的测试文件 tests/step5_tco.mal。函数 sum-to 不能被尾调用优化，因为它在递归调用之后又做了一些事情（sum-to 调用了它自身，之后执行了相加的操作）Lisp 用户说 sum-to 并没有在尾部调用。函数 sum2 在尾部调用了自己。换句话说，对 sum2 的递归调用是 sum2 最后一步做的事情。对于一个非常大的值调用 sum-to 将在大多数目标语言中导致栈溢出异常。（某些语言使用了非常特殊的技巧来避免栈溢出）\n祝贺你，你的 mal 实现已经有了大多数主流语言所缺少的（尾调用优化）特性。\n步骤 6: Files, Mutation, and Evil step6_file\n在步骤 5 中，你为解释器加入了尾调用优化。在本步骤中你将加入一些字符串和文件操作的功能，为你的实现增加一些 evil，呃 eval。只要你的语言支持函数闭包，那么本步骤将非常容易。然而，为了完成本步骤，你必须实现字符串类型的支持，所以如果你之前如果推迟了任务还没完成，你需要回去先把那个搞定。\n比较步骤 5 和步骤 6 的伪代码，可以对本步骤中将要做的修改有简要的了解：\ndiff -urp ../process/step5_tco.txt ../process/step6_file.txt 将 step5_tco.qx 复制为 step6_file.qx 为核心命名空间 (译注: core.ns) 增加两个新的字符串函数: read-string: 这个函数将 reader 中的 read_str 函数暴露了出来。如果你的 mal 字符串类型与你目标语言不一样（例如静态类型语言），那么你的 read-string 函数需要将原始字符串通过调用 read_str 函数从 mal 字符串类型中解包出来。 slurp: 这个函数接受一个文件名（字符串）并并且将文件的内容作为字符串返回。和上面那个函数一样，如果你的 mal 字符串类型封装了目标语言的字符串，那么你需要将字符串参数解码来得到原始的文件名字符串，并将结果编码 (封装) 成 mal 字符串类型。 在你的主程序中，为你的 REPL 环境增加一个新的符号 \u0026ldquo;eval\u0026rdquo;。这个符号对应的值是接受一个参数 ast 的函数。闭包调用你的 EVAL 函数，以 ast 作为第一个参数，REPL 环境作为第二个参数（外层的环境），将调用 EVAL 的结果返回。这个简单且强大新功能允许你将 mal 数据作为 mal 程序对待。例如，你现在可以这样做： (def! mal-prog (list + 1 2)) (eval mal-prog) 使用 mal 语言自身，定义一个 load-file 函数，在你的主程序里调用 rep 函数，参数为 \u0026ldquo;(def! load-file (fn* (f) (eval (read-string (str \u0026ldquo;(do \u0026quot; (slurp f) \u0026ldquo;)\u0026quot;)))))\u0026rdquo; 测试一下 load-file:\n(load-file \u0026ldquo;../tests/incA.mal\u0026rdquo;) -\u0026gt; 9 (inc4 3) -\u0026gt; 7 load-file 函数做了如下的事情：\n调用 slurp 来通过文件名读取一个文件。将文件内容用 \u0026ldquo;(do \u0026hellip;)\u0026rdquo; 进行封装，这样整个文件就可以作为一个单程序的 AST（抽象语法树）。 以 slurp 的返回值作为参数调用 read-string 函数。它使用 reader 读取 / 转换文件的内容，使之成为 mal 数据 / AST. 使用 eval(在 REPL 环境中的那个)函数处理 read-string 函数返回的 AST，“运行”它。 除了增加文件和求值的支持以外，在本步骤中我们也要增加原子数据类型。原子是 mal 用来表示状态的方式，这个灵感来自于Clojure 的原子。原子保存了对一个任意类型 mal 值的引用。它支持读取一个 mal 值，修改它的引用，将它指向另一个 mal 值。注意这是唯一一种可变类型（但是它所引用的 mal 值仍是不可变的，在步骤 7 中有关于不可变特性的进一步解释）你需要在核心命名空间中增加 5 个函数来支持原子。\natom: 输入一个 mal 值，并返回一个新的指向这个值的原子。 atom?: 判断输入的参数是不是原子，如果是，返回 true。 deref: 输入一个原子作为参数，返回这个原子所引用的值。 reset!: 输入一个原子以及一个 mal 值，修改原子，让它指向这个 mal 值，并返回这个 mal 值。 swap!: 输入一个原子，一个函数，以及零个或多个函数参数。将原子的值作为第一参数，并将余下的函数参数作为可选的参数传输函数中，将原子的值置为函数的求值结果。返回新的原子的值。(边注: Mal是单线程的，但在像Clojure之类的并发语言中，swap!将是一个原子操作，(swap! myatom (fn* [x] (+ 1 x)))总是会把myatom计数增加1，并且在原子被多个线程操作时不会导致结果出错) 你可以增加一个 reader 宏 @，它相当于一个 deref 的简略形式，因此 @a 相当于 (deref a)。为了达到这个目的，修改 read_form 函数的条件判断，增加一个规则，处理 @token: 如果 token 是 @(at 符号)，那么返回一个包括 deref 符号以及读取下一个形式 (read_form) 结果的新列表。\n现在回到目录顶层，运行步骤 6 的测试。可选测试包括了对注释，向量，哈希表，和 @ reader 宏的支持:\nmake \u0026ldquo;test^quux^step6\u0026rdquo; 恭喜你，你现在实现了一个完善的脚本语言，它可以运行其他的 mal 程序。slurp 函数把一个文件当作字符串读进来，read-string 函数调用 mal reader 将字符串转换为数据，然后 eval 函数读取数据，并把它当作一个普通的 mal 程序一样进行求值。然而，我们需要注意，eval 函数不是只能用来运行外部程序的。因为 mal 程序就是普通的 mal 数据结构，你可以在调用 eval 求值之前，动态生成或者操作这些数据结构。数据和程序之间的同形（形状相同），我们称之为同像性(homoiconicity)。Lisp 语言们的这种同像性将它们与其他大多数语言区分开来。\n你的 mal 实现现在已经非常强大了，但在 core.qx 中的这组可用的功能还相当有限。你将在步骤 9 和步骤 A 中增加许多功能进去，但你从在接下来的步骤中支持 quoting (步骤 7) 和 macros (步骤 8) 开始，逐渐完善它。\n可推迟的任务：\n增加通过命令行运行其他 mal 程序的能力。在进入 REPL 循环之前，检查你的 mal 实现在被调用的时候有没有带参数，如果有参数的话，将第一个参数视为文件名，使用 rep 调用 load-file 将文件导入并执行，最后退出 / 终止执行。 将剩下的命令行参数传入 REPL 环境，让通过 load-file 函数执行的程序能够访问调用它们的环境。为你的 REPL 环境加入一个 \u0026ldquo;ARGV\u0026quot;(符号)。它的值是命令行余下的参数的一个列表。\n步骤 7: Quoting step7_quote\n在步骤 7 中，你将为解释器加上 quote 和 quasiquote 这两个特殊形式，并且加入 cons 和 concat 这两个核心函数的支持。\n特殊形式 quote 告诉求值器 (EVAL) 不要对参数进行求值。一开始，看起来这个功能没啥卵用，但有一个例子能够证明它有用，让 mal 程序能够有引用一个符号的自身，而不是它经过求值后的结果。比如列表。例如，考虑下列情况：\n(prn abc): 这段程序将在当前求值环境中寻找符号 abc。并打印到屏幕上。如果 abc 没有被定义过的话，就会报错。 (prn (quote abc)): 这段程序会打印 \u0026ldquo;abc\u0026rdquo;（打印符号本身）。它不会去管在当前环境中 abc 是否已被定义。 (prn (1 2 3)): 这段程序会报错，因为 1 不是函数，不能被应用于参数 (2 3) 上。 (prn (quote (1 2 3))): 这段程序将打印 \u0026ldquo;(1 2 3)\u0026quot;。 (def! l (quote (1 2 3))): list quoting 允许我们在代码中直接定义 list(字面列表). 另一个做这件事的方法是使用 list 函数 (def! l (list 1 2 3))。 第二种特殊形式是 quasiquote。它允许一个 quoted 列表能够有一些临时 unquoted 的元素(正常求值)。有两种特殊形式unquote 和 splice-unquote 代表在 quasiquoted 列表里面的东西。最好来点例子解释一下:\n(def! lst (quote (2 3))) -\u0026gt; (2 3) (quasiquote (1 (unquote lst))) -\u0026gt; (1 (2 3)) (quasiquote (1 (splice-unquote lst))) -\u0026gt; (1 2 3) unquote 形式将将它的参数逆向求值，并将求值结果放入 quasiquoted 列表。形式 splice-unquote 也将它的参数逆向求值，但是被求值的值必须是列表，因为在后面它们会被切分 (splice) 到 quasiquoted 列表中。在将它于 macro 一起使用的时候，quasiquote 形式的真实力量才会展现出来(在下一步骤中)。\n比较步骤 6 和步骤 7 的伪代码，可以对本步骤中将要做的修改有简要的了解：\ndiff -urp ../process/step6_file.txt ../process/step7_quote.txt 将 step6_file.qx 复制为 step7_quote.qx 在实现这些 quoting 形式时，你需要先在核心命名空间里实现一些支持函数: cons: 这个函数将它的第一个参数连接到它的第二个参数 (一个列表) 前面，返回一个新列表。 concat: 这个函数接受零个或多个列表作为参数，并且返回由这些列表的所有参数组成的一个新列表。 关于不变可性: 注意 cons 和 concat 都没有修改它们的原始列表参数。所有对于它们的引用（换句话说，在其他列表中，它们可能作为其中的元素）将还指向原有的未变更的值。就像 Clojure 一样，mal 是一种使用不可变数据结构的语言。我建议你去学习一下 Clojure 语言中实现的不可变性的能力和重要性，mal 借用了它的大部分语法和特性。\n添加 quote 特殊形式，这个特殊形式返回它的参数（ast 的第二个列表元素）\n添加 quasiquote 特殊形式。实现实现一个 helper 函数 is_pair，它在参数是一个非空列表的时候返回 true。然后定义 quasiquote 函数。在 EVAL 中以 ast 的第一个参数（即第二个列表元素）为参数调用它，随后 ast 被设置为结果，并且回到循环的开头继续执行（TCO，尾调用优化）。quasiquote 函数输入 ast 参数后，进行如下的条件判断：\n如果 is_pair 对于 ast 的判断结果是 false: 返回一个新列表，里面包括了一个名为 \u0026ldquo;quote\u0026rdquo; 的符号，以及 ast。 否则，如果 ast 的第一个元素是符号 \u0026ldquo;unquote\u0026rdquo;: 返回 ast 的第二个元素。 如果 is_pair 对于 ast 的判断结果是 true，并且 ast 的第一个元素的第一个元素 (即 ast[0][0]) 是名为 \u0026ldquo;splice-unquote\u0026rdquo; 的符号：返回一个新的列表，其中包含：名为 \u0026ldquo;concat\u0026rdquo; 的符号，ast 的第一个元素的的第二个元素(即 ast[0][1])，以及以 ast 的第二个元素到最后一个元素为参数调用 quasiquote 的结果。 否则: 返回一个新的列表，包括：名为 \u0026ldquo;cons\u0026rdquo; 的符号，以 ast 的第一个参数(即 ast[0])为参数调用 quasiquote 的结果，以及以 ast 的第二个元素到最后一个元素为参数调用 quasiquote 的结果。 返回目录顶层，执行步骤 7 的测试。\nmake \u0026ldquo;test^quux^step7\u0026rdquo; Quoting 是 mal 中许多无聊的函数中的一个，但别因此而灰心。你的 mal 实现已接近完工了，而 quoting 为接下来的接近收工的步骤: 宏 (macro)，做好了准备。\n可推迟的任务 quoting 形式的全名相当罗嗦。大多数 Lisp 语言有一个简写的语法，mal 也不例外。这些简写语法被成为 reader macros 因为它们使我们能够在 reader 阶段中操作 mal 代码。在 eval 阶段中被执行的 macro 只是叫作 macro，我们将在下一节中介绍。扩展 reader 的 read_form 函数的条件判断，增加下列情况: token 是 \u0026ldquo;'\u0026quot;(单引号): 返回一个新列表，包含符号 \u0026ldquo;quote\u0026rdquo;，以及对下一个 form 读取的结果(read_form) token 是 \u0026ldquo;`\u0026rdquo; (反引号): 返回一个新列表，包含符号 \u0026ldquo;quasiquote\u0026rdquo;，以及对下一个 form 读取的结果(read_form) token 是 \u0026ldquo;~\u0026rdquo; (波浪号): 返回一个新列表，包含符号 \u0026ldquo;unquote\u0026rdquo;，以及对下一个 form 读取的结果(read_form) token 是 \u0026ldquo;~@\u0026rdquo; (波浪号和 at 符号): 返回一个新列表，包含符号 \u0026ldquo;splice-unquote\u0026rdquo;，以及对下一个 form 读取的结果(read_form) 增加对 vector 的 quoting 的支持。is_pair 函数在参数是非空列表或非空向量时应该返回 true。cons 应该也能接受向量作为第二个参数。但返回值总是列表。concat 应该支持列表、向量，对它们两者进行连接，结果永远是列表。\n步骤 8: Macros 宏 step8_macros\n现在，你的 mal 实现已经为加入最 Lisp 范的、最一颗赛艇的编程概念——macro 宏——做好了准备。在之前的步骤中，quoting 能实现一些简单的数据结构操作，以及对我们 mal 代码的一些操作（因为在步骤 6 中，我们的 eval 函数能够将 mal 数据结构转换为代码）。在本步骤中，你将实现将一个 mal 函数标记为宏的功能，它可以在求值之前操作 mal 代码。换句话说，宏就是用户自定义的特殊形式。从另一角度看，宏允许 mal 程序重新定义 mal 语言本身。\n比较步骤 7 和步骤 8 的伪代码，可以对本步骤中将要做的修改有简要的了解：\ndiff -urp ../process/step7_quote.txt ../process/step8_macros.txt 将 step7_quote.qx 复制为 step8_macros.qx 你可能认为，宏的无限力量可能需要实现某种复杂的机制。然而，事实上它实现起来非常简单。\n为 mal 函数类型添加一个新的属性 is_macro，这个属性默认是 false\n添加一个新形式 defmacro!。它与 def! 形式非常类似，但是在将 mal 函数加入到环境中之前，将 is_macro 属性设置为 true\n添加一个 is_macro_call 函数：这个函数接受两个参数 ast 和 env。当 ast 列表第一个元素是个符号，并且这个符号指向 env 环境中的一个 is_macro 属性为 true 函数时，返回 true，否则返回 false。\n添加一个 macroexpand 函数：这个函数接受两个参数 ast 和 env。它调用 is_macro_call 函数，传入参数 ast 和 env，并且在条件为 true 时进行循环。在循环中，ast 列表中的第一个元素 (一个符号) 在环境中查找 macro 函数。这个宏函数随后会以 ast 余下的元素（第二个到最后一个）作为参数被调用/应用。宏调用的的返回值将成为 ast 的新值。当 ast 不再是一个宏调用时，循环结束，当前 ast 的值会被返回。\n在求值器 (EVAL) 的特殊形式分支之前 (即apply部分之前)，通过以当前的 ast 和 env 为参数调用 macroexpand 函数，从而进行宏展开。将调用的结果设置给 ast。如果 ast 的新值在宏展开之后不再是一个列表，那么返回对它调用 eval_ast 的结果，否则继续剩下的 apply 部分(特殊形式的条件判断)。\n添加一个新的特殊形式macroexpand 。以 ast 的第一个参数（第二个列表元素）和 env 作为参数调用 macroexpand，并将得到的结果返回。这个特殊形式允许 mal 程序进行显式的宏展开而不对结果进行apply（这在调试宏展开时十分有用）\n回到目录顶层，执行步骤 8 的测试：\nmake \u0026ldquo;test^quux^step8\u0026rdquo; 在一开始，宏测试极有可能无法通过。尽管宏的实现非常简单，但调试宏的运行时 bug 非常的困难。如果你遇到了很难搞定的问题，我在这里给你一些建议：\n使用 macroexpand 特殊类型来排除 indirection 的一层（进行展开但是跳过求值）。通常这能让我们找到问题的源头。 在 eval 函数的最上面（在 TCO 循环中）增加一个 debug print 的语句，打印当前 ast 的值（提示：使用 pr_str 来获得便于 debug 的输出）。在其他语言的实现中找到步骤 8 的代码，并解除注释它的 eval 函数（是的，我允许你违反一次规则）。将两者同步执行，并进行对比。第一处不同的输出可能指示着 bug 的所在。 恭喜你！你的 Lisp 解释器现在有了超能力，而其他非 Lisp 语言只有羡慕的份。（我非常确信，编程语言在你不使用它们的时候是会做梦的）如果你还不熟悉 Lisp 宏，我建议你做如下练习：写一个递归宏，处理后缀 mal 代码（也巨是说将函数作为最后一个，而不是第一个参数）或者不做这样的练习，因为事实上我自己也没尝试过，但我听说这是一个很有趣的练习。\n在下一步骤中，你将为你的实现添加 try/catch 风格的异常处理，以及一些新的核心函数。经过步骤 9，你的实现将非常接近一个可以自举的 mal 语言实现。让我们继续吧！\n可推迟的任务：\n添加下列这些在宏函数中经常用到的核心函数：\nnth: 这个函数接受一个列表（或向量）以及一个数字（序号）作为参数，返回列表中给定序号位置的元素。如果序号超出了返回，函数抛出一个异常。 first: 这个函数接受一个列表（或向量）作为参数，返回它的第一个元素，如果列表（或向量）是空的，或者参数本身是 nil，则返回 nil。 rest: 这个函数接受一个列表（或向量）作为参数，返回由除第一个元素之外的所有元素组成的列表。 在主程序中，使用 rep 函数定义两个新的控制结构宏，下面是调用 rep 定义这些宏时用到的字符串参数:\ncond: \u0026ldquo;(defmacro! cond (fn* (\u0026amp; xs) (if (\u0026gt; (count xs) 0) (list\u0026rsquo;if (first xs) (if (\u0026gt; (count xs) 1) (nth xs 1) (throw \u0026ldquo;odd number of forms to cond\u0026rdquo;)) (cons\u0026rsquo;cond (rest (rest xs)))))))\u0026rdquo; 注意，cond 在 cond 为奇数个参数时调用了 throw 函数。 throw 函数将会在下一步中进行实现，但它仍要引发一个未定义符号错误来表明它的意图。 or: \u0026ldquo;(defmacro! or (fn* (\u0026amp; xs) (if (empty? xs) nil (if (= 1 (count xs)) (first xs) `(let* (or_FIXME ~(first xs)) (if or_FIXME or_FIXME (or ~@(rest xs))))))))\u0026rdquo;\n步骤 9: Try step9_try\n在本步骤中，你要实现 mal 的最后一种特殊形式，用来进行异常处理的：try*/catch*. 你也需要为你的实现添加一些核心函数。特别是，你将会为你的实现增加 apply 和 map 核心函数，来加强它的函数式编程的血统。\n比较步骤 8 和步骤 9 的伪代码，可以对本步骤中将要做的修改有简要的了解：\ndiff -urp ../process/step8_macros.txt ../process/step9_try.txt 将 step8_macros.qx 复制为 step9_try.qx 为 EVAL 函数添加 try*/catch* 特殊形式。try catch 形式看起来是这样的: (try* A (catch* B C)) 对 A 进行求值，如果抛出了异常，那么在符号 B 绑定到抛出异常的值的环境中，对 C 进行求值。 如果你的目标语言有内建的 try/catch 风格的异常处理，那么你已经完成了 90% 的工作。增加一个(原生语言)try/catch 程序块，在 try 部分中对 A 进行求值，并捕获所有异常。如果捕获到异常，则将异常翻译为一个 mal 类型/值。对于原生的异常，这可以是一个消息字符串或一个 mal 哈希表，其中包括了消息字符串和一些关于异常的其他异常。当一个通常的 mal 类型 / 值被当作异常，你可能需要将它保存在原生的异常类型中，以便使用原生的 try/catch 机制对它进行处理。然后你要将 mal 类型/值从原生的异常中解出来。创建一个新的 mal 环境，在这个环境中，将 B 与异常的值绑定。最后，使用新的环境对 C 进行求值。 如果你的目标语言没有内建的 try/catch 风格的异常处理，那么你就有一些额外的工作要做了。最直接的做法之一是创建一个全局的错误变量，保存被抛出的 mal 类型/值。但它的复杂之处在于，在许多地方你都必须检查这个全局错误状态是否已经被设置了，从函数中返回，中断执行。最佳的规则是，这个检查应该放在你 EVAL 函数的最开始，以及每一个对 EVAL 的调用之后（在后续调用链中的任何一个可能对 EVAL 进行调用的函数之后）是的，这样的做法非常不优雅，但在一开始选择目标语言的时候，我已经警告过你了。 添加 throw 核心函数 如果你的目标语言支持 try/catch 风格的异常处理，那么本函数接受一个 mal 类型/值，并将它作为一个异常抛出。为了做到这一点，你可能需要创建封装了 mal 对象/类型的自定义异常对象。 如果你的目标语言没有内建的 try/catch 风格的异常处理，则为这个 mal 对象/类型设置全局错误状态。 增加 apply 和 map 核心函数。在步骤 5 中，如果你没有将原始函数 fn 加入到 fn* 返回的结构中，那么要先把它搞定。 apply: 接受至少两个参数。第一个参数是一个函数，最后一个参数的是列表（或向量）。在函数和最后一个参数（如果有的话）之间的参数与最后一个参数连接起来，创建参数被用来调用函数。这个 apply 函数允许一个函数的参数被包含在一个列表（或）向量中。换句话说，(apply F A B [C D]) 就相当于 (F A B C D)。 map: 接受一个函数和一个列表，并对列表（或向量）中的每一个元素求值，并将结果返回为一个列表。 添加一些类型断言函数。在 Lisp 中，断言函数通常以以 \u0026ldquo;?\u0026rdquo; 或者 \u0026ldquo;p\u0026rdquo; 结尾，返回 true 或 false（或 true 值 / nil）。 nil?: 接受一个参数，如果参数是 nil(mal 中的 nil 值)的话返回 true (mal 中的 true 值)。 true?: 接受一个参数，如果参数是 true(mal 中的 true 值)的话，返回 true (mal 中的 true 值)。 false?: 接受一个参数，如果参数是 false(mal 中的 false 值)的话，返回 true (mal 中的 true 值)。 symbol?: 接受一个参数，如果参数是 symbol(mal 中的 symbol)的话，返回 true (mal 中的 true 值)。 现在回到顶层目录，运行步骤 9 的测试：\nmake \u0026ldquo;test^quux^step9\u0026rdquo; 你的 mal 实现现在大体上已经是一个功能完善的 Lisp 解释器了。但是如果你止步于此，就会错过创造一个 mal 实现中最激动人心和富有启发性的部分：自足执行 self-hosting。\n可推迟的任务 增加如下新的核心函数: symbol: 接受一个字符串，返回以这个字符串作为名字的符号。 keyword: 接受一个字符串，返回有相同名字的关键字 (通常是有前缀的特殊unicode符号) 这个函数也被用来判断参数是否已经是一个关键字，并返回它。 keyword?: 接受一个参数，如果参数是关键字的话，返回 true(mal 中的 true 值)，否则返回 false(mal 中的 false 值) vector: 接受若干个参数，返回包含这些参数的一个向量。 vector?: 接受一个参数，如果参数是向量的话，返回 true(mal 中的 true 值)，否则返回 false(mal 中的 false 值) hash-map: 接受偶数数量的参数，返回一个新的 mal 哈希表，其中键为奇数位置的参数，它们的值分别为与之对应的偶数位置的参数，它基本上是 {}reader 字面语法的函数形式。 map?: 接受一个参数，如果参数是哈希表的话，返回 true(mal 中的 true 值)，否则返回 false(mal 中的 false 值) assoc: 接受一个哈希表作为第一个参数，余下的参数为需要关联(合并)到哈希表里的奇/偶-键/值对。注意，原始的哈希表不会被修改(记住，mal 的值是不可变的)，旧哈希表中的键/值与参数中的键/值对合并而成的新的哈希表作为结果返回。 dissoc:接受一个哈希表作为第一个参数，余下的参数为需要从哈希表中删除的键。与前面一样，注意原始的哈希表是不变的，只是把删除了参数中指定的键的新哈希表返回出来。参数列表中在原哈希表不存在的键会被忽略。 get: 接受一个哈希表和一个键，返回哈希表中与这个键对应的值，如果哈希表中不存在这个键，则返回 nil。 contains?: 接受一个哈希表和一个键，如果哈希表中包含这个键，则返回 true(mal 中的 true 值)，否则返回 false(mal 中的 false 值)。 keys: 接受一个哈希表，并返回一个列表(mal 中的 列表值)，其中包含了哈希表中的所有的键。 vals: 接受一个哈希表，并返回一个列表(mal 中的 列表值)，其中包含了哈希表中的所有的值。 sequential?: 接受一个参数，如果参数是列表或者向量的话，返回 true(mal 中的 true 值)，否则返回 false(mal 中的 false 值)\n步骤 A: Metadata, Self-hosting and Interop stepA_mal\n现在你来到了实现 mal 的最后一个步骤。本步骤是对一些无法放入到其他步骤中的任务的集合。更重要的是，在本步骤你做的事情，将解锁名为“自足执行”的神秘力量。你可能已经注意到，我们的诸多 mal 实现中其中一个，是用 mal 语言实现的。任何足够完善的 mal 实现都可以运行由 mal 语言实现的 mal。如果你之前从未构建过一个编译器或是解释器的话，你可能需要些时间思考一会。查看 mal 语言实现的 mal 的源码文件（因为你已经到了步骤 A，所以这不算是作弊了）。\n如果你推迟了关键字，向量和哈希表的实现，那么如果你想实现自足执行的话，现在就需要先回去把这些任务完成。\n比较步骤 9 和步骤 A 的伪代码，可以对本步骤中将要做的修改有简要的了解：\ndiff -urp ../process/step9_try.txt ../process/stepA_mal.txt 将 step9_try.qx 复制为 stepA_mal.qx 添加 readline 核心函数。这个函数接受一个字符串，用来提示用户输入。用户输入的文本作为一个字符串返回。如果用户输入了 EOF(通常是 Ctrl-D)，则返回 nil. 通过在 mal 函数上增加一个 metadata 属性，来为 mal 函数增加 meta-data 支持。这个属性引用了另一个 val 值/类型 (默认是nil)。添加下列与 metadata 相关的核心函数： meta: 它以一个 mal 函数作为参数，返回 metadata 属性的值。 with-meta: 这个函数接受两个参数，第一个参数是一个 mal 函数，第二个参数为要设置为 metadata 的 mal 值/类型。本函数将返回第一个参数函数的拷贝，且它的 meta 属性设置为第二个参数。注意环境和宏属性在拷贝的时候要同样保留下来。 添加 reader-macro，将 token \u0026ldquo;^\u0026rdquo; 展开为一个新列表，其中的元素依次为：symbol \u0026ldquo;with-meta\u0026rdquo;，读取(read_form)下下个形式的结果(第二个参数)和读取下个形式 (第一个参数)的结果。(注意，在^宏中metadata是第一个参数，函数是第二个参数，与with-meta函数所接受的参数顺序正好相反) 为你的 REPL 环境添加一个新的 \u0026ldquo;host-language\u0026quot;(symbol)入口。这个入口的值包含了当前实现的名字。 当 REPL 启动时（区别于使用脚本和参数调用启动时），调用 rep 函数，打印下列字符串启动信息: \u0026ldquo;(println (str \u0026ldquo;Mal [\u0026quot;host-language\u0026quot;]\u0026quot;))\u0026rdquo; 现在，回到目录顶层，运行步骤 A 的测试:\nmake \u0026ldquo;test^quux^stepA\u0026rdquo; 当你通过了步骤 A 的所有非可选测试，现在是尝试自足执行的时候了。正常启动你步骤 A 的实现，但是使用你在步骤 6 中实现的文件参数模式来运行 mal 语言版本的实现。\n./stepA_mal.qx ../mal/step1_read_print.mal ./stepA_mal.qx ../mal/step2_eval.mal \u0026hellip; ./stepA_mal.qx ../mal/step9_try.mal ./stepA_mal.qx ../mal/stepA_mal.mal 这是一个很好的机会，在你运行 mal 语言实现的 mal 时找到一些错误。在自足执行时进行 debug 会更加困难，并且非常虐心。我自己找到的一个最好的方式是在 mal 实现的出错的步骤中添加 prn 语句（不是你自己的 mal 实现中）\n另一个我经常用的方式是，将 mal 实现中导致问题的代码拿出来，一步步简化这些代码，直到将它们简化为可以重现问题的最简代码片段。当这段代码足够精简时，你可能就知道你 mal 实现的问题出在哪了。请将你的精简复现代码加入到测试用例中，将来的实现者就可以在它们进行自足执行之前就能避免问题，因为在这一步进行问题的定位和修复太困难了。\n一旦你可以手工运行所有的自足执行步骤时，现在是在自足执行模式下运行所有测试的时候了。\nmake MAL_IMPL=quux \u0026ldquo;test^mal\u0026rdquo; 当你遇到问题时（你几乎肯定要遇到），使用上面说过的方式来进行 debug。\n恭喜你！！！当所有测试通过后，你可以停下来并想想你已经完成了什么。你已经实现了一个 Lisp 解释器，它非常强大，并足够完整——可以运行一个大型的 mal 程序，而这个程序是 mal 语言实现的 mal 解释器。你甚至可能会问可否继续使用你的 mal 实现来运行 mal 实现，而它自己也是一个 mal 实现，如同盗梦空间一样。\n可选的任务: gensym 我们在步骤 8 中加入的 or 宏有一个 bug。它定义了一个名为 or_FIXME 的变量，它覆盖了用户代码中使用了这个宏。如果用户有一个变量叫 or_FIXME，它就无法作为 or宏的参数。为了修复这个问题，我们引入了 gensym: 这个函数返回一个在此前的程序中从未用到的符号。这也是一个使用 mal 原子来维护状态 (这里的状态是目前由 gensym 产生的符号的数量) 的例子。\n之前，你使用 rep 来定义 or 宏。移除这个定义，使用 rep 定义一个新的，反向的 gensym 函数和清真的 or 宏。下面是你需要传给 rep 的字符串参数:\n\u0026ldquo;(def! gensym-counter (atom 0))\u0026rdquo;\n\u0026ldquo;(def! gensym (fn* [] (symbol (str \u0026quot;G__\u0026quot;(swap! *gensym-counter* (fn* [x] (+ 1 x)))))))\u0026rdquo;\n\u0026ldquo;(defmacro! or (fn* (\u0026amp; xs) (if (empty? xs) nil (if (= 1 (count xs)) (first xs) (let* (condvar (gensym)) `(let* (~condvar ~(first xs)) (if ~condvar ~condvar (or ~@(rest xs)))))))))\u0026rdquo; 如果你想了解更多，请阅读这一篇Peter Seibel\u0026rsquo;s thorough discussion about gensym and leaking macros in Common Lisp\n可选的任务 为其他的复合数据类型 (list, vector和hash-map) 以及原生函数添加 metadata 支持 添加如下新的核心函数： time-ms: 不需要参数，返回从 epoch(1970 年 1 月 1 日 00:00:00 UTC)到当前时间之间的毫秒数。如果不能的话，就返回从某一特定时间点到当前时间之间的毫秒数。(time-ms 通常被用来进行比较，以衡量持续时间）。在实现 time-ms 之后，你可以运行 make perf^quux 来对你的 mal 实现进行性能 benchmark。 conj: 接受一个或更多元素的集合作为参数，返回包含原有集合中的元素以及新元素的集合。如果集合是一个列表，则新元素以逆序插入到列表的前面并返回新列表；如果集合是向量，则新元素被加入到给定的向量的尾部，并返回新向量。 string?: 如果参数是一个字符串，返回 true number?: 如果参数是数字，返回 true fn?: 如果参数是(内建或用户定义的)函数，返回true macro?: 如果参数是宏，返回true seq: 接受一个 列表, 向量, 字符串或者 nil。如果传入的是空列表，空向量，或空字符串(\u0026quot;\u0026quot;)，则返回 nil，否则，如果为列表，则原样返回，如果是向量，则转换为列表并返回；如果是字符串，则将字符串切分为单个字符的字符串列表并返回。 为了实现对目标语言的互操作(interop)，添加如下核心函数: quux-eval: 接受一个字符串，在目标语言中进行求值，并将返回值转换为相应的 mal 类型并返回。你也可以添加一些其他你觉得合适的互操作函数；比如 Clojure，有一个名为 . 的函数，允许调用 Java 的方法。如果目标语言是静态类型语言，尝试使用 FFI 或者一些因语言而异的反射机制。quux-eval 和其他的互操作函数的测试应该添加到 quux/tests/stepA_mal.mal 中。（例子请见lua-eval 的测试） 下一步 加入 #mal IRC 频道。那里其实挺安静的，但有时候会有与mal，Lisp或一些深奥的编程语言相关的讨论。 如果你搞了一个新目标语言的实现（或是现有实现的唯一且有趣的变种），可以考虑向 mal 项目提交 Pull Request。FAQ 解释了一个实现能够被合并到仓库中的通常要求。 让你的解释器实现生成目标语言的源代码，而不是马上执行它。换句话说，做一个编译器。 选一个新的目标语言，用它实现一个 mal。选一个与你所掌握的语言差异较大的语言。 用你的 mal 实现去做一个现实世界的项目。可以考虑实现如下的项目： Web server （以 mal 作为 CGI 语言实现功能扩展） IRC/Slack 聊天机器人 编辑器（用 GUI 或者 curses），以 mal 作为脚本/扩展语言 象棋或者围棋的AI 实现一些本指南中未提到的功能，一些参考： 命名空间 (Namespaces) 多线程支持 带有行号或堆栈信息的报错 惰性序列 Clojure-style 的协议 完整的 call/cc (call-with-current-continuation) 支持 显式的 TCO (例如recur) 带有尾部错误检查\n","permalink":"/zh-cn/posts/note/make-my-lisp-name-lispluo/","series":null,"tags":null,"title":""},{"categories":null,"content":"rust学习 所有权\nRust 的核心功能（之一）是 所有权（ownership）。虽然该功能很容易解释，但它对语言的其他部分有着深刻的影响。\n所有运行的程序都必须管理其使用计算机内存的方式。一些语言中具有垃圾回收机制，在程序运行时不断地寻找不再使用的内存；在另一些语言中，程序员必须亲自分配和释放内存。Rust 则选择了第三种方式：通过所有权系统管理内存，编译器在编译时会根据一系列的规则进行检查。在运行时，所有权系统的任何功能都不会减慢程序。（其他的GC会不断运行来寻找垃圾）\n因为所有权对很多程序员来说都是一个新概念，需要一些时间来适应。好消息是随着你对 Rust 和所有权系统的规则越来越有经验，你就越能自然地编写出安全和高效的代码。持之以恒！\n当你理解了所有权，你将有一个坚实的基础来理解那些使 Rust 独特的功能。在本章中，你将通过完成一些示例来学习所有权，这些示例基于一个常用的数据结构：字符串。\n所有权（系统）是 Rust 最独特的功能，其令 Rust 无需垃圾回收（garbage collector）即可保障内存安全。因此，理解 Rust 中所有权如何工作是十分重要的。\n 栈（Stack）与堆（Heap） 在很多语言中，你并不需要经常考虑到栈与堆。不过在像 Rust 这样的系统编程语言中，值是位于栈上还是堆上在更大程度上影响了语言的行为以及为何必须做出这样的抉择。我们会在本章的稍后部分描述所有权与栈和堆相关的内容，所以这里只是一个用来预热的简要解释。\n栈和堆都是代码在运行时可供使用的内存，但是它们的结构不同。栈以放入值的顺序存储值并以相反顺序取出值。这也被称作 后进先出（last in, first out）。想象一下一叠盘子：当增加更多盘子时，把它们放在盘子堆的顶部，当需要盘子时，也从顶部拿走。不能从中间也不能从底部增加或拿走盘子！增加数据叫做 进栈（pushing onto the stack），而移出数据叫做 出栈（popping off the stack）。\n栈的操作是十分快速的，这主要是得益于它存取数据的方式：因为数据存取的位置总是在栈顶而不需要寻找一个位置存放或读取数据。另一个让操作栈快速的属性是，栈中的所有数据都必须占用已知且固定的大小。\n在编译时大小未知或大小可能变化的数据，要改为存储在堆上。堆是缺乏组织的：当向堆放入数据时，你要请求一定大小的空间。操作系统在堆的某处找到一块足够大的空位，把它标记为已使用，并返回一个表示该位置地址的 指针（pointer）。这个过程称作 在堆上分配内存（allocating on the heap），有时简称为 “分配”（allocating）。将数据推入栈中并不被认为是分配。因为指针的大小是已知并且固定的，你可以将指针存储在栈上，不过当需要实际数据时，必须访问指针。\n想象一下去餐馆就座吃饭。当进入时，你说明有几个人，餐馆员工会找到一个够大的空桌子并领你们过去。如果有人来迟了，他们也可以通过询问来找到你们坐在哪。\n访问堆上的数据比访问栈上的数据慢，因为必须通过指针来访问。现代处理器在内存中跳转越少就越快（缓存）。继续类比，假设有一个服务员在餐厅里处理多个桌子的点菜。在一个桌子报完所有菜后再移动到下一个桌子是最有效率的。从桌子 A 听一个菜，接着桌子 B 听一个菜，然后再桌子 A，然后再桌子 B 这样的流程会更加缓慢。出于同样原因，处理器在处理的数据彼此较近的时候（比如在栈上）比较远的时候（比如可能在堆上）能更好的工作。在堆上分配大量的空间也可能消耗时间。\n栈： ​ 执行期间编译器自动分配，编译器用它实现函数调用，调用函数时，栈增长，函数返回时，栈收缩。局部变量、函数参数、返回数据、返回地址等放在栈中\n栈的特点  内存分配取决于编译器，用户栈在程序运行期间可以动态的扩展和收缩。 和数据结构中的“栈”本质上是不一样的，但是操作方式类似于栈。 数据从栈中的进出满足“后进先出”的规律。 栈向低地址方向增长，esp（栈指针）指向栈顶元素。  堆： ​ 动态储存器分配器维护着的一个进程的虚拟存储器区域。一般由程序员分配释放（堆在操作系统对进程初始化的时候分配），若程序员不释放，程序结束时可能由OS回收，每个进程，内核都维护着一个变量brk指向堆顶。\n堆的特点  内存分配取决于程序员，C/C++可以手动释放该片内存。 在所有权系统中，会自动完成清理堆的活动 和数据结构的”堆“完全两回事，没有半点关系，在这里堆的结构更像链表。 所有的对象，包括数组的对象都存在堆上。 堆内存被所有的线程共享。 引用类型总是放在堆中。 堆向高地址方向增长，内核都维护的变量brk指向堆顶。  注意：值类型和指针总是放在他们被声明的地方（复杂） 当值类型的数据在方法体内被声明时，它们都应该放在栈上。 如果一个只类型被声明在方法体外且存在于一个引用类型中，那么它将会被堆里的引用类型所取代。\n全局区/静态区： ​ 全局变量、静态变量、常量的存储区域，程序终止时系统释放。\n文字常量区： ​ 存放常量字符串，程序结束后由系统释放。\n程序代码区： ​ 存放函数体（类成员函数和全局函数）的二进制代码。\n栈和堆的区别：  栈内存存储的的是局部变量，堆内存存储的是实体。 栈内存的更新的速度会更快些（局部变量），堆内存的更新速度相对更慢。 栈内存的访问直接从地址读取数据到寄存器，然后放到目标地址，而堆内存的访问更麻烦，先将分配的地址放到寄存器，在读取地址的值，最后再放到目标文件中，开销更大。 栈内存是连续的空间，堆内存一般情况不是连续的，频繁地开辟空间，释放空间容易产生内存碎片（外碎片）。  栈和堆的联系： ​ 堆中对象是直接由栈中的句柄（引用）管理者，所以堆负责产生真实对象，栈负责管理对象。\n当你的代码调用一个函数时，传递给函数的值（包括可能指向堆上数据的指针）和函数的局部变量被压入栈中。当函数结束时，这些值被移出栈。\n跟踪哪部分代码正在使用堆上的哪些数据，最大限度的减少堆上的重复数据的数量，以及清理堆上不再使用的数据确保不会耗尽空间，这些问题正是所有权系统要处理的。一旦理解了所有权，你就不需要经常考虑栈和堆了，不过明白了所有权的存在就是为了管理堆数据，能够帮助解释为什么所有权要以这种方式工作。\n 所有权规则   Rust 中的每一个值都有一个被称为其 所有者（owner）的变量。 值有且只有一个所有者。 当所有者（变量）离开作用域，这个值将被丢弃。   内存与分配 就字符串字面值来说，我们在编译时就知道其内容，所以文本被直接硬编码进最终的可执行文件中。这使得字符串字面值快速且高效。不过这些特性都只得益于字符串字面值的不可变性。不幸的是，我们不能为了每一个在编译时大小未知的文本而将一块内存放入二进制文件中，并且它的大小还可能随着程序运行而改变。\n对于 String 类型，为了支持一个可变，可增长的文本片段，需要在堆上分配一块在编译时未知大小的内存来存放内容。这意味着：\n 必须在运行时向操作系统请求内存。 需要一个当我们处理完 String 时将内存返回给操作系统的方法。  第一部分由我们完成：当调用 String::from 时，它的实现 (implementation) 请求其所需的内存。这在编程语言中是非常通用的。\n然而，第二部分实现起来就各有区别了。在有 垃圾回收（garbage collector，GC）的语言中， GC 记录并清除不再使用的内存，而我们并不需要关心它。没有 GC 的话，识别出不再使用的内存并调用代码显式释放就是我们的责任了，跟请求内存的时候一样。从历史的角度上说正确处理内存回收曾经是一个困难的编程问题。如果忘记回收了会浪费内存。如果过早回收了，将会出现无效变量。如果重复回收，这也是个 bug。我们需要精确的为一个 allocate 配对一个 free。\nRust 采取了一个不同的策略：内存在拥有它的变量离开作用域后就被自动释放。\n具体的细节 两个数据指针指向了同一位置。这就有了一个问题：当 s2 和 s1 离开作用域，他们都会尝试释放相同的内存。这是一个叫做 二次释放（double free）的错误，也是之前提到过的内存安全性 bug 之一。两次释放（相同）内存会导致内存污染，它可能会导致潜在的安全漏洞。\n为了确保内存安全，这种场景下 Rust 的处理有另一个细节值得注意。与其尝试拷贝被分配的内存，Rust 则认为 s1 不再有效，因此 Rust 不需要在 s1 离开作用域后清理任何东西。\n因为只有 s2 是有效的，当其离开作用域，它就释放自己的内存，完毕。\n另外，这里还隐含了一个设计选择：Rust 永远也不会自动创建数据的 “深拷贝”。因此，任何 自动 的复制可以被认为对运行时性能影响较小。\n克隆，用于深拷贝 如果我们 确实 需要深度复制 String 中堆上的数据，而不仅仅是栈上的数据，可以使用一个叫做 clone 的通用函数。\nlet s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1.clone(); println!(\u0026#34;s1 = {}, s2 = {}\u0026#34;, s1, s2); 只在栈上的数据：拷贝 这里还有一个没有提到的小窍门。这些代码使用了整型并且是有效的，他们是示例 4-2 中的一部分：\nlet x = 5; let y = x; println!(\u0026#34;x = {}, y = {}\u0026#34;, x, y); 但这段代码似乎与我们刚刚学到的内容相矛盾：没有调用 clone，不过 x 依然有效且没有被移动到 y 中。\n原因是像整型这样的在编译时已知大小的类型被整个存储在栈上，所以拷贝其实际的值是快速的。这意味着没有理由在创建变量 y 后使 x 无效。换句话说，这里没有深浅拷贝的区别.\nCopy trait Rust 有一个叫做 Copy trait 的特殊注解，可以用在类似整型这样的存储在栈上的类型上。如果一个类型拥有 Copy trait，一个旧的变量在将其赋值给其他变量后仍然可用。Rust 不允许自身或其任何部分实现了 Drop trait 的类型使用 Copy trait,比如string。如果我们对其值离开作用域时需要特殊处理的类型使用 Copy 注解，将会出现一个编译时错误。要学习如何为你的类型增加 Copy 注解，请阅读附录 C 中的 “可派生的 trait”。\n那么什么类型是 Copy 的呢？可以查看给定类型的文档来确认，不过作为一个通用的规则，任何简单标量值的组合可以是 Copy 的，不需要分配内存或某种形式资源的类型是 Copy 的。如下是一些 Copy 的类型：\n 所有整数类型，比如 u32。 布尔类型，bool，它的值是 true 和 false。 所有浮点数类型，比如 f64。 字符类型，char。 元组，当且仅当其包含的类型也都是 Copy 的时候。比如，(i32, i32) 是 Copy 的，但 (i32, String) 就不是。  悬垂引用（Dangling References） 在具有指针的语言中，很容易通过释放内存时保留指向它的指针而错误地生成一个 悬垂指针（dangling pointer），所谓悬垂指针是其指向的内存可能已经被分配给其它持有者。相比之下，在 Rust 中编译器确保引用永远也不会变成悬垂状态：当你拥有一些数据的引用，编译器确保数据不会在其引用之前离开作用域。\n字符串字面值就是 slice let s = \u0026#34;Hello, world!\u0026#34;; 这里 s 的类型是 \u0026amp;str：它是一个指向二进制程序特定位置的 slice。这也就是为什么字符串字面值是不可变的；\u0026amp;str 是一个不可变引用。\nstructure 定义结构体，需要使用 struct 关键字并为整个结构体提供一个名字。结构体的名字需要描述它所组合的数据的意义。接着，在大括号中，定义每一部分数据的名字和类型，我们称为 字段（field）。\n使用了自身拥有所有权的 String 类型而不是 \u0026amp;str字符串 slice 类型。这是一个有意而为之的选择，因为我们想要这个结构体拥有它所有的数据，为此只要整个结构体是有效的话其数据也是有效的。可以使结构体存储被其他对象拥有的数据的引用，不过这么做的话需要用上 生命周期（lifetimes）\n使用没有命名字段的元组结构体来创建不同的类型 也可以定义与元组（在第三章讨论过）类似的结构体，称为 元组结构体（tuple structs）。元组结构体有着结构体名称提供的含义，但没有具体的字段名，只有字段的类型。当你想给整个元组取一个名字，并使元组成为与其他元组不同的类型时，元组结构体是很有用的，这时像常规结构体那样为每个字段命名就显得多余和形式化了。定义元组结构体，以 struct 关键字和结构体名开头并后跟元组中的类型。\n没有任何字段的类单元结构体 我们也可以定义一个没有任何字段的结构体，它们被称为 类单元结构体（unit-like structs）因为它们类似于 ()，即 unit 类型。类单元结构体常常在你想要在某个类型上实现 trait 但不需要在类型中存储数据的时候发挥作用。\nDebug 是一个 trait，它允许我们以一种对开发者有帮助的方式打印结构体，以便当我们调试代码时能看到它的值。\n枚举 枚举是一个很多语言都有的功能，不过不同语言中其功能各不相同。Rust 的枚举与Haskell中的 代数数据类型（algebraic data types）最为相似。\n","permalink":"/zh-cn/posts/note/rust%E5%AD%A6%E4%B9%A0/","series":null,"tags":null,"title":""},{"categories":null,"content":"Scala 入门之随便写写\nimport scala.util.control._ object HelloWorld{ def hello(name:String) = { s\u0026#34;Hello ,${name}\u0026#34; } def add(x: Int,y:Int) = x+y def main(args:Array[String]):Unit = { /** * 违反引用透明的例子: * 怎么样获得引用透明性:{ * 需要具有不变性,即为了获得引用透明性,任何值都不能改变 * } */ var x = new StringBuilder(\u0026#34;Hello \u0026#34;); println(x); var y = x.append(\u0026#34; world\u0026#34;); println(y); var z = x.append(\u0026#34; world\u0026#34;); println(z); /** * 递归函数: * 使用递归实现循环 * 尾递归函数 */ /** * 变量: * val 定义immutable variable:常量 * var 定义mutable variable:变量 * lazy val:惰性求值常量 * 可以再定义时不指定变量的类型,Scala会自动进行类型推导 */ println(hello(\u0026#34;Euraxluo\u0026#34;)) println(add(1,2)) /** * for循环 */ val list = List(\u0026#34;Euraxluo\u0026#34;,\u0026#34;xiaoli\u0026#34;,\u0026#34;xiaoxiong\u0026#34;) //循环1  for ( s \u0026lt;- list//generator  )println(s) println(\u0026#34;\u0026#34;) //循环2  for { s\u0026lt;-list if (s.length\u0026gt;6)//filter  }println(s) println(\u0026#34;\u0026#34;) //循环3  val res_for = for { s\u0026lt;- list s1 = s.toUpperCase()//变量绑定  if(s1 != \u0026#34;\u0026#34;) }yield (s1)//将s1放在新的collection中  println(res_for) println(\u0026#34;\u0026#34;) /** * 无限循环 */ // var a = 10 // while (true){ // println(s\u0026#34;a的值:${a}\u0026#34;) // }  /** * 中断循环 */ var loop = new Breaks; val numl = List(0,1,2,3,6,5,6,7) loop.breakable{ for(a\u0026lt;-numl){ println(a) if(a\u0026gt;=6){ loop.break() } } } println(\u0026#34;\u0026#34;) /** * 嵌套循环 */ val outer = new Breaks; val inner = new Breaks; outer.breakable{ for (a\u0026lt;-numl){ inner.breakable{ for (b\u0026lt;-numl){//次数  println(a*a) if (a*a \u0026gt; 36){ inner.break; } } } } } println(\u0026#34;\u0026#34;) /** * try{}catch{}finally{} */ var res_try = try { Integer.parseInt(\u0026#34;sa\u0026#34;) }catch { case _ =\u0026gt; 2222222 }finally { println(\u0026#34;finally\u0026#34;) } println(res_try) println(\u0026#34;\u0026#34;) /** * match */ val code = 600 var res_match = code match { case 200 =\u0026gt; \u0026#34;OK\u0026#34; case 404 =\u0026gt; \u0026#34;Not Found\u0026#34; case 400 =\u0026gt; \u0026#34;Bad Request\u0026#34; case _ =\u0026gt; \u0026#34;Server Error\u0026#34; } println(res_match) println(\u0026#34;\u0026#34;) /** * 重要概念 * 表达式求值策略:严格求值与非严格求值 * Scala中:Call By Value vs. Call By Name * 惰性求值(lazy Evluation): * 当定义表达式时,不会立即求值,而是当这个表达式第一次被调用时才会求值 */ def bar(x:Int,y: =\u0026gt; Int) = x//Call By Value , Call By Name  def Loop():Int= {println(\u0026#34;...\u0026#34;);Loop} //无限循环 // println(bar(Loop,1))//将Loop传给call by value ,函数体中即便没有使用到,也去运行这个无限循环  println(bar(1,Loop))//将Loop传给call by name ,函数体中没有使用到,因此不会去运行这个无限循环  /** * 柯里化 * @param a * @param b * @return */ //def curriedAdd(a:Int,b:Int) = a+b  def curriedAdd(a:Int)(b:Int) = a+b println(curriedAdd(2)(2)) val addOne = curriedAdd(1)_//Int=\u0026gt;Int  println(addOne(2)) println(\u0026#34;\u0026#34;) /** * 递归例子 * n! */ def factorial(n:Int):Int = if (n\u0026lt;=0) 1 else n*factorial(n-1) println(factorial(5)) println(\u0026#34;\u0026#34;) /** * 尾递归函数 * 尾递归函数中所有递归形式的调用都出现在函数的末尾 * 当编译器检测到一个函数调用是尾递归的时候, * 他就会覆盖当前的栈,而不是在栈中创建一个新的 * * 优化:把之前的递归调用的结果保存起来,而不是用栈去做这件事 */ @annotation.tailrec //开启尾递归调用优化  def factorial_tailrec(n:Int,m:Int):Int = if (n\u0026lt;=0) m else factorial_tailrec(n-1,m*n) println(factorial_tailrec(5,1)) println(\u0026#34;\u0026#34;) /** * 求f(x){x=a...b}的和 * @param f :一个func * @param a :x=a * @param b :x=b * @return :返回和 */ def sum (f:Int=\u0026gt;Int)(a:Int)(b:Int):Int = { //定义一个循环  @annotation.tailrec def loop(n: Int,acc:Int):Int = { if (n\u0026gt;b) acc//如果当前N大于b,返回相加结果  else loop(n+1,acc+f(n)) //尾调用优化  } loop(a,0) } println(sum(x=\u0026gt;x)(0)(100)) println(sum(x=\u0026gt;x*x)(0)(5)) val sumSquare = sum(x=\u0026gt;x*x)_ //定义一个函数,是平方的和,_通配a,b  println(sumSquare(1)(5)) println(\u0026#34;\u0026#34;) /** * list相关操作 */ /** * 连接操作 */ val listB = List(5,6,7):::list //连接两个list  for ( s \u0026lt;- listB//generator  )println(s) println(\u0026#34;\u0026#34;) val listC = 6::list //连接一个对象和其他的对象(List/Object)  //list是引用类型,6是值类型,因此listC的类型是List(Any)  for ( s \u0026lt;- listC//generator  )println(s) val listD = \u0026#34;7\u0026#34;::\u0026#34;8\u0026#34;::Nil for ( s \u0026lt;- listD//generator  )println(s) println(\u0026#34;\u0026#34;) /** * head方法,获取第一个元素 */ println(listC.head) /** * tail方法,获取除了第一个元素以外的元素 */ println(listC.tail) /** * isEmpty:判断是否为空 * */ println(listC.isEmpty == Nil.isEmpty) /** * 自己的toString * @param l * @return */ def walkthru(l:List[Any]) :String = { if (l.isEmpty) \u0026#34;\u0026#34; else l.head.toString+\u0026#34; \u0026#34;+walkthru(l.tail) } println(walkthru(listC)) println(\u0026#34;\u0026#34;) /** * filter(func),如果func返回为true,保留此元素 */ val listE = List(1,2,3,4,5) // println(listE.filter(x=\u0026gt;x%2==1))  println(listE.filter(_%2==1)) /** * toList */ println(\u0026#34;Hello Scalar 666\u0026#34;.toList.filter(x=\u0026gt;Character.isDigit(x))) /** * takeWhile,获取元素,指导P返回为False */ println(\u0026#34;Hello Scalar 666\u0026#34;.toList.takeWhile(x =\u0026gt; !Character.isDigit(x))) /** * map */ println(\u0026#34;Hello Scalar 66\u0026#34;.toList.map(_.toUpper)) /** * flatMap */ val l1 = List(List(3,4),List(4,5,6)) println(l1) //map 返回值与原来的类型一致  println(l1.map(_.filter(_%2==0))) //会将多层的容器打平  println(l1.flatMap(_.filter(_%2==0))) println(\u0026#34;\u0026#34;) /** * reduce */ println(listE.reduce(_+_))//==reduceLeft  println(listE.reduceLeft(_+_)) /** * foldLeft */ println(listE.fold(0)(_+_)) println(listE.fold(1)(_*_))//会根据U的值进行类型改变  /** * Range */ /** * to */ println((1 to 10).toList) /** * until */ println((1 until 10).toList) /** * stream is a lazy List */ val s1 = 1 #:: 2 #:: 3 #:: Stream.empty println(s1) val s2 = (1 to 1000000).toStream println(s2.tail) println(\u0026#34;\u0026#34;) /** * tuple */ /** * paire */ println((1,2)) println(1-\u0026gt;2) val t1 = (1,\u0026#34;Euraxluo\u0026#34;,21,\u0026#34;男\u0026#34;) println(\u0026#34;Euraxluo is :\u0026#34;+t1._4) println(\u0026#34;\u0026#34;) /** * * @param l:一个List * @return (List元素个数,List元素和,List元素平方和) */ def sumSq(l:List[Int]):(Int,Int,Int) = l.foldLeft((0,0,0))((t, v) =\u0026gt; (t._1 + 1, t._2 + v, t._3 + v * v)) println(sumSq(listE)) println(\u0026#34;\u0026#34;) /** * Map */ val map = Map(1-\u0026gt;\u0026#34;Euraxluo\u0026#34;,2-\u0026gt;\u0026#34;hehe\u0026#34;,4-\u0026gt;\u0026#34;sa\u0026#34;) println(map) println(map(4))//通过key获取value  println(map.contains(3))//判断是否有这个key  println(map.keys)//获取keys  println(map.values)//获取values  /** * +:添加一个k-v * 返回一个新Map */ println(map+(6-\u0026gt;\u0026#34;hehheheh\u0026#34;)) /** * -:根据key删除一个k-v * 返回一个新Map */ println(map - 1) /** * ++:添加多个 */ println( map ++ List(22-\u0026gt;\u0026#34;alice\u0026#34;,51-\u0026gt;\u0026#34;sas\u0026#34;)) /** * --:删除多个 */ println(map -- List(1,2)) println(\u0026#34;\u0026#34;) /** * 递归实现的快速排序 * @param l * @return */ def qSort(l:List[Int]):List[Int] = if (l.length \u0026lt; 2 ) l//如果List元素小于两个,返回其自身  else qSort(l.filter(_\u0026lt;l.head)) ++ //小于l.head的部分,然后加上剩下部分  l.filter(_==l.head) ++ //等于l.head的部分,加上大于l.head的部分  qSort(l.filter(_ \u0026gt; l.head))//大于l.head的部分  println(qSort(List(9,3,7,6,5,4,2,8,1))) } } //函数式编程的重要概念 //引用透明:对于相同的输入,总是得到相同的输出 //如果F(x)的参数x和函数体都是引用透明的,那么函数F是纯函数 ","permalink":"/zh-cn/posts/note/scala-%E5%85%A5%E9%97%A8%E4%B9%8B%E9%9A%8F%E4%BE%BF%E5%86%99%E5%86%99/","series":null,"tags":null,"title":""},{"categories":null,"content":"TCP的三次握手和四次挥手\n三次握手: 为什么需要三次握手? 客户端:我可以发东西给你(确保客户端的发送能力) 服务器:我可以收到,你能收到么?(确保服务器的接受和发送) 客户端:我能收到!(确保能收到)\n连接建立!\n如果是四次握手? 没必要啊,第三次已经确认可以收到消息了\n如果是两次握手? 当网络阻塞时,客户端会发送两次,第一次请求到达服务器的时间慢于第二次 如果当时通信结束,服务器又收到了第一次阻塞的消息,如果是两次握手,就会分配资源 然而客户端已经完成了通信,不需要再连接了,会造成资源的浪费和安全隐患\n四次挥手: 客户端:我说完了,我想停止发送请求了 服务器:我知道你要停止发送了,我会停止接受消息 ( 服务器停止接受消息,但是可能还有很多待发送的消息\n客户端:收到服务器的确认信息,于是默不作声,等待服务器发送完他的消息\n) 服务器:我的东西全发完啦!,我想要停止发送消息啦! 客户端:我知道你也要停止发送了,我也要停止接收消息(实际上还等了两个最大周期才真正停止接收消息) ( 服务器:收到了客户端的确认消息,于是停止发送消息 )\n关于tcp的博客 使用tcp和udp让进程之间进行通信\nip地址：用來標記網絡上的主機 動態端口：1024-65535的端口，用完就回收\ntcp socket client的基本流程\nimport socket ##創建socket s = socket.socket(socket.af_inet,socket.sock_stream) ##使用 ipaddr = (\u0026#34;ip\u0026#34;,port)#服务器的ip addr s.connect(ipaddr)#连接服务器 ### 发送数据 send_msg = \u0026#34;sasa\u0026#34; s.send(send_msg.encode(\u0026#34;utf-8\u0026#34;)) ### 接受数据 recvData = s.rec(1024)#一次接收的字符数 print(\u0026#34;recved msg:\u0026#34;,recvData.decode(\u0026#34;\u0026#34;utf-8)) ##關閉 s.close() tcp server的基本过程\n# socket创建套接字 tcp = socket.socket(socket.AF_INET,socket.SOCK_STREAM) # 绑定端口 tcp.bind((\u0026#34;127.1\u0026#34;,7788)) # 设置为被动监听 tcp.listen(128) while True: #等待客户端的连接 #tcp套接字,现在用来被动接听 # accept阻塞等待链接 new_client_socket,client_addr = tcp.accept()#阻塞等待一个客户端进行conect,返回元组: 新的套接字,(客户端的ip,端口) #有客户端connect后,阻塞解除,返回connect的一个客户端的addr,以及已经和客户端完成连接的套接字,接下来的收发都是用这个新的socket while True: # 处理请求,先收,再发,因此,这里会阻塞等待这个new_client_socket接收到消息 recv_data = new_client_socket.recv(1024) print(recv_data) #当recv解阻塞时,有两种情况,1.客户端发送了消息 ;2.客户端调用了close() #通过判断recv_data是否为空,那么判断出客户端断开了链接 if recv_data: #收到消息后,我们返回一下,非必要的 new_client_socket.send(\u0026#34;服务器返回的消息\u0026#34;.encode(\u0026#39;utf-8\u0026#39;)) else: break new_client_socket.close() tcp.close() 創建一個udp socket\nimport socket ##創建 send_data = input(\u0026#34;input:\u0026#34;) s = socket.socket(socket.AF_INET,socket.SOCK_DGRAM) #bind a port,接受方可以不绑定 s.bind(\u0026#34;\u0026#34;,7890) ##使用 #s.sendto(b\u0026#34;test\u0026#34;,(\u0026#34;127.1\u0026#34;,8888))#需要使用二进制第二个参数是元组 s.sendto(send_data.encode(\u0026#34;utf-8\u0026#34;),(\u0026#34;127.1\u0026#34;,8888))#需要编码 s.close()#关闭 socket.socket(AddressFamily,Type) AddressFamily:協議族 Type:套接字類型\n绑定端口接收数据\nimport socket def main(): #创建套接字 udp = socket.socket(socket.AF_INET,socket.SOCK_DGRAM) #绑定端口 localaddr = (\u0026#34;\u0026#34;,7788) udp.bind(localaddr) #接收数据 recv_data = udp.recvfrom(1024)#可以接收的最大字节数 #打印接受的数据 #会接收到一个元组二进制流,发送方地址 msg = recv_data[0] sendaddr = recv_data[1] print(\u0026#34;%s:%s\u0026#34;%str(sendaddr),msg.decode(\u0026#34;utf-8\u0026#34;))#需要解码 #关闭套接字 udp.close() if __name__ == \u0026#34;__main__\u0026#34;: main() 一个套接字可以同时接收全双工的\n一个攻击 扫描端口向缓冲区发送数据\n使用tcp进行文件下载\nclient:\nimport socket def main(): #1.创建套接字 tcp_socket = socket.socket(socket.AF_INET,socket.SOCK_STREAM) #2.获取服务器的ip port dest_ip = input(\u0026#34;ip:\u0026#34;) dest_port = input(\u0026#34;port:\u0026#34;) #3.连接服务器 tcp_socket.connect((dest_ip,dest_port)) #4.获取下载的名字 download_file_name = input(\u0026#34;input the file name\u0026#34;) #5.将名字发送到服务器 tcp_socket.send(download_file_name.encode(\u0026#34;utf-8\u0026#34;)) #6.接受文件中的数据 recv_data = tcp_socket.recv(1024)#1k if recv_data: #7.保存文件中的数据 with open(\u0026#34;[new]\u0026#34;+download_file_name,\u0026#34;wb\u0026#34;) as f: f.write(recv_data) #8.关闭套接字 tcp_socket.close() if __name__ == \u0026#34;__main__\u0026#34;: main() server:\nimport socket def send_file2client(new_client_socket,client_addr): #1.接受客户端需要下载的文件名 file_name = new_client_socket.recv(1024).decode(\u0026#39;utf-8\u0026#39;) print(\u0026#34;客户端下载的文件是:%s\u0026#34;%(str(client_addr),file_name)) #2.打开这个文件,读取数据 file_content = None try: f = open(file_name,\u0026#34;rb\u0026#34;) file_content = f.read() f.close() except Exception as ret: print(\u0026#34;没有要下载的文件(%s)\u0026#34;%file_name) #3.发送文件的数据给客户端 if file_content: new_client_socket.send(file_conect) def main(): # socket创建套接字 tcp_socket = socket.socket(socket.AF_INET,socket.SOCK_STREAM) # 绑定端口 tcp_socket .bind((\u0026#34;127.1\u0026#34;,7788)) # 设置为被动监听 tcp_socket .listen(128) while True: # accept阻塞等待链接 new_client_socket,client_addr = tcp_socket .accept()#阻塞等待一个客户端进行conect,返回元组: 新的套接字,(客户端的ip,端口) # 调用函数,发送文件 send_file2client(new_client_socket,client_addr) # 关闭套接字 new_client_socket.close() tcp_socket .close() if __name__ == \u0026#34;__main__\u0026#34;: main() ","permalink":"/zh-cn/posts/note/socket/","series":null,"tags":null,"title":""},{"categories":null,"content":"VSLAM ## project1 熟悉Linux   sudo apt-get install 安装软件，apt-get 下载后软件的路径一般为/var/cache/apt/archives\n具体的安装目录是由包维护者决定\n  可以通过echo $PATH查看当前的PATH，通过export PATH=$PATH:/XXX/XXX将需要的配置路径加入$PATH等号两边不能有空格\n  /usr/bin可执行文件 ，/usr/share文档的路径， /usr/liblib文件， /etc配置文件\n  chmod +x 文件名 为文件增加可执行权限\n  chown root filename 更改文件的所有者\n  SLAM综述文献阅读 Visual Simultaneous Localization and Mapping:A Survey 最初，定位与建图是独立的。但是要在一个环境中精确的定位，必须有一个正确的地图；但是为了构造一个好的地图，必须在构造地图是，添加合适的定位信息\nVSLAM系统在以下条件下会失败：外部环境，动态环境，显著特征太多或者太少的环境，大规模环境，相机不稳定运动以及传感器发生部分或全部遮挡。一个成功的VSLAM系统的关键是可以在以下环境中任然能够正确操作。\n为了从环境中构建地图，物体必须拥有传感器。使其能够感知并获得周围环境中元素的测量值。这些传感器分为外部感受和本体感受。在外部传感器中有可能找到声纳、距离激光器，gps。所有的这戏传感器都是有噪声的，而且范围有限。此外，使用这些传感器只能获得环境的局部视图。\n同时他们有以下问题：\n1.在高度杂乱的环境中或在识别对象时，没有用处。者两种机器人都很昂贵，笨重，而且由大型设备组成，是的他们难以用于机载，而GPS传感器在狭窄的街道，水下，其他星球不能很好的工作。\n本体传感器可以获得位姿信息，速度，位置变化，加速度等测量值，但是这些方法不足以始终准确的估计实体位置，因为误差会累计\n使用相机作为唯一的外部传感器。\n基于摄像头的系统能够获取距离信息，同时也能获取环境的外观，颜色和纹理，这使得机器人可以集成其他高级任务，如对人和地点的检测和识别。并且相机更便宜更轻。\n","permalink":"/zh-cn/posts/note/vslam/","series":null,"tags":null,"title":""},{"categories":null,"content":"关于musicplayer 首先给权限 \u0026lt;!-- 网络权限 --\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.INTERNET\u0026#34;/\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.READ_EXTERNAL_STORAGE\u0026#34;/\u0026gt; \u0026lt;!-- 向SD卡写入数据权限 --\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.WRITE_EXTERNAL_STORAGE\u0026#34;/\u0026gt; \u0026lt;!-- 在SD卡中创建与删除文件权限 --\u0026gt; \u0026lt;!-- 扫描数据库的权限 --\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.MOUNT_UNMOUNT_FILESYSTEMS\u0026#34; tools:ignore=\u0026#34;ProtectedPermissions\u0026#34;/\u0026gt; 包含ListView的布局文件\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;LinearLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:orientation=\u0026#34;vertical\u0026#34; android:layout_gravity=\u0026#34;center\u0026#34; tools:context=\u0026#34;.MainActivity\u0026#34;\u0026gt; \u0026lt;LinearLayout android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;400dp\u0026#34; android:orientation=\u0026#34;vertical\u0026#34;\u0026gt; \u0026lt;ListView android:id=\u0026#34;@+id/lv1\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34;\u0026gt;\u0026lt;/ListView\u0026gt; \u0026lt;/LinearLayout\u0026gt; \u0026lt;SeekBar android:id=\u0026#34;@+id/sb\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;30dp\u0026#34; android:maxHeight=\u0026#34;2dp\u0026#34; android:minHeight=\u0026#34;2dp\u0026#34; android:paddingBottom=\u0026#34;3dp\u0026#34; android:paddingLeft=\u0026#34;12dp\u0026#34; android:max=\u0026#34;200\u0026#34; android:paddingRight=\u0026#34;12dp\u0026#34; android:paddingTop=\u0026#34;3dp\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv1\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; /\u0026gt; \u0026lt;LinearLayout android:orientation=\u0026#34;horizontal\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34;\u0026gt; \u0026lt;cn.study.euraxluo.androidtup.CircleImageView android:id=\u0026#34;@+id/imageView\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;70dp\u0026#34; android:scaleType=\u0026#34;centerCrop\u0026#34; /\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_last\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;@string/btn_last\u0026#34;/\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_star\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;@string/btn_star\u0026#34;/\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_next\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;@string/btn_next\u0026#34;/\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_stop\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;@string/btn_stop\u0026#34;/\u0026gt; \u0026lt;/LinearLayout\u0026gt; \u0026lt;/LinearLayout\u0026gt; MainActivity.java\npublic class MainActivity extends AppCompatActivity implements Runnable { private static final String TAG = \u0026#34;MainActivity\u0026#34;; int flag = 1;//设置一个标志，供点击“开始/暂停”按钮使用  private Button btnStart, btnStop, btnNext, btnLast; private TextView txtInfo; private ListView listView; private SeekBar seekBar; private MusicService musicService; private Handler handler;// 处理改变进度条事件  int UPDATE = 0x101; private boolean autoChange, manulChange;// 判断是进度条是自动改变还是手动改变  private boolean isPause;// 判断是从暂停中恢复还是重新播  AudioUtils audioUtils = new AudioUtils(); // ArrayList\u0026lt;Song\u0026gt; songs;  Bitmap musicFm;//音乐的封面的bitmap  private ImageView imageView;//封面的imageView  RotateAnimation rotateAnimation;//特效  @Override protected void onCreate(Bundle savedInstanceState) { Log.d(TAG,\u0026#34;onCreate\u0026#34;); super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); Log.d(TAG,\u0026#34;checkSelfPermission\u0026#34;); //关于验证的函数，如果缺少这两个函数，那么需要自己开启应用的权限  //判断权限,申请权限  if (ContextCompat.checkSelfPermission(MainActivity.this, Manifest.permission.WRITE_EXTERNAL_STORAGE ) != PackageManager.PERMISSION_GRANTED) { ActivityCompat.requestPermissions(MainActivity.this, new String[]{Manifest .permission.WRITE_EXTERNAL_STORAGE}, 1); } else { initMediaPlayer(); } if (ContextCompat.checkSelfPermission(MainActivity.this, Manifest.permission.READ_EXTERNAL_STORAGE ) != PackageManager.PERMISSION_GRANTED) { ActivityCompat.requestPermissions(MainActivity.this, new String[]{Manifest .permission.READ_EXTERNAL_STORAGE}, 2); } else { initMediaPlayer(); } } //关于验证的函数  //请求权限处理回调  @Override public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) { Log.d(TAG,\u0026#34;onRequestPermissionsResult\u0026#34;); switch (requestCode) { case 1: if (grantResults.length \u0026gt; 0 \u0026amp;\u0026amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) { initMediaPlayer(); } else { Toast.makeText(this, \u0026#34;获取授权失败\u0026#34;, Toast.LENGTH_SHORT).show(); } break; case 2: if (grantResults.length \u0026gt; 0 \u0026amp;\u0026amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) { initMediaPlayer(); } else { Toast.makeText(this, \u0026#34;正在获取授权\u0026#34;, Toast.LENGTH_SHORT).show(); } break; default: Toast.makeText(this, \u0026#34;获取授权失败\u0026#34;, Toast.LENGTH_SHORT).show(); } } //如果有权限就会运行这里的函数  private void initMediaPlayer() { Log.d(TAG,\u0026#34;init MediaPlayer \u0026#34;); //必须在获取权限后new MusicService，  musicService = new MusicService(); /* 非扫描的方式获取的音乐，是从数据库中直接获取 songs = audioUtils.getAllSongs(this); // for (Song song:songs){ // musicService.test(songs.get(0)); Bitmap fm = songs.get(0).getThumbnail(); imageView.setImageBitmap(fm); Toast.makeText(this, songs.get(0).getFileName()+\u0026#34; \u0026#34;+songs.size(), Toast.LENGTH_SHORT).show(); // } */ try { setListViewAdapter(); } catch (Exception e) { Log.i(\u0026#34;TAG\u0026#34;, \u0026#34;读取信息失败\u0026#34;); } imageView = (ImageView) findViewById(R.id.imageView); btnStart = (Button) findViewById(R.id.btn_star); //初始化特效  rotateAnimation = new RotateAnimation(0,360, Animation.RELATIVE_TO_SELF,0.5f, Animation.RELATIVE_TO_SELF,0.5f); //开始的监听按钮，我们可以直接从这开始  btnStart.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { try { /** * flag为1 的时候，此时player内没有东西，所以执行musicService.play()函数 * 进行第一次播放，然后flag自增二不再进行第一次播放 * 当再次点击“开始/暂停”按钮次数即大于1 将执行暂停或继续播放goplay()函数 */ if (flag == 1) { btnStart.setText(R.string.btn_pause); Rotate();//旋转开始  musicService.play(); flag++; } else { if (!musicService.player.isPlaying()) { btnStart.setText(R.string.btn_pause); Rotate();//旋转开始  musicService.goPlay(); } else if (musicService.player.isPlaying()) { btnStart.setText(R.string.btn_star); rotateAnimation.cancel();//暂停图片  musicService.pause(); } } } catch (Exception e) { Log.i(\u0026#34;LAT\u0026#34;, \u0026#34;开始异常！\u0026#34;); } } }); btnStop = (Button) findViewById(R.id.btn_stop); btnStop.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { try { btnStart.setText(R.string.btn_star); rotateAnimation.cancel();//暂停旋转  musicService.stop(); flag = 1;//当点击停止按钮时，flag置为1  seekBar.setProgress(0); txtInfo.setText(\u0026#34;播放已经停止\u0026#34;); } catch (Exception e) { Log.i(\u0026#34;LAT\u0026#34;, \u0026#34;停止异常！\u0026#34;); } } }); btnLast = (Button) findViewById(R.id.btn_last); btnLast.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { try { btnStart.setText(R.string.btn_pause); Rotate();//继续旋转  musicService.last(); } catch (Exception e) { Log.i(\u0026#34;LAT\u0026#34;, \u0026#34;上一曲异常！\u0026#34;); } } }); btnNext = (Button) findViewById(R.id.btn_next); btnNext.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { try { btnStart.setText(R.string.btn_pause); // Rotate();//继续旋转  rotateAnimation.startNow(); musicService.next(); } catch (Exception e) { Log.i(\u0026#34;LAT\u0026#34;, \u0026#34;下一曲异常！\u0026#34;); } } }); seekBar = (SeekBar) findViewById(R.id.sb); seekBar.setOnSeekBarChangeListener(new SeekBar.OnSeekBarChangeListener() { @Override public void onProgressChanged(SeekBar seekBar, int i, boolean b) {//用于监听SeekBar进度值的改变  } @Override public void onStartTrackingTouch(SeekBar seekBar) {//用于监听SeekBar开始拖动  } @Override public void onStopTrackingTouch(SeekBar seekBar) {//用于监听SeekBar停止拖动 SeekBar停止拖动后的事件  int progress = seekBar.getProgress(); Log.i(\u0026#34;TAG:\u0026#34;, \u0026#34;\u0026#34; + progress + \u0026#34;\u0026#34;); int musicMax = musicService.player.getDuration(); //得到该首歌曲最长秒数  int seekBarMax = seekBar.getMax(); musicService.player .seekTo(musicMax * progress / seekBarMax);//跳到该曲该秒  autoChange = true; manulChange = false; } }); txtInfo = (TextView) findViewById(R.id.tv1); Thread t = new Thread(this);// 自动改变进度条的线程  //实例化一个handler对象  handler = new Handler() { @Override public void handleMessage(Message msg) { super.handleMessage(msg); //更新UI  int mMax = musicService.player.getDuration();//最大秒数  if (msg.what == UPDATE) { try { seekBar.setProgress(msg.arg1); txtInfo.setText(setPlayInfo(msg.arg2 / 1000, mMax / 1000)); } catch (Exception e) { e.printStackTrace(); } } else { seekBar.setProgress(0); txtInfo.setText(\u0026#34;播放已经停止\u0026#34;); } } } ; t.start(); } //向列表添加MP3名字，和listView有关的函数  private void setListViewAdapter() { Log.d(TAG,\u0026#34;musicList.size:\u0026#34;+musicService.musicList.size()); String[] str = new String[musicService.musicList.size()]; int i = 0; for (String path : musicService.musicList) { File file = new File(path); str[i++] = file.getName(); } ArrayAdapter adapter = new ArrayAdapter(this, android.R.layout.simple_list_item_1,str); listView = (ListView) findViewById(R.id.lv1); listView.setAdapter(adapter); //通过播放的音乐路径来得到音乐大的封面  String dataSource = musicService.musicList.get(musicService.songNum);//得到当前播放音乐的路径  musicFm = audioUtils.createAlbumArt(dataSource); imageView.setImageBitmap(musicFm); } @Override public void run() {//这里需要新开一个线程在后台播放，同时需要控制bar，因此需要service通信  int position, mMax, sMax; while (!Thread.currentThread().isInterrupted()) { if (musicService.player != null \u0026amp;\u0026amp; musicService.player.isPlaying()) { position = musicService.getCurrentProgress();//得到当前歌曲播放进度(秒)  mMax = musicService.player.getDuration();//最大秒数  sMax = seekBar.getMax();//seekBar最大值，算百分比  Message m = handler.obtainMessage();//获取一个Message  m.arg1 = position * sMax / mMax;//seekBar进度条的百分比  m.arg2 = position; m.what = UPDATE; handler.sendMessage(m); // handler.sendEmptyMessage(UPDATE);  try { Thread.sleep(1000);// 每间隔1秒发送一次更新消息  } catch (InterruptedException e) { e.printStackTrace(); } } } } //设置当前播放的信息  private String setPlayInfo(int position, int max) { //设置图片  String dataSource = musicService.musicList.get(musicService.songNum);//得到当前播放音乐的路径  musicFm = audioUtils.createAlbumArt(dataSource); imageView.setImageBitmap(musicFm); //设置音乐信息  String info = \u0026#34;正在播放: \u0026#34; + musicService.songName + \u0026#34;\\t\\t\u0026#34;; int pMinutes = 0; while (position \u0026gt;= 60) { pMinutes++; position -= 60; } String now = (pMinutes \u0026lt; 10 ? \u0026#34;0\u0026#34; + pMinutes : pMinutes) + \u0026#34;:\u0026#34; + (position \u0026lt; 10 ? \u0026#34;0\u0026#34; + position : position); int mMinutes = 0; while (max \u0026gt;= 60) { mMinutes++; max -= 60; } String all = (mMinutes \u0026lt; 10 ? \u0026#34;0\u0026#34; + mMinutes : mMinutes) + \u0026#34;:\u0026#34; + (max \u0026lt; 10 ? \u0026#34;0\u0026#34; + max : max); return info + now + \u0026#34; / \u0026#34; + all; } //音乐封面旋转特效  public void Rotate(){ // AnimationSet animationSet = new AnimationSet(true);  rotateAnimation.setDuration(20000);//设定转一圈的时间  rotateAnimation.setRepeatCount(Animation.INFINITE);//设定无限循环  rotateAnimation.setRepeatMode(Animation.RESTART);//  // animationSet.addAnimation(rotateAnimation);  imageView.startAnimation(rotateAnimation); } } 我的MusicService文件\npublic class MusicService { private static final File PATH = Environment.getExternalStorageDirectory();// 获取SD卡总目录。  public List\u0026lt;String\u0026gt; musicList;// 存放找到的所有mp3的绝对路径。  public MediaPlayer player; // 定义多媒体对象  public int songNum; // 当前播放的歌曲在List中的下标,flag为标致  public String songName; // 当前播放的歌曲名  class MusicFilter implements FilenameFilter { public boolean accept(File dir, String name) { return (name.endsWith(\u0026#34;.mp3\u0026#34;));//返回当前目录所有以.mp3结尾的文件  } } public MusicService() { super(); player = new MediaPlayer(); musicList = new ArrayList\u0026lt;String\u0026gt;(); try { File MUSIC_PATH = new File(PATH, \u0026#34;netease/cloudmusic/Music\u0026#34;);//获取Music文件的二级目录  if (MUSIC_PATH.listFiles(new MusicFilter()).length \u0026gt; 0) { for (File file : MUSIC_PATH.listFiles(new MusicFilter())) { musicList.add(file.getAbsolutePath()); } } } catch (Exception e) { Log.i(\u0026#34;TAG\u0026#34;, \u0026#34;读取文件异常\u0026#34;); } } public void setPlayName(String dataSource) { File file = new File(dataSource);//假设为D:\\\\mm.mp3  String name = file.getName();//name=mm.mp3  int index = name.lastIndexOf(\u0026#34;.\u0026#34;);//找到最后一个.  songName = name.substring(0, index);//截取为mm  } public void play() { try { player.reset(); //重置多媒体  String dataSource = musicList.get(songNum);//得到当前播放音乐的路径  setPlayName(dataSource);//截取歌名  // 指定参数为音频文件  player.setAudioStreamType(AudioManager.STREAM_MUSIC); player.setDataSource(dataSource);//为多媒体对象设置播放路径  player.prepare();//准备播放  player.start();//开始播放  //setOnCompletionListener 当当前多媒体对象播放完成时发生的事件  player.setOnCompletionListener(new MediaPlayer.OnCompletionListener() { public void onCompletion(MediaPlayer arg0) { next();//如果当前歌曲播放完毕,自动播放下一首.  } }); } catch (Exception e) { Log.v(\u0026#34;MusicService\u0026#34;, e.getMessage()); } } /*和数据库有关的 public void test(Song song){//测试数据库 try { player.reset(); //重置多媒体 String dataSource = song.getFileUrl(); // String dataSource = musicList.get(songNum);//得到当前播放音乐的路径 setPlayName(dataSource);//截取歌名 // 指定参数为音频文件 player.setAudioStreamType(AudioManager.STREAM_MUSIC); player.setDataSource(dataSource);//为多媒体对象设置播放路径 player.prepare();//准备播放 player.start();//开始播放 //setOnCompletionListener 当当前多媒体对象播放完成时发生的事件 player.setOnCompletionListener(new MediaPlayer.OnCompletionListener() { public void onCompletion(MediaPlayer arg0) { next();//如果当前歌曲播放完毕,自动播放下一首. } }); } catch (Exception e) { Log.v(\u0026#34;MusicService\u0026#34;, e.getMessage()); } } */ //继续播放  public void goPlay() { int position = getCurrentProgress(); player.seekTo(position);//设置当前MediaPlayer的播放位置，单位是毫秒。  try { player.prepare();// 同步的方式装载流媒体文件。  } catch (Exception e) { e.printStackTrace(); } player.start(); } // 获取当前进度  public int getCurrentProgress() { if (player != null \u0026amp; player.isPlaying()) { return player.getCurrentPosition(); } else if (player != null \u0026amp; (!player.isPlaying())) { return player.getCurrentPosition(); } return 0; } public void next() { songNum = songNum == musicList.size() - 1 ? 0 : songNum + 1; play(); } public void last() { songNum = songNum == 0 ? musicList.size() - 1 : songNum - 1; play(); } // 暂停播放  public void pause() { if (player != null \u0026amp;\u0026amp; player.isPlaying()) { player.pause(); } } public void stop() { if (player != null \u0026amp;\u0026amp; player.isPlaying()) { player.stop(); player.reset(); } } } 我的圆形封面\npackage cn.study.euraxluo.androidtup;/* AndroidTup * cn.study.euraxluo.androidtup * CircleImageView * 2019/5/13 13:26 * author:Euraxluo * TODO */ import android.content.Context; import android.graphics.*; import android.graphics.drawable.BitmapDrawable; import android.graphics.drawable.ColorDrawable; import android.graphics.drawable.Drawable; import android.support.annotation.Nullable; import android.util.AttributeSet; import android.widget.ImageView; public class CircleImageView extends android.support.v7.widget.AppCompatImageView { private Paint mPaintBitmap = new Paint(Paint.ANTI_ALIAS_FLAG); private Bitmap mRawBitmap; private BitmapShader mShader; private Matrix mMatrix = new Matrix(); public CircleImageView(Context context,AttributeSet attrs) { super(context, attrs); } @Override protected void onDraw(Canvas canvas) { Bitmap rawBitmap = getBimap(getDrawable()); if (rawBitmap != null) { int viewWidth = getWidth(); int viewHeight = getHeight(); int viewMinSize = Math.min(viewWidth, viewHeight); float dstHeight = viewMinSize; float dstWidth = viewMinSize; if (mShader == null || !rawBitmap.equals(mRawBitmap)) { mRawBitmap = rawBitmap; mShader = new BitmapShader(mRawBitmap, Shader.TileMode.CLAMP, Shader.TileMode.CLAMP); } if (mShader != null) { mMatrix.setScale(dstWidth / rawBitmap.getWidth(), dstHeight / rawBitmap.getHeight()); mShader.setLocalMatrix(mMatrix); } mPaintBitmap.setShader(mShader); float radius = viewMinSize / 2.0f; canvas.drawCircle(radius, radius, radius, mPaintBitmap); } else super.onDraw(canvas); } private Bitmap getBimap(Drawable drawable) { if (drawable instanceof BitmapDrawable) { return ((BitmapDrawable) drawable).getBitmap(); } else if (drawable instanceof ColorDrawable) { Rect rect = drawable.getBounds(); int width = rect.right - rect.left; int height = rect.bottom - rect.top; int color = ((ColorDrawable) drawable).getColor(); Bitmap bitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888); Canvas canvas = new Canvas(bitmap); canvas.drawARGB(Color.alpha(color), Color.red(color), Color.green(color), Color.blue(color)); return bitmap; } else return null; } }  数据库扫描用的：Song实体类\npackage cn.study.euraxluo.androidtup; import android.graphics.Bitmap; public class Song { private String fileName; private String title; private int duration; private String singer; private String album; private String year; private String type; private String size; private String fileUrl; private Bitmap Thumbnail; public Bitmap getThumbnail() { return Thumbnail; } public void setThumbnail(Bitmap thumbnail) { Thumbnail = thumbnail; } public String getFileName() { return fileName; } public void setFileName(String fileName) { this.fileName = fileName; } public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public int getDuration() { return duration; } public void setDuration(int duration) { this.duration = duration; } public String getSinger() { return singer; } public void setSinger(String singer) { this.singer = singer; } public String getAlbum() { return album; } public void setAlbum(String album) { this.album = album; } public String getYear() { return year; } public void setYear(String year) { this.year = year; } public String getType() { return type; } public void setType(String type) { this.type = type; } public String getSize() { return size; } public void setSize(String size) { this.size = size; } public String getFileUrl() { return fileUrl; } public void setFileUrl(String fileUrl) { this.fileUrl = fileUrl; } public Song() { super(); } public Song(String fileName, String title, int duration, String singer, String album, String year, String type, String size, String fileUrl) { super(); this.fileName = fileName; this.title = title; this.duration = duration; this.singer = singer; this.album = album; this.year = year; this.type = type; this.size = size; this.fileUrl = fileUrl; } @Override public String toString() { return \u0026#34;Song [fileName=\u0026#34; + fileName + \u0026#34;, title=\u0026#34; + title + \u0026#34;, duration=\u0026#34; + duration + \u0026#34;, singer=\u0026#34; + singer + \u0026#34;, album=\u0026#34; + album + \u0026#34;, year=\u0026#34; + year + \u0026#34;, type=\u0026#34; + type + \u0026#34;, size=\u0026#34; + size + \u0026#34;, fileUrl=\u0026#34; + fileUrl + \u0026#34;]\u0026#34;; } } 扫描数据的AudioUtils.java\npackage cn.study.euraxluo.androidtup; import android.content.Context; import android.database.Cursor; import android.graphics.Bitmap; import android.graphics.BitmapFactory; import android.media.MediaMetadataRetriever; import android.provider.MediaStore; import java.util.ArrayList; public class AudioUtils { /** * 获取sd卡所有的音乐文件 * * @return * @throws Exception */ public static ArrayList\u0026lt;Song\u0026gt; getAllSongs(Context context) { ArrayList\u0026lt;Song\u0026gt; songs = null; Cursor cursor = context.getContentResolver().query( MediaStore.Audio.Media.EXTERNAL_CONTENT_URI, new String[] { MediaStore.Audio.Media._ID, MediaStore.Audio.Media.DISPLAY_NAME, MediaStore.Audio.Media.TITLE, MediaStore.Audio.Media.DURATION, MediaStore.Audio.Media.ARTIST, MediaStore.Audio.Media.ALBUM, MediaStore.Audio.Media.YEAR, MediaStore.Audio.Media.MIME_TYPE, MediaStore.Audio.Media.SIZE, MediaStore.Audio.Media.DATA }, MediaStore.Audio.Media.MIME_TYPE + \u0026#34;=? or \u0026#34; + MediaStore.Audio.Media.MIME_TYPE + \u0026#34;=?\u0026#34;, new String[] { \u0026#34;audio/mpeg\u0026#34;, \u0026#34;audio/x-ms-wma\u0026#34; }, null); songs = new ArrayList\u0026lt;Song\u0026gt;(); if (cursor.moveToFirst()) { Song song = null; do { song = new Song(); // 文件名  song.setFileName(cursor.getString(1)); // 歌曲名  song.setTitle(cursor.getString(2)); // 时长  song.setDuration(cursor.getInt(3)); // 歌手名  song.setSinger(cursor.getString(4)); // 专辑名  song.setAlbum(cursor.getString(5)); // 年代  if (cursor.getString(6) != null) { song.setYear(cursor.getString(6)); } else { song.setYear(\u0026#34;未知\u0026#34;); } // 歌曲格式  if (\u0026#34;audio/mpeg\u0026#34;.equals(cursor.getString(7).trim())) { song.setType(\u0026#34;mp3\u0026#34;); } else if (\u0026#34;audio/x-ms-wma\u0026#34;.equals(cursor.getString(7).trim())) { song.setType(\u0026#34;wma\u0026#34;); } // 文件大小  if (cursor.getString(8) != null) { float size = cursor.getInt(8) / 1024f / 1024f; song.setSize((size + \u0026#34;\u0026#34;).substring(0, 4) + \u0026#34;M\u0026#34;); } else { song.setSize(\u0026#34;未知\u0026#34;); } // 文件路径  if (cursor.getString(9) != null) { song.setFileUrl(cursor.getString(9)); } //获取专辑封面（如果数据量大的话，会很耗时——需要考虑如何开辟子线程加载）  Bitmap albumArt = createAlbumArt(song.getFileUrl()); song.setThumbnail(albumArt); songs.add(song); } while (cursor.moveToNext()); cursor.close(); } return songs; } public static int calculateInSampleSize(BitmapFactory.Options options,int reqWidth,int reqHeight){ final int height = options.outHeight; final int width = options.outWidth; int inSampleSize = 1; if(height \u0026gt; reqHeight || width \u0026gt; reqWidth){ final int halfHeight = height/2; final int halfWidth = width/2; while ((halfHeight/inSampleSize)\u0026gt;reqHeight \u0026amp;\u0026amp; (halfWidth/inSampleSize)\u0026gt;reqWidth) inSampleSize*=2; } return inSampleSize; } public static Bitmap createAlbumArt(final String filePath) { Bitmap bitmap = null; //能够获取多媒体文件元数据的类  MediaMetadataRetriever retriever = new MediaMetadataRetriever(); try { retriever.setDataSource(filePath); //设置数据源  byte[] embedPic = retriever.getEmbeddedPicture(); //得到字节型数据  final BitmapFactory.Options options = new BitmapFactory.Options(); options.inJustDecodeBounds = true; BitmapFactory.decodeByteArray(embedPic, 0, embedPic.length,options); options.inSampleSize = calculateInSampleSize(options,100,100); options.inJustDecodeBounds = false; bitmap = BitmapFactory.decodeByteArray(embedPic, 0, embedPic.length,options); //转换为图片  } catch (Exception e) { e.printStackTrace(); } finally { try { retriever.release(); } catch (Exception e2) { e2.printStackTrace(); } } return bitmap; } } ","permalink":"/zh-cn/posts/note/%E5%85%B3%E4%BA%8Emusicplayer/","series":null,"tags":null,"title":""},{"categories":null,"content":"关于ViewPager 使用方法：先在xml中定义\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;android.support.design.widget.CoordinatorLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; android:id=\u0026#34;@+id/main_content\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; android:fitsSystemWindows=\u0026#34;true\u0026#34; tools:context=\u0026#34;.MainActivity\u0026#34;\u0026gt; \u0026lt;android.support.v4.view.ViewPager android:background=\u0026#34;@drawable/img5\u0026#34; android:id=\u0026#34;@+id/view_pager\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; app:layout_behavior=\u0026#34;@string/appbar_scrolling_view_behavior\u0026#34;/\u0026gt; \u0026lt;/android.support.design.widget.CoordinatorLayout\u0026gt; 再到Activity中写\npackage cn.euraxluo.myapplication; import android.support.annotation.NonNull; import android.support.v4.view.PagerAdapter; import android.support.v7.app.AppCompatActivity; import android.support.v4.view.ViewPager; import android.os.Bundle; import android.util.Log; import android.view.*; import android.widget.ImageView; import cn.euraxluo.myapplication.transform.ZoomOutPageTransformer; import java.util.ArrayList; import java.util.List; public class MainActivity extends AppCompatActivity { private static final String TAG = \u0026#34;MainActivity\u0026#34;; private ViewPager mViewPager;//viewpager  private textViewAdapter mViewAdapter; private pictureViewAdapter mpViewAdapter;//图片的adapter  private int[] mImage = new int[10]; private View view1, view2, view3; private List\u0026lt;View\u0026gt; viewList = new ArrayList\u0026lt;View\u0026gt;(3);//view数组  private LayoutInflater inflater; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); initView(); } private void initView() { Log.d(TAG, \u0026#34;initView\u0026#34;); mViewPager = (ViewPager) findViewById(R.id.view_pager); //关于图片的 // initmImage(); // mpViewAdapter = new pictureViewAdapter(mImage); // mViewPager.setAdapter(mpViewAdapter);  //页面滑动  initmlayouts(); mViewAdapter = new textViewAdapter(); mViewPager.setAdapter(mViewAdapter); mViewPager.setPageTransformer(true, new ZoomOutPageTransformer());//这一句是特效  } private void initmImage() { mImage[0] = R.drawable.img1; mImage[1] = R.drawable.img2; mImage[2] = R.drawable.img3; mImage[3] = R.drawable.img4; mImage[4] = R.drawable.img5; mImage[5] = R.drawable.img6; } private void initmlayouts() { //findViewById是找具体的widget控件  inflater = getLayoutInflater();//寻找xml下的布局文件，并且实例化  view1 = (View) inflater.inflate(R.layout.activity_music, null);//这是三个layout  view2 = (View) inflater.inflate(R.layout.activity_list, null);//实际用的时候发生了OOM  view3 = (View) inflater.inflate(R.layout.activity_about, null); viewList.add(view1); viewList.add(view2); viewList.add(view3); } public class pictureViewAdapter extends PagerAdapter { private int[] mImage; public pictureViewAdapter(int[] mImage) { this.mImage = mImage;//接受传入的mImge  } @NonNull @Override public Object instantiateItem(@NonNull ViewGroup container, int position) { ImageView imageView = new ImageView(container.getContext()); imageView.setImageResource(mImage[position]);//设置图片  container.addView(imageView); return imageView; } @Override public void destroyItem(@NonNull ViewGroup container, int position, @NonNull Object object) { container.removeView((View) object); } @Override public int getCount() {//在viewpager显示几个页面  return mImage.length; } @Override public boolean isViewFromObject(@NonNull View view, @NonNull Object o) { return view == o; } } public class textViewAdapter extends PagerAdapter { @Override public int getCount() { return viewList.size();//在viewPager中显示3个页面  } @NonNull @Override public Object instantiateItem(@NonNull ViewGroup container, int position) { container.addView(viewList.get(position));//添加到viewPager容器中  return viewList.get(position);//返回填充的对象  //1.将当前视图添加到container中，2.返回当前View  } @Override public boolean isViewFromObject(@NonNull View view, @NonNull Object o) { return view == o; } public void destroyItem(ViewGroup container, int position, Object obj) { container.removeView((View) obj);//从当前container删除指定位置的view  } } } 一些简单的特效 package cn.euraxluo.myapplication.transform; import android.support.v4.view.ViewPager; import android.util.Log; import android.view.View; //扇子变换 public class RotateDownTransformer implements ViewPager.PageTransformer { private static final float ROT_MAX = 20.0f; private float mRot; public void transformPage(View view, float position) { Log.e(\u0026#34;TAG\u0026#34;, view + \u0026#34; , \u0026#34; + position + \u0026#34;\u0026#34;); if (position \u0026lt; -1) { // [-Infinity,-1)  // This page is way off-screen to the left.  view.setRotation(0); } else if (position \u0026lt;= 1) // a页滑动至b页 ； a页从 0.0 ~ -1 ；b页从1 ~ 0.0  { // [-1,1]  // Modify the default slide transition to shrink the page as well  if (position \u0026lt; 0) { mRot = (ROT_MAX * position); view.setPivotX(view.getMeasuredWidth() * 0.5f); view.setPivotY(view.getMeasuredHeight()); view.setRotation( mRot); } else { mRot = (ROT_MAX * position); view.setPivotX(view.getMeasuredWidth() * 0.5f); view.setPivotY(view.getMeasuredHeight()); view.setRotation( mRot); } // Scale the page down (between MIN_SCALE and 1)  // Fade the page relative to its size.  } else { // (1,+Infinity]  // This page is way off-screen to the right.  view.setRotation( 0); } } } package cn.euraxluo.myapplication.transform;/* MyApplication2 * cn.euraxluo.myapplication.Transform * ScalePageTransformer * 2019/5/18 16:31 * author:Euraxluo * TODO */ import android.support.annotation.NonNull; import android.support.v4.view.ViewPager; import android.view.View; public class ScalePageTransformer implements ViewPager.PageTransformer { private static final float MIN_SCALE=0.75f; @Override public void transformPage(@NonNull View page, float position) { if(position\u0026lt;-1.0f) { page.setScaleX(MIN_SCALE); page.setScaleY(MIN_SCALE); } // slide left  else if(position\u0026lt;=0.0f) { page.setAlpha(1.0f); page.setTranslationX(0.0f); page.setScaleX(1.0f); page.setScaleY(1.0f); } // slide right  else if(position\u0026lt;=1.0f) { page.setAlpha(1.0f-position); page.setTranslationX(-page.getWidth()*position); float scale=MIN_SCALE+(1.0f-MIN_SCALE)*(1.0f-position); page.setScaleX(scale); page.setScaleY(scale); } // out of right screen  else { page.setScaleX(MIN_SCALE); page.setScaleY(MIN_SCALE); } } } package cn.euraxluo.myapplication.transform;/* MyApplication2 * cn.euraxluo.myapplication.Transform * ZoomOutPageTransformer * 2019/5/18 17:06 * author:Euraxluo * TODO */ import android.annotation.SuppressLint; import android.support.v4.view.ViewPager; import android.view.View; public class ZoomOutPageTransformer implements ViewPager.PageTransformer { private static final float MIN_SCALE = 0.85f; private static final float MIN_ALPHA = 0.85f; @SuppressLint(\u0026#34;NewApi\u0026#34;) public void transformPage(View view, float position) { if (position \u0026lt;= 1) //a页滑动至b页 ； a页从 0.0 -1 ；b页从1 ~ 0.0  {// 还可以修改默认的幻灯片转换以缩小页面  float scaleFactor = Math.max(MIN_SCALE, 1 - Math.abs(position)); if (position \u0026lt; 0) {//代表左边的view  view.setAlpha(1); } else {// 使页面相对于大小淡入颜色。  view.setAlpha(MIN_ALPHA + (scaleFactor - MIN_SCALE) / (2 - MIN_SCALE) * (2 - MIN_ALPHA)); } } } } ","permalink":"/zh-cn/posts/note/%E5%85%B3%E4%BA%8Eviewpager/","series":null,"tags":null,"title":""},{"categories":null,"content":"前端 CSS 网格布局\ntable标签（具有性能问题）=\u0026gt;\nhack\nfloat流式布局=\u0026gt;position绝对定位（不利于使用响应式）-\u0026gt;inline(块级放在同一行)\nflexBox(正对某一维度进行自适应)\n=》grid布局\nBackbone.js提供了一套web开发的框架，通过Models进行key-value绑定及自定义事件处理，通过Collections提供一套丰富的API用于枚举功能，通过Views来进行事件处理及与现有的Application通过RESTful JSON接口进行交互.它是基于jQuery和underscore的一个前端js框架。\n在Backbonejs有几个重要的概念，先介绍一下:Model，Collection，View，Router。其中Model是根据现实数据建立的抽象，比如人（People）；Collection是Model的一个集合，比如一群人；View是对Model和Collection中数据的展示，把数据渲染（Render）到页面上；Router是对路由的处理，就像传统网站通过url现实不同的页面，在单页面应用（SPA）中通过Router来控制前面说的View的展示。\n通过Backbone，你可以把你的数据当作Models，通过Models你可以创建数据，进行数据验证，销毁或者保存到服务器上。当界面上的操作引起model中属性的变化时，model会触发change的事件。那些用来显示model状态的views会接受到model触发change的消息，进而发出对应的响应，并且重新渲染新的数据到界面。在一个完整的Backbone应用中，你不需要写那些胶水代码来从DOM中通过特殊的id来获取节点，或者手工的更新HTML页面，因为在model发生变化时，views会很简单的进行自我更新。\n","permalink":"/zh-cn/posts/note/%E5%89%8D%E7%AB%AF/","series":null,"tags":null,"title":""},{"categories":null,"content":"pattern:斑图\n是一种构型，是一种系统，不关心是使用的什么物质去实现\n把各种方法论抽取出来\ncomplexity:复杂性科学\n按照复杂性思维去设计虚拟世界\n 仿真 层次 初始条件的影响 时间之箭？ 因果箭头  movie：黑客帝国，盗梦空间，时间之箭，超体，蝴蝶效应，前目的地\nbook：失控\n我们需要对抗的是复杂系统\n根据用户去决定复杂系统\n设计的系统？ 涌现的系统？\n区块链：ai，算法管理社会\n奇点，技术奇点\n","permalink":"/zh-cn/posts/note/%E5%A4%8D%E6%9D%82%E7%B3%BB%E7%BB%9F/","series":null,"tags":null,"title":""},{"categories":null,"content":"卡包开发步骤 开发步骤\n 需求规划,需求拆解,需求辩论 技术选型:为什么是HBase or MySQL 工程设计:工程图各个模块设计的功能点,各个功能点涉及的技术 编码 测试:功能测试,压力测试 部署:自动化上线  开发技术\n kafka 消息队列 Mysql存储商户信息 HBase存储用户信息 Spring-boot 搭建项目 Redis存储Token信息  测试用例\n测试上线\n应用技术分层\n 框架层:Spring-boot 存储层:MySql,HBase,Redis 消息队列:Kafka  基础工具介绍:\n Maven PostMan/RestAPI  需求分析: 功能需求解析:\n 什么是卡包应用:卡券收集聚合类应用 包含哪些子系统:商户投放子系统,用户使用子系统 优惠卷使用方法:展示型,兑换型,token核销型 扩展:存储纪念性卡券,身份证件信息,银行卡  我的卡包:\n 我的卡包(显示我领取的优惠券,临近过期时需要提醒) 过期优惠券(显示过期优惠券) 优惠券库存:可以领取商家投放的优惠券,每个优惠券只能领取一张(可以改一下?) 用户反馈:分为卡包应用反馈和优惠券反馈  商户投放系统\n商户接口字段:\n         name 商户名   logo_url 商户logo   business_license_url 商户营业执照   phone 商户联系电话   address 商户地址   is_audit 商户是否通过审核    优惠券接口字段:\n         id 所属商户Id   title 优惠卷标题   summary 优惠卷摘要   desc 优惠卷详细信息   limit 最大发放总数个数限制   has_token 是否具有token   background 优惠卷背景颜色   start/end 优惠卷 开始/结束 时间    应用架构 表结构设计 Mysql          name 商户名   logo_url 商户logo   business_license_url 商户营业执照   phone 商户联系电话   address 商户地址   is_audit 商户是否通过审核    HBase passtemplate\n         id 所属商户Id   title 优惠卷标题   summary 优惠卷摘要   desc 优惠卷详细信息   has_token 是否具有token   background 优惠卷背景颜色   limit 最大发放总数个数限制   start/end 优惠卷 开始/结束 时间   pass        \u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;   user_id 优惠卷所属用户   template_id 优惠卷id用于映射具体的优惠卷信息   token 优惠卷token,不存在为-1   assigned_date 领取日期   con_date 消费日期   feedback        \u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;   user_id 评论所属用户   template_id 如果type标识此评论针对优惠卷,则需要指出优惠卷id   type 标识此评论针对卡包还是优惠卷   comment 评论内容   user        \u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;   name 用户名   age 用户年龄   sex 用户性别   phone 用户手机号   address 用户地址    开发步骤  修改配置文件 定义数据结构:merchants.sql 定义常量类以及枚举类 定义Token拦截器,去拿到每个请求中header中的token字段 定义实体类,与merchants.sql中的字段对应 定义dao接口,继承JpaRepository\u0026lt;Merchants, Integer\u0026gt; vo的编写,除了属性,还需要验证对象的有效性,以及对象的转换(vo-\u0026gt;entity/pojo)  ","permalink":"/zh-cn/posts/note/%E5%BC%80%E5%8F%91%E6%AD%A5%E9%AA%A4/","series":null,"tags":null,"title":""},{"categories":null,"content":"引导程序：guide\n 加载配置 iocfactory？类注入 日志系统 路由控制 注解解析？  首先需要根据后台的注解，生成route树，前台请求来了后，解析路由，获取最匹配的路径，并实例化对应的类\n自动全局分析注解，对标了路由注解的类和方法进行解析\n//存入树中？\n存入缓存中，以及路由树中，路由树用于匹配请求路由，具有一定的匹配规则（是否可自定义路由规则）\nroute{\n/lg=\u0026gt;{\nctrl=\u0026gt;app\\ctrls\\indexCtrl\naction=\u0026gt;login()\ntype=\u0026gt;get\n}\n/home/test=\u0026gt;app\\ctrls\\testCtrl::test() =\u0026gt;post\n}\n 初始化，存入缓存，不设过期时间  ","permalink":"/zh-cn/posts/note/%E5%BC%95%E5%AF%BC%E7%A8%8B%E5%BA%8Fguide/","series":null,"tags":null,"title":""},{"categories":null,"content":"并发系统 为什么需要并行\n 业务需求，不同的线程完成不同的功能，交给操作系统进行调度 性能，提高cpu密集型在多核处理机的效率  同步synchronous和异步asynchronous 同步等待调用返回\n异步调用马上返回，但是后台新开一个线程/进行慢慢运行，再返回\n并发Concurrency和并行Parallelism 多核CPU天然并行，不同的CPU做不同的事\n并发，是指通过调度，一会儿做这个事，一会儿做另一个事\n临界区  表示一个公共的资源或者共享数据，可以被多个线程使用，但是每一次，只能有一个线程使用它，一旦临界资源被占用，其他线程想使用这个资源，必须等待 进程 ==》 进入去(申请资源，如果资源被占用，就进去阻塞等待队列) ==》临界区 ==》退出区  阻塞Blocking和非阻塞N-Blocking  阻塞和非阻塞通常用来形容多线程之间的相互影响 阻塞：一个线程占用了临界区资源，那么其他所有需要这个资源的线程都必须再这个临界区中等待，等待导致线程挂起，这就是阻塞。如果占用资源的线程一直不释放资源，那么其他所有在这个临界区上的的线程都不能工作 非阻塞允许多个线程同时进入临界区  死锁Deadlock，饥饿Starvation，活锁Livelock 死锁：\n一组进程中的每一个进程都在等待仅由该组中的其他进程才能引发的事件，那么该组进程是死锁的\n饥饿：\n由于个别资源长期被其他进程占用，而致等待该资源的进程迟迟无法开始运行\n活锁：\n进程为了避免死锁，而释放资源，导致资源一直在被释放和抢占中，同时活锁的进程也无法执行\n并发级别 阻塞  当一个线程进入临界区后，其他线程必须等待  无障碍  无障碍是一种最弱的非阻塞调度 自由出入临界区 无竞争时，有限步内完成操作 有竞争时，回滚数据 各个线程在尝试获取一个独立的系统快照  无锁  首先无障碍的 保证在至少一个线程可以胜出竞争  while(!atomicVar.compareAndSet(localVar,localVar+1)){//无锁计算  localVar = atomicVar.get(); } 无等待  首先无锁的 要求所有的线程都必须在有限步内完成 一定无饥饿  Amdahl定律   串行系统并行化后的加速比的计算公式和理论上限\n  加速比 = 优化前系统耗时/优化后系统耗时\nCPU并行化后系统耗时的计算公式： $$ Tn = T_1(F+\\frac{1}{n}(1-F)) = \\frac{1}{F+\\frac{1}{n}(1-F)} $$ {n:处理器个数，F串行比例，(1-F)并行比例}\n  ","permalink":"/zh-cn/posts/note/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B0%8F%E8%AE%A1/","series":null,"tags":null,"title":""},{"categories":null,"content":"数学杂谈 欧氏空间：在实数域上的有限的内积向量空间对加法和数乘封闭\n意思是。在“向量空间”V这个向量集合中：\n①。任意取V的两个向量α，β。则α+β∈V，[这叫V对加法封闭]\n②，任意取V的一个向量α，及一个实数k.则kα∈V，[这叫V对数乘封闭]\n** 距离和空间 **\n傅里叶分析之掐死教程（完整版）更新于2014.06.06 \n欧拉公式 ","permalink":"/zh-cn/posts/note/%E6%95%B0%E5%AD%A6%E6%9D%82%E8%B0%88/","series":null,"tags":null,"title":""},{"categories":null,"content":"系统\n 价值 必要 讨论 工具  教务管理系统\n 角色 可行性分析报告 明确网站的功能 效果图 测试答辩与总结  任务：\n设计思路:\n 明确网站的功能 网页效果图 数据库设计 网站模块制作 作品测试与验收及总结  接口：\n在下列情况考虑RPC风格的API或说是RPC：\n 偏向内部的API 没有太多的时间考虑API的设计或没有架构师 提供的API很难进行资源、对象抽象 对性能有高要求  在下列情况考虑REST风格：\n 偏向外部API 提供的API天生围绕资源、对象、管理展开 不能耦合客户端实现 资源的CRUD是可以对齐的（功能完整的）  在下列情况考虑GraphQL：\n 客户端对于数据的需求多变 数据具有图的特点  在线考试\n出题，组卷，发布考试，导入考生信息，监考，自动评卷/人工评卷，帮助管理基于网络的考试管理\n 使用浏览器登陆 参加在线考试，在线调查，在线报名，在线练习等 按题型随机抽题组卷，在线考试，题库管理，系统管理，可以对客观题在线评分 丰富的题型，随机试卷动态缓存技术，支持高并发 抽题策略丰富（按题分类，难度，题型） 锁屏，锁键盘 章节练习，保存考生的练习进度  功能：\n管理员\n 考试设计  知识点管理（是题库的分类目录，支持无限级分类） 题型管理（进行题型设置，基本题型：单项选择，多项选择，判断题，填空题，问答题，组合/综合题） 题库管理（对题库信息进行增，删，批删，改，查，导出，导入，下载，批量导入，手工添加） 考试类别管理（新增试卷类别信息，修改，保存） 试卷管理（对试卷和题型进行设置，对抽题规则进行设计。包括随机试卷，手工试卷，固定试卷，考试时，系统根据试卷的规则，生成试卷）   考试管理  考试安排：对考试，练习进行安排，对考试，联系进行授权，设置需要考试的人员 练习安排：管理员安排练习，设置练习参数 人工评卷：对填空，问题，综述等题型，可以进行人工评卷，备注 成绩管理：对考生的成绩进行查看，导出，管理 准考证管理：对需要参加的用户自动生成准考生    考生\n  我的考试\n 参加考试：可以选择考试分类下的试卷进行考试 考试恢复：不小心停电，可以恢复考试 历史考试：本人的考试记录 我的错题：查看考试中做错的题目    我的练习\n 参加练习：对一些科目下的题型进行练习 人工评卷：自己对自己的练习参照答案进行评价 历史练习：查看自己以前参加过的练习    我的信息\n 我的收件箱：收取考试题型，考试结果等    我的账户\n账号密码进行修改\n 个人资料： 密码修改    个人中心\n包含：\n  我的考试\n  我的练习\n  我的班级\n  我的收藏\n 收藏一些题目    消息中心\n收取考试信息，考试结果等\n  个人信息\n 修改密码 修改信息：对自己的信息进行查看和修改，保存 绑定账号      公告栏\n新闻：关于考试的新闻\n 新闻类别管理：新增新闻类别，修改所属类别，填写名称，类型排序的保存和修改删除 新闻信息管理：管理员新增信息，查看，修改信息，保存，删除信息 新闻信息：查看新闻的详细信息  ","permalink":"/zh-cn/posts/note/%E7%B3%BB%E7%BB%9F/","series":null,"tags":null,"title":""},{"categories":["无人驾驶"],"content":"Apollo无人车架构 以HD-map为核心\n线控车辆，计算机和传感器通过CAN卡进行通信 ROTS(Ubuntu+apollo kernel) 保证实时性\nFeameworf(ROS+)  共享内存    减少传输中的数据拷贝，提高传输效率，减少传输延迟\n  有效解决一对多传输\n  共享内存减少CPU资源占用，提高机器计算能力\n  数据兼容    引入了protopuf文件格式\n  可以向后兼容\n  ROS深度兼容protopuf格式\n  去中心化，减小单点故障的影响    使用RTPS服务发现协议\n  以域作为划分，通过rtps相互广播，实现完全P2P\n  sub节点启动，组播registerNode-\u0026gt;节点发现及建立unicast-\u0026gt;向新加节点发送历史消息-\u0026gt;收发双方建立连接，开始通信\n  application   planning\n  control\n  end-to-end driving\n  human-machine\n  map-engine\n  localization\n  preception\n  REDME： 定位   GPS+IMU -\u0026gt; Real Time Kine\n  GPS+IMU+激光雷达（光探测，测距传感器）-\u0026gt;多传感器融合\n  预测 从感知模块接受障碍物信息（位置，方向速度，加速度）\n生成不同概率的预测轨迹\n 容器  存储订阅通道的输入数据（障碍物，车辆定位，车辆规划）\n 评估器  对任何给定的障碍物分别预测路径和速度，通过模型给出的路径概率来进行评估\n1).成本评估器:概率是由成本函数给出\n2).MLP评估器:用MLP模型计算概率\n3).RNN评估器:用RNN模型计算\n 预测器  生成障碍物的预测轨迹，预测规则有很多：\n1). 单行道：在公路导航模式下障碍物沿着单条车道移动。不在车道上的障碍物将被忽略。\n2). 车道顺序：障碍物沿车道移动\n3). 移动序列：障碍物沿其运动模式沿车道移动\n4). 自由运动：障碍物自由移动\n5). 区域运动：障碍物在可能的区域中移动\n路由 根据路由请求(开始和结束位置)以及地图数据生成高级导航信息\n 依赖路由拓扑文件  规划 通过配置和参数规划不同的场景\napollo是车道保持，通过障碍物，通过十字路有\n  planning\n1). FSM，有限状态机\n2). Planning Dispatcher,根据车辆状态和其他信息，调用合适的planner\n3). planner获取context，确定车辆意图，执行该意图所需的规划任务，并生成规划轨迹，并更新未来作业的contxt\n4)Deciders\u0026amp;Optimizers：实现决策和优化的无状态库。优化器优化车辆的轨迹和速度。决策者对当前场景进行分类\n  控制 基于规划和当前的汽车状态，使用不同的控制算法，控制模块可以在正常模式和导航模式下工作\n  输入：规划轨迹，车辆状态，定位和自动模式更改请求\n  输出：给底盘的控制指令\n  HD Map   给出道路网的精确三维表征\n  提供语义信息，帮助决策规划器减小选择范围\n  HD-map构建过程\n    data source（百度有300辆地图车）\n  data peocessing，整理，分类，清洗 -\u0026gt;without semantic \u0026amp; annotation\n  obj detection\n  手动验证（apollo使用软件进行地图编辑）\n  map publication（使用众包，加快构建过程，大家都可以参与）\n  定位   GNSS RTK\n  惯性导航\n  LIDAR定位\n  视觉定位\n  Apollo定位\n  GNSS RTK GPS是最广泛的GNSS系统，分为三个部分：\n  卫星（Satellites），在任何时间大约有30颗GPS卫星在外太空运行\n  地面上世界各地的控制站组成（Control Stations）:用于监视和控制卫星\n  GPS接收器（手机，汽车，电脑，轮船等上）\n  这样的话GPS是有很大的误差的，距离太远，时间太长。使用实时运动定位（或RTK）\n 可信性  RTK涉及在地面上建立几个基站，每个基站都知道自己精确的“地面实况”位置，但是每个基站也通过GPS测量自己的位置，将测出来的位置与自身位置对比得出误差，再将这个误差传给接收设备，以供其调整自身位置计算。\n 不可行性  虽然在RTK的作用下，能将车辆的位置精度确定在10厘米以内，但还是存在很多问题，比如GPS信号被高楼大厦挡住了，或者受到天气影响，导致更本无法接收到信号，另外更新频率很低，大于10赫兹或者每秒更新10次 。\n惯性导航  可行性  我们需要知道将测量值转换为全局坐标系，这种转换需要一个名叫陀螺仪的传感器，三轴陀螺仪的三个外部平衡环一直在旋转， 但三轴陀螺仪的旋转轴始终固定在世界坐标系中，计算车辆在坐标系中的位置是通过测量旋转轴和三个外部平衡环的相对位置来计算的。加速度计和陀螺仪是惯性测量单元（或IMU）的主要组件，IMU的主要特征在于高频更新，更新速度达到1000赫兹，所以IMU所提供的位置几乎是实时位置信息。\n 不可行性  运动误差随时间的增加而增加\n因此可以集合GPS和IMU\nLIDAR定位 利用激光雷达可以通过点云匹配来给车给汽车进行定位，该方法来自于激光雷达传感器的检测数据与预先存在的高精度地图连续匹配，通过这种匹配可以获得汽车在高精度地图上的全球位置及行驶方向。\n匹配点运算法很多，几个常见的算法如下\n其中：迭代最近点（或IPC）是一种方法。\n假如我们相对两次点云扫描进行匹配，对第一次扫描的每一个点我们需要找到另一次扫描中最近的匹配点，最终我们会收都许多匹配点对，将每对点距离误差相加，然后计算平均距离误差。目标是通过点云旋转和平移来最大限度地降低这一平均误差，一旦实现，就可以在传感器扫描和地图之间找到匹配，这样我们将传感器扫描得到到的位置转换成全球地图上的位置，并计算出地图上的精度位置。\n其次：滤波算法是LIDAR定位的另一种算法。\n可消除冗余信息，并在地图上找最可能的车辆位置，Apollo采用了直方图滤波算法（有时也叫误差平方和算法（或SSD））,为了利用直方滤波，我们将通过传感器扫描的点云滑过地图的每一个位置，在每个位置，我们计算扫描的点和高精度地图上对应点之间的距离误差或距离，然后对误差的平方求和，求和的数越小说明扫描结果与地图之间的匹配越好。在该示例中，匹配最好的点显示红色，最差的点显示蓝色，绿色代表适中的点。\n最后：卡尔曼滤波是LIDAR的另一种定位方法。\n卡尔曼滤波是一种算法，用于根据我们在过去的状态和新的传感器测量的结果预测我们当前的状态。卡尔曼滤波使用了预测更新周期，首先我们根据之前的状态以及对移动距离和方向的估计来估计和“预测”我们新的位置。\nLIDAR定位的优势：稳健性\n主要缺点：难以构建高精度地图，即使能够绘制也无法跟上世界瞬时变化的速度。\n视觉定位 图像数据是收集最容易的数据，摄像头便宜且种类繁多，还易于使用，但要用摄像头来实现高精度定位是很困难的。但是可以将摄像头数据与地图和GPS结合起来，利用概率来判断摄像头数据与地图或者GPS等传感器采集的数据做比对，来定位车辆或者障碍物的位置。下图为利用视觉概率思维来确定树的位置。\n优点：图像易于采集\n缺点：缺乏三维信息和对三维地图的依赖\nApollo定位 Apollo使用基于GPS,IMU和激光雷达等多种传感器融合的定位系统。这种融合利用了不同传感器的互补优势，提高了稳定性和准确性。Apollo定位模块依赖于IMU,GPS,激光雷达，雷达和高精度地图，这些传感器同时支持GNSS定位和LIDAR定位，GNSS定位输出速度和位置信息，LIDAR定位输出位置和行进方向信息，融合框架通过卡尔曼滤波将这些输出结合在一起，卡尔曼滤波建立在两步预测测量周期之上。\n*在Apollo中，惯性导航解决方案，用于卡尔曼滤波的预测步骤，GNSS定位和LIDAR定位用于卡尔曼滤波的测量结果更新步骤。\n分类器有很多种，但他们都包含类似的步骤：**\n  首先，计算机接收类似摄像头这样的成像设备的输入，这通常被捕获为图像或一系列图像\n  然后，通过预处理发送每个图像，预处理对每个图片进行了标准化处理，常见的预处理步骤包括\n    调整图像大小或者旋转图像\n  将图像从一个色彩空间换到另一个色彩空间，如从全彩到灰度\n  预处理可以帮助我们的模型更快地处理和学习图像。\n  提取特征，特征有助于计算机理解图片，例如：将自行车和汽车区分开来的一些特征\n  这些特征最后被输入到分类模型中，此步骤用特征来选择图像类别。\n   感知 摄像头图像 摄像头图像是最常见的计算机视觉数据，从计算机的角度来看，图像就是一张二维网格，也被称为矩阵，矩阵中的每个单元格都包含一个数字，数字图像全由像素组成，其中包括非常小的颜色和强度单位，图像中的每个像素都只是一个数值，这些数值构成了我们的图像矩阵，甚至可以改变这些像素值，我们可以通过为每一个像素值添加一个标量整数来改变图片的亮度，向右移动每个像素，也可以执行其它的许多操作。数字网格是许多图像处理技术的基础，多数颜色和形状转换都是通过对图像进行了数学运算以及逐一像素进行更改完成的。\n彩色图像组成 彩色图像被构建为值的三维立方， 每个立方体都有长度，宽度，高度。深度为颜色通道数量，大多数图像由三种颜色组成表示，分别为红色，绿色，蓝色，这些图像被称为RGB图像，对于RGB图像深度为3，可以将其看成一个盒子，三个颜色通道看成三层。三层叠加形成了一张彩色图片。\nLIDAR图像 感知扩展到传感器，而不仅是摄像头，激光雷达传感器创建环境的点云表征，提供了难以通过摄像头获得的信息，通过对点云信息的聚类和分析，这些数据提供里足够的对象检测，跟踪和分类信息，如距离和高度，物体形状和纹理等。\n激光雷达采用光线，尤其是采用激光来测量与环境中反射该光线的物体的距离，将每个激光脉冲反射回传感器所花费的时间，反射所需的时间越长，说明物体离传感器越远，激光雷达正是通过这种方式来构建世界的视觉表征。如下图检测和聚类的结果：红点代表行人，绿点代表其它车辆。\n 机器学习 机器学习是使用特殊的算法来训练计算机从数据中学习的计算机科学领域，通常，这种学习结果被存放在一个叫‘模型’的数据结构中，有很多中“模型”，事实上“模型”就是一种可以用于理解和预测世界的数据结构。\n应用领域：\n（1）金融领域正用机器学习来对汇率和证券交易进行预测\n（2）零售业用机器学习来预测需求\n（3）医生甚至运用机器学习来辅助诊断\n机器学习涉及使用数据和相关的真值标记来进行模型训练\n监督学习：可能显示车辆和行人计算机的图像，以及告诉计算机哪个是哪个的标签，我们要让计算机学习如何最好地区分两类图像，这类学习也被成为监督式学习。\n无监督学习：没有真值标记的行人和车辆图片，让计算机自行决定，哪些图片相似，哪些图片不同。在这里我们不用提供真值标记，通过分析输入数据，在这种情况下为计算机图像，计算机凭借自己学习来区别。\n**半监督学习：**将监督学习和无监督学习的特点结合在一起，使用少量的标记数据和大量的为标记数据来训练模型。\n**强化学习：**强化学习涉及允许模型通过尝试许多不同的方法来解决问题，然后衡量哪种方法最为成功，计算机将尝试许多种不同的解决方案，最终使其方法与环境相适应。例如：在模拟器中，强化学习智能体可以训练汽车进行右转，智能体将在初始位置启动车辆，然后进行实验性驾驶，以多种方向和速度，如果汽车实际完成了右转，智能体会提高奖励，即得分，这是针对导致成功结果的初始化操作。最初可能车辆会出现走错的结果，多学习几次之后，汽车就不会再错了。\n反向传播算法 学习方法也被称为训练，一般由三部循环组成：\n  前馈\n  误差测定\n  反向传播\n  通过前馈来输出每张图片的值，误差是输出值与输入值的差距，将误差通过与前馈相反的方向传回从而更新权重，达到误差最小化的过程叫反向传播。通过这样多次循环，得出误差最小的结果。前馈一般采用梯度下降来实现，想更多了解点击下面链接。\n 梯度下降   用梯度下降，我们通过多个小步骤来实现目标。我们希望一步一步改变权重来减小误差。误差就像是山，我们希望走到山下。下山最快的路应该是最陡峭的那个方向，因此我们也应该寻找能够使误差最小化的方向。我们可以通过计算误差平方的梯度来找到这个方向。\n梯度是改变率或者斜度的另一个称呼。如果你需要回顾这个概念，可以看下可汗学院对这个问题的讲解 。\n 反向传播   如何让多层神经网络学习呢？首先了解如何使用梯度下降来更新权重，反向传播算法则是它的一个延伸。以一个两层神经网络为例，可以使用链式法则计算输入层-隐藏层间权重的误差。\n要使用梯度下降法更新隐藏层的权重，需要知道各隐藏层节点的误差对最终输出的影响。每层的输出是由两层间的权重决定的，两层之间产生的误差，按权重缩放后在网络中向前传播。既然我们知道输出误差，便可以用权重来反向传播到隐藏层。\n卷积神经网络CNN 卷积神经网络（CNN）是一种人工神经网络，对感知问题特别有效，CNN接受多维度输入，包括大多数传感器数据的二维和三维形状。\n标准神经网络：将图像矩阵重塑为一个矢量，并在一大行中链接所有列，将图像“展开”为一维像素阵列。这种方法打破了图像中的空间信息\nCNN可以维持图像输入的的空间信息，CNN通过过滤器连续滑过图像来收集信息，每次收集信息只对图片的一小部分区域进行分析，这被称为卷积。\n例如：CNN可以识别第一个卷积层的基本边缘和颜色信息，然后通过在第一层上卷积新过滤器，CNN可以使用边缘和颜色信息来归纳更复杂的结构，如车轮，车门和挡风玻璃，而另一个卷积可以使用车轮和车门，挡风玻璃来识别整个车，最后神经网络可以使用这一高阶信息对车辆进行分类。\n 检测和分类 在感知任务中，首先想到的是障碍物的检测和分类，动态的障碍物，如行走的人，车，自行车等；静态的障碍物，如树木，停好的车，自行车，建筑物等；计算机首先需要知道障碍物的位置，然后进行分类，无人驾驶车载途中会探测到许多不同物体，汽车根据检测到的物体类型来确定路径和速度。\n无人车是靠什么进行检测和分类？\n使用检测CNN来来查找图像中的对象位置，在对图像中的对象进行定位后，我们可以将图像发给另一个CNN进行分类。也可以用一个单一的CNN结构体系对对象进行检测和分类，在单个网络体系的末端加几个不同的“头”，一个头执行检测，一个头执行分类。一个经典结构为R-CNN及其变体Fast R-CNN和 Faster R-CNN。\n论文\n  R-CNN   Fast R-CNN   Faster-RCNN   YOLO   SSD   跟踪 在检测完对象之后我们需要追踪。\n追踪的意义：对每个帧中的对象进行检测并用边界框对每个对象进行标记。\n跨帧追踪的好处：\n（1）追踪在检测失败时是至关重要的，如果在运用检测算法时，对象被其他对象遮挡一部分，则检测算法可能会失败，追踪可以解决这一问题。\n（2）追中可以保留身份，障碍物检测的输出为包含对象的边界框，但是对象没有与任何身份关联，单独使用对象检测时，计算机不知道一帧中的哪些对象与下一帧的哪些对象相对应。\n追踪步骤：\n  确认身份：通过查找对象相特征似度最高的对象，将在之前一帧中检测的所有对象与之前一帧中检测到的对象进行匹配，对象具有很多特征，一些特征可能基于颜色，一些特征可能基于形状，计算机视觉算法可以计算出复杂的图像特征。\n  快速找到匹配的对象：还要考虑连续视频帧中的。两个障碍物之间的位置和速度。由于两帧之间的对象位置和速度没有太大变化，该信息可以帮助快速找到匹配的对象。\n  分割 语义分割涉及对图像的每个像素进行分类，用于尽可能详细的了解环境，并确定车辆可行驶区域。\n语义分割依赖于一种特殊的CNN，全卷积神经网络（或CFN） ,FCN用卷积层来替代传统CNN的末端平坦层，使得网络中的每一层都是卷积层。故名为全卷积网络。\nCFN提供了可在原始输入图像之上叠加的逐像素输出，复杂因素是大小，传统CNN输出的图片大小比输入小得多，为了进行语义分割，我们必须得到与输入同样大小的输出。\n编码和解码，下面图片前部分叫编码，后部分叫解码，经过这样的处理使得输入尺寸与输出尺寸相等。\nApollo感知 Apollo软件栈可感知障碍物，交通信号灯和车道\n 对三维对象检测  Apollo在高精度地图上使用感兴趣区域（ROI）来重点关注相关对象，Apollo将ROI过滤器用于点云和图像数据以缩小搜素范围并加快感知。\n然后，通过检测网络馈送已过滤的点云，输出用于构建围绕对象三维边界框 。\n最后，使用被称为检测跟踪关联的算法来跨时间步识别单个对象，该算法先保留在每个时间步要跟踪的对象列表，然后在下一个时间步中找到每一个对象的最佳匹配。\n 对于交通信号灯的分类  Apollo先利用高精度地图来确认前方是否有交通信号灯，如果前方有交通信号灯，高精度地图就会返回信号灯的位置，这侧重于摄像头搜索范围，在摄像头捕捉到交通信号灯的图像后，Apollo使用检测网络对图像中的灯进行定位，然后Apollo从较大图像中提取交通灯信号，Apollo将裁剪的交通灯图像提供给分类网络， 以确定灯的颜色，如果有学多灯，系统需要选择哪些灯与其车道有关。\n YOLO网络  Apollo使用YOLO网络来检测车道线和动态物体，其中包括车辆，卡车，骑自行车的人和行人，在经过YOLO网络检测后，在线检测模块会并入来自其它传感器的数据，对车道线进行调整，车道线最终被并入名为“虚拟车道”的单一数据结构中，同样，也通过其它传感器的数据，对YOLO检测到的动态对象进行调整，以获得每个对象的类型，位置，速度，和前进方向。虚拟通道和动态对象都被传到规划和控制模块。\n 传感器数据比较 雷达与激光雷达\n雷达已经在汽车上使用很多年，在各种系统中都需要雷达，如自适应巡航控制、盲点警告、碰撞浸膏和碰撞预防系统等。尽管雷达技术已经成熟，它仍在不断进步，作用不断提升。其他传感器测量速度的方法是计算两次读数之间的差距，而雷达则通过多普勒效应来直接测量速度。多普勒效应根据对象在远离还是接近你，测量出雷达的频率变化。就像消防车警报器一样，当车辆正在远离你和驶向你时，听起来声是不一样的。多普勒效应对传感器融合至关重要。因为它可以把速度作为独立的测量参数，从而提升了融合算法的收敛速度。雷达还可以生成环境的雷达地图，进而实现定位。因为雷达波在坚硬表面会回弹。因此，它可以直接测量对象距离，无需在视线范围内也可以。雷达可以看到其他车辆底部。并发现可能会被阻挡的建筑物和对象。在车上的所有传感器中，雷达是至不容易受雨雾影响的。而且视野宽阔，可达 150 度，距离可达200 多米。与激光雷达和摄像头相比，雷达分辨率较低，尤其是在垂直方向，分辨率非常有限。分辨率低意味着来自静态物体的反射可能产生问题。例如，街道上检修孔盖或汽水罐，可能产生很高的雷达反射率，但他们并不大。我们将其称为雷达杂波。因此，当前的车载雷达通常会忽视静态物体。\n激光雷达是激光探测与测量的简称，而雷达则谁无线电探测与测量的简称。雷达使用无线电波，而激光雷达则使用红激光束来确定传感器和附近对象的距离。目前的激光雷达大多使用 900 纳米光波长度的光源。但部分激光雷达使用的光波长度更长，在雨雾中性能更好。当前的激光雷达使用旋转座架发射激光，扫描周边环境。激光室脉冲式的，脉冲被对象反射，然后返回一个点云，来代表这些物体。激光雷达的空间分辨率远远高于雷达。因为激光束越聚焦，垂直方向的扫描层数量就越多，因此每层的激光雷达的密度也越高。目前，激光雷达还不能直接测量对象的速度，必须使用两次或多次扫描之间的位置差来确定。激光雷达受天气和传感器清洁程度影响也很大，因此需要保持清洁。它们块头也比其他传感器更大，因此也很难安装，除非你只想在车顶安装一个大的激光扫描器。\n 感知融合策略 Apollo采用雷达和激光雷达来检测障碍物，用于融合输出的算法为卡尔曼滤波，卡尔曼滤波有两步。卡尔曼算法时预测更新步骤的无限循环。\n  第一步预测状态\n  第二部为更新测量结果\n  两种测量结果更新步骤\n  同步更新：同步融合同时更新来自不同传感器的测量结果\n  异步更新：异步融合则逐个更新所收到的传感器测量结果\n  传感器融合可提高感知性能，因为各传感器相辅相成，融合也可以减少跟踪误差。\n预测 预测路径目标要求：   实时性要求：想要我们的算法的延时越短越好\n  准确性要求：能让无人车尽可能准确的做出决策\n  预测模块也应该能学习新的行为\n  预测的两种不同方式：  基于模型的预测  例如：怎样预测左侧的车是直行还是右转？\n基于模型的预测，无人车将会提供两个模型，预测车辆直行的模型和右转的模型，然后根据预测车辆的下一步来更新模型，最终确定车辆下一步的动作。\n 数据驱动的预测  数据驱动预测使用机器学习算法，通过观察结果来训练模型，一旦机器模型训练好，就可以在现实中利用此模型去做做预测。\n数据驱动预测优点：训练数据越多训练模型效果越好\n基于模型预测优点：比较直观，并且结合了现有的物理知识和交通法规还有人类行为多方面知识。\n基于车道序列的预测 为了建立车道序列，现将车道分为多个部分，每一部分覆盖了一个易于描述车辆运动的区域，我们如果要预测别的车辆运动状态，只要预测该车在此区域的转换，而不是在某一区域的具体行为。\n将车辆的行为划分为一组有限的模式组合，并将这些模式组合描述物车道的系列。例如：将直行车的路径划分为一个0-1-3-7的系列。\n障碍物状态\n为了预测物体的运动，需要了解障碍物的状态，一般人是通过物体朝向，位置，速度，加速度等来预测物体将做什么？\n无人车也是同样的道理，除了朝向，位置，速度，加速度外，无人车还得考虑该段车道内物体的位置。例如：预测模块会考虑从物体到车道路线段边界的纵向和横向距离，预测模块还包括前面提到的时间间隔状态信息，以便做出更准确的信息。\n预测目标车道\n前面运用车道系列将一个复杂的问题简单化了，现在是预测车辆最有可能采取的车道系列。可以通过计算每个车道系列的概率来进行选择。我们需要一个模型，将车辆状态和车道系列作为输入，该模型用于提供车辆可能采用每个车道系列的概率，我们希望我们的模型能学习新的行为，因此应该使用观测数据对模型进行经验性训练，整改记录由一系列车道段和对象相关状态组成。\n递归神经网络或RNN RNN是利用时间系列数据特征的一种预测方法，利用神经网络建立多重结构递归神经网络，称做MLP单元，从数据中提取高级特征，每个MLP单元将系列的一个元素作为一个输入，并预测系列的下一个元素作为输出，为了对元素的顺序关系建立模型，在每个单元之间建立额外的连接，这意味着每个单元根据原始输入和前一单元的输出进行预测，这就是RNN的基本结构。\nRNN在目标车道预测中的应用\nApollo为车道系列提供一个RNN模型，为相关对象状态提供另一个RNN模型，Apollo连接这两个RNN的输出并将其馈送到另一个神经网络，该神经网络会估计每个车道系列的概率，具有最高概率的车道系列，是我们预测目标车辆将遵循的系列。\n为了训练这个网络，比较真值，得出误差，反向传播更新权重，从而使得模型更好，预测结果更精确。\n轨道生成\n轨道生成是预测的最后一步，一旦我们预测到物体的车道系列，我们就可以预测物体的轨迹，在任何两个点A和,B之间，物体的行进轨迹有无限种可能。\n如何确定我们想要的轨迹？可以先设置条件去除大部分的轨迹路线，我们并不是逐一排除，相反，只是在数学理论上来运用这一想法，注意车辆在两点之间的位置和方位，这两个姿势表示运动模型的初始状态和最终状态，我们可以使用这两个条件来拟合一个多项式模型，在大多数情况下，这种多项式足够满足预测。RNN在目标车道预测中的应用\nApollo为车道系列提供一个RNN模型，为相关对象状态提供另一个RNN模型，Apollo连接这两个RNN的输出并将其馈送到另一个神经网络，该神经网络会估计每个车道系列的概率，具有最高概率的车道系列，是我们预测目标车辆将遵循的系列。\n为了训练这个网络，比较真值，得出误差，反向传播更新权重，从而使得模型更好，预测结果更精确。\n规划 规划中通过结合高进度地图，定位和预测来构建车辆的轨迹。\n第一步：路径导航，如从A地道B地，将地图数据作为输入，并输出可行驶路径\n第二步：路径规划目标：找到从地图上的A地到B地的最佳路线。\n路由 路线规划使用三个输入：\n  地图：地图数据包括公路网和实时交通信息\n  我们当前在地图上的位置\n  我们的目的地：通常取决于车辆的乘客\n  世界地图 从地图A-B，无人驾驶通常货沿道路搜索有没有任何路径，称作搜索。Apollo也利用搜索来查找路径，但搜索算法更智能，在搜索之前将地图重新格式化成“图形”的数据结构，该图形由“节点”和“边缘”组成。\n可以对从一个节点到另一节点所需要的成本进行建模，从实际中就可以得出从1-3所需成本是比1到其它节点的要少，从上图可知，蓝色的为低成本。在计算机领域里，人们已经发现许多用于从图形中搜索路径的算法，所以将地图装换为图形有利于无人驾驶车搜索路径。\n网格世界 从初始节点开始，还需要相邻的八个节点中哪个是最有希望的最佳候选节点，对每个候选节点都要考虑两件事：\n  首先：计算候选节点到开始节点的成本；\n  然后：计算从候选节点到最后节点的成本，可以自己定义计算成本的规则，比如有交通堵塞等情况。\n  定义：\ng:代表从初始节点到候选节点的成本\nh:表示候选节点到目标节点的成本\nf:表示两个值的和，值越小，表示成本越低。\nA*算法 通过g,h值相加得到的f值来确定最佳路线，如下图，最佳路线是网右转，f值最小。\n从路由到轨迹\n高等级地图只是规划过程的一部分，我们需要构建沿这条道路的低等级轨迹，意味找要处理地图上没有的物体，如其它车辆，行人及自行车等。如试图与调头的车辆互动。这一级别的规划称为轨迹生成。\n3D轨迹\n轨迹生成目的是：生成由一系列路径点所定义的轨迹，每个路径点都分配了一个时间戳和速度，让一条曲线与这些路径点拟合，生成轨迹的几何表征，移动的障碍物可能会暂时阻挡部分路段，路段的每个路径点都有一个时间戳，将时间戳与预测模块的输出结合起来，以确保车辆在通过时，路径上的每个点都未被占用。这些时间戳创建了一个三维轨迹。\n评估一条轨迹\n如何评估一条轨迹，采用成函数，选择成本最低的路径。轨迹成本由各种规范和处罚组成。\n例如：\n  车辆偏离中心线的距离\n  可能发生碰撞\n  速度限制\n  舒适度\n  通过将这些成本计算成数字，最终的出最佳的路径。\n车辆甚至可以在不同环境中使用不同的成本函数。\nFrenet坐标  笛卡尔坐标系  通常我们使用笛卡尔坐标系来描述物体的位置，但对于车辆来说，确不是最佳的选择，我们即使能够知道车辆的(x,y)坐标，我们不知道路在哪里，很难知道车辆行驶了多远，以难以确定车辆是否偏移车道中心。\n Frenet坐标系  描述了汽车相对于车道的位置，在Frenet框架中，s代表沿道路的距离，已被称为纵坐标，d表示与纵向线的位移，已被称为横坐标，在道路的每个点，横轴与纵轴都是垂直的。\n纵坐标表示车辆行驶距离，横坐标表示车辆偏离中心线的距离。\n路径速度解耦规划 路径-速度解耦规划将轨迹规划划分为两步：\n  路径规划：生成候选曲线，这是车辆可行驶的路径，我们使用成本函数对每条路径进行成本评估，该函数包含平滑，安全性，与车道中心的偏离，以及我们想要考虑的其它的任何因素。按成本对路径进行排名，并选择成本最低的路径。\n  速度规划：路径规划之后就考虑速度的规划，我们可能希望改变在该路段是的速度，我们需要选择的事与路径点相关的一系列速度，而不是单个速度，该系列称之为“速度曲线”，可以用优化功能为路径选择，受到各种限制的良好速度曲线，通过将路径曲线和速度曲线相结合，可构建车辆的行驶轨迹。\n  控制 控制的输入和输出一样？转向角，加速度和制动？\nPID控制 P是比例控制器\nD是阻尼项，让控制更加稳定，较少控制器输出的变化速度\nI是惩罚项，对累计误差进行惩罚\n线性二次调节器 保持误差的总和和控制输入的综合，我没听懂他在说啥。。总之就是给每一项加权重，大致有控制输入项和误差项生成一个代价函数，最小化它\nx^=Ax+Bu 为状态空间方程\n模型预测控制MPC   建立汽车模型\n  使用优化器计算有限时间范围的控制输出\n  执行第一组控制输出\n  每个时间段单独计算当前时间段的的控制输出，避免误差\n  车辆模型 无人车可以提供的控制输入有两个，一个是刹车|油门，反映在汽车的线性加速度上，一个是方向盘，可以控制在前轮和行驶方向的夹角。\n在感知和定位之后，无人车的路线规划会选择路线。而这个时候控制模块要保证无人车安全的贴近这个预计的路线（参考路线）。一般来说一个路线可以用一个三次曲线来描述。\nSlip angle\n轮胎前进方向，和轮胎轮盘平面的夹角。也可以用轮胎平面的速度和轮胎的漂移速度的反三角来表示。不同的轮胎产生的力不同。赛车胎在同样的Slip angle会产生更大的力。（赛车抓地力更强更不容易出现漂移）\n漂移率\n轮胎在自己平面上面打滑了多少。轮胎受到的力和漂移角是非线性的。另外似乎有一个最优的转向角，那个角度上面轮胎可以提供最大的力来转向，超过那个角度力会下降。另外一般轮胎的转角有30度的限制。\n越大的漂移角会产生越大的力\n轮胎不打滑的情况下，轮胎受力的方向应该是垂直于轮胎的。打滑的话，打滑那个方向也会有一个速度。摩擦力应该和速度反向。在不打滑的时候应该有一个可以提供最大转向力的夹角，打滑的时候这个夹角应该会减小。\nMPC MPC是一个总称，有着各种各样的算法。其动态矩阵控制（DMC）是代表作。DMC采用的是系统的阶跃响应曲线，其突出的特点是解决了约束控制问题。那么是DMC是怎么解决约束的呢？在这里只给出宏观的解释，而不做详细的说明。DMC把线性规划和控制问题结合起来，用线性规划解决输出约束的问题，同时解决了静态最优的问题\n","permalink":"/zh-cn/posts/driverless/apollo%E6%9E%B6%E6%9E%84/","series":["无人驾驶"],"tags":["Apollo无人驾驶"],"title":"Apollo无人车架构"}]