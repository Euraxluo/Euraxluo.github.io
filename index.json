[{"categories":["notes"],"content":" 1. caddy 简介 2. caddy VS. nginx 3. caddy 简单使用 1. 安装 4. Run the daemon 5. 创建一个配置 6. 使用caddy file 1. caddy 简介 官方文档：https://caddyserver.com/docs/\n我认为caddy 就是类似于nginx 的角色，并且其没有依赖，丰富的平台支持性，简洁的使用方式，完全可以用于在某些场景替换nginx\nnginx VS. caddy：https://cloudinfrastructureservices.co.uk/caddy-vs-nginx-which-web-server-is-better/\n2. caddy VS. nginx GPT: 比较Caddy和Nginx的方面：\n配置简单性： Caddy以其简洁的配置语法而闻名，通过Caddyfile配置文件，用户可以轻松地完成各种任务，包括自动配置HTTPS、反向代理、静态文件服务等。相比之下，Nginx的配置文件语法可能相对复杂一些。\n自动HTTPS： Caddy内置了自动获取和管理SSL证书的功能，可以在几乎不需要额外配置的情况下实现自动化的HTTPS支持。而Nginx需要手动设置和配置SSL证书。\n插件生态系统： Caddy具有丰富的插件生态系统，可以通过插件扩展功能。Nginx也有很多模块和插件，但配置和管理可能需要更多的技术知识。\n性能： 在性能方面，Nginx通常被认为是高性能的Web服务器，适用于处理大量的并发连接。Caddy也具备良好的性能，但在处理大规模负载时，Nginx可能会稍微更有优势。\n学习曲线： 由于Caddy的简单配置和自动化特性，对于初学者来说，上手和学习可能会更容易。而Nginx的配置可能需要一些时间来理解和掌握。\n需要注意的是，选择Caddy还是Nginx取决于你的需求和经验水平。如果你需要更高级的配置选项、对性能要求很高，或者已经熟悉Nginx，那么Nginx可能更适合你。如果你想要一个简单、自动化的解决方案，并且不需要太多复杂的配置，Caddy可能是一个更好的选择。\n3. caddy 简单使用 1. 安装 caddy 支持很多平台，文档：https://caddyserver.com/docs/install\nOfficial:\nStatic binaries Debian, Ubuntu, Raspbian packages Fedora, RedHat, CentOS packages Arch Linux, Manjaro, Parabola packages Docker image Our official packages come only with the standard modules. If you need third-party plugins, build from source with xcaddy or use our download page.\nCommunity-maintained:\nHomebrew (Mac) Chocolatey (Windows) Scoop (Windows) Webi Ansible Termux Nix/Nixpkgs/NixOS\n我这里使用scoop 在windows 平添安装caddy\nscoop install caddy\nScoop was updated successfully! Installing \u0026#39;caddy\u0026#39; (2.7.4) [64bit] from main bucket caddy_2.7.4_windows_amd64.zip (14.1 MB) [===========================================================] 100% Checking hash of caddy_2.7.4_windows_amd64.zip ... ok. Extracting caddy_2.7.4_windows_amd64.zip ... done. Linking D:\\scoop\\apps\\caddy\\current =\u0026gt; D:\\scoop\\apps\\caddy\\2.7.4 Creating shim for \u0026#39;caddy\u0026#39;. \u0026#39;caddy\u0026#39; (2.7.4) was installed successfully! caddy 的子命令相当多：\n(base) PS D:\\Projects\\windmill\\frontend\u0026gt; caddy Caddy is an extensible server platform written in Go. At its core, Caddy merely manages configuration. Modules are plugged in statically at compile-time to provide useful functionality. Caddy\u0026#39;s standard distribution includes common modules to serve HTTP, TLS, and PKI applications, including the automation of certificates. To run Caddy, use: - \u0026#39;caddy run\u0026#39; to run Caddy in the foreground (recommended). - \u0026#39;caddy start\u0026#39; to start Caddy in the background; only do this if you will be keeping the terminal window open until you run \u0026#39;caddy stop\u0026#39; to close the server. When Caddy is started, it opens a locally-bound administrative socket to which configuration can be POSTed via a restful HTTP API (see https://caddyserver.com/docs/api). Caddy\u0026#39;s native configuration format is JSON. However, config adapters can be used to convert other config formats to JSON when Caddy receives its configuration. The Caddyfile is a built-in config adapter that is popular for hand-written configurations due to its straightforward syntax (see https://caddyserver.com/docs/caddyfile). Many third-party adapters are available (see https://caddyserver.com/docs/config-adapters). Use \u0026#39;caddy adapt\u0026#39; to see how a config translates to JSON. For convenience, the CLI can act as an HTTP client to give Caddy its initial configuration for you. If a file named Caddyfile is in the current working directory, it will do this automatically. Otherwise, you can use the --config flag to specify the path to a config file. Some special-purpose subcommands build and load a configuration file for you directly from command line input; for example: - caddy file-server - caddy reverse-proxy - caddy respond These commands disable the administration endpoint because their configuration is specified solely on the command line. In general, the most common way to run Caddy is simply: $ caddy run Or, with a configuration file: $ caddy run --config caddy.json If running interactively in a terminal, running Caddy in the background may be more convenient: $ caddy start ... $ caddy stop This allows you to run other commands while Caddy stays running. Be sure to stop Caddy before you close the terminal! Depending on the system, Caddy may need permission to bind to low ports. One way to do this on Linux is to use setcap: $ sudo setcap cap_net_bind_service=+ep $(which caddy) Remember to run that command again after replacing the binary. See the Caddy website for tutorials, configuration structure, syntax, and module documentation: https://caddyserver.com/docs/ Custom Caddy builds are available on the Caddy download page at: https://caddyserver.com/download The xcaddy command can be used to build Caddy from source with or without additional plugins: https://github.com/caddyserver/xcaddy Where possible, Caddy should be installed using officially-supported package installers: https://caddyserver.com/docs/install Instructions for running Caddy in production are also available: https://caddyserver.com/docs/running Usage: caddy [command] Examples: $ caddy run $ caddy run --config caddy.json $ caddy reload --config caddy.json $ caddy stop Available Commands: adapt Adapts a configuration to Caddy\u0026#39;s native JSON add-package Adds Caddy packages (EXPERIMENTAL) build-info Prints information about this build completion Generate completion script environ Prints the environment file-server Spins up a production-ready file server fmt Formats a Caddyfile hash-password Hashes a password and writes base64 help Help about any command list-modules Lists the installed Caddy modules manpage Generates the manual pages for Caddy commands reload Changes the config of the running Caddy instance remove-package Removes Caddy packages (EXPERIMENTAL) respond Simple, hard-coded HTTP responses for development and testing reverse-proxy A quick and production-ready reverse proxy run Starts the Caddy process and blocks indefinitely start Starts the Caddy process in the background and then returns stop Gracefully stops a started Caddy process storage Commands for working with Caddy\u0026#39;s storage (EXPERIMENTAL) trust Installs a CA certificate into local trust stores untrust Untrusts a locally-trusted CA certificate upgrade Upgrade Caddy (EXPERIMENTAL) validate Tests whether a configuration file is valid version Prints the version Flags: -h, --help help for caddy Use \u0026#34;caddy [command] --help\u0026#34; for more information about a command. Full documentation is available at: https://caddyserver.com/docs/command-line 4. Run the daemon caddy run to run a daemon\n(base) PS D:\\Projects\\windmill\\frontend\u0026gt; caddy run 2023/08/21 06:10:38.907 INFO admin admin endpoint started {\u0026#34;address\u0026#34;: \u0026#34;localhost:2019\u0026#34;, \u0026#34;enforce_origin\u0026#34;: false, \u0026#34;origins\u0026#34;: [\u0026#34;//localhost:2019\u0026#34;, \u0026#34;//[::1]:2019\u0026#34;, \u0026#34;//127.0.0.1:2019\u0026#34;]} 2023/08/21 06:10:38.907 INFO serving initial configuration 5. 创建一个配置 caddy_conig.demo.json\n{ \u0026#34;apps\u0026#34;: { \u0026#34;http\u0026#34;: { \u0026#34;servers\u0026#34;: { \u0026#34;example\u0026#34;: { \u0026#34;listen\u0026#34;: [\u0026#34;:2015\u0026#34;], \u0026#34;routes\u0026#34;: [ { \u0026#34;handle\u0026#34;: [{ \u0026#34;handler\u0026#34;: \u0026#34;static_response\u0026#34;, \u0026#34;body\u0026#34;: \u0026#34;Hello, world!\u0026#34; }] } ] } } } } } 加载配置：\n$ curl localhost:2019/load \\ \u0026gt; -H \u0026#34;Content-Type: application/json\u0026#34; \\ \u0026gt; -d @caddy_config.demo.json 这时在http://localhost:2019/config/中就可以看到我们的配置了\n根据配置文件，我们curl :2015\ncurl localhost:2015 Hello, world! 该文档详细介绍了使用json作为服务配置以及使用/load端点来加载配置文件：https://caddyserver.com/docs/quick-starts/api\n6. 使用caddy file 上述为了显示一个hello world ，工作量非常大\n我们使用CaddyFile:\n:2016 respond \u0026#34;Hello, world! with Caddyfile\u0026#34; 然后使用caddy 重新加载该文件： caddy adapt --config /path/to/Caddyfile\n$ caddy adapt --config Caddyfile {\u0026#34;apps\u0026#34;:{\u0026#34;http\u0026#34;:{\u0026#34;servers\u0026#34;:{\u0026#34;srv0\u0026#34;:{\u0026#34;listen\u0026#34;:[\u0026#34;:2016\u0026#34;],\u0026#34;routes\u0026#34;:[{\u0026#34;handle\u0026#34;:[{\u0026#34;body\u0026#34;:\u0026#34;Hello, world! with Caddyfile\u0026#34;,\u0026#34;handler\u0026#34;:\u0026#34;static_response\u0026#34;}]}]}}}}} 2023/08/21 06:29:21.751 WARN caddyfile Caddyfile input is not formatted; run \u0026#39;caddy fmt --overwrite\u0026#39; to fix inconsistencies {\u0026#34;file\u0026#34;: \u0026#34;Caddyfile\u0026#34;, \u0026#34;line\u0026#34;: 3} 这里是使用了caddy 的适配器：配置适配器，将我们的 Caddyfile 转换为 Caddy 的原生 JSON 结构。\n我们只需要重启一下：caddy stop \u0026amp;\u0026amp; caddy run 使用reload重载配置 caddy reload\n$ curl localhost:2016 Hello, world! with Caddyfile 如果我们有多个端点，可以使用大括号包裹\nlocalhost { respond \u0026#34;Hello, world!\u0026#34; } localhost:2016 { respond \u0026#34;Goodbye, world!\u0026#34; } 该文档介绍了Caddyfile的常用示例和模式：https://caddyserver.com/docs/caddyfile/patterns\n","date":"2023-08-21","img":"","permalink":"/posts/note/caddy%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/","series":["notes"],"tags":["notes"],"title":"caddy简单使用"},{"categories":["notes"],"content":" 1. 安装环境 2. 修改节点的hosts 3. 安装依赖，并且下载kk 4.创建配置 5.进行安装 1. 安装环境 2. 修改节点的hosts 最后得到节点： 192.168.110.21 paas-node1 192.168.110.22 paas-node2 192.168.110.23 paas-node3\n主机 IP 主机名 角色 192.168.110.21 paas-node1 control plane, etcd 192.168.110.22 paas-node2 worker 192.168.110.23 paas-node2 worker 配置ssh三个节点互相免密 在每一个节点运行以下命令：\nssh-keygen 三次回车，生成rsa 公钥和私钥 ssh-copy-id user@ip 将公钥分发给所有的机器 可以上别的机器，查看 cat ~/.ssh/authorized_keys 可以本机直接ssh ip，登录别的机器 3. 安装依赖，并且下载kk sudo apt install socat conntrack ebtables ipset curl openssl tar -y\n然后我们在node1 上安装kk\ncurl -sfL https://get-kk.kubesphere.io | VERSION=v3.0.7 sh -\n4.创建配置 ./kk create config \u0026ndash;with-kubesphere v3.3.2 \u0026ndash;with-kubernetes v1.22.12\n集群配置如下\napiVersion: kubekey.kubesphere.io/v1alpha2 kind: Cluster metadata: name: sample spec: hosts: - {name: paas-node1, address: 192.168.110.21, internalAddress: 192.168.110.21, privateKeyPath: \u0026#34;~/.ssh/id_rsa\u0026#34;} - {name: paas-node2, address: 192.168.110.22, internalAddress: 192.168.110.22, privateKeyPath: \u0026#34;~/.ssh/id_rsa\u0026#34;} - {name: paas-node3, address: 192.168.110.23, internalAddress: 192.168.110.23, privateKeyPath: \u0026#34;~/.ssh/id_rsa\u0026#34;} roleGroups: etcd: - paas-node[1:3] control-plane: - paas-node[1:3] worker: - paas-node[1:3] controlPlaneEndpoint: ## Internal loadbalancer for apiservers internalLoadbalancer: haproxy domain: lb.kubesphere.local address: \u0026#34;\u0026#34; port: 6443 kubernetes: version: v1.22.12 clusterName: cluster.local autoRenewCerts: true containerManager: docker etcd: type: kubekey network: plugin: calico kubePodsCIDR: 10.233.64.0/18 kubeServiceCIDR: 10.233.0.0/18 ## multus support. https://github.com/k8snetworkplumbingwg/multus-cni multusCNI: enabled: false registry: privateRegistry: \u0026#34;\u0026#34; namespaceOverride: \u0026#34;\u0026#34; registryMirrors: [] insecureRegistries: [] addons: [] --- apiVersion: installer.kubesphere.io/v1alpha1 kind: ClusterConfiguration metadata: name: ks-installer namespace: kubesphere-system labels: version: v3.3.2 spec: persistence: storageClass: \u0026#34;\u0026#34; authentication: jwtSecret: \u0026#34;\u0026#34; zone: \u0026#34;\u0026#34; local_registry: \u0026#34;\u0026#34; namespace_override: \u0026#34;\u0026#34; # dev_tag: \u0026#34;\u0026#34; etcd: monitoring: true endpointIps: localhost port: 2379 tlsEnable: true common: core: console: enableMultiLogin: true port: 30880 type: NodePort # apiserver: # resources: {} # controllerManager: # resources: {} redis: enabled: true volumeSize: 2Gi openldap: enabled: true volumeSize: 2Gi minio: volumeSize: 20Gi monitoring: # type: external endpoint: http://prometheus-operated.kubesphere-monitoring-system.svc:9090 GPUMonitoring: enabled: false gpu: kinds: - resourceName: \u0026#34;nvidia.com/gpu\u0026#34; resourceType: \u0026#34;GPU\u0026#34; default: true es: # master: # volumeSize: 4Gi # replicas: 1 # resources: {} # data: # volumeSize: 20Gi # replicas: 1 # resources: {} logMaxAge: 7 elkPrefix: logstash basicAuth: enabled: false username: \u0026#34;\u0026#34; password: \u0026#34;\u0026#34; externalElasticsearchHost: \u0026#34;\u0026#34; externalElasticsearchPort: \u0026#34;\u0026#34; alerting: enabled: true # thanosruler: # replicas: 1 # resources: {} auditing: enabled: true # operator: # resources: {} # webhook: # resources: {} devops: enabled: true # resources: {} jenkinsMemoryLim: 8Gi jenkinsMemoryReq: 4Gi jenkinsVolumeSize: 8Gi events: enabled: true # operator: # resources: {} # exporter: # resources: {} # ruler: # enabled: true # replicas: 2 # resources: {} logging: enabled: true logsidecar: enabled: true replicas: 2 # resources: {} metrics_server: enabled: true monitoring: storageClass: \u0026#34;\u0026#34; node_exporter: port: 9100 # resources: {} # kube_rbac_proxy: # resources: {} # kube_state_metrics: # resources: {} # prometheus: # replicas: 1 # volumeSize: 20Gi # resources: {} # operator: # resources: {} # alertmanager: # replicas: 1 # resources: {} # notification_manager: # resources: {} # operator: # resources: {} # proxy: # resources: {} gpu: nvidia_dcgm_exporter: enabled: false # resources: {} multicluster: clusterRole: none network: networkpolicy: enabled: false ippool: type: none topology: type: weave-scope openpitrix: store: enabled: true servicemesh: enabled: true istio: components: ingressGateways: - name: istio-ingressgateway enabled: false cni: enabled: false edgeruntime: enabled: false kubeedge: enabled: false cloudCore: cloudHub: advertiseAddress: - \u0026#34;\u0026#34; service: cloudhubNodePort: \u0026#34;30000\u0026#34; cloudhubQuicNodePort: \u0026#34;30001\u0026#34; cloudhubHttpsNodePort: \u0026#34;30002\u0026#34; cloudstreamNodePort: \u0026#34;30003\u0026#34; tunnelNodePort: \u0026#34;30004\u0026#34; # resources: {} # hostNetWork: false iptables-manager: enabled: true mode: \u0026#34;external\u0026#34; # resources: {} # edgeService: # resources: {} terminal: timeout: 600 5.进行安装 ./kk create cluster -f config-sample.yaml\n","date":"2023-08-01","img":"","permalink":"/posts/note/%E5%AE%89%E8%A3%85k8s%E9%9B%86%E7%BE%A4/","series":["notes"],"tags":["notes"],"title":"安装K8S集群"},{"categories":["redis"],"content":"import redis import time import math import threading import typing from redis import Redis class _WatchThread(threading.Thread): def __init__(self, target, args=(), kwargs={}): super(_WatchThread, self).__init__() self.func = target self.args = args self.kwargs = kwargs self.result = None def run(self): # 接受返回值 self.result = self.func(*self.args, **self.kwargs) def get_result(self, default=None, transform=lambda x: x): # 线程不结束,返回值为None try: return transform(self.result) except Exception as e: return transform(default) # 加载脚本并执行的函数 def _script_load(script): sha = [None] def call(conn: Redis, keys=None, args=None, force_eval=False): if args is None: args = [] if keys is None: keys = [] if not force_eval: # 加载并缓存校验和 if not sha[0]: sha[0] = conn.execute_command(\u0026#34;SCRIPT\u0026#34;, \u0026#34;LOAD\u0026#34;, script, parse=\u0026#34;LOAD\u0026#34;) try: return conn.execute_command(\u0026#34;EVALSHA\u0026#34;, sha[0], len(keys), *(keys + args)) except redis.exceptions.ResponseError as msg: if not msg.args[0].startswith(\u0026#34;NOSCRIPT\u0026#34;): raise # 如果需要强制执行或者脚本接收到错误时，会使用eval执行脚本，eval执行完脚本后，会把脚本的sha1值缓存下来 return conn.execute_command(\u0026#34;EVAL\u0026#34;, script, len(keys), *(keys + args)) return call \u0026#34;\u0026#34;\u0026#34;添加互斥锁\u0026#34;\u0026#34;\u0026#34; _acquire_lock_with_timeout_lua = _script_load( \u0026#34;\u0026#34;\u0026#34; if (redis.call(\u0026#39;exists\u0026#39;,KEYS[1]) == 0) then return redis.call(\u0026#39;setex\u0026#39;,KEYS[1],unpack(ARGV)) end \u0026#34;\u0026#34;\u0026#34; ) def acquire_lock_with_timeout(conn: Redis, lock_name: str, identifier: str, acquire_timeout: int = 10, lock_timeout: int = 10): lock_name = lock_name lock_timeout = int(math.ceil(lock_timeout)) acquired = False end = time.time() + acquire_timeout while time.time() \u0026lt; end and not acquired: acquired = _acquire_lock_with_timeout_lua(conn, [lock_name], [lock_timeout, identifier]) == \u0026#39;OK\u0026#39; time.sleep(0.001 * (not acquired)) return acquired and identifier \u0026#34;\u0026#34;\u0026#34;释放互斥锁\u0026#34;\u0026#34;\u0026#34; _release_lock_lua = _script_load( \u0026#34;\u0026#34;\u0026#34; if (redis.call(\u0026#39;get\u0026#39;,KEYS[1])== ARGV[1]) then return redis.call(\u0026#39;del\u0026#39;,KEYS[1]) or true end \u0026#34;\u0026#34;\u0026#34; ) def release_lock(conn: Redis, lock_name: str, identifier: str): lock_name = lock_name return _release_lock_lua(conn, [lock_name], [identifier]) \u0026#34;\u0026#34;\u0026#34;为可重入锁续约\u0026#34;\u0026#34;\u0026#34; _renew_re_entrant_lock_lua = _script_load( # KEYS : lock_name # ARGV : lock_timeout,id \u0026#34;\u0026#34;\u0026#34; if (redis.call(\u0026#39;hexists\u0026#39;,KEYS[1],ARGV[2])==1) then redis.call(\u0026#39;pexpire\u0026#39;,KEYS[1],ARGV[1]) return 1 end return 0 \u0026#34;\u0026#34;\u0026#34; ) def _renew_re_entrant_lock(conn: Redis, lock_name: str, identifier: str, lock_timeout: int): \u0026#34;\u0026#34;\u0026#34; 为锁续约 :param conn:redis链接 :param lock_name:lock_key :param identifier:lock_唯一id :param lock_timeout: 上锁超时时间ms :return: \u0026#34;\u0026#34;\u0026#34; while _renew_re_entrant_lock_lua(conn, [lock_name], [lock_timeout, identifier]): # 若未续约成功则直接退出 time.sleep(lock_timeout / 3000) \u0026#34;\u0026#34;\u0026#34;添加可重入锁\u0026#34;\u0026#34;\u0026#34; def _watch_operation_time(limit_time: int): \u0026#34;\u0026#34;\u0026#34; 监视运行时间 :param limit_time: :return: \u0026#34;\u0026#34;\u0026#34; def functions(func): def run(*params): watch_thread = _WatchThread(target=func, args=params) watch_thread.setDaemon(True) watch_thread.start() for i in range(int(limit_time // 0.001)): if watch_thread.get_result(default=-1) != -1: return watch_thread.get_result time.sleep(0.001) time.sleep(round(limit_time - int(limit_time // 0.001) * 0.001, 4)) return watch_thread.get_result # 时间结束后,返回thread对象 return run return functions _acquire_re_entrant_lock_with_timeout_lua = _script_load( # KEYS : lock_name # ARGV : lock_timeout,id # 如果exists 结果为 0 ，标识无锁，加锁，将本线程获取的id加到hset中，重置过期时间，返回nil # 相同线程加锁：exists 为 1，此时判断本进程id 是否存在于hset中，若存在，将信号量+1，并重置过期时间，返回nil # 其他线程加锁：直接pttl key，返回剩余过期时间，脚本未返回nil，加锁失败 \u0026#34;\u0026#34;\u0026#34; if (redis.call(\u0026#39;exists\u0026#39;,KEYS[1]) == 0) then redis.call(\u0026#39;hset\u0026#39;,KEYS[1],ARGV[2],1) redis.call(\u0026#39;pexpire\u0026#39;,KEYS[1],ARGV[1]) return nil end if (redis.call(\u0026#39;hexists\u0026#39;,KEYS[1],ARGV[2])==1) then redis.call(\u0026#39;hincrby\u0026#39;,KEYS[1],ARGV[2],1) redis.call(\u0026#39;pexpire\u0026#39;,KEYS[1],ARGV[1]) return nil end return redis.call(\u0026#39;pttl\u0026#39;,KEYS[1]) \u0026#34;\u0026#34;\u0026#34; ) def acquire_re_entrant_lock_with_timeout(conn: Redis, lock_name: str, identifier: str, acquire_timeout: int = -1, lock_timeout: int = -1) -\u0026gt; typing.Callable: \u0026#34;\u0026#34;\u0026#34; :param conn: Redis链接 :param lock_name: 锁名 :param acquire_timeout: 加锁超时时间 单位s :param lock_timeout: 锁的原始租期 单位ms :return: \u0026#34;\u0026#34;\u0026#34; end = time.time() + acquire_timeout if acquire_timeout \u0026gt; 0 else float(\u0026#39;inf\u0026#39;) acquired = False identifier: str = identifier lock_name = lock_name lock_timeout = int(math.ceil(lock_timeout)) # 判断是否超时监测 def acquire_lock(): acquire_lock_lua_result = _acquire_re_entrant_lock_with_timeout_lua(conn, [lock_name], [30 * 1000 if lock_timeout == -1 else lock_timeout, identifier]) def result(*args, **kwargs): return acquire_lock_lua_result return result # 如果不是返回ttl，则成功拿到锁 # cant write this if end \u0026lt; float(\u0026#39;inf\u0026#39;): acquire_lock = _watch_operation_time(limit_time=end - time.time())(acquire_lock) lua_result = acquire_lock() if lua_result(default=-1) == -1: # 请求锁超时,但是依然将这个future对象传出 return lua_result else: if lua_result(default=-1) == None: # 获取锁成功 if lock_timeout == -1: watch_thread = _WatchThread(target=_renew_re_entrant_lock, args=[conn, lock_name, identifier, 30 * 1000]) watch_thread.setDaemon(True) watch_thread.start() def result(*args, **kwargs): return identifier return result elif acquire_timeout != 0: while time.time() \u0026lt; end and not acquired: lua_result = _acquire_re_entrant_lock_with_timeout_lua(conn, [lock_name], [lock_timeout, identifier]) acquired = lua_result == None time.sleep(0.001 * (not acquired)) def result(*args, **kwargs): return acquired and identifier return result else: def result(*args, **kwargs): return acquired and identifier return result \u0026#34;\u0026#34;\u0026#34;释放可重入锁\u0026#34;\u0026#34;\u0026#34; _release_re_entrant_lock_lua = _script_load( # KEYS: lock name # ARGV ：lock_timeout,id # 1. 如果exists 结果为 0 ，**标识无锁**，发送释放锁的消息，返回2，释放成功 # 2. 如果key存在，但是自己不是持锁者，**无权释放**，返回 nil # 3. 如果自己是持锁者，直接-1，然后**判断是否还有重入锁，刷新过期时间**，返回0 # 4. 如果**无其他重入锁，则删除key**，释放锁，并发送释放消息，并返回1，释放成功 \u0026#34;\u0026#34;\u0026#34; if (redis.call(\u0026#39;exists\u0026#39;,KEYS[1]) == 0) then return 2 end if (redis.call(\u0026#39;hexists\u0026#39;,KEYS[1],ARGV[2])==0) then return nil end local counter = redis.call(\u0026#39;hincrby\u0026#39;,KEYS[1],ARGV[2],-1) if (counter \u0026gt; 0) then redis.call(\u0026#39;pexpire\u0026#39;,KEYS[1],ARGV[1]) return 0 else redis.call(\u0026#39;del\u0026#39;,KEYS[1]) return 1 end return nil \u0026#34;\u0026#34;\u0026#34; ) def release_re_entrant_lock(conn: Redis, lock_name: str, identifier: str, lock_timeout: int = 30 * 1000) -\u0026gt; typing.Union[int, None]: \u0026#34;\u0026#34;\u0026#34; 释放可重入锁 :param conn: :param lock_name: :param identifier: :param lock_timeout: :return: 0：释放了自己的锁,当还有别的可重入锁 1：释放成功 2:无锁 None:无权释放 \u0026#34;\u0026#34;\u0026#34; lock_name = lock_name return _release_re_entrant_lock_lua(conn, [lock_name], [lock_timeout, identifier]) __all__ = [\u0026#34;acquire_re_entrant_lock_with_timeout\u0026#34;, \u0026#34;release_re_entrant_lock\u0026#34;, \u0026#34;acquire_lock_with_timeout\u0026#34;, \u0026#34;release_lock\u0026#34;] ","date":"2022-02-13","img":"","permalink":"/posts/redis/redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","series":["redis"],"tags":["redis"],"title":"Redis 实现分布式锁"},{"categories":null,"content":"I’m currently working for headingdata\nI’m currently learning Compiler Design,Distributed Systems,Architecture Design\nHow to reach me: euraxluo@outlook.com Ask me about Python/Compiler/Operational,Constraint Programming\n","date":"2022-02-10","img":"","permalink":"/about/","series":null,"tags":null,"title":"About"},{"categories":["notes"],"content":"连接客户端 config = clientv3.Config{ Endpoints: []string{\u0026#34;127.0.0.1:2379\u0026#34;}, // 集群列表 DialTimeout: 5 * time.Second, } // 建立一个客户端 if client, err = clientv3.New(config); err != nil { fmt.Println(err) return } put //PUT if putResp, err = kv.Put(context.TODO(), \u0026#34;/prefix/keys/k1\u0026#34;, \u0026#34;v1\u0026#34;, clientv3.WithPrevKV(), //请求 prev KV ); err != nil { fmt.Println(err) } else { fmt.Println(\u0026#34;Revision:\u0026#34;, putResp.Header.Revision) // 操作 版本号 fmt.Println(\u0026#34;ClusterId:\u0026#34;, putResp.Header.ClusterId) // 交互集群id fmt.Println(\u0026#34;MemberId:\u0026#34;, putResp.Header.MemberId) // 交互节点 fmt.Println(\u0026#34;RaftTerm:\u0026#34;, putResp.Header.RaftTerm) //raft 任期 if putResp.PrevKv != nil { // 打印value fmt.Println(\u0026#34;PrevValue:\u0026#34;, string(putResp.PrevKv.Value)) } } get //GET KVS if getResp, err = kv.Get(context.TODO(), \u0026#34;/prefix/keys/k1\u0026#34;, ); err != nil { fmt.Println(err) } else { fmt.Println(\u0026#34;Kvs:\u0026#34;, getResp.Kvs) //kv列表 } //GET Count if getResp, err = kv.Get(context.TODO(), \u0026#34;/prefix/keys/k1\u0026#34;, clientv3.WithCountOnly(), //请求 prev KV ); err != nil { fmt.Println(err) } else { fmt.Println(\u0026#34;Count:\u0026#34;, getResp.Count) //KV Count } //GET 以前缀开始的所有key //1. PUT if putResp, err = kv.Put(context.TODO(), \u0026#34;/prefix/keys/k2\u0026#34;, \u0026#34;v2\u0026#34;, clientv3.WithPrevKV(), //请求 prev KV ); err != nil { fmt.Println(err) } else { fmt.Println(\u0026#34;Revision:\u0026#34;, putResp.Header.Revision) // 操作 版本号 fmt.Println(\u0026#34;ClusterId:\u0026#34;, putResp.Header.ClusterId) // 交互集群id fmt.Println(\u0026#34;MemberId:\u0026#34;, putResp.Header.MemberId) // 交互节点 fmt.Println(\u0026#34;RaftTerm:\u0026#34;, putResp.Header.RaftTerm) //raft 任期 if putResp.PrevKv != nil { // 打印value fmt.Println(\u0026#34;PrevValue:\u0026#34;, string(putResp.PrevKv.Value)) } } //2. GET 以前缀开始的所有key if getResp, err = kv.Get(context.TODO(), \u0026#34;/prefix/keys/\u0026#34;, clientv3.WithPrefix(), ); err != nil { fmt.Println(err) } else { fmt.Println(\u0026#34;Kvs:\u0026#34;, getResp.Kvs) //kv列表 } delete //DELETE if delResp, err = kv.Delete(context.TODO(), \u0026#34;/prefix/keys/k2\u0026#34;, clientv3.WithPrevKV(), ); err != nil { fmt.Println(err) } else { if len(delResp.PrevKvs) != 0 { for idx, kvpair := range delResp.PrevKvs { fmt.Println(\u0026#34;idx\u0026#34;, idx, \u0026#34;kvpair\u0026#34;, string(kvpair.Value), string(kvpair.Value)) //kv列表 } } } //DELETE 多个 //1. PUT if putResp, err = kv.Put(context.TODO(), \u0026#34;/prefix/keys/k3\u0026#34;, \u0026#34;v2\u0026#34;, clientv3.WithPrevKV(), //请求 prev KV ); err != nil { fmt.Println(err) } else { fmt.Println(\u0026#34;Revision:\u0026#34;, putResp.Header.Revision) // 操作 版本号 fmt.Println(\u0026#34;ClusterId:\u0026#34;, putResp.Header.ClusterId) // 交互集群id fmt.Println(\u0026#34;MemberId:\u0026#34;, putResp.Header.MemberId) // 交互节点 fmt.Println(\u0026#34;RaftTerm:\u0026#34;, putResp.Header.RaftTerm) //raft 任期 if putResp.PrevKv != nil { // 打印value fmt.Println(\u0026#34;PrevValue:\u0026#34;, string(putResp.PrevKv.Value)) } } //2. delete if delResp, err = kv.Delete(context.TODO(), \u0026#34;/prefix/keys/\u0026#34;, clientv3.WithPrefix(), clientv3.WithPrevKV(), ); err != nil { fmt.Println(err) } else { if len(delResp.PrevKvs) != 0 { for idx, kvpair := range delResp.PrevKvs { fmt.Println(\u0026#34;idx\u0026#34;, idx, \u0026#34;kvpair\u0026#34;, string(kvpair.Value), string(kvpair.Value)) //kv列表 } } } lease租约 var ( lease clientv3.Lease leaseGrantResp *clientv3.LeaseGrantResponse leaseId clientv3.LeaseID keepAliveResp *clientv3.LeaseKeepAliveResponse keepAliveChan \u0026lt;-chan *clientv3.LeaseKeepAliveResponse ) //lease lease = clientv3.NewLease(client) //1. 申请租约 if leaseGrantResp, err = lease.Grant(context.TODO(), 1); err != nil { fmt.Println(err) } else { //2.获取租约ID leaseId = leaseGrantResp.ID //3. 自动续租 //3.1 构造5秒过期取消的上下文 ctx, _ := context.WithTimeout(context.TODO(), 5*time.Second) if keepAliveChan, err = lease.KeepAlive(ctx, leaseId); err != nil { fmt.Println(err) } else { // 3.2 通过keepalive返回的只读管道，获取续约时向管道返回的信息 go func() { for { select { case keepAliveResp = \u0026lt;-keepAliveChan: if keepAliveResp == nil { fmt.Println(\u0026#34;租约失效\u0026#34;) goto END } else { // 每秒会续租一次 fmt.Println(\u0026#34;自动续租应答\u0026#34;, keepAliveResp.ID) } } } END: }() } //4. 获取KV对象 kv = clientv3.NewKV(client) //5.PUT,并，将该put的值绑定一个租约 if putResp, err = kv.Put(context.TODO(), \u0026#34;/prefix/keys/k1\u0026#34;, \u0026#34;\u0026#34;, clientv3.WithLease(leaseId), //绑定租约 ); err != nil { fmt.Println(err) } else { fmt.Println(\u0026#34;Revision:\u0026#34;, putResp.Header.Revision) // 操作 版本号 fmt.Println(\u0026#34;ClusterId:\u0026#34;, putResp.Header.ClusterId) // 交互集群id fmt.Println(\u0026#34;MemberId:\u0026#34;, putResp.Header.MemberId) // 交互节点s fmt.Println(\u0026#34;RaftTerm:\u0026#34;, putResp.Header.RaftTerm) //raft 任期 } //6.定时查看key是否过期 for { if getResp, err = kv.Get(context.TODO(), \u0026#34;/prefix/keys/k1\u0026#34;, ); err != nil { fmt.Println(err) } else { if getResp.Count == 0 { fmt.Println(\u0026#34;过期了\u0026#34;) break } else { fmt.Println(\u0026#34;Kvs:\u0026#34;, getResp.Kvs) //kv列表 } } } } watch 监听 //watch var ( watcher clientv3.Watcher watchRespChan clientv3.WatchChan ) //1. 初始化监听上下文，当kv变化10次是，取消该上下文 watcherCtx, cancelFunc := context.WithCancel(context.TODO()) //2. 监听kv变化 go func() { i := 0 for { i += 1 kv.Put(context.TODO(), \u0026#34;/prefix/keys/k1\u0026#34;, \u0026#34;v\u0026#34;+strconv.Itoa(i)) kv.Delete(context.TODO(), \u0026#34;/prefix/keys/k1\u0026#34;) time.Sleep(1 * time.Second) if i \u0026gt; 10 { println(\u0026#34;变化结束，取消监听\u0026#34;) cancelFunc() break } } }() //3. 先获取到当前的值，并进行监听 if getResp, err = kv.Get(context.TODO(), \u0026#34;/prefix/keys/k1\u0026#34;); err != nil { fmt.Println(err) } else { if len(getResp.Kvs) != 0 { fmt.Println(string(getResp.Kvs[0].Value)) } //3.1 定义需要监听的reversion watchStartRevision := getResp.Header.Revision + 1 println(\u0026#34;watchStartRevision\u0026#34;, watchStartRevision) //3.2 创建一个watcher watcher = clientv3.NewWatcher(client) //3.3 启动监听 watchRespChan = watcher.Watch(watcherCtx, \u0026#34;/prefix/keys/k1\u0026#34;, clientv3.WithRev(watchStartRevision), //监听Revision起点 ) //3.4 处理kv变化 for watchResp := range watchRespChan { for _, event := range watchResp.Events { switch event.Type { case mvccpb.PUT: fmt.Println(\u0026#34;修改为\u0026#34;, string(event.Kv.Value), \u0026#34;Revison\u0026#34;, event.Kv.CreateRevision, event.Kv.ModRevision) case mvccpb.DELETE: fmt.Println(\u0026#34;删除了\u0026#34;, event.Kv.ModRevision) } } } } 分布式锁 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;github.com/coreos/etcd/clientv3\u0026#34; \u0026#34;time\u0026#34; ) type HandlerFunc func() error type LockError string func (err LockError) Error() string { return string(err) } func Lock(endpoint []string, dialTimeout time.Duration, lockKey string, lockValue string, callback HandlerFunc) (err error) { var ( client *clientv3.Client leaseGrantResp *clientv3.LeaseGrantResponse keepAliveRespChan \u0026lt;-chan *clientv3.LeaseKeepAliveResponse txnResp *clientv3.TxnResponse ) config := clientv3.Config{ Endpoints: endpoint, DialTimeout: dialTimeout, } if client, err = clientv3.New(config); err != nil { return err } //1. 上锁 //1.1 创建租约 lease := clientv3.NewLease(client) //1.2 设置租期 leaseCtx, _ := context.WithTimeout(context.TODO(), 1*time.Second) if leaseGrantResp, err = lease.Grant(leaseCtx, 1); err != nil { return err } //1.3 获取租约id leaseId := leaseGrantResp.ID leaseRevokeCtx, _ := context.WithTimeout(context.TODO(), 1*time.Second) defer lease.Revoke(leaseRevokeCtx, leaseId) // 函数退出时，直接结束租约 //1.4 准备一个用于取消租约的上下文 cancelCtx, cancelFunc := context.WithCancel(context.TODO()) defer cancelFunc() //退出函数后，关闭租约，此时，会导致租约监听协程退出 //1.5 在函数退出之前持续续租 if keepAliveRespChan, err = lease.KeepAlive(cancelCtx, leaseId); err != nil { return err } //1.6 启动处理续约的协程 go func() { for { select { case keepAliveResp := \u0026lt;-keepAliveRespChan: if keepAliveResp == nil { goto KeepAliveListenEnd } else { println(keepAliveResp.ID) } } } KeepAliveListenEnd: }() //1.7 创建事务 kv := clientv3.NewKV(client) txnCtx, _ := context.WithTimeout(context.TODO(), 1*time.Second) txn := kv.Txn(txnCtx) txn.If(clientv3.Compare(clientv3.CreateRevision(lockKey), \u0026#34;=\u0026#34;, 0)). //如果 key 不存在 Then(clientv3.OpPut(lockKey, lockValue, clientv3.WithLease(leaseId))). //上锁 Else(clientv3.OpGet(locValue)) //否则抢锁失败 //1.8 提交事务，并判断是否成功 if txnResp, err = txn.Commit(); err != nil { return err } //如果失败，则锁被占用 if !txnResp.Succeeded { return LockError(\u0026#34;Lock Failed\u0026#34;) } //否则上锁成功 return callback() } func handler() error { fmt.Println(\u0026#34;处理任务\u0026#34;) time.Sleep(5 * time.Second) return nil } func main() { err := Lock([]string{\u0026#34;127.0.0.1:2379\u0026#34;}, 1*time.Second, \u0026#34;/prefix/lock/lock_key\u0026#34;, \u0026#34;lock_value\u0026#34;, handler) println(err) if err != nil { fmt.Println(err) } } ","date":"2022-02-10","img":"","permalink":"/posts/note/etcd%E5%85%A5%E9%97%A8/","series":null,"tags":["etcd"],"title":"etcd 基本使用"},{"categories":["notes"],"content":"GORM 模型定义 模型实现了Scanner和Valuer接口\n模型约定：\nGORM 使用ID作为主键\n如果不默认使用ID作为主键，应该使用标签primaryKey 指定\n// 将 `UUID` 设为主键 type Animal struct { ID int64 UUID string `gorm:\u0026#34;primaryKey\u0026#34;` Name string Age int64 } 复合主键\ntype Product struct { ID string `gorm:\u0026#34;primaryKey\u0026#34;` LanguageCode string `gorm:\u0026#34;primaryKey\u0026#34;` Code string Name string } 关闭整形主键的自增，显示关闭 autoIncrement\ntype Product struct { CategoryID uint64 `gorm:\u0026#34;primaryKey;autoIncrement:false\u0026#34;` TypeID uint64 `gorm:\u0026#34;primaryKey;autoIncrement:false\u0026#34;` } 使用结构体名的下划线表示的复数作为表名\n更改默认表名,为结构体实现TableName方法\ntype Tabler interface { TableName() string } // TableName 会将 User 的表名重写为 `profiles` func (User) TableName() string { return \u0026#34;profiles\u0026#34; } 动态修改表名：使用Scopes\n用Scopes来动态添加条件\nfunc UserTable(user User) func (tx *gorm.DB) *gorm.DB { return func (tx *gorm.DB) *gorm.DB { if user.Admin { return tx.Table(\u0026#34;admin_users\u0026#34;) } return tx.Table(\u0026#34;users\u0026#34;) } } db.Scopes(UserTable(user)).Create(\u0026amp;user) 临时指定表名，使用Table方法临时指定表名\n// 根据 User 的字段创建 `deleted_users` 表 db.Table(\u0026#34;deleted_users\u0026#34;).AutoMigrate(\u0026amp;User{}) 修改默认的命名策略：实现结构体的命名相关的接口\nTableName、ColumnName、JoinTableName、RelationshipFKName、CheckerName、IndexName等接口 使用字段名的下划线表示作为列名\n使用column标签或者命名策略 来指定列名\ntype Animal struct { AnimalID int64 `gorm:\u0026#34;column:beast_id\u0026#34;` // 将列名设为 `beast_id` Birthday time.Time `gorm:\u0026#34;column:day_of_the_beast\u0026#34;` // 将列名设为 `day_of_the_beast` Age int64 `gorm:\u0026#34;column:age_of_the_beast\u0026#34;` // 将列名设为 `age_of_the_beast` } 使用CreatedAt、UpdatedAt 字段追踪创建、更新时间\nCreatedAt字段的修改规则\ndb.Create(\u0026amp;user) // 将 `CreatedAt` 设为当前时间 user2 := User{Name: \u0026#34;jinzhu\u0026#34;, CreatedAt: time.Now()} db.Create(\u0026amp;user2) // user2 的 `CreatedAt` 不会被修改 // 想要修改该值，您可以使用 `Update` db.Model(\u0026amp;user).Update(\u0026#34;CreatedAt\u0026#34;, time.Now()) UpdateAt字段的修改规则\ndb.Save(\u0026amp;user) // 将 `UpdatedAt` 设为当前时间 db.Model(\u0026amp;user).Update(\u0026#34;name\u0026#34;, \u0026#34;jinzhu\u0026#34;) // 会将 `UpdatedAt` 设为当前时间 db.Model(\u0026amp;user).UpdateColumn(\u0026#34;name\u0026#34;, \u0026#34;jinzhu\u0026#34;) // `UpdatedAt` 不会被修改 user2 := User{Name: \u0026#34;jinzhu\u0026#34;, UpdatedAt: time.Now()} db.Create(\u0026amp;user2) // 创建记录时，user2 的 `UpdatedAt` 不会被修改 user3 := User{Name: \u0026#34;jinzhu\u0026#34;, UpdatedAt: time.Now()} db.Save(\u0026amp;user3) // 更新时，user3 的 `UpdatedAt` 会修改为当前时间 gorm.Model默认的结构体，包含了默认的字段\n定义\n// gorm.Model 的定义 type Model struct { ID uint `gorm:\u0026#34;primaryKey\u0026#34;` CreatedAt time.Time UpdatedAt time.Time DeletedAt gorm.DeletedAt `gorm:\u0026#34;index\u0026#34;` } 可以嵌入到自己的结构体中以包含这些默认字段\n时间相关约定\n类型约定\ntime.Time，时间类型\nint，时间戳秒数\nint64，默认为时间戳秒数\nUpdated int64 `gorm:\u0026#34;autoUpdateTime:nano\u0026#34;` //使用时间戳填纳秒数充更新时间 Updated int64 `gorm:\u0026#34;autoUpdateTime:milli\u0026#34;` //使用时间戳毫秒数填充更新时间 Created int64 `gorm:\u0026#34;autoCreateTime\u0026#34;` //使用时间戳秒数填充创建时间 结构体嵌入\n匿名字段\ntype User struct { gorm.Model Name string } // 等效于 type User struct { ID uint `gorm:\u0026#34;primaryKey\u0026#34;` CreatedAt time.Time UpdatedAt time.Time DeletedAt gorm.DeletedAt `gorm:\u0026#34;index\u0026#34;` Name string } 具名字段，使用标签embedded嵌入\ntype Author struct { Name string Email string } type Blog struct { ID int Author Author `gorm:\u0026#34;embedded\u0026#34;` Upvotes int32 } // 等效于 type Blog struct { ID int64 Name string Email string Upvotes int32 } 资源前缀修改,embeddedPrefix标签\ntype Blog struct { ID int Author Author `gorm:\u0026#34;embedded;embeddedPrefix:author_\u0026#34;` Upvotes int32 } // 等效于 type Blog struct { ID int64 AuthorName string AuthorEmail string Upvotes int32 } 字段标签 关联标签 数据库连接 数据库驱动以及连接 MYSQL\nmysql高级配置 import ( \u0026#34;gorm.io/driver/mysql\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) func main() { // 参考 https://github.com/go-sql-driver/mysql#dsn-data-source-name 获取详情 dsn := \u0026#34;user:pass@tcp(127.0.0.1:3306)/dbname?charset=utf8mb4\u0026amp;parseTime=True\u0026amp;loc=Local\u0026#34; db, err := gorm.Open(mysql.Open(dsn), \u0026amp;gorm.Config{}) } PostgreSQL\npostgre高级配置 import ( \u0026#34;gorm.io/driver/postgres\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) dsn := \u0026#34;user=gorm password=gorm dbname=gorm port=9920 sslmode=disable TimeZone=Asia/Shanghai\u0026#34; db, err := gorm.Open(postgres.Open(dsn), \u0026amp;gorm.Config{}) SQLite\nimport ( \u0026#34;gorm.io/driver/sqlite\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) // github.com/mattn/go-sqlite3 db, err := gorm.Open(sqlite.Open(\u0026#34;gorm.db\u0026#34;), \u0026amp;gorm.Config{}) SQL Server\nimport ( \u0026#34;gorm.io/driver/sqlserver\u0026#34; \u0026#34;gorm.io/gorm\u0026#34; ) // github.com/denisenkom/go-mssqldb dsn := \u0026#34;sqlserver://gorm:LoremIpsum86@localhost:9930?database=gorm\u0026#34; db, err := gorm.Open(sqlserver.Open(dsn), \u0026amp;gorm.Config{}) 数据库连接池 *sql.DB // 获取通用数据库对象 sql.DB，然后使用其提供的功能 sqlDB, err := db.DB() // Ping sqlDB.Ping() // Close sqlDB.Close() // 返回数据库统计信息 sqlDB.Stats() sqlDB, err := db.DB() // SetMaxIdleConns 设置空闲连接池中连接的最大数量 sqlDB.SetMaxIdleConns(10) // SetMaxOpenConns 设置打开数据库连接的最大数量。 sqlDB.SetMaxOpenConns(100) // SetConnMaxLifetime 设置了连接可复用的最大时间。 sqlDB.SetConnMaxLifetime(time.Hour) 对象生命周期 Hook 是在创建、查询、更新、删除等操作之前、之后调用的函数。\n如果您已经为模型定义了指定的方法，它会在创建、更新、查询、删除时自动被调用。如果任何回调返回错误，GORM 将停止后续的操作并回滚事务。\nCRUD 创建 创建记录\nuser := User{Name: \u0026#34;Jinzhu\u0026#34;, Age: 18, Birthday: time.Now()} result := db.Create(\u0026amp;user) // 通过数据的指针来创建 user.ID // 返回插入数据的主键 result.Error // 返回 error result.RowsAffected // 返回插入记录的条数 将数据对象的制作传递给Create方法来进行创建 方法将会返回error以及插入的条数，同时数据对象的ID字段将会被回写 插入指定的字段\ndb.Select(\u0026#34;Name\u0026#34;, \u0026#34;Age\u0026#34;, \u0026#34;CreatedAt\u0026#34;).Create(\u0026amp;user) // INSERT INTO `users` (`name`,`age`,`created_at`) VALUES (\u0026#34;jinzhu\u0026#34;, 18, \u0026#34;2020-07-04 11:05:21.775\u0026#34;) 创建记录，并且将选择的字段更新 db.Omit(\u0026#34;Name\u0026#34;, \u0026#34;Age\u0026#34;, \u0026#34;CreatedAt\u0026#34;).Create(\u0026amp;user) // INSERT INTO `users` (`birthday`,`updated_at`) VALUES (\u0026#34;2020-01-01 00:00:00.000\u0026#34;, \u0026#34;2020-07-04 11:05:21.775\u0026#34;) 创建记录，并且更新未给出的字段 批量插入:使用slice传递给Create方法\nvar users = []User{{Name: \u0026#34;jinzhu1\u0026#34;}, {Name: \u0026#34;jinzhu2\u0026#34;}, {Name: \u0026#34;jinzhu3\u0026#34;}} db.Create(\u0026amp;users) for _, user := range users { user.ID // 1,2,3 } 批量插入:使用 CreateInBatches 创建，并支持指定创建的数量\nvar users = []User{name: \u0026#34;jinzhu_1\u0026#34;}, ...., {Name: \u0026#34;jinzhu_10000\u0026#34;}} // 数量为 100 db.CreateInBatches(users, 100) 对象Hook\n生命周期\n// 开始事务 BeforeSave BeforeCreate // 关联前的 save // 插入记录至 db // 关联后的 save AfterCreate AfterSave // 提交或回滚事务 跳过Hook，使用SkipHooks 会话模式\nDB.Session(\u0026amp;gorm.Session{SkipHooks: true}).Create(\u0026amp;user) 根据 map[string]interface{} 和 []map[string]interface{}{} 创建记录\ndb.Model(\u0026amp;User{}).Create(map[string]interface{}{ \u0026#34;Name\u0026#34;: \u0026#34;jinzhu\u0026#34;, \u0026#34;Age\u0026#34;: 18, }) // batch insert from `[]map[string]interface{}{}` db.Model(\u0026amp;User{}).Create([]map[string]interface{}{ {\u0026#34;Name\u0026#34;: \u0026#34;jinzhu_1\u0026#34;, \u0026#34;Age\u0026#34;: 18}, {\u0026#34;Name\u0026#34;: \u0026#34;jinzhu_2\u0026#34;, \u0026#34;Age\u0026#34;: 20}, }) 使用clause.Expr创建记录\n// 通过 map 创建记录 db.Model(User{}).Create(map[string]interface{}{ \u0026#34;Name\u0026#34;: \u0026#34;jinzhu\u0026#34;, \u0026#34;Location\u0026#34;: clause.Expr{SQL: \u0026#34;ST_PointFromText(?)\u0026#34;, Vars: []interface{}{\u0026#34;POINT(100 100)\u0026#34;}}, }) // INSERT INTO `users` (`name`,`point`) VALUES (\u0026#34;jinzhu\u0026#34;,ST_PointFromText(\u0026#34;POINT(100 100)\u0026#34;)); 关联创建\n如果两个数据结构有关联，那么在会把关联对象一起upsert\ntype CreditCard struct { gorm.Model Number string UserID uint } type User struct { gorm.Model Name string CreditCard CreditCard } db.Create(\u0026amp;User{ Name: \u0026#34;jinzhu\u0026#34;, CreditCard: CreditCard{Number: \u0026#34;411111111111\u0026#34;} }) // INSERT INTO `users` ... // INSERT INTO `credit_cards` ... skip 关联创建\ndb.Omit(\u0026#34;CreditCard\u0026#34;).Create(\u0026amp;user) // 跳过所有关联 db.Omit(clause.Associations).Create(\u0026amp;user) 默认值,可以是值，也可以是数据库函数\n使用标签 default 为字段定义默认值\ntype User struct { gorm.Mode Name string `gorm:\u0026#34;default:galeone\u0026#34;` Weight int64 `gorm:\u0026#34;default:18\u0026#34;` Age *int `gorm:\u0026#34;default:18\u0026#34;` Active sql.NullBool `gorm:\u0026#34;default:true\u0026#34;` } 像 0、''、false 等零值，不会将这些字段定义的默认值保存到数据库。需要使用指针类型或 Scanner/Valuer 来避免这个问题 当具有生成数据时，必须设置default标签\ntype User struct { ID string `gorm:\u0026#34;default:uuid_generate_v3()\u0026#34;` // 数据库函数 FirstName string LastName string Age uint8 FullName string `gorm:\u0026#34;-\u0026gt;;type:GENERATED ALWAYS AS (concat(firstname,\u0026#39; \u0026#39;,lastname));default:(-);` } Upsert及其冲突，相关链接 出现冲突时，一般分为DoNothing，DoUpdates，UpdateAll 查询 检索单个对象\nFirst函数，按照主键升序获取第一条记录\n// 获取第一条记录（主键升序） db.First(\u0026amp;user) // SELECT * FROM users ORDER BY id LIMIT 1; Take函数，不指定排序字段，获取第一条记录\n// 获取一条记录，没有指定排序字段 db.Take(\u0026amp;user) // SELECT * FROM users LIMIT 1; Last函数，按照主键降序，获取第一条记录\n// 获取最后一条记录（主键降序） db.Last(\u0026amp;user) // SELECT * FROM users ORDER BY id DESC LIMIT 1; First，Last函数，仅在通过结构体和model值进行查询时才会生效，因为他需要使用结构体中的主键，或者是第一个字段来进行字段排序\nvar user User // 可以 db.First(\u0026amp;user) // SELECT * FROM `users` ORDER BY `users`.`id` LIMIT 1 // 可以 result := map[string]interface{}{} db.Model(\u0026amp;User{}).First(\u0026amp;result) // SELECT * FROM `users` ORDER BY `users`.`id` LIMIT 1 // 不行 result := map[string]interface{}{} db.Table(\u0026#34;users\u0026#34;).First(\u0026amp;result) // 但可以配合 Take 使用 result := map[string]interface{}{} db.Table(\u0026#34;users\u0026#34;).Take(\u0026amp;result) // 根据第一个字段排序 type Language struct { Code string Name string } db.First(\u0026amp;Language{}) // SELECT * FROM `languages` ORDER BY `languages`.`code` LIMIT 1 返回值，当成功时，返回找到的记录数，没有找到时，返回 ErrRecordNotFound 错误\nresult := db.First(\u0026amp;user) result.RowsAffected // 返回找到的记录数 result.Error // returns error // 检查 ErrRecordNotFound 错误 errors.Is(result.Error, gorm.ErrRecordNotFound) 根据主键查询\n内联条件检索\ndb.First(\u0026amp;user, 10) // SELECT * FROM users WHERE id = 10; db.First(\u0026amp;user, \u0026#34;10\u0026#34;) // SELECT * FROM users WHERE id = 10; db.Find(\u0026amp;users, []int{1,2,3}) // SELECT * FROM users WHERE id IN (1,2,3); 检索全部对象\nFind\n// 获取全部记录 result := db.Find(\u0026amp;users) // SELECT * FROM users; result.RowsAffected // 返回找到的记录数，相当于 `len(users)` result.Error // returns error 检索条件\nWhere函数，支持string类型的条件以及struct\u0026amp;Map类型的条件\n// 获取第一条匹配的记录 db.Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).First(\u0026amp;user) // SELECT * FROM users WHERE name = \u0026#39;jinzhu\u0026#39; ORDER BY id LIMIT 1; // 获取全部匹配的记录 db.Where(\u0026#34;name \u0026lt;\u0026gt; ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Find(\u0026amp;users) // SELECT * FROM users WHERE name \u0026lt;\u0026gt; \u0026#39;jinzhu\u0026#39;; // IN db.Where(\u0026#34;name IN ?\u0026#34;, []string{\u0026#34;jinzhu\u0026#34;, \u0026#34;jinzhu 2\u0026#34;}).Find(\u0026amp;users) // SELECT * FROM users WHERE name IN (\u0026#39;jinzhu\u0026#39;,\u0026#39;jinzhu 2\u0026#39;); // LIKE db.Where(\u0026#34;name LIKE ?\u0026#34;, \u0026#34;%jin%\u0026#34;).Find(\u0026amp;users) // SELECT * FROM users WHERE name LIKE \u0026#39;%jin%\u0026#39;; // AND db.Where(\u0026#34;name = ? AND age \u0026gt;= ?\u0026#34;, \u0026#34;jinzhu\u0026#34;, \u0026#34;22\u0026#34;).Find(\u0026amp;users) // SELECT * FROM users WHERE name = \u0026#39;jinzhu\u0026#39; AND age \u0026gt;= 22; // Time db.Where(\u0026#34;updated_at \u0026gt; ?\u0026#34;, lastWeek).Find(\u0026amp;users) // SELECT * FROM users WHERE updated_at \u0026gt; \u0026#39;2000-01-01 00:00:00\u0026#39;; // BETWEEN db.Where(\u0026#34;created_at BETWEEN ? AND ?\u0026#34;, lastWeek, today).Find(\u0026amp;users) // SELECT * FROM users WHERE created_at BETWEEN \u0026#39;2000-01-01 00:00:00\u0026#39; AND \u0026#39;2000-01-08 00:00:00\u0026#39;; Not条件，使用Not函数\ndb.Not(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).First(\u0026amp;user) // SELECT * FROM users WHERE NOT name = \u0026#34;jinzhu\u0026#34; ORDER BY id LIMIT 1; // Not In db.Not(map[string]interface{}{\u0026#34;name\u0026#34;: []string{\u0026#34;jinzhu\u0026#34;, \u0026#34;jinzhu 2\u0026#34;}}).Find(\u0026amp;users) // SELECT * FROM users WHERE name NOT IN (\u0026#34;jinzhu\u0026#34;, \u0026#34;jinzhu 2\u0026#34;); // Struct db.Not(User{Name: \u0026#34;jinzhu\u0026#34;, Age: 18}).First(\u0026amp;user) // SELECT * FROM users WHERE name \u0026lt;\u0026gt; \u0026#34;jinzhu\u0026#34; AND age \u0026lt;\u0026gt; 18 ORDER BY id LIMIT 1; // 不在主键切片中的记录 db.Not([]int64{1,2,3}).First(\u0026amp;user) // SELECT * FROM users WHERE id NOT IN (1,2,3) ORDER BY id LIMIT 1; Or条件，使用Or函数\nSelectdb.Where(\u0026#34;role = ?\u0026#34;, \u0026#34;admin\u0026#34;).Or(\u0026#34;role = ?\u0026#34;, \u0026#34;super_admin\u0026#34;).Find(\u0026amp;users) // SELECT * FROM users WHERE role = \u0026#39;admin\u0026#39; OR role = \u0026#39;super_admin\u0026#39;; // Struct db.Where(\u0026#34;name = \u0026#39;jinzhu\u0026#39;\u0026#34;).Or(User{Name: \u0026#34;jinzhu 2\u0026#34;, Age: 18}).Find(\u0026amp;users) // SELECT * FROM users WHERE name = \u0026#39;jinzhu\u0026#39; OR (name = \u0026#39;jinzhu 2\u0026#39; AND age = 18); // Map db.Where(\u0026#34;name = \u0026#39;jinzhu\u0026#39;\u0026#34;).Or(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;jinzhu 2\u0026#34;, \u0026#34;age\u0026#34;: 18}).Find(\u0026amp;users) // SELECT * FROM users WHERE name = \u0026#39;jinzhu\u0026#39; OR (name = \u0026#39;jinzhu 2\u0026#39; AND age = 18); Struct\u0026amp;Map条件\n```go // Struct db.Where(\u0026amp;User{Name: \u0026quot;jinzhu\u0026quot;, Age: 20}).First(\u0026amp;user) // SELECT * FROM users WHERE name = \u0026quot;jinzhu\u0026quot; AND age = 20 ORDER BY id LIMIT 1; // Map db.Where(map[string]interface{}{\u0026quot;name\u0026quot;: \u0026quot;jinzhu\u0026quot;, \u0026quot;age\u0026quot;: 20}).Find(\u0026amp;users) // SELECT * FROM users WHERE name = \u0026quot;jinzhu\u0026quot; AND age = 20; // 主键切片条件 db.Where([]int64{20, 21, 22}).Find(\u0026amp;users) // SELECT * FROM users WHERE id IN (20, 21, 22); - 在使用**结构体**查询时，GORM只会查询非零值字段，当查询字段值为 `0`、`\u0026#39;\u0026#39;`、`false` 或其他 [零值](https://tour.golang.org/basics/12)，该字段不会被用于构建查询条件 ```go db.Where(\u0026amp;User{Name: \u0026#34;jinzhu\u0026#34;, Age: 0}).Find(\u0026amp;users) // SELECT * FROM users WHERE name = \u0026#34;jinzhu\u0026#34;; 可以使用map来构建该类零值查询条件\n```go db.Where(map[string]interface{}{\u0026quot;Name\u0026quot;: \u0026quot;jinzhu\u0026quot;, \u0026quot;Age\u0026quot;: 0}).Find(\u0026amp;users) // SELECT * FROM users WHERE name = \u0026quot;jinzhu\u0026quot; AND age = 0; ``` 内联条件,即不使用Where函数完成查询\n```go // SELECT * FROM users WHERE id = 23; // 根据主键获取记录，如果是非整型主键 db.First(\u0026amp;user, \u0026quot;id = ?\u0026quot;, \u0026quot;string_primary_key\u0026quot;) // SELECT * FROM users WHERE id = 'string_primary_key'; // Plain SQL db.Find(\u0026amp;user, \u0026quot;name = ?\u0026quot;, \u0026quot;jinzhu\u0026quot;) // SELECT * FROM users WHERE name = \u0026quot;jinzhu\u0026quot;; db.Find(\u0026amp;users, \u0026quot;name \u0026lt;\u0026gt; ? AND age \u0026gt; ?\u0026quot;, \u0026quot;jinzhu\u0026quot;, 20) // SELECT * FROM users WHERE name \u0026lt;\u0026gt; \u0026quot;jinzhu\u0026quot; AND age \u0026gt; 20; // Struct db.Find(\u0026amp;users, User{Age: 20}) // SELECT * FROM users WHERE age = 20; // Map db.Find(\u0026amp;users, map[string]interface{}{\u0026quot;age\u0026quot;: 20}) // SELECT * FROM users WHERE age = 20; ``` 字段选择\nSelect，选择特定字段\ndb.Select(\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;).Find(\u0026amp;users) // SELECT name, age FROM users; db.Select([]string{\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;}).Find(\u0026amp;users) // SELECT name, age FROM users; db.Table(\u0026#34;users\u0026#34;).Select(\u0026#34;COALESCE(age,?)\u0026#34;, 42).Rows() // SELECT COALESCE(age,\u0026#39;42\u0026#39;) FROM users; 智能选择字段，通过定义一个查询结构体，在调用时自动选择字段\ntype User struct { ID uint Name string Age int Gender string // 假设后面还有几百个字段... } //查询字段的小结构体 type APIUser struct { ID uint Name string } // 查询时会自动选择 `id`, `name` 字段 db.Model(\u0026amp;User{}).Limit(10).Find(\u0026amp;APIUser{}) // SELECT `id`, `name` FROM `users` LIMIT 10 Order，指定数据库检索记录时的排序方式\ndb.Order(\u0026#34;age desc, name\u0026#34;).Find(\u0026amp;users) // SELECT * FROM users ORDER BY age desc, name; // 多个 order db.Order(\u0026#34;age desc\u0026#34;).Order(\u0026#34;name\u0026#34;).Find(\u0026amp;users) // SELECT * FROM users ORDER BY age desc, name; db.Clauses(clause.OrderBy{ Expression: clause.Expr{SQL: \u0026#34;FIELD(id,?)\u0026#34;, Vars: []interface{}{[]int{1, 2, 3}}, WithoutParentheses: true}, }).Find(\u0026amp;User{}) // SELECT * FROM users ORDER BY FIELD(id,1,2,3) Order就是order by语句，所以当Order函数后接First函数或者Last时，First和Last的order将会失效 Limit \u0026amp; Offset函数，并且可以通过传值为-1重置这些条件\ndb.Limit(3).Find(\u0026amp;users) // SELECT * FROM users LIMIT 3; // 通过 -1 消除 Limit 条件 db.Limit(10).Find(\u0026amp;users1).Limit(-1).Find(\u0026amp;users2) // SELECT * FROM users LIMIT 10; (users1) // SELECT * FROM users; (users2) db.Offset(3).Find(\u0026amp;users) // SELECT * FROM users OFFSET 3; db.Limit(10).Offset(5).Find(\u0026amp;users) // SELECT * FROM users OFFSET 5 LIMIT 10; // 通过 -1 消除 Offset 条件 db.Offset(10).Find(\u0026amp;users1).Offset(-1).Find(\u0026amp;users2) // SELECT * FROM users OFFSET 10; (users1) // SELECT * FROM users; (users2) 分页查询器\nfunc Paginate(r *http.Request) func(db *gorm.DB) *gorm.DB { return func (db *gorm.DB) *gorm.DB { //此处应该传入page_num,page_size,而不是使用*http.Request类型 page, _ := strconv.Atoi(r.Query(\u0026#34;page\u0026#34;)) if page == 0 { page = 1 } pageSize, _ := strconv.Atoi(r.Query(\u0026#34;page_size\u0026#34;)) switch { case pageSize \u0026gt; 100: pageSize = 100 case pageSize \u0026lt;= 0: pageSize = 10 } offset := (page - 1) * pageSize return db.Offset(offset).Limit(pageSize) } } db.Scopes(Paginate(r)).Find(\u0026amp;users) db.Scopes(Paginate(r)).Find(\u0026amp;articles) Group \u0026amp; Having\ntype result struct { Date time.Time Total int } db.Model(\u0026amp;User{}).Select(\u0026#34;name, sum(age) as total\u0026#34;).Where(\u0026#34;name LIKE ?\u0026#34;, \u0026#34;group%\u0026#34;).Group(\u0026#34;name\u0026#34;).First(\u0026amp;result) // SELECT name, sum(age) as total FROM `users` WHERE name LIKE \u0026#34;group%\u0026#34; GROUP BY `name` db.Model(\u0026amp;User{}).Select(\u0026#34;name, sum(age) as total\u0026#34;).Group(\u0026#34;name\u0026#34;).Having(\u0026#34;name = ?\u0026#34;, \u0026#34;group\u0026#34;).Find(\u0026amp;result) // SELECT name, sum(age) as total FROM `users` GROUP BY `name` HAVING name = \u0026#34;group Distinct，从模型中选择不想同的值\ndb.Distinct(\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;).Order(\u0026#34;name, age desc\u0026#34;).Find(\u0026amp;results) Joins，感觉像脱裤子放屁，都写到这个份上了，还不如直接写SQL\ntype result struct { Name string Email string } db.Model(\u0026amp;User{}).Select(\u0026#34;users.name, emails.email\u0026#34;).Joins(\u0026#34;left join emails on emails.user_id = users.id\u0026#34;).Scan(\u0026amp;result{}) // SELECT users.name, emails.email FROM `users` left join emails on emails.user_id = users.id rows, err := db.Table(\u0026#34;users\u0026#34;).Select(\u0026#34;users.name, emails.email\u0026#34;).Joins(\u0026#34;left join emails on emails.user_id = users.id\u0026#34;).Rows() for rows.Next() { ... } db.Table(\u0026#34;users\u0026#34;).Select(\u0026#34;users.name, emails.email\u0026#34;).Joins(\u0026#34;left join emails on emails.user_id = users.id\u0026#34;).Scan(\u0026amp;results) // 带参数的多表连接 db.Joins(\u0026#34;JOIN emails ON emails.user_id = users.id AND emails.email = ?\u0026#34;, \u0026#34;jinzhu@example.org\u0026#34;).Joins(\u0026#34;JOIN credit_cards ON credit_cards.user_id = users.id\u0026#34;).Where(\u0026#34;credit_cards.number = ?\u0026#34;, \u0026#34;411111111111\u0026#34;).Find(\u0026amp;user) Joins预加载，Joins Predlaod会使用inner join加载相关数据\ndb.Joins(\u0026#34;Company\u0026#34;).Joins(\u0026#34;Manager\u0026#34;).Joins(\u0026#34;Account\u0026#34;).First(\u0026amp;user, 1) db.Joins(\u0026#34;Company\u0026#34;).Joins(\u0026#34;Manager\u0026#34;).Joins(\u0026#34;Account\u0026#34;).First(\u0026amp;user, \u0026#34;users.name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;) db.Joins(\u0026#34;Company\u0026#34;).Joins(\u0026#34;Manager\u0026#34;).Joins(\u0026#34;Account\u0026#34;).Find(\u0026amp;users, \u0026#34;users.id IN ?\u0026#34;, []int{1,2,3,4,5}) Count，用于获取匹配的记录数\nvar count int64 db.Model(\u0026amp;User{}).Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Or(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu 2\u0026#34;).Count(\u0026amp;count) // SELECT count(1) FROM users WHERE name = \u0026#39;jinzhu\u0026#39; OR name = \u0026#39;jinzhu 2\u0026#39; db.Model(\u0026amp;User{}).Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Count(\u0026amp;count) // SELECT count(1) FROM users WHERE name = \u0026#39;jinzhu\u0026#39;; (count) db.Table(\u0026#34;deleted_users\u0026#34;).Count(\u0026amp;count) // SELECT count(1) FROM deleted_users; Scan，扫描结果到结构体中，用法和Find类似\ntype Result struct { Name string Age int } var result Result db.Table(\u0026#34;users\u0026#34;).Select(\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;).Where(\u0026#34;name = ?\u0026#34;, \u0026#34;Antonio\u0026#34;).Scan(\u0026amp;result) // 使用原生SQL时，利用Scan扫描数据 db.Raw(\u0026#34;SELECT name, age FROM users WHERE name = ?\u0026#34;, \u0026#34;Antonio\u0026#34;).Scan(\u0026amp;result) Rows，支持通过行进行迭代\nrows, err := db.Model(\u0026amp;User{}).Where(\u0026#34;name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;).Rows() defer rows.Close() for rows.Next() { var user User // ScanRows 方法用于将一行记录扫描至结构体 db.ScanRows(rows, \u0026amp;user) } 命名参数，通过\n可嵌套的子查询，查询语句可以嵌套，形成子查询\ndb.Where(\u0026#34;amount \u0026gt; (?)\u0026#34;, db.Table(\u0026#34;orders\u0026#34;).Select(\u0026#34;AVG(amount)\u0026#34;)).Find(\u0026amp;orders) // SELECT * FROM \u0026#34;orders\u0026#34; WHERE amount \u0026gt; (SELECT AVG(amount) FROM \u0026#34;orders\u0026#34;); subQuery := db.Select(\u0026#34;AVG(age)\u0026#34;).Where(\u0026#34;name LIKE ?\u0026#34;, \u0026#34;name%\u0026#34;).Table(\u0026#34;users\u0026#34;) db.Select(\u0026#34;AVG(age) as avgage\u0026#34;).Group(\u0026#34;name\u0026#34;).Having(\u0026#34;AVG(age) \u0026gt; (?)\u0026#34;, subQuery).Find(\u0026amp;results) // SELECT AVG(age) as avgage FROM `users` GROUP BY `name` HAVING AVG(age) \u0026gt; (SELECT AVG(age) FROM `users` WHERE name LIKE \u0026#34;name%\u0026#34;) 将嵌套的条件，Group可以实现很复杂的SQL，但是为什么不直接使用原生SQL呢？\ndb.Where( db.Where(\u0026#34;pizza = ?\u0026#34;, \u0026#34;pepperoni\u0026#34;).Where(db.Where(\u0026#34;size = ?\u0026#34;, \u0026#34;small\u0026#34;).Or(\u0026#34;size = ?\u0026#34;, \u0026#34;medium\u0026#34;)), ).Or( db.Where(\u0026#34;pizza = ?\u0026#34;, \u0026#34;hawaiian\u0026#34;).Where(\u0026#34;size = ?\u0026#34;, \u0026#34;xlarge\u0026#34;), ).Find(\u0026amp;Pizza{}).Statement // SELECT * FROM `pizzas` WHERE (pizza = \u0026#34;pepperoni\u0026#34; AND (size = \u0026#34;small\u0026#34; OR size = \u0026#34;medium\u0026#34;)) OR (pizza = \u0026#34;hawaiian\u0026#34; AND size = \u0026#34;xlarge\u0026#34;) From子查询,允许在Table方法中嵌套一条新的查询语句\ndb.Table(\u0026#34;(?) as u\u0026#34;, db.Model(\u0026amp;User{}).Select(\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;)).Where(\u0026#34;age = ?\u0026#34;, 18}).Find(\u0026amp;User{}) // SELECT * FROM (SELECT `name`,`age` FROM `users`) as u WHERE `age` = 18 subQuery1 := db.Model(\u0026amp;User{}).Select(\u0026#34;name\u0026#34;) subQuery2 := db.Model(\u0026amp;Pet{}).Select(\u0026#34;name\u0026#34;) db.Table(\u0026#34;(?) as u, (?) as p\u0026#34;, subQuery1, subQuery2).Find(\u0026amp;User{}) // SELECT * FROM (SELECT `name` FROM `users`) as u, (SELECT `name` FROM `pets`) as p Find至map，通过指定 Model 或 Table，扫描至 map[string]interface{} 或 []map[string]interface{}\nvar result map[string]interface{} db.Model(\u0026amp;User{}).First(\u0026amp;result, \u0026#34;id = ?\u0026#34;, 1) var results []map[string]interface{} db.Table(\u0026#34;users\u0026#34;).Find(\u0026amp;results) Pluck，将单列数据，查询后返回到切片中\nvar ages []int64 db.Model(\u0026amp;users).Pluck(\u0026#34;age\u0026#34;, \u0026amp;ages) var names []string db.Model(\u0026amp;User{}).Pluck(\u0026#34;name\u0026#34;, \u0026amp;names) db.Table(\u0026#34;deleted_users\u0026#34;).Pluck(\u0026#34;name\u0026#34;, \u0026amp;names) // Distinct Pluck db.Model(\u0026amp;User{}).Distinct().Pluck(\u0026#34;Name\u0026#34;, \u0026amp;names) // SELECT DISTINCT `name` FROM `users` Scopes，通过将常用的查询，实现为一种接口，就可以在Scopes中进行调用，方便查询\nfunc AmountGreaterThan1000(db *gorm.DB) *gorm.DB { return db.Where(\u0026#34;amount \u0026gt; ?\u0026#34;, 1000) } func PaidWithCreditCard(db *gorm.DB) *gorm.DB { return db.Where(\u0026#34;pay_mode_sign = ?\u0026#34;, \u0026#34;C\u0026#34;) } func PaidWithCod(db *gorm.DB) *gorm.DB { return db.Where(\u0026#34;pay_mode_sign = ?\u0026#34;, \u0026#34;C\u0026#34;) } func OrderStatus(status []string) func (db *gorm.DB) *gorm.DB { return func (db *gorm.DB) *gorm.DB { return db.Where(\u0026#34;status IN (?)\u0026#34;, status) } } db.Scopes(AmountGreaterThan1000, PaidWithCreditCard).Find(\u0026amp;orders) // 查找所有金额大于 1000 的信用卡订单 db.Scopes(AmountGreaterThan1000, PaidWithCod).Find(\u0026amp;orders) // 查找所有金额大于 1000 的货到付款订单 db.Scopes(AmountGreaterThan1000, OrderStatus([]string{\u0026#34;paid\u0026#34;, \u0026#34;shipped\u0026#34;})).Find(\u0026amp;orders) // 查找所有金额大于 1000 且已付款或已发货的订单 优化查询计划\nimport \u0026#34;gorm.io/hints\u0026#34; db.Clauses(hints.New(\u0026#34;MAX_EXECUTION_TIME(10000)\u0026#34;)).Find(\u0026amp;User{}) // SELECT * /*+ MAX_EXECUTION_TIME(10000) */ FROM `users` 指定索引\nimport \u0026#34;gorm.io/hints\u0026#34; db.Clauses(hints.UseIndex(\u0026#34;idx_user_name\u0026#34;)).Find(\u0026amp;User{}) // SELECT * FROM `users` USE INDEX (`idx_user_name`) db.Clauses(hints.ForceIndex(\u0026#34;idx_user_name\u0026#34;, \u0026#34;idx_user_id\u0026#34;).ForJoin()).Find(\u0026amp;User{}) // SELECT * FROM `users` FORCE INDEX FOR JOIN (`idx_user_name`,`idx_user_id`)\u0026#34; Hook，查询操作，支持AfterFindhook，查询记录时会调用\nfunc (u *User) AfterFind(tx *gorm.DB) (err error) { if u.Role == \u0026#34;\u0026#34; { u.Role = \u0026#34;user\u0026#34; } return } 查询控制，针对查询结果执行额外的任务查询控制 原生SQL查询\nRaw形式\ntype Result struct { ID int Name string Age int } var result Result db.Raw(\u0026#34;SELECT id, name, age FROM users WHERE id = ?\u0026#34;, 3).Scan(\u0026amp;result) var age int db.Raw(\u0026#34;select sum(age) from users where role = ?\u0026#34;, \u0026#34;admin\u0026#34;).Scan(\u0026amp;age) Exec函数\ndb.Exec(\u0026#34;DROP TABLE users\u0026#34;) db.Exec(\u0026#34;UPDATE orders SET shipped_at=? WHERE id IN ?\u0026#34;, time.Now(), []int64{1,2,3}) // Exec SQL 表达式 db.Exec(\u0026#34;update users set money=? where name = ?\u0026#34;, gorm.Expr(\u0026#34;money * ? + ?\u0026#34;, 10000, 1), \u0026#34;jinzhu\u0026#34;) 命名参数，支持在Where，Raw,Exec等函数中使用，效果同上\ndb.Where(\u0026#34;name1 = @name OR name2 = @name\u0026#34;, sql.Named(\u0026#34;name\u0026#34;, \u0026#34;jinzhu\u0026#34;)).Find(\u0026amp;user) // SELECT * FROM `users` WHERE name1 = \u0026#34;jinzhu\u0026#34; OR name2 = \u0026#34;jinzhu\u0026#34; db.Where(\u0026#34;name1 = @name OR name2 = @name\u0026#34;, map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;jinzhu2\u0026#34;}).First(\u0026amp;result3) // SELECT * FROM `users` WHERE name1 = \u0026#34;jinzhu2\u0026#34; OR name2 = \u0026#34;jinzhu2\u0026#34; ORDER BY `users`.`id` LIMIT 1 // 原生 SQL 及命名参数 db.Raw(\u0026#34;SELECT * FROM users WHERE name1 = @name OR name2 = @name2 OR name3 = @name\u0026#34;, sql.Named(\u0026#34;name\u0026#34;, \u0026#34;jinzhu1\u0026#34;), sql.Named(\u0026#34;name2\u0026#34;, \u0026#34;jinzhu2\u0026#34;)).Find(\u0026amp;user) // SELECT * FROM users WHERE name1 = \u0026#34;jinzhu1\u0026#34; OR name2 = \u0026#34;jinzhu2\u0026#34; OR name3 = \u0026#34;jinzhu1\u0026#34; db.Exec(\u0026#34;UPDATE users SET name1 = @name, name2 = @name2, name3 = @name\u0026#34;, sql.Named(\u0026#34;name\u0026#34;, \u0026#34;jinzhunew\u0026#34;), sql.Named(\u0026#34;name2\u0026#34;, \u0026#34;jinzhunew2\u0026#34;)) // UPDATE users SET name1 = \u0026#34;jinzhunew\u0026#34;, name2 = \u0026#34;jinzhunew2\u0026#34;, name3 = \u0026#34;jinzhunew\u0026#34; db.Raw(\u0026#34;SELECT * FROM users WHERE (name1 = @name AND name3 = @name) AND name2 = @name2\u0026#34;, map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;jinzhu\u0026#34;, \u0026#34;name2\u0026#34;: \u0026#34;jinzhu2\u0026#34;}).Find(\u0026amp;user) // SELECT * FROM users WHERE (name1 = \u0026#34;jinzhu\u0026#34; AND name3 = \u0026#34;jinzhu\u0026#34;) AND name2 = \u0026#34;jinzhu2\u0026#34; type NamedArgument struct { Name string Name2 string } db.Raw(\u0026#34;SELECT * FROM users WHERE (name1 = @Name AND name3 = @Name) AND name2 = @Name2\u0026#34;, NamedArgument{Name: \u0026#34;jinzhu\u0026#34;, Name2: \u0026#34;jinzhu2\u0026#34;}).Find(\u0026amp;user) // SELECT * FROM users WHERE (name1 = \u0026#34;jinzhu\u0026#34; AND name3 = \u0026#34;jinzhu\u0026#34;) AND name2 = \u0026#34;jinzhu2\u0026#34; 更新 Save,保存所有字段，即使字段是零值\ndb.First(\u0026amp;user) user.Name = \u0026#34;jinzhu 2\u0026#34; user.Age = 100 db.Save(\u0026amp;user) // UPDATE users SET name=\u0026#39;jinzhu 2\u0026#39;, age=100, birthday=\u0026#39;2016-01-01\u0026#39;, updated_at = \u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111; 使用Select,Omit函数，在struct或者map[string]interface{}更新选定字段\n// Select 和 Map // User\u0026#39;s ID is `111`: db.Model(\u0026amp;user).Select(\u0026#34;name\u0026#34;).Updates(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 18, \u0026#34;actived\u0026#34;: false}) // UPDATE users SET name=\u0026#39;hello\u0026#39; WHERE id=111; db.Model(\u0026amp;user).Omit(\u0026#34;name\u0026#34;).Updates(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 18, \u0026#34;actived\u0026#34;: false}) // UPDATE users SET age=18, actived=false, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111; // Select 和 Struct （可以选中更新零值字段） db.Model(\u0026amp;result).Select(\u0026#34;Name\u0026#34;, \u0026#34;Age\u0026#34;).Updates(User{Name: \u0026#34;new_name\u0026#34;, Age: 0}) // UPDATE users SET name=\u0026#39;new_name\u0026#39;, age=0 WHERE id=111; Update，更新单列\n// 条件更新 db.Model(\u0026amp;User{}).Where(\u0026#34;active = ?\u0026#34;, true).Update(\u0026#34;name\u0026#34;, \u0026#34;hello\u0026#34;) // UPDATE users SET name=\u0026#39;hello\u0026#39;, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE active=true; // User 的 ID 是 `111` db.Model(\u0026amp;user).Update(\u0026#34;name\u0026#34;, \u0026#34;hello\u0026#34;) // UPDATE users SET name=\u0026#39;hello\u0026#39;, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111; // 根据条件和 model 的值进行更新 db.Model(\u0026amp;user).Where(\u0026#34;active = ?\u0026#34;, true).Update(\u0026#34;name\u0026#34;, \u0026#34;hello\u0026#34;) // UPDATE users SET name=\u0026#39;hello\u0026#39;, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111 AND active=true; 注意点：需要指定条件进行更新，否则会返回ErrMissingWhereClause 错误 Updates，更新多列，支持struct和map[string]interface{} 作为参数\n// 根据 `struct` 更新属性，只会更新非零值的字段 db.Model(\u0026amp;user).Updates(User{Name: \u0026#34;hello\u0026#34;, Age: 18, Active: false}) // UPDATE users SET name=\u0026#39;hello\u0026#39;, age=18, updated_at = \u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id = 111; // 根据 `map` 更新属性 db.Model(\u0026amp;user).Updates(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 18, \u0026#34;actived\u0026#34;: false}) // UPDATE users SET name=\u0026#39;hello\u0026#39;, age=18, actived=false, updated_at=\u0026#39;2013-11-17 21:34:10\u0026#39; WHERE id=111; 获取受影响的行数，Updates返回更新的记录数和更新时发生的异常\n// 通过 `RowsAffected` 得到更新的记录数 result := db.Model(User{}).Where(\u0026#34;role = ?\u0026#34;, \u0026#34;admin\u0026#34;).Updates(User{Name: \u0026#34;hello\u0026#34;, Age: 18}) // UPDATE users SET name=\u0026#39;hello\u0026#39;, age=18 WHERE role = \u0026#39;admin; result.RowsAffected // 更新的记录数 result.Error // 更新的错误 批量更新，当数据对象Model中没有指定主键，那么就会更新条件中的全部记录\n// 根据 struct 更新 db.Model(User{}).Where(\u0026#34;role = ?\u0026#34;, \u0026#34;admin\u0026#34;).Updates(User{Name: \u0026#34;hello\u0026#34;, Age: 18}) // UPDATE users SET name=\u0026#39;hello\u0026#39;, age=18 WHERE role = \u0026#39;admin; // 根据 map 更新 db.Table(\u0026#34;users\u0026#34;).Where(\u0026#34;id IN ?\u0026#34;, []int{10, 11}).Updates(map[string]interface{}{\u0026#34;name\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 18}) // UPDATE users SET name=\u0026#39;hello\u0026#39;, age=18 WHERE id IN (10, 11); 强制全局更新，默认GORM不会执行为加条件的批量更新，因此需要使用原生SQL或者加一些额外的条件\ndb.Model(\u0026amp;User{}).Update(\u0026#34;name\u0026#34;, \u0026#34;jinzhu\u0026#34;).Error // gorm.ErrMissingWhereClause db.Model(\u0026amp;User{}).Where(\u0026#34;1 = 1\u0026#34;).Update(\u0026#34;name\u0026#34;, \u0026#34;jinzhu\u0026#34;) // UPDATE users SET `name` = \u0026#34;jinzhu\u0026#34; WHERE 1=1 db.Exec(\u0026#34;UPDATE users SET name = ?\u0026#34;, \u0026#34;jinzhu\u0026#34;) // UPDATE users SET name = \u0026#34;jinzhu\u0026#34; db.Session(\u0026amp;gorm.Session{AllowGlobalUpdate: true}).Model(\u0026amp;User{}).Update(\u0026#34;name\u0026#34;, \u0026#34;jinzhu\u0026#34;) // UPDATE users SET `name` = \u0026#34;jinzhu\u0026#34; 使用SQL表达式和Context Valuer更新列\nSQL表达式\n// product 的 ID 是 `3` db.Model(\u0026amp;product).Update(\u0026#34;price\u0026#34;, gorm.Expr(\u0026#34;price * ? + ?\u0026#34;, 2, 100)) // UPDATE \u0026#34;products\u0026#34; SET \u0026#34;price\u0026#34; = price * 2 + 100, \u0026#34;updated_at\u0026#34; = \u0026#39;2013-11-17 21:34:10\u0026#39; WHERE \u0026#34;id\u0026#34; = 3; db.Model(\u0026amp;product).Updates(map[string]interface{}{\u0026#34;price\u0026#34;: gorm.Expr(\u0026#34;price * ? + ?\u0026#34;, 2, 100)}) // UPDATE \u0026#34;products\u0026#34; SET \u0026#34;price\u0026#34; = price * 2 + 100, \u0026#34;updated_at\u0026#34; = \u0026#39;2013-11-17 21:34:10\u0026#39; WHERE \u0026#34;id\u0026#34; = 3; db.Model(\u0026amp;product).UpdateColumn(\u0026#34;quantity\u0026#34;, gorm.Expr(\u0026#34;quantity - ?\u0026#34;, 1)) // UPDATE \u0026#34;products\u0026#34; SET \u0026#34;quantity\u0026#34; = quantity - 1 WHERE \u0026#34;id\u0026#34; = 3; db.Model(\u0026amp;product).Where(\u0026#34;quantity \u0026gt; 1\u0026#34;).UpdateColumn(\u0026#34;quantity\u0026#34;, gorm.Expr(\u0026#34;quantity - ?\u0026#34;, 1)) // UPDATE \u0026#34;products\u0026#34; SET \u0026#34;quantity\u0026#34; = quantity - 1 WHERE \u0026#34;id\u0026#34; = 3 AND quantity \u0026gt; 1; Context Valuer\n// 根据自定义数据类型创建 type Location struct { X, Y int } func (loc Location) GormValue(ctx context.Context, db *gorm.DB) clause.Expr { return clause.Expr{ SQL: \u0026#34;ST_PointFromText(?)\u0026#34;, Vars: []interface{}{fmt.Sprintf(\u0026#34;POINT(%d %d)\u0026#34;, loc.X, loc.Y)}, } } db.Model(\u0026amp;User{ID: 1}).Updates(User{ Name: \u0026#34;jinzhu\u0026#34;, Point: Point{X: 100, Y: 100}, }) // UPDATE `user_with_points` SET `name`=\u0026#34;jinzhu\u0026#34;,`point`=ST_PointFromText(\u0026#34;POINT(100 100)\u0026#34;) WHERE `id` = 1 Hook\n// 开始事务 BeforeSave BeforeUpdate // 关联前的 save // 更新 db // 关联后的 save AfterUpdate AfterSave // 提交或回滚事务 示例\nfunc (u *User) BeforeUpdate(tx *gorm.DB) (err error) { if u.readonly() { err = errors.New(\u0026#34;read only user\u0026#34;) } return } // 在同一个事务中更新数据 func (u *User) AfterUpdate(tx *gorm.DB) (err error) { if u.Confirmed { tx.Model(\u0026amp;Address{}).Where(\u0026#34;user_id = ?\u0026#34;, u.ID).Update(\u0026#34;verfied\u0026#34;, true) } return } UpdateColumn，UpdateColumns跳过Hook，并且不自动追踪更新时间\n// 更新单个列 db.Model(\u0026amp;user).UpdateColumn(\u0026#34;name\u0026#34;, \u0026#34;hello\u0026#34;) // UPDATE users SET name=\u0026#39;hello\u0026#39; WHERE id = 111; // 更新多个列 db.Model(\u0026amp;user).UpdateColumns(User{Name: \u0026#34;hello\u0026#34;, Age: 18}) // UPDATE users SET name=\u0026#39;hello\u0026#39;, age=18 WHERE id = 111; // 更新选中的列 db.Model(\u0026amp;user).Select(\u0026#34;name\u0026#34;, \u0026#34;age\u0026#34;).UpdateColumns(User{Name: \u0026#34;hello\u0026#34;, Age: 0}) // UPDATE users SET name=\u0026#39;hello\u0026#39;, age=0 WHERE id = 111; Changed检查Model对象字段是否与Update，Updates的值是否一样，字段是否有变更，当字段未被忽略，且发生变更，则返回true，可以用在Before Update Hook\n注意：Changed方法只能与Update，Updates一起使用 func (u *User) BeforeUpdate(tx *gorm.DB) (err error) { // 如果 Role 字段有变更 if tx.Statement.Changed(\u0026#34;Role\u0026#34;) { return errors.New(\u0026#34;role not allowed to change\u0026#34;) } if tx.Statement.Changed(\u0026#34;Name\u0026#34;, \u0026#34;Admin\u0026#34;) { // 如果 Name 或 Role 字段有变更 tx.Statement.SetColumn(\u0026#34;Age\u0026#34;, 18) } // 如果任意字段有变更 if tx.Statement.Changed() { tx.Statement.SetColumn(\u0026#34;RefreshedAt\u0026#34;, time.Now()) } return nil } db.Model(\u0026amp;User{ID: 1, Name: \u0026#34;jinzhu\u0026#34;}).Updates(map[string]interface{\u0026#34;name\u0026#34;: \u0026#34;jinzhu2\u0026#34;}) // Changed(\u0026#34;Name\u0026#34;) =\u0026gt; true db.Model(\u0026amp;User{ID: 1, Name: \u0026#34;jinzhu\u0026#34;}).Updates(map[string]interface{\u0026#34;name\u0026#34;: \u0026#34;jinzhu\u0026#34;}) // Changed(\u0026#34;Name\u0026#34;) =\u0026gt; false, 因为 `Name` 没有变更 db.Model(\u0026amp;User{ID: 1, Name: \u0026#34;jinzhu\u0026#34;}).Select(\u0026#34;Admin\u0026#34;).Updates(map[string]interface{ \u0026#34;name\u0026#34;: \u0026#34;jinzhu2\u0026#34;, \u0026#34;admin\u0026#34;: false, }) // Changed(\u0026#34;Name\u0026#34;) =\u0026gt; false, 因为 `Name` 没有被 Select 选中并更新 db.Model(\u0026amp;User{ID: 1, Name: \u0026#34;jinzhu\u0026#34;}).Updates(User{Name: \u0026#34;jinzhu2\u0026#34;}) // Changed(\u0026#34;Name\u0026#34;) =\u0026gt; true db.Model(\u0026amp;User{ID: 1, Name: \u0026#34;jinzhu\u0026#34;}).Updates(User{Name: \u0026#34;jinzhu\u0026#34;}) // Changed(\u0026#34;Name\u0026#34;) =\u0026gt; false, 因为 `Name` 没有变更 db.Model(\u0026amp;User{ID: 1, Name: \u0026#34;jinzhu\u0026#34;}).Select(\u0026#34;Admin\u0026#34;).Updates(User{Name: \u0026#34;jinzhu2\u0026#34;}) // Changed(\u0026#34;Name\u0026#34;) =\u0026gt; false, 因为 `Name` 没有被 Select 选中并更新 SetColumn更新时在Hook中变更字段值\nfunc (user *User) BeforeSave(tx *gorm.DB) (err error) { if pw, err := bcrypt.GenerateFromPassword(user.Password, 0); err == nil { tx.Statement.SetColumn(\u0026#34;EncryptedPassword\u0026#34;, pw) } if tx.Statement.Changed(\u0026#34;Code\u0026#34;) { s.Age += 20 tx.Statement.SetColumn(\u0026#34;Age\u0026#34;, s.Age+20) } } db.Model(\u0026amp;user).Update(\u0026#34;Name\u0026#34;, \u0026#34;jinzhu\u0026#34;) 删除 Delete指定主键，删除一条记录\ndb.Delete(\u0026amp;User{}, 10) // DELETE FROM users WHERE id = 10; db.Delete(\u0026amp;User{}, \u0026#34;10\u0026#34;) // DELETE FROM users WHERE id = 10; db.Delete(\u0026amp;users, []int{1,2,3}) // DELETE FROM users WHERE id IN (1,2,3); Delete不指定主键批量删除\ndb.Where(\u0026#34;email LIKE ?\u0026#34;, \u0026#34;%jinzhu%\u0026#34;).Delete(Email{}) // DELETE from emails where email LIKE \u0026#34;%jinzhu%\u0026#34;; db.Delete(Email{}, \u0026#34;email LIKE ?\u0026#34;, \u0026#34;%jinzhu%\u0026#34;) // DELETE from emails where email LIKE \u0026#34;%jinzhu%\u0026#34;; Gorm默认不执行无条件的批量删除，需要添加额外的条件以强制批量删除\ndb.Delete(\u0026amp;User{}).Error // gorm.ErrMissingWhereClause 使用原生SQL\ndb.Exec(\u0026#34;DELETE FROM users\u0026#34;) // DELETE FROM users 添加额外的条件\ndb.Where(\u0026#34;1 = 1\u0026#34;).Delete(\u0026amp;User{}) // DELETE FROM `users` WHERE 1=1 启用AllowGlobalUpdate模式\ndb.Session(\u0026amp;gorm.Session{AllowGlobalUpdate: true}).Delete(\u0026amp;User{}) // DELETE FROM users 添加gorm.Deleteat字段，启用GORM的软删除\n启用软删除时，当使用Delete时，记录不会从数据库中删除，GORM会将DeleteAt置为当前时间，并且无法通过正常的查询方法找到该条记录\n// user 的 ID 是 `111` db.Delete(\u0026amp;user) // UPDATE users SET deleted_at=\u0026#34;2013-10-29 10:23\u0026#34; WHERE id = 111; // 批量删除 db.Where(\u0026#34;age = ?\u0026#34;, 20).Delete(\u0026amp;User{}) // UPDATE users SET deleted_at=\u0026#34;2013-10-29 10:23\u0026#34; WHERE age = 20; 正常查询无法找到被软删除的记录\n// 在查询时会忽略被软删除的记录 db.Where(\u0026#34;age = 20\u0026#34;).Find(\u0026amp;user) // SELECT * FROM users WHERE age = 20 AND deleted_at IS NULL; 查找被软删除的记录\ndb.Unscoped().Where(\u0026#34;age = 20\u0026#34;).Find(\u0026amp;users) // SELECT * FROM users WHERE age = 20; 永久删除\ndb.Unscoped().Delete(\u0026amp;order) // DELETE FROM orders WHERE id=10; Hook\n// 开始事务 BeforeDelete // 删除 db 中的数据 AfterDelete // 提交或回滚事务 示例\n// 在同一个事务中更新数据 func (u *User) AfterDelete(tx *gorm.DB) (err error) { if u.Confirmed { tx.Model(\u0026amp;Address{}).Where(\u0026#34;user_id = ?\u0026#34;, u.ID).Update(\u0026#34;invalid\u0026#34;, false) } return } Locking FOR UPDATE\ndb.Clauses(clause.Locking{Strength: \u0026#34;UPDATE\u0026#34;}).Find(\u0026amp;users) // SELECT * FROM `users` FOR UPDATE FOR SHARE\ndb.Clauses(clause.Locking{ Strength: \u0026#34;SHARE\u0026#34;, Table: clause.Table{Name: clause.CurrentTable}, }).Find(\u0026amp;users) // SELECT * FROM `users` FOR SHARE OF `users` 关联 Belongs To ","date":"2022-02-10","img":"","permalink":"/posts/note/gorm/","series":null,"tags":["gorm"],"title":"GORM学习"},{"categories":["notes"],"content":"","date":"2022-01-04","img":"","permalink":"/posts/note/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/","series":["notes"],"tags":["notes"],"title":"数据分析"},{"categories":["分布式技术原理"],"content":"在分布式系统中，排他性的资源访问方式,就叫做分布式互斥（Distributed Mutual Exclusion）,而这种被互斥访问的共享资源，就叫做临界资源\n分布式系统中解决分布式互斥主要有以下几种方式\n集中式算法/中央服务器算法 我们引入一个协调者程序，得到一个分布式互斥算法。每个程序在需要访问临界资源时，先给协调者发送一个请求。 如果当前没有程序使用这个资源，协调者直接授权请求程序访问；否则，按照先来后到的顺序为请求程序“排一个号”。 如果有程序使用完资源，则通知协调者，协调者从“排号”的队列里取出排在最前面的请求，并给它发送授权消息。 拿到授权消息的程序，可以直接去访问临界资源。\n集中式算法示意图：\n如上图所示，协调者程序根据普通程序请求临界资源的顺序，将其放入请求队列中，依次发放授权，每个程序完成临界资源请求后，通知协调者释放授权，排队的下一次程序继续获得授权。\n交互次数 向协调者发送请求授权信息 协调者向程序发放授权 程序使用完临界资源后，向协调者发送释放授权信息 优点 直观，简单，信息交互量少，易于实现\n缺点 协调者会成为性能瓶颈，当普通程序很多时，协调者需要处理的消息数量会随着需要访问临界资源的程序数量线性增加 容易引发单点故障，当协调者故障时，会导致所有的程序都无法访问临界资源，导致整个系统不可用。 可改进点 通过将master节点集群化，来降低协调者单点故障时，系统的可用性\n总结 集中式算法具有简单、易于实现的特点，但可用性、性能易受协调者影响。在可靠性和性能有一定保障的情况下，比如中央服务器计算能力强、性能高、故障率低，或者中央服务器进行了主备，主故障后备可以立马升为主，且数据可恢复的情况下，集中式算法可以适用于比较广泛的应用场景。\n分布式算法/使用组播和逻辑时钟的算法 如何不引入协调者的情况下，实现对于临界资源的互斥访问呢。当一个程序要访问临界资源时，先向系统中的其他程序发送一条请求消息，在接收到所有程序返回的同意消息后，就可以访问临界资源。其中，请求消息需要包含所请求的资源，请求者id，发起请求的时间。\n如图所示，程序 1、2、3 需要访问共享资源 A。在时间戳为 8 的时刻，程序 1 想要使用资源 A，于是向程序 2 和 3 发起使用资源 A 的申请，希望得到它们的同意。在时间戳为 12 的时刻，程序 3 想要使用资源 A，于是向程序 1 和 2 发起访问资源 A 的请求。\n此时程序 2 暂时不访问资源 A，因此同意了程序 1 和 3 的资源访问请求。对于程序 3 来说，由于程序 1 提出请求的时间更早，因此同意程序 1 先使用资源，并等待程序 1 返回同意消息。\n程序 1 接收到其他所有程序的同意消息之后，开始使用资源 A。当程序 1 使用完资源 A 后，释放使用权限，向请求队列中需要使用资源 A 的程序 3 发送同意使用资源的消息，并将程序 3 从请求队列中删除。此时，程序 3 收到了其他所有程序的同意消息，获得了使用资源 A 的权限，开始使用临界资源 A 的旅程。\n交互次数 向其他 n-1 个程序发送访问临界资源的请求，总共需要 n-1 次消息交互 需要接收到其他 n-1 个程序回复的同意消息，方可访问资源，总共需要 n-1 次消息交互。 一个程序要成功访问临界资源，至少需要 2*(n-1) 次消息交互。假设，现在系统中的 n 个程序都要访问临界资源，则会同时产生 2n(n-1) 条消息。 优点 基于先到先得，投票全票通过的公平访问机制\n缺点 在大型系统中使用分布式算法，消息数量会随着需要访问临界资源的程序数量呈指数级增加。当系统内需要访问临界资源的程序增多时，容易产生“信令风暴”，也就是程序收到的请求完全超过了自己的处理能力，而导致自己正常的业务无法开展。 一旦某一程序发生故障，无法发送同意消息，那么其他程序均处在等待回复的状态中，使得整个系统处于停滞状态，导致整个系统不可用。所以，相对于集中式算法的协调者故障，分布式算法的可用性更低。 可改进点 在某些场景下，可以当系统中过半数（n/2+1）程序回复通信消息即视为获取临界资源成功，这样可以降低通信数。常用于分布式选举场景\n总结 分布式算法是一个“先到先得”和“投票全票通过”的公平访问机制，但通信成本较高，可用性也比集中式算法低，适用于临界资源使用频度较低，且系统规模较小的场景。\n令牌环算法/基于环的算法 将临界资源的访问权以令牌的形式在程序间进行环形传递，收到令牌的程序有权访问临界资源，访问完成后，将令牌传递给下一个程序，如果该程序不需要访问临界资源，继续进行传递。\n如上图所示，每一个环中程序不管是否想要访问资源，都需要接收并传递令牌，所以也会带来一些无效的通信。不过，该算法的通信效率较高，并且在一个通信周期内，每一个程序都有机会使用到临界资源，公平性很好。\n如果出现单点故障，令牌环算法，可以最直接将令牌传递给故障程序的下一个程序，从而解决单点问题，提高系统的健壮性。\n优点 令牌环算法公平性高，当改进单点故障后，稳定性也很好\n缺点 程序1在使用完临界资源后，需要等待一个通信周期才能再次使用，实时性较低 如果程序对临界资源的使用频率较低，会带来很多无效通信 可改进点 可以根据参与者使用频率去更新程序的权重，结合权重值选出下一位参与者，这样可以提高单个程序实时性，降低其令牌周期\n总结 令牌环算法的公平性高，在改进单点故障后，稳定性也很高，适用于系统规模较小，并且系统中每个程序使用临界资源的频率高且使用时间比较短的场景。\n令牌环算法通常会与通信令牌结合，从而取得很好的效果。特别是当系统支持广播或组播通信模式时，该算法更加高效、可行。\n多层结构的分布式令牌环算法 由于大规模分布式系统的复杂性，因此该算法也比较复杂。它把整个广域网系统中的节点组织为多层结构，分割为多个局域网。\n在每个局域网中都构成环结构，有令牌环算法进行协调。同时局域网和局域网之间也构成环结构，这个·环为上级环。通过这种形式，实现分布式互斥。\n","date":"2021-11-23","img":"","permalink":"/posts/distributed/%E5%88%86%E5%B8%83%E5%BC%8F%E6%8A%80%E6%9C%AF%E5%8E%9F%E7%90%86_%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%92%E6%96%A5/","series":null,"tags":["分布式技术原理"],"title":"分布式互斥"},{"categories":["rpc"],"content":"gRPC概述 概览\ngRPC是Google开发并开源的一套语言中立的RPC框架\n特点\n语言中立 基于IDL文件定义服务，通过proto3工具生成指定语言的数据结构，服务端接口以及客户端Stub 通信协议基于标准的HTTP/2设计，支持双向流，消息头压缩，单TCP的多路复用，服务端推送等特性，可以在移动端设备上更加省电和节省流量 序列化支持Protocol Buffer 和JSON协议，该协议是一种语言无关的高性能序列化框架 服务端创建流程 gRPC服务端java版本的实现使用了Build模式，对底层服务绑定，transportServer和NettyServer的创建和实例化都做了封装和屏蔽，让服务调用者不用关心gRPC的调用细节\n整体流程分为3步：\n创建Netty HTTP/2服务端 将需要的服务端接口实现类注册到内容的Registy中，RPC调用时，可以根据RPC请求消息中的服务定义信息查询到服务接口实现类 创建gRPC Server，它是gRPC服务端的抽象，聚合了各种Listener，用于RPC消息的统一调度和处理 关键流程分析：\nNettyServer 实例创建：\n首先需要初始化NettyServer，它是gRPC基于Netty4.1 HTTP/2协议栈上封装的HTTP/2 服务端。NettyServer构建完成后，监听指定的Socket地址，即可实现基于HTTP/2协议的消息头接入\n绑定IDL定义的服务接口实现类:\ngRPC与其他很多RPC框架不同的是，服务接口实现类的调用并不是通过动态代理和反射机制，而是通过proto工具生成代码，在服务端启动时，将服务接口实现类实例注册到gRPC的内部服务注册中心上。当请求消息接入后，可以根据服务名和方法名，直接调用启动时注册的服务实例，而不需要通过反射的方式进行调用，性能更好\ngRPC服务实例（ServerImpl构建）:\nServerImpl负责整个gRPC服务端消息的调度和处理，创建ServerImpl实例过程中，会对服务端依赖的对象进行初始化，例如Netty的线程池资源，gRPC的线程池，内部的服务注册类（InternalHandlerRegitry）等，ServerImpl初始化完成后，就可以调用NettyServer的start方法启动HTTP/2服务端，接收gRPC客户端的服务调用请求\n服务端service调用流程 gRPC的客户端请求消息由Netty Http2ConnectionHandler接入，由gRPC负责将PB或者JSON消息反序列化为POJO对象，然后通过服务定义查询到该消息对应的接口实力，发起本地java接口调用。调用完成后，将响应消息序列化为对应和格式，通过HTTP2 Frame发送回客户端\n整体流程分为4步：\ngRPC请求消息接入 gRPC消息头和消息体处理 内部的服务路由和调用 响应消息发送 关键流程分析\ngRPC请求消息接入\nNetty通过底层的HTTP/2协议栈，通过Http2ConnectionHandler，实现了HTTP/2消息的统一接入和处理。gRPC通过注册Http2FrameListener监听器，回调接收HTTP2协议的消息数据。gRPC 通过 FrameListener 重载 Http2FrameListener 的 onDataRead、onHeadersRead 等方法，将Netty的HTTP/2消息转发到gRPC的NettyServerHandler中，实现基于HTTP/2的RPC请求消息接入\ngRPC 消息头处理\n通过NettyServerHandler的onHeadersRead()方法，实现对gRPC消息头和消息体的处理，流程如下\n1.对HTTP Header的Content-Type校验，此处必须是\u0026quot;application/grpc\u0026quot;\n2.从HTTP Header的URL中提取接口名和方法名\n3.将Netty的HTTP Header转换为gRPC内部的Metadata，Metadata内部维护了一个键值对的二维数组namesAndValues\n4.创建NettyServerStream对象，它持有了Sink和TransportState类，负责将消息封装为GrpcFrameCommand，与底层Netty进行交互，实现协议消息的处理\n5.创建NettyServerStreatm之后，触发erverTransportListener的streamCreated方法，完成消息上下文和gRPC业务监听器的创建\n6.gRPC上下文的创建，CancellableContext.CancellationListener的cancel方法，发送CancelServerStreamCommand指令\n7.JumpToApplicationThreadServerStreamListener 的创建，从 ServerStream 跳转到应用线程中进行服务调用，gRPC 服务端的接口调用主要通过 JumpToApplicationThreadServerStreamListener 的 messageRead 和 halfClosed 方法完成\n8.将 NettyServerStream 的 TransportState 缓存到 Netty 的 Http2Stream 中，当处理请求消息体时，可以根据 streamId 获取到 Http2Stream，进而根据“streamKey”还原 NettyServerStream 的 TransportState，进行后续处理\ngRPC消息体处理\n通过NettyServerHandler的onDataRead()方法，实现对gRPC消息头和消息体的处理，流程如下\n关键步骤:\n1.gRPC NettyServerHandler在处理完消息头之后需要缓存上下文，因为处理消息体时也需要使用\n2.onDataRead和onHeadersRead方法都是由NIO线程进行调度，同时在执行时，会采用并行+交叉串行的方式运行\n内部的服务路由和调用\n内部的服务路由和调用，主要包括如下步骤\n1.将请求消息体反序列化为JAVA的POJO对象，即IDL中定义的请求参数对象\n2.根据请求消息头中的方法名到注册中心查询对象的服务定义信息\n3.通过JAVA本地接口调用方式，调用服务端启动时注册对的IDL接口实现类\n流程如下：\n关键步骤：\n解码：对HTTP/2 Body进行应用层解码，转换为服务端接口的请求参数，解码的关键是调用requestMarshaller.patse(),将PB码流转换为JAVA对象 路由：根据URL中的方法名从内部服务注册中心查询到对应的服务实例，路由的关键是调用registry.lookupMethod(methodName)获取到ServerMethodDefinition对象 调用：调用服务端接口实现类的指定方法，实现RPC调用，与一些RPC框架不同的是，此处调用是Java本地接口，不是反射调用，因此性能更优，实现关键是UnaryRequestMethod.invoke(request,responseObserver)方法 响应消息发送\n响应消息的发送由StreamObserver的onNext触发，流程如下\n1.分别发送gRPC HTTP/2响应消息头和消息体，由NettyServerStream的Sink将响应消息封装为SendResponseHeadersCommand和SendGrpcFrameCommand，加入到WriteQueue中\n2.WriteQueue通过Netty的NioEventLoop线程进行消息处理，NioEventLoop将SendResponseHeadersCommand和SendGrpcFrameCommand写入到Netty的Channel中，进而触发DefaultChannelPipeline的write(Object msg,ChannelPipeline)操作\n3.响应消息通过ChannelPipeline职责链进行调度，触发NettyServerHandler的SendResponseHeaders和sendGrpcFrame方法，调用Http2ConnextionEncoder的witeHeaders和writeData方法，将响应消息通过Netty的HTTP/2协议栈发送给客户端\n服务端线程模型 BIO 调度模型：\n服务端监听线程Acceptor负责客户端连接的接入，每当有新的客户端接入，就会创建一个新的I/O线程负责处理Socket 客户端请求消息的读取和应答的发送，都由I/O线程负责 除了I/O读写操作，默认情况下业务的逻辑处理，例如DB操作，也都在I/O线程处理 I/O操作采用同步阻塞操作，读写没有完成，I/O线程会同步阻塞 存在的问题：\n性能问题：一连接一线程模型导致服务端的并发接入数和系统吞吐量受到极大的限制 可靠性问题：由于I/O操作采用同步阻塞模式，当网络拥塞或者通信对端处理缓慢会导致I/O线程被挂起，阻塞时间无法预测 可维护性问题：I/O线程数无法有效控制、资源无法有效共享（多线程并发问题）、系统可维护性差 优化方向：\n池化：\n​\t为了解决同步阻塞I/O面临的一个链路需要一个线程处理的问题。会使用线程池来处理客户端的请求接入，形成客户端个数“M”与线程池最大线程数“N”的比例关系，其中M可以远远大于N，通过线程池可以灵活的调配线程资源，设置线程的最大值，防止由于海量并发接入导致线程耗尽。\n​\t通过使用线程池，避免了为每个请求都创建一个独立线程造成的线程资源耗尽问题。但是由于底层依然是同步阻塞模型，线程阻塞时间依然取决于对方的处理速度，优化之后的BIO线程模型依然无法从根本上解决性能线性扩展问题\nBIO线程模型如下图所示：\nNIO NIO在2002年以JSR-51的身份随JDK发布。\nSelector会不断轮询注册在其上的Channel，如果某个Channel上面有新的TCP连接接入】读和写事件，这个Channel就会处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以获取就绪Channel集合，进行后续的I/O操作\n通常一个I/O线程会聚合一个Selector，一个Selector可以同时注册N个Channel，这样单个I/O线程都可以同时并发处理多个客户端连接。另外，由于I/O操作是非阻塞的，因此也不会受限于网络速度和对方端点的处理时延，可靠性和效率大大提升\nNIO线程模型（Reactor模式）如下图所示:\ngRPC线程模型 gRPC服务端线程模型 java语言实现的gRPC由Netty线程和gRPC应用线程组成，如下图所示：\nNetty Server 线程模型\n工作流程如下：\n从主线程池（bossGroup）中随机选择一个Reactor线程作为Acceptor线程，用于绑定监听端口，接收客户端连接 Acceptor线程接收客户端连接请求后创建新的SocketChannel，将其注册到主线程池（bossGroup）的其他Reactor线程上，由其负责接入认证，握手等操作 应用层链路开始，将SocketChannel从主线程池对的Reator线程的多路复用器上摘除，重新注册到Sub线程池（workerGroup）的线程上，用于处理IO操作 负责HTTP/2服务端创建、HTTP/2请求消息的接入和响应发送 gRPC service线程模型\ngRPC服务端调度线程为SerializingExecutor，它实现了Executor和Runnable接口，通过外部的Executor对象，调度和处理Runnable，同时内部通过任务队列（ConcurrentLinkedQueue），通过run方法循环处理队列中存放的Runnable对象 负责gRPC的序列化和反序列化，以及应用服务接口的调用 I/O通信线程模型\ngRPC的做法是服务端监听线程和I/O线程分离的Reactor多线程模型\n工作流程如下：\n业务线程发起创建服务端操作，在创建服务端时实例化两个EventLoopGroup。 服务端Selector轮询，监听客户端连接 若监听到客户端连接，则创建客户端SocketChannel连接，从workerGroup中随机选择一个NioEventLoop线程，将SocketChannel注册到该线程持有的Selecotr 通过调用EventLoopGroup的next()获取一个EventLoop(NioEventLoop)，用于处理网络I/O事件 工作原理如下：\n线程调度和切换策略\nNetty Server I/O 线程的职责：\ngRPC 请求消息的读取、响应消息的发送 HTTP/2 协议消息的编码和解码 NettyServerHandler 的调度 gRPC service 线程的职责：\n将 gRPC 请求消息（PB 码流）反序列化为接口的请求参数对象 将接口响应对象序列化为 PB 码流 gRPC 服务端接口实现类调用 Netty Server使用的NIO线程是NioEventLoop，具有以下职责\n作为服务端 Acceptor 线程，负责处理客户端的请求接入；\n作为客户端 Connecor 线程，负责注册监听连接操作位，用于判断异步连接结果；\n作为 I/O 线程，监听网络读操作位，负责从 SocketChannel 中读取报文；\n作为 I/O 线程，负责向 SocketChannel 写入报文发送给对方，如果发生写半包，会自动注册监听写事件，用于后续继续发送半包数据，直到数据全部发送完成；\n作为定时任务线程，可以执行定时任务，例如链路空闲检测和发送心跳消息等；\n作为线程执行器可以执行普通的任务 Task（Runnable）。\nNioEventLoop同时支持I/O操作和Runnable执行：这样可以避免锁竞争，例如心跳检测，往往需要周期性的执行，如果 NioEventLoop 不支持定时任务执行，则用户需要自己创建一个类似 ScheduledExecutorService 的定时任务线程池或者定时任务线程，周期性的发送心跳，发送心跳需要网络操作，就要跟 I/O 线程所持有的资源进行交互，例如 Handler、ByteBuf、NioSocketChannel 等，这样就会产生锁竞争，需要考虑并发安全问题。\n协议层消息的接收和编解码由Netty的I/O（NioEventLoop）线程负责\n应用层的处理由应用线程gRPC相关线程负责，防止由于应用层耗时阻塞Netty的I/O线程\n线程切换，调度:\n由于Netty线程和gRPC线程存在线程分工，因此需要频繁进行线程切换 这也是java版本gRPC的性能缺陷 gRPC客户端线程模型 gRPC客户端线程由三类组成：业务调用线程，客户端连接和I/O线程。请求消息业务处理和响应回调线程，如下图所示：\n应用线程：负责调用gRPC服务端并获取响应，其中请求消息的序列化由该线程负责 grpc-default-executor线程池：客户端负载均衡以及Netty Client创建 NioEventLoop 线程：HTTP/2客户端链路创建，网络I/O数据的读写 SerializingExecutor：响应消息消息的反序列化 responseFuture:SerializingExecutor调用responseFuture的set(value),唤醒阻塞对的应用现线程，完成RPC调用 I/O通信线程模型\n工作流程如下:\n由 grpc-default-executor 发起客户端连接，并且客户端只创建一个NioEventLoop，同时客户端使用EventLoop作为work线程 发起连接操作，判断连接结果，判断连接结果，如果没有连接成功，则监听连接网络操作位SelectionKey。OP_CONNECT.如果连接成功，则调用pipeline().fireChannelActive()将监听位修改位READ 由NioEventLoop的多路复用器轮询连接操作结果，判断连接结果，如果连接成功，重新设置监听为READ 和服务端一样，由NioEventLoop线程负责I/O读写 工作原理如下所示：\n总结 优点：\nNetty线程模型\nNetty4之后，对线程模型进行了优化，通过串行化的设计避免线程竞争；并且减少了线程切换，避免额外的性能损耗\nNetty4采用串行化设计，将消息的读取，编码以及后续的Handler执行，都由I/O线程NioEventLoop负责，这样线程上下文就不用了进行切换。数据不会出现并发写的问题。\ngRPC线程模型\n消息的序列化和反序列化都由gRPC线程负责。因为Netty的I/O操作和业务Handler都是有NioEventLoop负责。但是某些CUP密集操作，适合放在业务应用的线程池中执行，否则会影响Handler串行执行操作。这样并发处理能力较均衡。\n改进点:\n将时间可控的接口调用直接在NettyI/O线程上处理:\ngRPC采用的网络I/O线程和业务调用线程分离的策略，大部分场景下都最优。但是当接口逻辑简单，执行时间很短，不需要和外部网络，数据库进行交互，也不需要等待其他资源的。应该直接在Netty I/O线程中执行\n减少锁竞争：\n当前I/O线程和业务线程间没有任何的关联关系。也就是core*2个I/O线程和N个业务线程进行锁竞争\n可以通过线程绑定（通过一致性hash，将Netty的I/O线程和服务调用线程建立绑定关系），让锁竞争降低为1个I/O线程和N个业务线程进行绑定。提高性能\ngRPC服务调用原理 服务调用方式 gRPC提供了多种服务调用方式\n同步服务调用：最常用的服务调用方式，也是RPC/微服务默认的的调用方式\n工作原理：\n​\t客户端发起RPC调用，将请求消息路由到I/O线程，无论I/O线程是同步还是异步发送消息，发起调用的业务线程都会同步阻塞，等待服务端的应答，由I/O线程唤醒同步等待的业务线程，获取应答，然后业务流程继续执行。\n​\t同步服务调用会阻塞调用方的业务线程，为了防止服务端长时间不返回应答消息导致客户端用户线程被挂死，业务线程等待的时候需要设置超时时间，通常该值应该综合考虑业务端到端的通信延时，自身可靠性，超时时间不宜过大或者过小，在几百毫秒到几秒之间。\n消费者调用服务端发布的接口，接口调用由服务框架包装成动态代理，发起远程服务调用 通信框架的I/O线程通过网络将请求消息发送给服务端 消费者业务线程调用通信框架的消息发送接口之后，直接或者间接调用wait()方法，同步阻塞等待应答 服务端返回应答消息给消费者，由通信框架负责应答消息的反序列化 I/O线程获取到应答消息之后，根据消息上下文找到之前同步阻塞的业务线程。notify()阻塞的业务线程，返回应答给消费者，完成服务调用 原理图如下：\n并行服务调用：对于无上下文依赖的多个服务，可以一次并行发起多个调用，这样可以有效降低服务调用的时延\n工作原理：\n​\t大多数业务应用中，服务总是串行化调用和执行，但是当多个服务之前没有上下文依赖关系，并且执行先后顺序没有严格要求，逻辑上可以被并行执行。又例如长流程业务，调用多个服务，对于时延比较敏感，其中有部分逻辑没有上下文关系，可以被并行调用和执行。\n服务框架提供必将服务调用接口供接口消费者使用，一般形如ParallelService.invoke(serviceName[],methodName[],args[]) 平台的并行服务调用器创建并行Future，缓存批量服务调用上下文信息 并行服务调用器循环调用普通的Invoker，通过循环的方式执行单个服务调用，获取到单个服务的Future之后设置到Parallel Future中； 返回Parallel Future给消费者 普通的Invoker调用通信框架的消息发送接口，发起远程服务调用 服务端返回应答，通信框架对报文做反序列化，转换成业务对象更新Parallel Future的结果列表 消费者调用Parallel Future的get(timeoout)方法，同步阻塞，等待所有结果全部返回； Parallel Future 通过对结果集进行判断，看所有的服务调用是否都已经完成（包括成功，失败，异常） 所有批量服务调用结果都已经返回，notify消费者线程，消费者获取到结果列表，完成批量服务调用，流程继续执行 通过批量服务调用和Future机制，可以实现并行服务调用，由于在调用过程中没有创建新的线程，用户就不需要担心依赖线程上下文的功能发生异常 原理图如下：\n异步服务调用：客户端发起服务调用后，不同步等待响应，而是注册监听器或者回调函数，待接收到响应之后发起异步回调，驱动业务流程继续执行，比较常用的是Reactive响应式编程和JDK的Future-Listener回调\n工作原理：\n​\tJDK原生的Future只要用于异步操作，它代表了异步操作的执行结果，用户可以通过调用它的get方法获取结果。如果当前操作没有执行完，get操作将阻塞调用线程。实际项目中，往往会扩展JDK的Future，提供Future-Listener机制，支持主动获取和被动异步回调通知两种模式，适用于不同的业务场景。\n​\t异步服务调用的优点：提交服务调用效率，减少业务线程阻塞啥时间，避免业务线程阻塞\n消费者调用服务端发布的接口，接口调用由服务框架包装为动态代理，发起远程服务的调用 通信框架异步发送请求消息，如果没有发生I/O异常，返回； 请求消息发送成功后，I/O线程构造Future对象，设置到RPC上下文中 业务线程通过RPC上下文获取Future对象； 构造Listener对象，将其添加到Future中，用于服务端应答异步回调通知。 业务线程返回，不阻塞等待应答 服务端返回应答消息，通信框架负责反序列化工作 I/O线程将应答设置到Future对象的操作结果中 Future对象扫描注册的监听器列表，循环调用监听器额的operationComplete方法，将结果通知给监听器，监听器获取到结果后，继续后续业务逻辑的执行，异步服务调用结束 服务调用的误区 I/O异步服务就是异步\n通信框架基于NIO实现，并不意味着服务框架就支持异步服务调用了\n在RPC/微服务框架中，引入NIO的好处有：\n所有的I/O操作都是非阻塞的，避免有限的I/O线程因为网络，对方处理慢等原因被阻塞 多路复用的RReactor线程模型，基于Linux的epoll和Selector，一个I/O线程可以并行处理成百上千链路，解决了传统同步I/O通信线程膨胀的问题 NIO只解决了通信层面的异步问题，和服务调用的异步没有必然关系。\n通信框架和异步服务框架的关系：\n​\t用户发起远程服务调用之后，经历层层业务逻辑处理，消息编码，最终序列化后的消息会被放入到通信框架的消息队列中。业务线程可以选择同步等待，也可以选择直接返回。通过消息队列对的方式实现业务层和通信层的分离是比较典型的做法。\n​\t通信层采用NIO或者是BIO对上层的业务是不可见的，双方的汇聚点就是消息队列，在JAVA中通常为Queue，业务线程将消息放入到发送队列中，可以选择主动等待或者立即返回，和通信框架是否是NIO的没有任何关系。因此不能认为I/O异步就代表服务调用也是异步。\n如图所示：\n异步服务调用性能更高：\n对于I/O密集型，资源不是瓶颈，大部分时间都在同步等待应答，异步服务调用可以带来巨大的吞吐量提升，资源使用率也可以提高，更加充分的利用硬件资源提升性能。\n对于时延不稳定的接口，如第三方服务的响应速度，数据库操作，异步服务也会带来性能提升\n但是如果接口调用的时延本身就小(毫秒级)，内存计算型，不依赖第三方服务，内部也没有I/O操作，异步服务调用并不会提升性能\nRestful接口的问题和收益\n问题：\n潜在性能风险：若RestfulAPI底层使用的HTTP协议栈是同步阻塞I/O，则服务端的处理性能将大打折扣 收益：\n接口更加规范和标准，可以通过Swagger API规范来描述服务接口，并生成客户端和服务端代码\nRestful API可读性更好，更容易维护\n服务提供者和消费者基于API契约，双方可以解耦，不需要在客户端引入SDK和类库的直接依赖，未来的独立升级也更加方便\n内外使用同一套API，非常容易开放给外部或者合作伙伴使用\n解决方案：\n如果选择RestfulAPI作为内部RPC或者微服务的接口协议，则建议使用HTTP/2.0 协议，优点：支持双向流，消息头压缩，单TCP的多路复用，服务端推送等。效果和基于TCP的私有协议类似。 gRPC服务调用 gRPC的通信协议基于标准的HTTP/2设计，主要提供了两种RPC调用方式\n普通的RPC调用，请求-响应模式 基于HTTP/2.0 的streaming调用方式 普通RPC调用 同步阻塞式服务调用\n实现类是xxxBlockingStub，gRPC框架的ClientCalls在框架层做了封装，当异步发起服务调用后，会同步阻塞调用方线程。直到收到响应(queue.task()方法)再唤醒被阻塞的业务线程\n异步非阻塞调用\n基于Future-Listener机制，通常实现类是xxxFutureStub。当调用这种实现类的方法时，返回的不是应答，而是ListenableFuture，将ListenableFuture加入到gRPC的Future列表中，创建一个新的FutureCallback对象，当ListenableFuture获取到响应之后，gRPC的DirectExecutor线程池会调用新创建的FutureCallback，执行onSuccess或者onFailure，实现异步回调通知\n异步非阻塞调用\n基于Reactive的响应式编程模式，通常实现类是xxxStub。框架会构造响应StreamObserver，通过响应式编程，处理正常和异常回调，将响应StreamObserver作为入参传递到异步服务调用中后，该方法返回空，程序继续执行不会产生阻塞。当收到响应消息时，调用StreamObserver的onNext方法。当Straming关闭时，调用onCompleted方法。Reactive风格的异步调用，相比于Future模式，没有任何同步阻塞点，无论是业务线程还是gRPC框架的线程都不会同步等待。\nStreaming模式服务调用 服务端streaming方式\nrpc ListFeatures(Rectangle) returns (stream Feature) {}\n服务端streaming模式，指的是客户端一个请求，服务端返回N个响应，每个响应可以返回。服务端Streaming模式也支持同步阻塞，和Reactive异步两种调用方式。\n客户端streaming\nrpc RecordRoute(stream Point) returns (RouteSummary) {}\n与客户端发送多个请求，服务端返回一个响应，多用于聚合计算。\n异步服务端调用获取请求StreamObserver对象，循环调用requestObserver.onNext(point),异步发送请求消息到服务端，发送完成后，调用requestObserver.onCompleted(),通知服务端所有请求已经发送。\n双向streaming\nrpc RouteChat(stream RouteNote) returns (stream RouteNote) {}\n客户端发送N个请求，服务端返回N个或者M个响应。该特性可以充分利用HTTP/2.0的的多路复用功能。HTTP/2.0的链路上，请求和响应可以同时存在，实现全双工通信。该方式，只支持异步通信。\ngRPC安全性设计 敏感数据加密传输 基于SSL/TLS的通道加密\n当存在跨网络边界RPC调用时，往往会需要通过TLS/SSL对传输通道加密，以防止请求和响应消息中的敏感数据泄露。跨网络边界包括:\n后端微服务开放给端侧，例如手机等，没有统一的API Gateway/SLB做安全接入和认证 后端微服务直接开放给DMZ部署的管理或者运维类Portal 后端微服务直接开放给第三方合作伙伴/渠道 场景如下图所示：\n针对敏感数据的单独加密\n当RPC调用并不涉及敏感字段或者，敏感字段的占比较低，为了最大程度的提升吞吐量，降低调用时延，通常会采用HTTP/TCP+敏感字段单独加密的方式，即保障了敏感信息的传输安全，同时也降低了采用SSL/TLS加密通道的性能损耗。\n业务方，通常有Handler拦截，对请求和响应消息进行统一拦截，根据注解或者加解密标识对敏感字段进行加解密，避免侵入业务。\n原理如下：\n缺点：\n对敏感信息的识别可能存在偏差，容易遗漏或者过度保护，需要解读数据和隐私保护方面的法律法规，而且不同国家对敏感数据的定义也不同，这会为识别带来很多困难 接口升级时容易遗漏，例如开发新增字段，忘记识别是否为敏感数据。 gRPC安全机制 通道凭证：默认提供了基于 HTTP/2 的 TLS，对客户端和服务端交换的所有数据进行加密传输 调用凭证：被附加在每次 RPC 调用上，通过 Credentials 将认证信息附加到消息头中，由服务端做授权认证； 组合凭证：将一个频道凭证和一个调用凭证关联起来创建一个新的频道凭证，在这个频道上的每次调用会发送组合的调用凭证来作为授权数据，最典型的场景就是使用 HTTP S 来传输 Access Token； Google 的 OAuth 2.0：gRPC 内置的谷歌的 OAuth 2.0 认证机制，通过 gRPC 访问 Google API 时，使用 Service Accounts 密钥作为凭证获取授权令牌。 SSL/TLS工作原理 SSL/TLS 分为单向认证和双向认证，在实际业务中，单向认证使用较多，即客户端认证服务端，服务端不认证客户端。\n单向认证原理如下：\nSL 客户端向服务端传送客户端 SSL 协议的版本号、支持的加密算法种类、产生的随机数，以及其它可选信息； 服务端返回握手应答，向客户端传送确认 SSL 协议的版本号、加密算法的种类、随机数以及其它相关信息； 服务端向客户端发送自己的公钥； 客户端对服务端的证书进行认证，服务端的合法性校验包括：证书是否过期、发行服务器证书的 CA 是否可靠、发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”、服务器证书上的域名是否和服务器的实际域名相匹配等； 客户端随机产生一个用于后面通讯的“对称密码”，然后用服务端的公钥对其加密，将加密后的“预主密码”传给服务端； 服务端将用自己的私钥解开加密的“预主密码”，然后执行一系列步骤来产生主密码； 客户端向服务端发出信息，指明后面的数据通讯将使用主密码为对称密钥，同时通知服务器客户端的握手过程结束； 服务端向客户端发出信息，指明后面的数据通讯将使用主密码为对称密钥，同时通知客户端服务器端的握手过程结束； SSL 的握手部分结束，SSL 安全通道建立，客户端和服务端开始使用相同的对称密钥对数据进行加密，然后通过 Socket 进行传输 流程如下图所示：\ngRPC序列化机制 常用的序列化机制：json序列化，MessagePack序列化，Thrift序列化框架，Protocol Buffers 序列化框架\nThrift 序列化框架 thrift是facebook开源的，支持多语言的高性能通信中间件。他能提供序列化和多种的类型的RPC服务\nThrift由5部分组成\n1.语言系统以及IDL编译器：负责将IDL文件生成对应语言的接口代码\n2.TProtocol：RPC协议层，可以选择多种不同的序列化方式，如果JSON，Binary\n3.TTransport:RPC传输层，可以选择不同的传输层实现：如socket，NIO，MemeoryBuffer等\n4.TProcessor:作为协议层和用户提供的服务实现之间的纽带，负责调用服务实现的接口\n5.TServer：聚合Tprotocol，TTransport和TProcessor等对象\n其中编解码框架是Tprotocol部分。\nTProtocol codec: 与Protocol Buffers 类似，Thrift通过IDL描述接口和数据结构定义，它支持8种Java基本类型，Map，Set，List 支持可选和必选定义。\nThrift支持三种编解码方式：\n通用的二进制编解码 压缩二进制编解码 优化的可选择字段压缩编解码 MessagePack 序列化框架 MessagePack是一个高效的二进制序列化框架，可以向json一样支持不同语言间的数据交换，但是性能更好，序列化后的码流也更小\nMessagePack支持多语言，并且API设计也像Json序列化一样简单\nProtocol Buffers序列化框架 Protocol Buffers 是一个可以独立使用的序列化框架，它并不与grpc框架绑定，任何需要支持多语言的RPC框架都可以选择使用Protocol Buffers作为序列化框架\nProtocol Buffers 的使用包括：\nIDL文件定义（*.proto）,包含数据结构定义，以及可选的服务接口定义（gRPC）； 各种语言的代码生成（含数据结构定义，序列化和反序列化接口） 使用Protocol Buffers的API进行序列化和反序列化 Netty 中使用：\nNetty 提供了对于Protocol Buffers 的支持，在服务端和客户端创建时，只需要将Protocol Buffers 相关的CodeC Handler加入到ChannelPipeline中即可\ngRPC序列化 gRPC默认使用Protocol Buffers作为RPC序列化框架，通过Protocol Buffers 对消息进行序列化和反序列化，然后通过Netty的HTTP/2，以Stream 的方式进行数据传输。\n1.客户端请求消息序列化 客户端通过build模式构造请求消息，然后通过同步/异步方式发起RPC调用，gRPC框架负责客户端请求消息的序列化，以及HTTP/2 Header和Body的构造，然后通过Netty提供的HTTP/2协议栈，将HTTP/2请求消息发送给服务端\n客户端请求消息发送流程 请求消息的构建：使用Protocol Buffers生成的代码，通过build模式对请求消息设置，完成请求消息的初始化\n请求消息的序列化：使用Protocol Buffers 的Marshaller 工具类，对于生成的请求对象进行序列化，生成ProtoInputStream\n请求消息的首次封装：主要用于创建NettyClientStream，构造gRPC的HTTP/2消息头等\n请求消息的二次封装：将序列化之后的请求消息封装成SendGrpcFrameCommand，通过异步的方式由Netty的NIO线程执行消息的发送\nNettyClientHandler处理：gRPC的NettyClientHandler拦截到write请求后，根据Command类型判断是业务消息发送，调用Netty的Http2ConnectionEncoder，由Netty的HTTP/2协议栈创建HTTP/2 Stream并最终发送给服务端\n线程模型：请求消息构建，请求消息序列化，请求消息封装都由客户端用户线程执行；请求消息的发送由Netty的NIO线程执行。\n发送流程如下图所示：\n2.服务端请求消息反序列化 服务端接收到客户端的HTTP/2请求消息之后，由Netty HTTP/2协议栈的FrameListener.onDataRead方法调用gRPC的NettyServerHandler，对请求消息进行解析和处理。\n服务端读取客户端消息反序列化流程 Http/2内容读取：通过FrameListener监听onDataRead，获取HTTP/2消息内容\n构造NettyServerStream：通过HTTP/2 Stream构造gRPC NettyServerStream，，并将内容拷贝到NettyReadableBuffer中\n解析Body：调用MessaeDeframer解析请求消息体。并且由gRPC的SerializingExecutor负责body的解析\n反序列化请求消息：使用Marshaller对请求消息做反序列化。\n线程模型：Netty HTTP/2消息的读取和校验，由Netty NIO线程负责。后续HTTP Body 的反序列化，则由gRPC的SerializingExecutor 线程池完成\n数据流图如下所示：\n3.服务端响应消息序列化 服务端接口调用完成之后，需要将响应消息序列化，然后通过 HTTP/2 Stream（与请求相同的 Stream ID）发送给客户端。\n服务端响应消息流程 服务端的接口实现类中调用responseObserver.onNext(reply),触发响应消息的发送流程\n响应消息的序列化：使用Protocol Buffers的Marshaller工具类，对于生成的响应对象进行序列化，生成ProtoInputStream\n对HTTP响应Header进行处理，包括设置响应消息的content-length 字段，根据是否压缩标识对响应消息进行gzip压缩等\n对响应消息进行二次封装，将序列化之后的响应消息封装成SendGrpcFrameCommand，通过异步的方式由Netty的NIO线程发送\ngRPC的NettyServerHandler拦截到write的请求消息之后，根据Command类型判断是业务消息发送，调用Netty的Http2ConnctionEncoder，由Netty的HTTP/2协议栈创建Http/2 Stream 并最终发送给客户端\n线程模型：响应消息的序列化以及HTTP Header的初始化等操作由gRPC的SerializiingExecutor线程池负责。HTTP/2消息的编码以及后续发送，由Netty的NIO线程池负责\n数据流图如下所示：\n4.客户端响应消息反序列化 客户端接收到服务端响应之后，将 HTTP/2 Body 反序列化为原始的响应消息，然后回调到客户端监听器，驱动业务获取响应并继续执行。\n客户端响应消息反序列化流程 读取消息：与服务端类似，通过Netty HTTP/2 协议栈的FrameListener监听并回调gRPC Handler（NettyClientHandler）,读取消息。\n获取stream对象： 根据streamId，获取Http2Stream，通过Http2Stream的getProperty方法获取NettyClientStream\n解析响应消息体： 调用MessageDeframer的deframe 方法，对响应消息体进行解析。客户端和服务端实现机制不同（通过不同的Lisstener重载messageRead方法）\n线程切换：调用ClientStreamListenerImpl的messageRead进行线程切换，将反序列化操作切换到gRPC工作线程或者客户端业务线程中（同步阻塞调用）\n调用Protocol Buffers的Marshaller对响应消息进行反序列化，还原成原始对的message对象\n数据流图如下所示：\n","date":"2021-11-22","img":"","permalink":"/posts/rpc/grpc%E5%AD%A6%E4%B9%A0/","series":["rpc"],"tags":["rpc","gRPC"],"title":"gRPC学习"},{"categories":["rpc"],"content":"server 学习 服务注册: 在进行rpc方法调用前,需要先进行方法注册\nfunc (server *Server) register(rcvr interface{}, name string, useName bool) error { //整个工作就是构造service对象,填充属性 //最后调用`sync.Map.LoadOrStore(sname,s)`方法完成服务注册 s := new(service) s.typ = reflect.TypeOf(rcvr) s.rcvr = reflect.ValueOf(rcvr) sname := reflect.Indirect(s.rcvr).Type().Name() if useName { sname = name } if sname == \u0026#34;\u0026#34; { s := \u0026#34;rpc.Register: no service name for type \u0026#34; + s.typ.String() log.Print(s) return errors.New(s) } if !token.IsExported(sname) \u0026amp;\u0026amp; !useName { s := \u0026#34;rpc.Register: type \u0026#34; + sname + \u0026#34; is not exported\u0026#34; log.Print(s) return errors.New(s) } s.name = sname // Install the methods s.method = suitableMethods(s.typ, true) if len(s.method) == 0 { str := \u0026#34;\u0026#34; // To help the user, see if a pointer receiver would work. method := suitableMethods(reflect.PtrTo(s.typ), false) if len(method) != 0 { str = \u0026#34;rpc.Register: type \u0026#34; + sname + \u0026#34; has no exported methods of suitable type (hint: pass a pointer to value of that type)\u0026#34; } else { str = \u0026#34;rpc.Register: type \u0026#34; + sname + \u0026#34; has no exported methods of suitable type\u0026#34; } log.Print(str) return errors.New(str) } if _, dup := server.serviceMap.LoadOrStore(sname, s); dup { return errors.New(\u0026#34;rpc: service already defined: \u0026#34; + sname) } return nil } 链接处理： 循环等待socket连接建立，并且开启子协程处理每一个链接go server.ServeConn(conn) 在ServeConn中，参数是一个链接，该方法首先创建了编解码器gobServerCodec,然后使用server.ServeCodec(srv)利用编解码器对链接进行处理 // Accept 接受侦听器上的连接并提供请求 // 对于每个传入连接。 接受块直到侦听器 // 返回一个非零错误。 调用者通常在一个 // 去语句。 func (server *Server) Accept(lis net.Listener) { for { conn, err := lis.Accept() if err != nil { log.Print(\u0026#34;rpc.Serve: accept:\u0026#34;, err.Error()) return } go server.ServeConn(conn) } } // ServeConn 在单个连接上运行服务器。 // ServeConn 阻塞，服务连接直到客户端挂断。 // 调用者通常在 go 语句中调用 ServeConn。 // ServeConn 使用 gob 线格式（见包 gob） // 使用通用编解码器，请使用 ServeCodec。 // 有关并发访问的信息，请参阅 NewClient 的注释。 func (server *Server) ServeConn(conn io.ReadWriteCloser) { buf := bufio.NewWriter(conn) srv := \u0026amp;gobServerCodec{ rwc: conn, dec: gob.NewDecoder(conn), enc: gob.NewEncoder(buf), encBuf: buf, } //传入执行的解码器，进行解码 server.ServeCodec(srv) } 链接数据读取,请求处理: 编解码接口:\ntype ServerCodec interface { ReadRequestHeader(*Request) error ReadRequestBody(interface{}) error WriteResponse(*Response, interface{}) error // Close can be called multiple times and must be idempotent. Close() error } type gobServerCodec struct { rwc io.ReadWriteCloser dec *gob.Decoder enc *gob.Encoder encBuf *bufio.Writer closed bool } 连接请求读取方法\nfunc (server *Server) ServeCodec(codec ServerCodec) { sending := new(sync.Mutex) wg := new(sync.WaitGroup) //死循环读取请求,每从链接中读取到一个请求,就交由service.call 该接口方法进行服务调用 for { //通过server.readRequest(codec)利用编解码器接口读取请求 service, mtype, req, argv, replyv, keepReading, err := server.readRequest(codec) if err != nil { if debugLog \u0026amp;\u0026amp; err != io.EOF { log.Println(\u0026#34;rpc:\u0026#34;, err) } if !keepReading { break } // send a response if we actually managed to read a header. if req != nil { server.sendResponse(sending, req, invalidRequest, codec, err.Error()) server.freeRequest(req) } continue } wg.Add(1) //开启一个协程,通过请求决定调用的方法进行方法调用 //此处通过mtype.method.Func 得到方法的函数对象 //最后通过reflect来进行最后的函数对调用 res = function.Call([]reflect.Value{s.rcvr,argv,replyv}) //将sending互斥锁对象交给了该协程.保证了每次请求的返回不会进行冲突. go service.call(server, sending, wg, mtype, req, argv, replyv, codec) } //我们在推出前需要保证每一个服务请求都处理完毕.即等待所有请求的service.call 协程完成调用 // We\u0026#39;ve seen that there are no more requests. // Wait for responses to be sent before closing codec. wg.Wait() codec.Close() } func (server *Server) readRequest(codec ServerCodec) (service *service, mtype *methodType, req *Request, argv, replyv reflect.Value, keepReading bool, err error) { //得到读取结果.顺利的话将会读取到服务名,方法名,并且会从`server.serviceMap`这个`sync.Map`结构中获取到注册的服务信息(`svci,ok:=server.ServiceMap.Load(serviceName)`).然后从服务信息中获取方法的详细信息:mtype=svci.(*service).method[methodName];如果读取发生任何错误,keepReading将会返回默认值false service, mtype, req, keepReading, err = server.readRequestHeader(codec) if err != nil { if !keepReading { return } // discard body codec.ReadRequestBody(nil) return } //通过mtype.ArgType 的判断,利用reflect.New(),得到argv这样一个指针类型的请求参数 // Decode the argument value. argIsValue := false // if true, need to indirect before calling. if mtype.ArgType.Kind() == reflect.Ptr { argv = reflect.New(mtype.ArgType.Elem()) } else { argv = reflect.New(mtype.ArgType) argIsValue = true } //此处直接使用 对应解码器的编解码方法,此处是`gob.Decoder.Decode(body)`,填充argv指针 // argv guaranteed to be a pointer now. if err = codec.ReadRequestBody(argv.Interface()); err != nil { return } if argIsValue { argv = argv.Elem() } //得到replyv指针 replyv = reflect.New(mtype.ReplyType.Elem()) //根据replyv的类型,正确的处理指针,最后返回 switch mtype.ReplyType.Elem().Kind() { case reflect.Map: replyv.Elem().Set(reflect.MakeMap(mtype.ReplyType.Elem())) case reflect.Slice: replyv.Elem().Set(reflect.MakeSlice(mtype.ReplyType.Elem(), 0, 0)) } return } ","date":"2021-11-22","img":"","permalink":"/posts/rpc/net_rpc%E5%AD%A6%E4%B9%A0/","series":["rpc"],"tags":["rpc"],"title":"net/rpc学习"},{"categories":["rpc"],"content":"RPC原理解析 简介： RPC 的全称是 Remote Procedure Call，即远程过程调用\n具有以下作用：\n屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法； 隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。 TIPs:\n使用rpc的场景是否合适， 什么是否需要开启压缩，根据配置，根据部署机器配置，根据网络环境，根据传输数据大小 调用过程超时处理，以及失败重试机制，例如dubbo的failfast，failover等 服务集群注意点 服务注册，发现，服务注册中心 服务治理，服务分组，服务别名，服务限流，服务降级，服务调用链，链路跟踪 服务监控，调用链监控，方法监控，数据指标监控（TPS，调用量，可用率，调用返回时间，服务网络响应时间） 服务日志，聚合查询，整理，告警 服务集群化，分组化的在线配置中心。支持日志等级控制，服务控制 RPC通信流程： 步骤如下：\nRPC是远程调用，需要网络传输数据，并且由于常用于业务系统之间进行远程调用，所以需要使用TCP来进行传输\n网络传输的数据必须是二进制数据，但是调用方请求的出入参数都是对象，所以需要使用可逆的算法，来将对象转化为二进制数据，这一步叫做序列化\n调用方持续的将请求序列化为二进制数据，经过TCP后传输给了服务提供方。服务提供方如何知道请求的数据的大小，以及请求的是哪个接口类型；因此需要约定数据包的格式，这个步骤就是协议的约定\n根据协议格式，服务提供者可以正确的从二进制数据中分割出不同的请求，同事根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象，这一步就叫反序列化\n服务提供方根据反序列化出来的请求对象，找到对象的实现类，完成方法调用\n将执行结果序列化后，回写到TCP通道中。调用方获取到应答数据后，再进行反序列化得到Reponse数据，完成RPC调用\n简化调用链，利用反射或者其他方法让调用方在调用远程方法时，能够像调用本地接口一样\nRPC协议 RPC协议简介\nRPC请求在发送到网络中之前，需要将请求转为二进制数据，基于TCP连接和服务方通信，TCP链接会根据系统配置和TCP窗口大小，在同一个TCP链接中，对数据包进行拆分，合并。服务方需要正确处理TCP通道中的二进制数据。\nRPC协议是一种应用层协议，主要负责应用间的通信，相对于HTTP协议，需要的性能更高，并且RPC是有状态的协议，请求和响应一一对应。RPC一般会设计更加紧凑的私有协议\nRPC协议的设计\n消息边界语义：利用一个定长数据来保存整个请求协议体的大小；先读取固定长度的位置里面的值，得到协议体长度，再去读取整个协议体的数据\n协议数据序列化方法信息：利用定长的位置存储协议数据的序列化方式\n将整个协议分为协议头和协议体，得到定长协议头，该协议头是不可扩展的\n可扩展协议，将协议头改为可扩展的。将协议分为三部分：固定部分，协议头内容，协议体内容；前两部分统称为协议头\nRPC为了吞吐量，都是异步并发发送的请求，等待服务应答，因此需要消息ID，来判断应答对应哪个请求\n### RPC网络通信 **常见的网络IO模型** - 同步阻塞 IO（BIO） - 在 Linux 中，默认情况下所有的 socket 都是 blocking 的 - 应用进程发起 IO 系统调用后，应用进程被阻塞，转到内核空间处理。之后，内核开始等待数据，等待到数据之后，再将内核中的数据拷贝到用户内存中，整个 IO 处理完毕后返回进程。最后应用的进程解除阻塞状态，运行业务逻辑。 - ![image-20210522185621450](https://euraxluo.github.io/images/picgo/image-20210522185621450.png) - 系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。而在这两个阶段中，应用进程中 IO 操作的线程会一直都处于阻塞状态，如果是基于 Java 多线程开发，那么每一个 IO 操作都要占用线程，直至 IO 操作结束。 - 阻塞 IO 每处理一个 socket 的 IO 请求都会阻塞进程（线程），但使用难度较低。在并发量较低、业务逻辑只需要同步进行 IO 操作的场景下，阻塞 IO 已经满足了需求，并且不需要发起 select 调用，开销上还要比 IO 多路复用低。 - 同步非阻塞 IO（NIO） - 同步IO 多路复用（select，poll，epoll） - 多路复用 IO 是在高并发场景中使用最为广泛的一种 IO 模型 - linux总的多个网络连接的 IO 可以注册到一个复用器（select）上，当用户进程调用了 select，那么整个进程会被阻塞。同时，内核会“监视”所有 select 负责的 socket，当任何一个 socket 中的数据准备好了，select 就会返回。这个时候用户进程再调用 read 操作，将数据从内核中拷贝到用户进程。 - 优势在于，用户可以在一个线程内同时处理多个 socket 的 IO 请求。用户可以注册多个 socket，然后不断地调用 select 读取被激活的 socket，即可达到在同一个线程内同时处理多个 IO 请求的目的。而在同步阻塞模型中，必须通过多线程的方式才能达到这个目的。 - IO 多路复用更适合高并发的场景，可以用较少的进程（线程）处理较多的 socket 的 IO 请求。 - 异步非阻塞 IO（AIO） **RPC网络io模型** RPC 调用在大多数的情况下，是一个高并发调用的场景 - 在 RPC 框架的实现中，在网络通信的处理上，我们会选择 IO 多路复用的方式。 - 选择基于 Reactor 模式实现的io框架来实现IO多路复用 - 在 Linux 环境下，也要开启 epoll 来提升系统性能（Windows 环境下是无法开启 epoll 的，因为系统内核不支持）。 **网络io中的零拷贝** 系统内核处理 IO 操作分为两个阶段——等待数据和拷贝数据。 - 等待数据，就是系统内核在等待网卡接收到数据后，把数据写到内核中 - 拷贝数据，就是系统内核在获取到数据后，将数据拷贝到用户进程的空间中。 应用进程的每一次写操作，都会把数据写到用户空间的缓冲区中，再由 CPU 将数据拷贝到系统内核的缓冲区中，之后再由 DMA 将这份数据拷贝到网卡中，最后由网卡发送出去。一次写操作数据要拷贝两次才能通过网卡发送出去 ![image-20210522192234064](https://euraxluo.github.io/images/picgo/image-20210522192234064.png) - 零拷贝技术 - 零拷贝，就是取消用户空间与内核空间之间的数据拷贝操作，应用进程每一次的读写操作，都可以通过一种方式，让应用进程向用户空间写入或者读取数据，就如同直接向内核空间写入或者读取数据一样，再通过 DMA 将内核中的数据拷贝到网卡，或将网卡中的数据 copy 到内核。 - 零拷贝实现 - mmap+write 方式，核心原理是通过虚拟内存来解决的 - sendfile 方式 - Netty零拷贝实现： - 用户空间数据操作零拷贝优化 - 收到数据包后，在对数据包进行处理时，需要根据协议，处理数据包，在进行处理时，免不了需要进行在用户空间内部内存中进行拷贝处理，Netty就是在用户空间中对数据操作进行优化 - Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝。 - ByteBuf 支持 slice 操作，因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝。 - 通过 wrap 操作，我们可以将 byte[] 数组、ByteBuf、ByteBuffer 等包装成一个 Netty ByteBuf 对象, 进而避免拷贝操作。 - 用户空间与内核空间之间零拷贝优化 - Netty 的 ByteBuffer 可以采用 Direct Buffers，使用堆外直接内存进行 Socket 的读写操作，效果和虚拟内存所实现的效果是一样的。 - Netty 还提供 FileRegion 中包装 NIO 的 FileChannel.transferTo() 方法实现了零拷贝，这与 Linux 中的 sendfile 方式在原理上也是一样的。 ### RPC框架设计： #### 屏蔽处理流程 - java使用动态代理屏蔽实现细节 - golang使用反射等，来实现的 #### RPC架构 ##### 网络传输模块 用于收发二进制数据 ##### 协议模块 保证数据在网络中正确传输，包括序列化和反序列化功能，数据压缩功能，以及通信协议约定 ##### Bootstrap模块 用于屏蔽RPC细节，利用反射或者代理让远程调用大大简化 ##### 服务治理模块 赋予RPC服务集群能力，包括服务注册和发现，负载均衡，连接管理，路由，容错和配置管理 架构图如下： ![](https://euraxluo.github.io/images/picgo/30f52b433aa5f103114a8420c6f829fb.jpg) ##### 利用微内核架构，将组件插件化 将每个功能点抽象成一个接口，将这个接口作为插件的契约，然后把这个功能的接口与功能的实现分离并提供接口的默认实现。 提升了RPC框架的可扩展性，实现了开闭原则，用户可以非常方便地通过插件扩展实现自己的功能，而且不需要修改核心功能的本身；其次保持了核心包的精简，依赖外部包少，这样可以有效减少开发人员引入 RPC 导致的包版本冲突问题。 ![](https://euraxluo.github.io/images/picgo/a3688580dccd3053fac8c0178cef4ba6.jpg) ### 服务注册与发现： #### 概述： 服务发现（Service Discoery）要解决的是分布式系统中最常见的问题之一，即在同一个分布式系统中的进程如何才能找到对方并建立连接。 ##### 服务发现组件的需求 服务发现组件需要以下一些功能： - 怎么标识一个服务 - 根据服务名的得到服务可用列表 - 服务注册功能，因此高组件是一个独立的，简单的第三方存储，并且存储极简化。 - 同时服务发现组件还需要有服务探活功能，应当提供很多的服务探活选项 ##### 服务代理 服务发现组件的从需求上看是服务代理，常见对的服务代理有： 1. 网络代理 - 如果是使用http通信，那么可以使用nginx作为反向代理，转到各个服务 - 如果是RPC服务则可以使用LVS或者ESB之内的网络代理服务地址 - 缺点：当服务增多是，需要维护超多的网络代理，最后将陷入到运维灾难中 2. DNS方式 - 为服务A配置域名，然后通过配置两个分别指向服务A的实例，客户端只需要使用配置A的域名就可以 - 问题：DNS是IP级别，无法处理端口信息，DNS携带的数据较少，节点权重，序列化信息等数据无法传递。 服务代理无法满足服务发现组件对的所有需求，所以需要找另外的组件。 #### zookeeper做为服务发现的问题 Zookeeper旨在解决大规模分布式应用场景下的服务协调同步问题；他可以为同在一个分布式系统中的其他服务提供：统一命名服务，配置管理服务，分布式锁服务，集群管理服务等。 ##### CAP（C-数据一致性；A-服务可用性；P-服务对网络分区故障的容错性） zk是一个CP的，即咋子任何时候对于ZK的访问请求都能得到一致的是数据结果，同时系统对于网络分割具备容错性。 ##### ZK解决的问题 Zk是一个分布式协调服务，他被设计用于保证数据在其管辖下，在所有服务之前保持同步，一致，因此ZK被设计为CP的。 ##### ZK作为服务发现服务的问题 由于zk不能保证每次服务的可用性： 1. 因为对于服务发现服务来说，宁可返回某个包含了不实信息的结果也比什么都不返回的好。 2. 宁可返回某服务5分钟之前在在某几台服务器上可用的信息，也不能因为暂时的网络故障找不到可用的服务器。 3. ZK中，若某网络分区中的节点数小于ZK选取leader节点的法定人数，那么这些节点将会断开，就无法正确提供服务了 4. ZK的特点是强一致性，所有导致ZK集群的每个节点数据在发生更新时，需要通知其他ZK节点同时执行更新，所以当大量服务节点上线时，可能会导致ZK集群无法承载 ##### 局限性: 1. 网络化分后，强一致性导致服务注册机制会失效 ZAB协议保证数据一致性，当发生网络分割时，会破坏服务的整体联通性 2. 持久化存储和事务日志 为了保证数据一致性，zk使用的事务日志，当集群半数节点写入成功时，该事务有效。同时事务写使用的2PC提交的方式 但是注册中心只关心实时的健康服务列表，因为调用方不关心历史服务和状态 3. 服务探活 ZK注册镇中心通常利用session活性心跳和临时节点机制进行服务探活 将服务的健康检查检测绑定在了ZK对于Session的健康监测上。然后其实应该由服务方决定探活方式 4. 服务容灾 服务调用链路弱依赖注册中心，同时ZK客户端并无客户端缓存机制 ##### 改良 1. 加上服务可用性。使用客户端缓存，当部分节点与zk断开时，每个节点依然能从本地缓存中获取到数据，但是ZK不能保证所有节点任何时刻都能缓存所有的服务注册信息。 2. 将ZK的强一致性改为Ap并保证最终一致性：当我们需要最终一致性时，可以使用消息总线机制。注册数据可以全量缓存在每个注册中心内存中。通过消息总线同步数据。当有一个节点接收到服务节点注册时，会产生一个消息推送到消息总线，最后再通过消息总线通知给其他的注册中心节点更新数据，并进行服务下发，从而达到注册中心数据的最终一致性。 #### Eureka:专为服务发现设计对的开源组件 Eureka由Eureka服务器和Eureka客户端组成，Eureka服务器作为服务注册服务器，Eureka客户端是一个java客户端，用于简化与服务器的操作，作为轮询负载均衡器，并提供服务的故障切换支持。 ##### Eureka Server：注册中心服务端 注册中心服务端主要提供了三个功能 **服务注册** 服务提供者启动后，会通过Eureka Client 向Eureka Server注册信息，Eureka Server会存储该服务的信息，Eureka Server内部有二层缓存机制来维护整个注册表 **提供注册表** 服务消费者在调用服务时，如果Eureka Client 没有缓存注册表的话，会从Eureka Server 获取最新的注册表 **同步状态** Eureka Client 通过注册，心跳机制和Eureka Server 同步当前客户端的状态 ##### Eureka Client：注册中心客户端 Eureka Client是一个java客户端，用于简化与Eureka Server的交互，Eureka Client会拉取，更新和缓存Eureka Server中的信息。因此当所有的Eureka Server节点都宕掉，服务消费者依然可以使用缓存中的信息找到服务提供者，但是当服务更改时会出现信息不一致 **Registry：服务注册** 服务的提供者，将自身注册到注册中心，服务提供者也是一个Eureka Client。当Eureka Client向Eureka Server注册时，它提供自身的元数据。 **Renew：服务续约** Eureka Client会每间隔30s发送一次心跳进行续约。如果续约来告知Eureka Server该Eureka Client运行正常，没有正常问题。默认情况下，如果Eureka Server在90s内没有收到Eureka Client的续约，Server端就会将实例从注册表中删除。 **Eviction：服务剔除** 当Eureka Client和Eureka Server不在有心跳时，Eureka Server会从该服务实例从服务注册列表中删除，即服务剔除 **Cancel：服务下线** Eureka Client在程序关闭时向Eureka Server发送取消请求。发送请求后，该客户端实例信息将从Eureka Server的实力注册表中删除。该下线请求不会自动完成，需要调用特殊的方法 **GetRegistry：获取注册列表信息** Eureka Client从服务器获取注册表信息，并将其缓存在本地。客户端会使用该信息查找其他服务，从而进行远程调用。该注册列表信息会定期清理一次。重新拉取新的注册表信息 **Remote Call：远程调用** 当Eureka Client从注册中心获取到1服务提供者信息后，就可以通过Http请求调用对应的服务了；服务提供者有多个时，Eureka Client客户端会通过Ribbon进行自动负载均衡。 ##### 高可用： 在Eureka平台中，若某台服务器宕机，Eureka服务不会有类似Zookeeper选举的过程，客户端会自动切换到新的Eureka节点；当宕机的服务器重新恢复后，Eureka会再次将其纳入到服务器集群管理中；因此不用担心会有服务器从集群中剔除的风险 ##### 应对网络分割故障 当网络分割故障出现时，每个Eureka节点会持续的对外服务，接收新的服务注册请求同时将他们提供给下游的服务发现请求。这样在一个子网中，新发布的服务依然可以被发现与访问 ##### 节点自我保护 Eureka内置了心跳服务，用于淘汰一些假死的服务器；如果在Eureka中注册的服务，心跳变的迟缓，Eureka会将其整个剔除出管理范围。这个功能在发生网路分割故障时会很危险。因为可能服务器是正常的，只不过是因为网络问题到了一个子网中 Netflix考虑添加了自我保护机制,如果Eureka服务节点在短时间内丢失了大量心跳连接，那么该服务节点会进入自我保护状态，这些节点的服务注册信息将不会过期，即便是假死状态，以防还有客户端会向该假死节点发起请求。同时当Eureka节点恢复后，会退出自我保护模式 ##### 客户端缓存 Eureka最后还有客户端缓存的功能。当所有的Eureka集群节点都失效，或者发生网络分割故障导致客户端不能访问任何一台Eureka服务器。Eureka消费者依然可以通过客户端缓存找到现有对的服务注册信息 #### etcd 工作原理 etcd是CoreOS团队于2013年发起的开源项目，目标是构建一个高可用的分布式键值数据库，etcd内部采用raft协议作为一致性算法，并给予Golang语言实现 ##### 架构 - 网络层:提供网络数据读写功能，监听服务端口，完成集群节点之间数据通信，收发客户端数据。 - Raft模块: Raft强一致性算法的具体实现。 - 存储模块:涉及KV存储、WAL文件、Snapshot管理等，用于处理etcd支持的各类功能的事务，包括数据索引、节点状态变更、监控与反馈、事件处理与执行等，是etcd对用户提供的大多数API功能的具体实现。 - 复制状态机:这是一个抽象的模块，状态机的数据维护在内存中，定期持久化到磁盘，每次写请求都会持久化到WAL文件，并根据写请求的内容修改状态机数据。除了在内存中存有所有数据的状态以及节点的索引之外，etcd还通过WAL进行持久化存储。基于WAL的存储系统其特点就是所有的数据在提交之前都会事先记录日志。Snapshot是为了防止数据过多而进行的状态快照。 ##### 基本功能 1. KV存储 可以用于存储数据，也就是可以存储配置数据 2. watch功能 可以发现配置的异动，在配置变化时可以起到通知作用 3. key TTL功能 有key TTL功能，etcdv3可以通过lease租约，设置服务的生存周期，然后通过KeepAlive定期续租，避免过期 ##### 服务注册原理 在etcd中服务的注册使用租约（lease）来实现，设置租约的时候按需求设置租约的时间（ttl），类似redis中的EXPIRE key，再把服务自身的节点元数据写入对应的key中，定时去调用KeepAliveOnce来保持租约，如果在期间KeepAliveOnce的消息丢失，或者延迟大于这个租约的ttl则etcd中即将会把这个节点的信息删除，恢复正常时重新发起租约流程 ##### 存储结构 etcd3没有树的概念，因此我们需要将平铺展开来的键值对抽象为树的概念，和其他类型的注册中心保持一致 例如：接口子目录,这些都是不过期的节点 ```bash /root/interface/providers /root/interface/consumers /root/interface/routers /root/interface/configurators ``` 临时节点存储： ```bash /root/interface/providers/protocol:ip:port/service?xxx=xxx /root/interface/consumers/protocol:ip:port/service?xxx=xxx /root/interface/routers/action:ip:port/service?xxx=xxx /root/interface/configurators/protocol:ip:port/service?xxx=xxx ``` ##### 优点 1. etcd 使用增量快照 ， 可以避免在创建快照时暂停 。 2. etcd 使用堆外存储 ， 没有垃圾收集暂停功能 。 3. etcd 己经在微服务 Kubernates 领域中有大量生产实践 ， 其稳定性经得起考验 。 4. 基于 etcd 实现服务发现时 ， 不需要每次感知服务进行全量拉取 ， 降低了网络冲击 。 5. etcd 具备更简单的运维和使用特性 ， 基于 Go 开发更轻量 。 6. etcd 的 watch 可以一直存在 。 7. ZooKeeper 会丢失一些旧的事件 ， etcd 设计了一个滑动窗口来保存一段时间内的事件 ， 客户端重新连接上就不会丢失事件了 。 8. etcd支持多语言客户端 ##### 临时节点的创建 注意点： - 防御性容错，允许失败充实，默认策略最多重试一次，每次重试休眠1秒 流程 1. 检查client是否正确初始化，只有正确初始化才会触发后续 2. 创建租约并进行保活，将用户配置的session作为keep-alive时间，默认30s 3. 创建key-value并绑定租约，通过两个线程，一个定期刷新TTL保活，第二个定期检测本地是否过期 ##### 获取子节点 注意点 - 因为etcd是平铺的key-value。这里为了避免每次单个provider上线都会触发所有客户端进行拉取，所以使用元数据作为key，并且使用特定的前缀进行区分 流程 ​\t若我们将获取服务为xxx的providers，这里path对应`xxx/providers`，我们需要将初始索引移动到path的最后一个`/`字符,也就是xxx后第一个字符。通过这个机制来获取我们需要的节点key ##### 删除子节点 流程 - 通过kvClient直接删除对应的path即可 ##### 接收watch事件变更 流程 1. 获取服务端事件推送 从gRPC响应中获取响应事件 2. 根据event.type做不同的处理 先判断是否为当前服务的path 3. PUT 新服务上线，动态配置，或者动态路由的下发，直接将服务的元数据保存在URL中 4. DELETE 服务下线或者动态配置，动态路由的删除 直接将元数据从URL中删除 ##### watch请求监听 注意点 - 幂等，对一个path多次watch时，会取消之前的watch - watch的丢失和取消，以及自动重试，应该保证可用性，否则会影响服务订阅 流程： 1. 幂等处理 2. 创建gRPC远程本地调用的代理 3. 创建watch对象，并关联回调函数 4. 发起gRPC watch调用 5. 首次监听时，先手动拉取全部的节点数据 ##### 保证一致性： etcd 使用raft协议来维护集群内各个节点状态的一致性。etcd集群是一个分布式系统，由多个节点相互通信构成一个整体对外服务，每个节点都存储了完整的数据，并且通过Rat协议保证每个节点维护的数据是一致的。 每个etcd节点都维护了一个状态机，并且任意时刻至多存在一个有效的主节点，主节点处理所有来自客户端的写操作，通过raft协议保证写操作对状态机的改动会可靠的同步到其他节点 ##### 高性能 单实例支持每秒一千次以上的写从操作，极限写性能可达10kQPS ##### 安全 支持TLS客户端安全认证 ### 健康监测 健康监测的目标是为了让调用方可以感知到节点的状态变化 ##### 心跳机制 服务调用方，每隔一段时间就询问服务提供方，节点的状态 状态： - 健康状态：建立连接成功，并且心跳探活成功 - 亚健康状态：建立连接成功，但是心跳请求连续失败 - 死亡状态：建立连接失败 ##### 业务优化 健康监测最终目的还是希望可以让某些不健康的节点不要影响我们的业务。因此可以再健康监测时，加入业务相关的因素，例如可用率`时间窗内接口调用成功次数/时间窗内总调用次数`。对于该类低于预期的节点，可以加入到亚健康状态中。 ##### 其他考虑 - 健康监测程序所在机器和节点所在机器的网络依然可能故障，也就会出现误判。这时可以将检测程序部署再不同的机器和机房中 - 可以将服务的返回状态保存在MQ中，然后使用专门的消费者进行消费，如果失败率大于阈值，就调用注册中心，进行下线。 ### 路由策略 路由策略的目标是希望使用合理的路由策略，1.：选出合适的服务节点子集；2.：让服务的变更平滑过渡。 在一般的集群中，如果采用灰度发布，但是服务如果出问题，影响范围依然不可控，特别是基础服务，影响范围会变得很大。 路由策略就是通过改变调用请求的路由方向，细粒度的控制服务的影响范围。 ##### 路由策略位置 调用方发起RPC调用流程： 1. 首先服务发现会返回可用的服务列表 2. 在可用服务列表中选择合适的节点发起请求 我们就可以在第二部，**在可用的服务列表中选择合适的节点**这个流程，加上合适的节点筛选规则，这个规则就是路由策略。 最后，流程图如下： ![](https://euraxluo.github.io/images/picgo/b78964a2db3adc8080364e9cfc79ca68.jpg) ##### IP路由 IP路由策略可以限制调用服务方的IP，使用了ip路由策略后，对于服务变更，我们就可以将服务调用方的ip做限制，让变更的节点，只被少数调用方使用。 ##### 参数路由 首先，将每次变更的节点打上tag，例如version等，用于区分不同批次的节点。然后我们需要一个参数配置中心。用于配置我们的参数路由策略。 然后当我们进行请求时，就可以根据请求参数，根据参数规则过滤响应的节点，然后就实现了我们的参数路由策略。 ##### 路由功能的用途 - 灰度发布 - 定点调用 - 黑白名单 - ab_test - 并行开发时，隔离出不同的环境 #### dubbo的路由功能 dubbo主要是服务路由，服务路由包含一条路由规则，路由规则决定了服务消费者的调用目标，即规定了服务消费者可以调用哪些服务提供者 ##### buddo的路由策略 - 条件路由ConditionRouter 将条件规则配置成kv对，然后对条件规则配置进行解析，路由时，将路由到符合条件host中 - 脚本路由ScriptRouter 将脚本作为字符串传入脚本路由解析器中，通过脚本的类型，调用对应的脚本解析器，然后将数据传入至脚本中，运行结束后得到应该路由的host - 标签路由TagRouter 对于服务配置tag标签对，例如tag_name1=\u0026gt;host1,加载tag配置后，解析为标签路由配置项，会将tag路由到对应的host中 ##### dubbo的路由创建时机 每次url发生变更后，都会触发路由信息重建 ### 负载均衡 负载均衡SLB是一种对流量进行按需分发的服务，通过将流量分发到不同的后端服务来扩展应用系统的吞吐能力，并且可以消除系统中的单调故障，提升系统的可用性 负载均衡主要分为应用型负载均衡和传统型负载均衡 应用型负载均衡主要面向七层，基于负载均衡应用 传统型负载均衡主要面向四层，基于物理机架构 ##### RPC的负载均衡 RPC的负载均衡完全由RPC框架自身实现，RPC的服务调用在每次发起RPC调用时，服务调用者都会根据负载均衡插件 RPC负载均衡策略一般是包括权重，随机权重，一致性Hash，轮询，随机。 ##### 轮询法 - 获取地址列表，并维护一个地址指针，每次循环取指针指向的地址，当指针大于地址列表长度时，重置为0 - 访问次数%地址列表长度，注意访问次数使用原子类计数器实现 ##### 权重法 例如： address1 weight 1 address2 weight 2 地址列表：address1 address2 address3 - 对地址列表中的地址，根据权重，重复，例如address2，权重为2，则重复两次。将这样的结果作为地址列表，再进行轮询 - **随机权重**，在得到根据权重修改的列表后，根据随机法获取地址 ##### 一致性hash：相同的参数总是落在一个节点上 - hash(参数)%地址列表长度，得到这样的index，然后从地址列表中获取对应的数据 ##### 最少活跃调用数 - 相同活跃数的随机，活跃数值得是调用前后技术差 ##### 自适应的负载均衡 负载均衡插件需要得到每一个服务节点的处理请求的能力，然后根据处理能力来分配流量。 服务调用者在与服务节点进行长连接时，可以手机服务节点的各个指标，例如：CPU核数，请求处理的耗时指标情况(请求平均耗时，TP99)，内存大小,服务节点的健康状态。然后根据很多指标，并根据每个指标的权重，得到一个总体的数据。 最后得到每个节点的分数后，根据最终的指标分数修改服务节点的最终权重，然后再使用随机权重法来进行流量调度 ![](https://euraxluo.github.io/images/picgo/00065674063f30c98caaa58bb4cd7baf.jpg) **步骤** 1. 添加服务指标收集器，并将其作为插件，可以在运行时收集状态指标，默认有健康状态收集，请求耗时收集等 2. 运行时状态指标收集器收集服务节点的基本数据和健康状态，在服务调用者和服务提供者的心跳数据中获取 3. 请求耗时指标收集器收集请求耗时指标，例如平均耗时，TP99等 4. 配置指标收集器的开启，并且可以设置这些参考指标的指标权重，再根据指标数据和指标权重来综合打分 5. 根据服务节点的综合打分和节点的权重，最终得到节点的最终权重，之后服务调用者再根据随机权重法选择服务节点 #### dubbo负载均衡 ##### 多种级别 - 服务端级别 - 服务端方法级别 - 客户端服务级别 - 客户端方法级别 dubbo的多种配置是有覆盖关系的，配置优先级是 1. 客户端方法级别 2. 客户端接口级别 3. 服务端方法级别 4. 服务端接口级别 ### 异常重试 RPC的重试机制：当服务调用端发起RPC调用时，会经过负载均衡，选择一个节点，之后会向该节点发起请求。当消息发送失败或者收到异常消息时，我们1就可以捕获异常，当异常符合条件，根据异常触发重试，重新通过负载均衡选一个新的节点请求消息，并且记录重试次数，当次数达到阈值，就返回给调用端一个失败异常。 ##### 幂等 在使用RPC框架时，我们要确保被调用的服务的业务逻辑是幂等的，这样才能根据开启RPC的异常重试。 ##### 注意点 - 当连续重试时，请求超时时间需要每次重试后都进行重置，否则会超出用户设置的超时时间 - 在发起重试，负载均衡选择节点时，应该去掉之前异常的节点，保证重试的成功率 - 异常重试白名单，当网络异常，连接异常等一些异常我们知道需要进行重试，但是由很多业务异常也是需要进行异常重试的。这时我们需要配置一个异常重试白名单。当捕获异常后，如果异常在白名单中，我们就需要对这个请求进行重试 #### dubbo集群容错 dubbo的集群容错功能由多个组件共同完成：包括Cluster，Cluster Invoker，Directory，Router，LoadBalance ![](https://euraxluo.github.io/images/picgo/830731-20200502203856324-835993574.jpg) - Failover Cluster:失败自动恢复 不断重试机制，会把请求过得节点保存进来，避免重复请求 - Failfast Cluster：快速失败 只调用一次，异常则抛出，正常则返回结果 - Failsafe Cluster：失败安全 只调用一次，异常时，忽略所有异常，返回默认值，正常则返回结果。 - Failback Cluster：失败自动恢复 只调用一次，当调用失败后，会将失败的请求，放入到延迟队列中，等待一会之后，重试。 - Forking Cluster：并行调用多个服务提供者 同时发起n个并发请求调用者，返回最先响应的结果，其他忽略。若都失败，则返回自定义异常 - Broadcast：-广播容错 向所有invoker发起调用，全部成功才算成功 - mergeable：归并容错 调用所有的invoker，最后merge所有的返回结果 ### 优雅关闭 当服务提供方进入关闭流程时，很多对象会开始被销毁，当关闭后再收到的请求，可能无法正常处理。因此需要优雅关闭，保证所有的调用方都能安全切走流量，不再调用自己，从而做到对业务无损。 **设置挡板**：应该在关闭的时候，设置请求挡板，当服务提供方开始关闭时，会将之后收到的请求直接返回特定的异常给调用方。 当调用方收到该异常响应后，RPC框架会把该节点从健康节点移除，并把请求自动重试到其他节点。并且该请求并未被处理过，可以安全重试到其他节点，实现对业务的无损。 **主动通知**：当服务端关闭后，可以主动通知注册中心下线节点。起到即使通知的作用。 **关闭事件捕获**：通过捕获操作系统的进程信号实现。当服务启动时，主动注册关闭事件的hook。在hook中，一个开启关闭标识，该关闭标识用于调用链，当调用链的hook判断关闭标识生效，则返回特定的请求。另一个负责关闭服务对象。JDK中可以通过ShutdownHook进行捕捉，该函数在以下情况生效 - 程序正常退出 - System.exit() - ORM异常 - kill PID **安全结束**：关闭过程中已经接受的请求应该保证正确处理结束。可以通过请求计数器实现。每开始处理请求时，请求计数器加一，完成请求响应，请求计数器减一。可以通过该请求计数器判断是否有未完成的请求。当业务请求耗时太长时间，可以设置关闭超时时间，超时时间到达时，强制关闭。 **总结**：从外层到里层逐层关闭，先保证 #### dubbo优雅停机 **步骤：** 1. zk和注册中心相关的释放 - 断开zk连接(当断开连接时，zk临时节点也会删除，此时provider就完成删除注册信息的功能) - consumer在zk的注册信息时持久化的，并没有删除，只删除了监听器，此时dubbo等待下一次注册上线时，重新设置监听器 2. protocl释放 - 释放 invoker redistry 信息，dubbo根据invoker 注册 flag判断是否释放完所有的invoker registry信息 - 服务协议关闭。该部分针对远程调用请求做了安全结束的处理，保证所有的以接入请求正常处理结束 - 关闭所有的client，保证作为消费者不发送新的远程调用请求 - 关闭所有的server，并且为server设置关闭 flag，保证作为provider不接受新请求 ### 优雅启动 在java中，JVM使用了JIT技术，运行了一段时间的应用会因为由缓存变得更快。所以我们可以利用优雅启动来实现启动预热。 **启动预热**： 让刚启动的服务提供方应用不承担全部的流量，而是让服务被调用的次数随着时间慢慢增加。也即对于刚注册上线的应用进行降权，并且随着时间慢慢加权。 - 需要让调用方可以发现刚启动不久的应用，并且通过负载均衡，使得刚启动上线的应用被选择的概率随着时间慢慢变大。 - 当服务在注册中心注册上线时，告知注册时间。同时在负载均衡部分。设置一个定时任务，他会把那些未达到预设权重的机器，让他的权重随着时间慢慢变大，直到到达预设权重。 **延迟暴露**： 应用启动时，除了在RPC注册中心注册上线，还包括很多对象初始化工作，加入对象初始化没有完成就开始接收请求，便可能导致服务调用失败。 - 将注册上线时间推迟到对象初始化之后 - 添加注册前hook，使得用户可以预加载缓存，并且对应用进行预热 ![](https://euraxluo.github.io/images/picgo/3c84f9cf6745f2d50e34bd8431c84abd.jpg) **大批量重启启动tips** 当请求较多时，若设置了启动预热的降权功能，可能会将原来可以负载的请求，变得无法负载，因为请求都会打到原来预留的机器上 - 分批启动 - 减慢启动速度，降低重启的并行度 - 请求低峰时重启 ### 服务保护：熔断，限流，降级 当RPC面临高并发的场景时，我们的服务器节点可能会因为访问量过大而引起一系列问题，比如业务处理耗时过长，CPU飘高，频繁Full GC以及服务进程直接宕机等。 我们需要对服务节点进行自我保护，保证在高访问量，高并发对的场景下，服务的稳定性和高可用。 ##### 限流 - 在RPC框架中集成限流功能，配置中心或者注册中心配置总的限流阈值，并且配置下发时，将总节点数一起下发，然后由各个服务节点计算自己的限流阈值，当服务调用请求流量超过阈值，框架直接返回限流异常 - 服务端手动添加限流逻辑，当调用方发送请求时，服务端在业务逻辑前先执行限流逻辑，当访问量过大时，服务端抛出限流异常。 **限流算法** - 计数器（固定窗口） 计数器算法是限流算法中最简单的一种算法。 假设对于某接口，1分钟内的访问次数不能超过100个。 计数器算法如下： 1. 初始化计数器 2. 每当一个请求到达，计数器incr 3. 当计数器值\u0026gt;阈值，且当前时间和初始化时间之差小于一分钟，说明需要限流，请求丢弃 4. 当计数器\u0026gt;阈值，且当前时间和初始化时间之差大于一分钟，计数器重新初始化 算法无论在单机还是分布式都很好实现，使用redis的incr+ttl即可，该算法通常用于QPS限流和访问量限流，但是该算法会有临界问题。 也即当两个相邻周期的临界点前后分别涌入大量请求，虽然都在各自周期的阈值内，但是在临界点前后的访问量已经超过了阈值 - 滑动窗口 滑动窗口算法是将时间周期分割为N个小周期，分别记录每个小周期内的访问次数，并且根据时间滑动删除过期的小周期 假设对于某接口，1分钟内的访问次数不能超过100个。 算法如下： 1. 根据需要将一分钟划分为多个小周期，比如划分为30s一个周期 2. 初始化计数器，维护一个小周期队列 3. 当请求到达时，计数器incr 4. 当计数器初始化时间和当前时间之差大于小周期时间30s，将该周期计数值放入队列中。并初始化下一个小周期的计数器，以及删除掉队列中过期的时间周期 5. 当计数值加上队列中的上几个周期的计数值，大于阈值，说明当前窗口达到阈值，需要限流。直到本小周期结束。 算法依然可以使用redis实现，其中队列的维护可以使用流水线事务或者lua，实现原子性 - 漏斗算法（漏桶算法） 漏斗算法是访问请求到达时直接放入漏桶中，如当前容量已经达到上限（缓存的上限）。则进行丢弃。漏桶以固定的速率通过请求。直到漏桶为空。 算法过程： 1. 到达的数据包，被放置于队列中 2. 队列中最多可以缓存x个字节的数据，当该内存满了，数据包应该被丢弃 3. 数据包从队列中取出，并且以固定的速率注入网络，因此**平滑了突发流量** 相对于计数器算法和滑动窗口算法，漏桶算法通过一个桶，能够装入一定量的请求，当发生突发流量时，在不超过桶容量的前提下，依然可将突发流量全部平滑的处理完。 - 令牌桶算法 令牌桶算法是程序以r（r=时间周期/限流值）的速度向令牌桶增加令牌，直到令牌桶满，请求到达时向令牌桶请求令牌，如获取到令牌则通过请求，否则触发限流，请求丢弃。 令牌桶为了处理流量速率多变的流量做了优化，令牌桶算法主要由三部分构成： - 令牌流：流通令牌的管道，用于生成的令牌的流通，放入令牌桶中 - 数据流：进入系统的数据流量 - 令牌桶：保存令牌的区域，可以理解为一个缓存区，令牌保存在这里用作使用 算法原理 1. 按照固定的速率生成令牌并放入令牌桶（队列）中 2. 数据访问系统时，需要从令牌桶（队列）中获取令牌，无令牌的需要被抛弃，有令牌对的可以进入。 当访问量小时，可以留存令牌，当有突发流量时，系统也能提高负载去解决突发流量，当流量持续性的大量流入时，最后会退化为漏斗算法的固定流量速率。 ##### 熔断 **限流**是为了保护服务端，通过限制流量请求保护自身节点不受影响。 **熔断**是为了对调用端进行保护。防止调用端收到被调用服务的影响。 **熔断机制** 状态转移： - 关闭 - 打开 - 半开 在正常状态下，熔断器为**关闭**状态；当调用端调用下游服务出现异常时，熔断器收集异常指标信息进行计算，当达到熔断条件时，**打开**熔断器，此时，调用端的请求会被熔断器拦截，并快速执行失败逻辑；当熔断器打开一段时间后，会转为**半开**，这时熔断器允许调用端发送一个请求给服务端，若该请求成功，则状态置为**关闭**，否则设置为**打开** **熔断模块** - 熔断请求判断算法：使用无锁循环队列计数，每个熔断器默认维护10个bucket，每秒一个bucket，每个bucket记录请求的成功，失败，超时，拒绝的状态。默认当错误超过50%且10s内超过20个请求时进行中断拦截 - 熔断恢复机制：对于被熔断的请求，每5s允许部分请求通过，若请求都是健康的，则恢复为关闭状态 - 熔断报警：对于被熔断的请求打日志，并且报警。 **RPC框架整合熔断器** 在RPC调用流程中，首先是动态代理，然后是编解码，然后是网络传输。因此应该添加到动态代理处 ##### 服务降级 服务降级是在服务器压力陡增的情况下，利用有限资源，根据当前业务情况，关闭某些服务接口或者页面，一次释放服务器资源以保证核心任务的正常运行。服务降级本质上是为了降低部分服务的处理能力，增强另一部分服务处理能力。 **服务降级方案** - 服务接口拒绝服务：当出现api降级时，前端提示服务器繁忙 - 服务级别降级，当某个页面服务降级时，该页面可以直接提示服务其繁忙。 - 延迟持久化，页面访问正常，但是当服务涉及CUD时，异步处理，将该部分请求放到延迟队列中，服务恢复后执行。 **服务降级需要考虑的问题** - 核心服务、非核心服务 - 是否支持降级，降级策略 - 业务放通场景、策略 ##### 降级和熔断的对比 **共性** - 目的: 目的一致，都是从系统的可用性、可靠性着想。放了防止系统的整体缓慢甚至奔溃而采用的技术手段。 - 最终表现: 表现类似,最终都是给用户一种当前服务不可用或者不可达的感觉 - 粒度: 大多都是在服务级别，当然也有一些在持久层层面的应用 - 自治: 基本都是靠系统达到某一临界条件时，实现自动的降级与熔断，人工降级并不是那么稳妥。 **区别** - 触发原因: 服务熔断一般指某个服务的下游服务出现问题时采用的手段,而服务降级一般是从整体层面考虑的。 - 管理目标层次: 熔断是一种框架级的处理，每一个微服务都需要。而降级一般需要对业务有层级之分，降级一般都是从外围服务开始的。 - 实现方式: 代码级别实现有差异 ### 业务分组和流量隔离 ##### 业务分组 例如两个城市的业务接口，例如北京的流量突然激增，北京的调用方负载变高，如果影响到上海的调用方，就会导致整个系统的可用率降低。 **RPC集成分组** 当调用方获取服务节点时，是通过接口名去注册中心获取所有的已注册节点，当我们添加分组功能后，我们在进行获取服务节点这一步时，除了使用接口名，那么还需要分组参数，相应的，服务节点在进行注册时也需要带上分组参数。 这样我们的RPC就可以把注册的服务提供方的所有实例分为若干组，每一个分组就可以给单个或者多个不同的调用方调用。 ![](https://euraxluo.github.io/images/picgo/128923fefc27a36d056393f9e9f25f69.jpg) **分组逻辑** - 非核心应用不要和核心应用一组 - 核心应用之间应该做好隔离 **调用方分组调用高可用** 当调用方在自己组内可调用节点全部done掉时，依然需要保证他能拿到**其他分组**的**部分服务**节点。 解决办法： - 允许调用方配置多个分组 - 每个分组区分主次分组，或者是优先级 - 当主分组上的节点都不可用时才选择次分组，并且也只能选择次分组某些节点 - 当主分组节点恢复正常，就必须将所有的流量都切换到主节点上 ##### 动态分组 动态修改分组数据，从而可以使每一个分组都能拥有动态扩容缩容的效果，在注册中心或者配置中心中修改分组信息，最后通过和服务之前的心跳数据进行交换，让服务提供方得到真实的分组信息。 ### 异步RPC RPC调用的吞吐量的主要原因就是服务端的业务逻辑比较耗时，并且CPU大部分都在等待而不是计算，导致CPU利用率不够。 ##### 调用端异步 调用端异步就是通过Future实现异步，调用端发起一次异步请求，并且从请求上下文中获取到一个Future，之后通过Future的get方法获取结果，如果业务逻辑中同时调用多个其他的服务，则可以通过Future的方式减少业务逻辑的耗时，提升吞吐量。 **服务端异步** - 服务调用方发起RPC调用，直接拿到异步对象，该对象应该有一个方法，能够等待并获取到异步执行结果 - 服务端在收到请求后，在执行业务逻辑前，先个构造异步对象，之后业务逻辑可以在异步处理，处理完成再进行异步通知 - 调用端在收到服务端发送回的响应后，自动将收到的异步对象的异步通知的值，设置到调用端获取的异步对象的通知函数中，这样，就异步通知了调用端。 ### 接口安全 RPC一般用于解决内部应用之间的通信，并且这些内部应用一般都是搭建在局域网中。相对于公网环境，局域网内的隔离性更好，也就相对更加安全，因此RPC安全很少考虑数据包篡改，请求伪造等恶意行为。 ##### 请求身份安全 服务提供方在收到请求时，不知道这次请求是哪个调用方发起，没法判断该请求是否是该服务确定能为其提供服务的调用方发起的。 解决办法 - 授权平台 - 调用方需要在授权平台申请自己的应用要登记调用的接口，服务提供方可以在授权平台进行审批。 - 授权检验： 方法一：调用方每次发起业务请求时，先去授权平台上发送认证请求，当授权平台返回可以调用时，调用方才将请求发送至服务提供方 方法二：调用方启动初始化时，将授权平台颁发的身份信息去服务提供进行认证，当认证通过时认为该接口可以调用。 认证过程：服务提供方在应用中放一个私钥，这个私钥在授权平台中可以自动为申请调用，并且申请通过的应用进行签名，该签名标识了调用方的唯一身份。当服务提供方收到调用方的授权请求后，只需要验证下这个签名和调用方应用信息是否对应即可。 ##### 服务方身份安全 服务调用方可能会在注册中心获取到不可信的。因为RPC接口没有和某个应用发布者进行绑定。 解决办法： - 授权平台，可以增加接口绑定应用的功能，将接口和某个私钥绑定在一起。 - 注册中心处理 - 当服务提供方启动时，需要把接口实例在注册中心进行注册登记。注册中心可以在收到服务提供方注册请求时，验证请求过来的应用是否和接口绑定的应用一样，当相同时才允许注册，否则就返回错误信息，注册失败。 ### 异常定位 ##### 异常信息封装 由于RPC系统之前是分布式的，各个子应用，子服务之前拥有复杂的依赖关系，所以通过日志难以定位问题。 所以我们可以将异常信息进行标准化，封装化，例如： 1. 异常码 2. 异常原因 3. 接口名 4. 服务分组 5. 服务名 6. 服务端ip 7. 客户端ip **日志聚合** 为每个请求都设置一个唯一id 通过请求Id，将该请求经过的日志都记录下来 ##### 分布式链路追踪 某分布式应用场景，服务依赖关系为A-\u0026gt;B-\u0026gt;C-\u0026gt;D. 那么整个调用链Trace为ABCD，Span为AB，BC，CD。 **链路追踪原理** - 每个Trance都由一个唯一标识，TraceID，分布式追踪系统中，通过TraceId来区分每个Trance，通常每个业务请求都对应一个TranceID。 - 每个Span也有自己的唯一ID，多个Span存在父子关系，多个Span组成某个Trance，每个Span描述一个子系统的处理细节。 - 在进行定义时，以span为一个单位进行定义和数据填充。当需要传播span时，可以通过context，http头部，一起其他通信协议的扩展字段部分进行传播。 - 一般而言，客户端程序在使用并定义span后，会将其传入分布式链路追踪的客户端中，由客户端收集并发送到服务端，在服务端进行存储和聚合计算，最后根据span的tag和服务名得到完整的调用链。 ### 时钟轮 **RPC中定时任务的解决方案** RPC中，很多场景都会使用到定时任务，我们有以下几种方案来实现定时任务： - **sleep**，当需要定时任务时，我们就创建一线程，之后sleep需要的秒数，实现定时的需求。**缺点**：当需要的定时任务较多时，我们需要创建的线程数也会变得很多。 - **轮询**，使用一个线程来处理所有的定时任务，每隔一段时间就扫描所有的定时任务，发现即将执行的定时任务，就进行执行。这里可以使用优先级队列来进行优化，只需要扫描优先级队首的周期睡眠时间内的定时任务。**缺点**：需要短轮询不断判断第一个元素是否过期，造成CPU空耗 - **时钟轮**，是一种优化定时任务的一种算法，可以减少轮询最近即将执行的定时任务的个数，并且还能减少轮询次数。 ##### 时钟轮算法 时钟轮是一种环形数据结构，分为多个格子。每个格子代表一段时间，时间越短，精度越高。每个格子上用一个链表保存在该格过期的任务。指针随着时间一格一格转动，并执行对应格子的到期任务。 **名词解释** - 时间格：环形数据结构，用于存放延迟任务的区块 - 指针：指向当前操作的时间格，代表当前时间 - 格数：时间轮中时间格的个数 - 间隔：每个时间格之间的间隔，代表时间轮能达到的精度 - 总间隔：当前时间轮总间隔，等于格数*间隔，代表时间轮能表达的时间范围。 ##### 单表时间轮 ![img](https://euraxluo.github.io/images/picgo/20180619115045d49ed7cf-54e2-47e0-bde2-61ba30259daa.jpg) 以上图为例，假设一个格子是1秒，则整个时间轮能表示的时间段为8s， 如果当前指针指向2，此时需要调度一个3s后执行的任务，需要放到第5个格子(2+3)中，指针再转3次就可以执行了。 **单表时间轮存在的问题** 格子的数量有限,所能代表的时间有限,当要存放一个10s后到期的任务怎么办？这会引起时间轮溢出。 有个办法是把轮次信息也保存到时间格链表的任务上。 ![img](https://euraxluo.github.io/images/picgo/201806191150588df84d64-ffd2-4170-b5f8-bdefe5e56384.jpg) 如果任务要在10s后执行，算出轮次10/8 round等1，格子10%8等于2，所以放入第二格。 检查过期任务时应当只执行**round为0**的任务，链表中其他任务的**round减1**。 **带轮次单表时间轮存在的问题** 如果任务的时间跨度很大，数量很大，单层时间轮会造成任务的round很大，单个格子的链表很长，每次检查的量很大，会做很多无效的检查 ##### 分层时间轮 ![img](https://nos.netease.com/cloud-website-bucket/201806191151122ea9ea70-02be-4b55-966e-60ddb8b90afa.jpg) 过期任务一定是在底层轮中被执行的，其他时间轮中的任务在接近过期时会不断的降级进入低一层的时间轮中。 分层时间轮中每个轮都有自己的格数和间隔设置，当最低层的时间轮转一轮时，高一层的时间轮就转一个格子。 分层时间轮大大增加了可表示的时间范围，同时减少了空间占用。 **举个例子：** 上图的分层时间轮可表达8 *8* 8=512s的时间范围，如果用单表时间轮可能需要512个格子， 而分层时间轮只要8+8+8=24个格子，如果要设计一个时间范围是1天的分层时间轮，三个轮的格子分别用24、60、60即可。 **工作原理：** 时间轮指针转动有两种方式： - 根据自己的间隔转动（秒钟轮1秒转1格；分钟轮1分钟转1格；时钟轮1小时转1格） - 通过下层时间轮推动（秒钟轮转1圈，分钟轮转1格；分钟轮转1圈，时钟轮转1格） 指针转到特定格子时有两种处理方式： - 如果是底层轮，指针指向格子中链表上的元素均表示过期 - 如果是其他轮，将格子上的任务移动到精度细一级的时间轮上，比如时钟轮的任务移动到分钟轮上 **举个例子：** - 添加1个5s后执行的任务 1. 算出任务应该放在秒钟轮的第5个格子 2. 在秒钟轮指针进行5次转动后任务会被执行 - 添加一个50s后执行的任务 1. 算出该任务的延迟时间已经溢出秒钟轮 2. 50/8=6,所以该任务会被保存在分钟轮的第6个格子 3. 在秒钟轮走了6圈(6*8s=48s)之后，分钟轮的指针指向第6个格子 4. 此时该格子中的任务会被降级到秒钟轮，并根据50%8=2，任务会被移动到秒钟轮的第2个格子 5. 在秒钟轮指针又进行2次转动后(50s)任务会被执行 - 添加一个250s后执行的任务 1. 算出该任务的延迟时间已经溢出分钟轮 2. 250/8/8=3,所以该任务会被保存在时钟轮的第3个格子 3. 在分钟轮走了3圈(3*64s=192s)之后，时钟轮的指针指向第3个格子 4. 此时该格子中的任务会被降级到分钟轮，并根据(250-192)/8=7，任务会被移动到分钟轮的第7个格子 5. 在秒钟轮走了7圈(7*8s=56s)之后，分钟轮的指针指向第7个格子 6. 此时该格子中的任务会被降级到秒钟轮，并根据(250-192-56)=2，任务会被移动到秒钟轮的第2个格子 7. 在秒钟轮指针又进行2次转动后任务会被执行 **优点：** - 高性能（插入任务、删除任务的时间复杂度均为O(1) **缺点：** - 数据是保存在内存，需要自己实现持久化 - 不具备分布式能力，需要自己实现高可用 - 延迟任务过期时间受时间轮总间隔限制 **缓冲区解决溢出问题** 对于超出范围的任务可放在一个缓冲区中(可用队列、redis或数据库实现)，等最高时间轮转到下一格子就从缓冲中取出符合范围的任务落到时间轮中。 **举例：** - 添加一个600s后执行的任务A 1. 算出该任务的延迟时间已经溢出时间轮 2. 所以任务被保存到缓冲队列中 3. 在时钟轮走了1格之后，会从缓冲队列中取满足范围的任务落到时间轮中 4. 缓冲队列中的所有任务延迟时间均需减去64s，任务A减去64s后是536s，依然大于时间轮范围，所以不会被移出队列 5. 在时钟轮又走了1格之后，任务A减去64s是536-64=472s，在时间轮范围内，会被落入时钟轮 ### 流量收集和回放 随着接口越来越多，变更也越来越频繁，传统额通过编写脚本的方式来测试接口已经不能满足需求。所以出现了线上流量回放这个测试方法 **基于线上流量回放的思路** 本质上是一种白盒测试，通过mock程序对外依赖中有可能产生变化的内容，使测试更关注接口的代码逻辑。 **RPC实现流量回放** 录制：由于RPC框架中，所有的请求和响应都会经过RPC，我们只要拿到请求的出入参数，并且将这些出入参数录制下来，异步存储，即可实现流量回放的录制功能。 回放：在RPC中，我们把能够接收请求的应用叫做服务提供方，那我们只需要模拟一个调用方，并且把录制的请求参数重新发送回要进行测试的应用中，这样就能实现回放功能。 更多功能：通过RPC框架中集成流量回放功能。我们可以实现在线启停，方法级别录制等功能。 ##### 流量回放功能 - 流量几率，流量复制 - 流量循环播放 - 流量速率放大缩小 - 流量频率，持续高压，以及间隔高压 - 流量过滤，使用正则等过滤流量 - 流量集成和写入到其他中间件 - 执行链路记录，能够得到请求的链路 - 链路聚类，对于不同的执行路径进行等价类划分，通过链路路径进行有选择流量回放，较少重复case ### 泛化调用 通常的RPC调用一般是基于接口的，也就是需要依赖服务提供提供的接口API，因为一般而言调用方需要通过该接口API生成动态代理，或者是代码生成服务类。 另一种调用方法就是泛化调用 **原理** 调用方将服务端需要知道的信息，接口名，业务分组名，方法名，参数信息等封装为请求消息发送给服务端，服务端就能解析这条消息 ![](https://euraxluo.github.io/images/picgo/a3c5ddba4960645b77d73e503da34b89.jpg) 因此我们使用一个统一的接口GenericService接口类生成动态代理，实现无接口的情况下进行RPC调用。 该接口类具有两个方法：invoke以及asyncInvoke，分别对应同步和异步调用两种方式 ##### 序列化问题 泛化调用在没有接口的定义，也即没有接口的传参的情况下，怎么对入参和出参进行正常的序列化呢。 **解决办法** - 首先我们需要为序列化部分增加一个专为泛化调用提供的专属序列化工具 - 入参和返回参数的类型使用Map来进行定义，然后通过专属的序列化工具进行序列化和反序列化 - 在进行序列化内容传输时，需要明确指出该序列应使用泛化调用的方式进行处理 ### 多种RPC协议的兼容 多协议兼容对的关键之处就是要使用一种协议无关的的对象。 - 二进制数据解析：在不同协议切换时，我们需要能根据协议二进制数据的magic number去找到对应协议，并且使用对应协议的数据格式来解析二进制数据包。 - 协议解析：协议解析的本质就是把二进制数据，解析为RPC内部对象，但是该对象一般都是和协议相关的。我们如果需要支持多协议，首先就需要将该协议相关的对象转为和协议无关的对象。 - 内部处理：当我们的协议解析部分返回给我们的是协议无关的对象时，我们就可以在内部逻辑中完全做到和协议脱离。保证协议转换的功能就有对应的协议解析类来完成。 **流程**： ![](https://euraxluo.github.io/images/picgo/43451aea86fef673c3928230191fac37.jpg) 如图：协议1和协议2和RPC内部逻辑进行完全脱离，使用协议无关的对象进行交流。 ","date":"2021-11-22","img":"","permalink":"/posts/rpc/rpc%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0/","series":["rpc"],"tags":["rpc"],"title":"RPC原理学习"},{"categories":["OR"],"content":"TSP，即Traveling Salesman Problem，也就是旅行商问题 ，又译为旅行推销员问题、货郎担问题 ，简称为TSP问题 ，是最基本的路线问题，该问题是在寻求单一旅行者由起点出发，通过所有给定的需求点之后，最后再回到原点的最小路径成本。最早的旅行商问题的数学规划是由Dantzig（1959）等人提出。\n二、\n有时间窗车辆路径问题（vehicle routing problems with time windows，VRPTW）车辆路线问题（VRP）最早是由Dantzig和Ramser于1959年首次提出，它是指一定数量的客户，各自有不同数量的货物需求，配送中心向客户提供货物，由一个车队负责分送货物，组织适当的行车路线，目标是使得客户的需求得到满足，并能在一定的约束下，达到诸如路程最短、成本最小、耗费时间最少等目的。 三、以下内容from：http://wiki.mbalib.com/wiki/%E8%BD%A6%E8%BE%86%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98\n车辆路径问题 车辆路径问题（Vehicle Routing Problem,VRP）\n什么是车辆路径问题 车辆路线问题（VRP）最早是由Dantzig 和Ramser 于1959年首次提出，它是指一定数量的客户，各自有不同数量的货物需求，配送中心 向客户提供货物，由一个车队负责分送货物，组织 适当的行车路线，目标是使得客户的需求 得到满足，并能在一定的约束下，达到诸如路程最短、成本 最小、耗费时间最少等目的[1] 。\n由此定义不难看出，旅行商问题 （Traveling Saleman Problem ,TSP）是VRP的特例，由于Gaery [2] 已证明TSP问题 是NP难题 ，因此，VRP也属于NP难题。\n车辆路线问题自1959年提出以来，一直是网络优化问题中最基本的问题之一，由于其应用的广泛性和经济 上的重大价值，一直受到国内外学者的广泛关注。车辆路线问题可以描述如下（如图1）：\n设有一场站（depot），共有M 辆货车，车辆容量为Q，有N位顾客 （customer），每位顾客有其需求量D。车辆从场站 出发对客户进行配送服务最后返回场站，要求所有顾客都被配送，每位顾客一次配送完成，且不能违反车辆容量的限制，目的是所有车辆路线的总距离最小。车辆路线的实际问题包括配送中心配送 、公共汽车路线制定、信件和报纸投递、航空和铁路时间表安排、工业废品收集等。\n[编辑 ]\n车辆路径问题的类型[3\\] 一般而言车辆路线问题大致可以分为以下三种类型（Ballou，1992）：\n1、相异的单一起点和单一终点。\n2、相同的单一起点和终点。\n3、多个起点和终点。\n[编辑 ]\n车辆路径问题的方法[3\\] 关于车辆路线问题之学术研究文献众多，也提出了相当多的求解策略与方法，Bodin and Golden（1981）将众多之求解方法归纳成以下七种：\n数学解析法 （Exact Procedure ）； 人机互动法 （Interactive Optimization ）； 先分群再排路线 （Cluster First–Route Second）； 先排路线再分群 （Route First–Cluster Second）； 节省法 或插入法 （Saving or Insertion）； 改善或交换法 （Improvement or Exchanges）； 数学规划近似法 （Mathematical programming）。 [编辑 ]\n车辆路线问题研究现状[4\\] 经过几十年的研究发展，车辆路线问题研究取得了大量成果。下面从车辆路线问题的现有研究型态和求解方法两个方面介绍车辆路线问题的研究现状。\n[编辑 ]\n车辆路线问题型态 在基本车辆路线问题（VRP）的基础上，车辆路线问题在学术研究和实际应用上产生了许多不同的延伸和变化型态，包括时窗限制车辆路线问题 （vehicle routing problems with time windows，VRPTW）、追求最佳服务时间的车辆路线问题 （VRPDT）、多车种车辆路线问题 （fleet size and mix vehicle routing problems，FSVRP）、车辆多次使用的车辆路线问题 （vehicle routingproblems with multiple use of vehicle，VRPM）、考虑收集的车辆路线问题 （vehicle routingproblems with backhauls，VRPB）、随机需求车辆路线问题 （vehicle routing problem with stochastic demand，VRPSD）等。\n[编辑 ]\n求解方法 1、求解方法演进\n综合过去有关车辆路线问题的求解方法，可以分为精确算法 （exact algorithm）与启发式解法 （heuristics），其中精密算法有分支界限法 、分支切割法 、集合涵盖法 等；启发式解法有节约法 、模拟退火法 、确定性退火法 、禁忌搜寻法 、基因算法 、神经网络 、蚂蚁殖民算法 等。1995年，Fisher [5] 曾将求解车辆路线问题的算法分成三个阶段。第一阶段是从1960年到1970年，属于简单启发式方式，包括有各种局部改善启发式算法和贪婪法（Greedy）等；第二阶段是从1970年到1980年，属于一种以数学规划 为主的启发式解法，包括指派法、集合分割法和集合涵盖法；第三阶段是从1990开始至今，属于较新的方法，包括利用严谨启发式方法、人工智能方法等。\n2、启发式算法\n由于VRP是NP-hard问题，难以用精确算发求解，启发式算法是求解车辆运输问题的主要方法，多年来许多学者对车辆运输问题进行了研究，提出了各种各样的启发式方法。车辆运输问题的启发式方法可以分为简单启发式算法 、两阶段启发式算法、人工智能方法建立的启发式方法。\n简单启发式方法包括节省法或插入法 、路线内／间节点交换法、贪婪法和局部搜索法等方法。节省法或插入法（savings or insertion）是在求解过程中使用节省成本最大的可行方式构造路线，直到无法节省为止。交换法则是依赖其他方法产生一个起始路线，然后以迭代的方式利用交换改善法减少路线距离，直到不能改善为止。1960年，Clarke和Wright[6] 首先提出一种启发式节省法（savings methods）来建立车队配送路线 。简单启发式方法简单易懂、求解速度快，但只适合求解小型、简单的VRP问题。\n两阶段方法包括先分组后定路线（clusterfirst-route second）和先定路线后分组（routefirst-cluster second）两种启发式策略。前者是先将所有需求点大略分为几个组，然后再对各个组分别进行路线排序；后者则是先将所有的需求点建构成一条路线，再根据车辆的容量将这一路线分割成许多适合的单独路线。\n1990年以来，人工智能方法在解决组合优化问题上显示出强大功能，在各个领域得到充分应用，很多学者也将人工智能 引入车辆路线问题的求解中，并构造了大量的基于人工智能的启发式算法。禁忌搜索法 （TS）基本上是属于一种人工智能型（AI）的局部搜寻方法，Willard首先将此算法用来求解VRP ，随后亦有许多位学者也发表了求解VRP的TS 算法。西南交通大学 的袁庆达[7] 等设计了考虑时间窗口和不同车辆类型的禁忌算法，这种算法主要采用GENIUS方法产生初始解，然后禁忌算法对初始解优化。模拟退火方法具有收敛速度快，全局搜索的特点，Osman[8] 对VRP的模拟退火算法进行了研究，他提出的模拟退火方法主要适合于解决路线分组。遗传算法 具有求解组合优化问题的良好特性，Holland首先采用遗传算法（GA）编码解决VRPTW 问题。现在多数学者采用混合策略 ，分别采用两种人工智能方法进行路线分组和路线优化。Ombuki[9] 提出了用遗传算法 进行路线分组，然后用禁忌搜索方法进行路线优化的混合算法。Bent和Van Hentenryck[[10]](http://wiki.mbalib.com/wiki/车辆路径问题#_note-8)则首先用[模拟退火算法](http://wiki.mbalib.com/wiki/模拟退火算法)将车辆路线的数量最小化，然后用大邻域搜索法（largneighborhood search）将运输费用降到最低。\n总结几种人工智能方法可以看出，TS算法所得到的解最接近最优解，但其运算时间也最长，是GA算法的2～3倍，SA算法的近20倍；由于GA算法也能较好的逼近最优解，同时使运算时间大大缩短，所以GA算法能兼顾运算时间和效率两方面，是具有较好的发展前途的方法；SA算法求解速度非常快，也能提供一定程度上的优化方案在求解较小规模问题上具有较好效果。\n","date":"2021-03-21","img":"","permalink":"/posts/or/%E8%BD%A6%E8%BE%86%E8%B7%AF%E5%BE%84%E9%97%AE%E9%A2%98/","series":null,"tags":["VRP","TSP"],"title":"车辆路径问题"},{"categories":["notes"],"content":"1.安装flower: pip install flower 1 2. 启动flower 例如启动项目工程下面celery_tasks目录的main.py 异步任务启动函数\nflower -A celery_tasks.main --port=5555 1.安装Celery\npip install celery\n2.编写task\nfrom celery import Celery app = Celery(\u0026#39;tasks\u0026#39;, broker=\u0026#39;amqp://guest@localhost//\u0026#39;) @app.task def add(x, y): return x + y 3.运行\n$ celery -A tasks worker --loglevel=info\n","date":"2021-02-21","img":"","permalink":"/posts/note/%E5%AE%89%E8%A3%85flower/","series":["notes"],"tags":["notes"],"title":"安装flower"},{"categories":["note"],"content":"关于切片和slice的内存共享 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;bytes\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; _errors \u0026#34;github.com/pkg/errors\u0026#34; \u0026#34;os\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) func main() { /** * @Description: foo boo内存共享 * @param []int * @param 5 */ foo := make([]int, 5) foo[3] = 3 foo[4] = 4 boo := foo[1:4] boo[1] = 2 for i := 0; i \u0026lt; 5; i++ { println(foo[i]) } /** * @Description: 当capcity够的时候，那么就不会重新分配内存 * @param []int * @param 8 */ a := make([]int, 8) b := a[1:8] b[1] = 1 //[01...],a=[001] a[2] = 2 //[002...] a = append(a, 1) //新内存空间 b[1] = 3 //b=[03...],a=[002] a[2] = 4 //a=[004] for i := 0; i \u0026lt; len(a); i++ { print(a[i]) } println() for i := 0; i \u0026lt; len(b); i++ { print(b[i]) } /** * @Description: dir1和dir2 共享内存，虽然dir1有个append， * 但是由于空间足够，所以没有重新申请空间 * */ println() path := []byte(\u0026#34;AAAAAA/BBBBBB\u0026#34;) sep := bytes.IndexByte(path, \u0026#39;/\u0026#39;) //dir1:=path[:sep] dir1 := path[:sep:sep] //todo 这个语法设置了最小的cap，后续append，就会重新分配内存 dir2 := path[sep+1:] println(string(dir1)) println(string(dir2)) dir1 = append(dir1, \u0026#34;/suffix\u0026#34;...) println(string(dir1)) println(string(dir2)) /** * @Description:深度比较 deepEqual */ v1 := data{} v2 := data{} println(reflect.DeepEqual(v1, v2)) m1 := map[string]string{\u0026#34;1\u0026#34;: \u0026#34;a\u0026#34;, \u0026#34;2\u0026#34;: \u0026#34;b\u0026#34;} m2 := map[string]string{\u0026#34;2\u0026#34;: \u0026#34;b\u0026#34;, \u0026#34;1\u0026#34;: \u0026#34;a\u0026#34;} println(reflect.DeepEqual(m1, m2)) s1 := []int{1, 2, 3} s2 := []int{2, 3, 4} println(reflect.DeepEqual(s1, s2)) /** * @Description: 成员函数Receiver */ p := Persion{ Name: \u0026#34;Euraxluo\u0026#34;, Sex: \u0026#34;Male\u0026#34;, Age: 44, } p.printPersion() /** * @Description:面向接口编程 */ c := Country{\u0026#34;CHINA\u0026#34;} city := City{\u0026#34;shanghai\u0026#34;} printStr(c) printStr(city) /** * @Description: 时间处理 */ //now time now := time.Now() fmt.Println(now) str_now := time.Now().String() fmt.Println(str_now) //Unix timestamp unix_now := time.Now().Unix() fmt.Println(unix_now) //获取日期 date_time := time.Now().Day() fmt.Println(date_time) //获取年份 year := time.Now().Year() fmt.Println(year) //获取月份 month := time.Now().Month() fmt.Println(month) //数字转字符串 x := strconv.Itoa(32131) println(x) //避免把String转成[]Byte //如果需要在for循环中对某个slice使用append()，先把slice的容量整到位，避免浪费内存 //拼接字符串 使用stringBuffer,StringBuild //plus 符号适合用于字面常量的拼接。编译器会直接进行优化 //StringBuild 通过合理的内存预分配，可以减少拼接时，内存的分配次数，减少GC次数 str_list := []string{\u0026#34;你好\u0026#34;, \u0026#34;世界\u0026#34;} s_build := StringBuilder(str_list, 20) println(s_build) //已有字符串的情况下，使用 strings.join比较好 s_join := strings.Join(str_list, \u0026#34;\u0026#34;) println(s_join) //![](https://www.flysnow.org/2018/11/11/golang-concat-strings-performance-analysis.html) //使用gorouting并发，使用sync.WaitGroup同步分片 //var wgs sync.WaitGroup wgs := new(sync.WaitGroup) for i := 0; i \u0026lt; 10; i++ { wgs.Add(1) //todo add 1 //go download(\u0026#34;test.com\u0026#34;, i,\u0026amp;wgs) go download(\u0026#34;test.com\u0026#34;, i, wgs) } wgs.Wait() //避免在热代码中进行内存分配，这样会导致gc繁忙，使用sync.Pool来重用对象 //![](https://zhuanlan.zhihu.com/p/76812714) //![](https://www.cnblogs.com/sunsky303/p/9706210.html) /** * @Description: sync.Pool 的使用场景： × 1.最好是高并发 × 2.最好两次GC之间的间隔长 */ time1 := time.Now().Unix() for i := 0; i \u0026lt; 900000; i++ { obj := make([]byte, 1024) _ = obj } time2 := time.Now().Unix() for j := 0; j \u0026lt; 900000; j++ { obj := bytePool.Get().(*[]byte) _ = obj bytePool.Put(obj) } time3 := time.Now().Unix() println(time2 - time1) println(\u0026#34;SYNC POOL\u0026#34;, time3-time2) //使用lock-free操作，避免使用mutex,应该使用sync/Atomic包 //lock free编程 https://www.cnblogs.com/gaochundong/p/lock_free_programming.html //todo https://coolshell.cn/articles/9703.html //todo https://coolshell.cn/articles/8239.html //提供原子操作 //加法(add), 比较并交换(compare and swap, 简称CAS)，加载(load), 存储(store),交换(swap) var l uint32 = 10 atomic_plus(\u0026amp;l, 10) fmt.Println(l) atomic_sub(\u0026amp;l, 5) fmt.Println(l) //使用I/O缓存，使用bufio.NewWrite()，bufio.NewReader() readBuffer() writeBuffer() //在for循环中使用正则，要使用regexp.Compile()编译正则，性能更高 for i := 0; i \u0026lt; 10; i++ { x := re_compile(\u0026#34;hello World\u0026#34;, `\\w+`) println(x) } //如果需要高性能，使用protobuf,msgp //使用Map时，使用整形的Key更快 //todo https://golang.org/doc/effective_go.html //todo https://github.com/uber-go/guide/blob/master/style.md //todo http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/ //todo https://github.com/cristaloleg/go-advice //todo https://www.instana.com/blog/practical-golang-benchmarks/ //todo https://github.com/alecthomas/go_serialization_benchmarks //todo https://github.com/golang/go/wiki/Performance //2.错误处理 //一段代码的改进 testa := []int{1, 2, 3, 4, 5} testb := []int{1, 2, 3, 4, 5} testc := Compares{ V1: 2, V2: 2, V3: 2, V4: 2, V5: 4, } if err := testc.exception_handler4(testa, testb); err != nil { println(err.Error()) } else { println(\u0026#34;check pass\u0026#34;) } //3.选项模式 //建造者模式 sb := OptionBuilder{} if option, err := sb.Create(\u0026#34;127.0.0.1\u0026#34;, \u0026#34;8080\u0026#34;).WithOption3(1).WithOption4(1.1).Build(); err == nil { option.printOpt() } //选项模式 op1, _ := NewSetting(Option1(\u0026#34;localhost\u0026#34;), Option2(\u0026#34;1023\u0026#34;)) op1.printOpt() //4.嵌入和委托 //嵌入结构多态 button1 := Button{Label{Widget{10, 70}, \u0026#34;OK\u0026#34;}} button2 := Button{Label{Widget{50, 70}, \u0026#34;NO\u0026#34;}} listBox := ListBox{Widget{10, 40}, []string{\u0026#34;AL\u0026#34;, \u0026#34;AK\u0026#34;, \u0026#34;AZ\u0026#34;, \u0026#34;AR\u0026#34;}, 0} println(\u0026#34;Painters\u0026#34;) for _, painter := range []Painter{listBox, button1, button2} { painter.Paint() } println(\u0026#34;Painters2\u0026#34;) for _, widget := range []interface{}{listBox, button1, button2} { widget.(Painter).Paint() if clicker, ok := widget.(Clicker); ok { clicker.Click() } fmt.Println() // print a empty line } //控制反转 //控制逻辑依赖业务逻辑： intSet := NewIntSet() intSet.Add(1) intSet.Add(2) intSet.Add(3) intSet.Delete(3) println(\u0026#34;intSet\u0026#34;) for k, v := range intSet.data { fmt.Println(k, v) } undoSet := NewUndoSet() undoSet.Add(1) undoSet.Add(2) undoSet.Add(3) undoSet.Delete(3) undoSet.Undo() println(\u0026#34;undoSet\u0026#34;) for k, v := range undoSet.data { fmt.Println(k, v) } strSet := NewStrSet() strSet.Add(\u0026#34;1\u0026#34;) strSet.Add(\u0026#34;2\u0026#34;) strSet.Add(\u0026#34;3\u0026#34;) strSet.Delete(\u0026#34;3\u0026#34;) strSet.Undo() println(\u0026#34;strSet\u0026#34;) for k, v := range strSet.data { fmt.Println(k, v) } //5.1map list := []string{\u0026#34;Euraxluo\u0026#34;, \u0026#34;Hello\u0026#34;, \u0026#34;World\u0026#34;} var mapres []interface{} mapres = Map(list, func(s interface{}) interface{} { return strings.ToUpper(reflect.ValueOf(s).String()) }) for k, v := range mapres { fmt.Println(k, v) } mapres = Map(list, func(s interface{}) interface{} { return len(reflect.ValueOf(s).String()) }) for k, v := range mapres { fmt.Println(k, v) } reduceres := Reduce(list, func(s interface{}) interface{} { return len(reflect.ValueOf(s).String()) }) println(reduceres.(int64)) reduceress := Reduce(list, func(s interface{}) interface{} { return reflect.ValueOf(s).String() + \u0026#34; \u0026#34; }) println(reduceress.(string)) var int_set = []int{1, 2, 3, 4, 5, 6, 7, 87, 8} out := Filter(int_set, func(s interface{}) bool { return reflect.ValueOf(s).Int()%2 == 1 }) for k, v := range out { fmt.Println(k, v) } } /** * @Description: 通用的map函数 * @param arr * @param fn * @return []interface{} */ func Map(arr interface{}, fn func(s interface{}) interface{}) []interface{} { if reflect.ValueOf(arr).Kind() != reflect.Slice { return nil } var newArr []interface{} for i := 0; i \u0026lt; reflect.ValueOf(arr).Len(); i++ { newArr = append(newArr, fn(reflect.ValueOf(arr).Index(i).Interface())) } return newArr } /** * @Description: 通用的reduce函数 * @param arr * @param fn * @return interface{} */ func Reduce(arr interface{}, fn func(s interface{}) interface{}) interface{} { if reflect.ValueOf(arr).Kind() != reflect.Slice { return nil } var sum interface{} for i := 0; i \u0026lt; reflect.ValueOf(arr).Len(); i++ { res := fn(reflect.ValueOf(arr).Index(i).Interface()) if sum == nil { psum := reflect.Indirect(reflect.ValueOf(sum)) if psum.CanSet() { psum.Set(reflect.ValueOf(res)) } else { sum = res } } else { switch reflect.ValueOf(sum).Kind() { case reflect.Interface: return nil case reflect.Int: sum = reflect.ValueOf(sum).Int() + reflect.ValueOf(res).Int() case reflect.String: sum = reflect.ValueOf(sum).String() + reflect.ValueOf(res).String() case reflect.Ptr: sum = reflect.ValueOf(sum).Pointer() + reflect.ValueOf(res).Pointer() } } } return sum } /** * @Description: 通用的filter函数 * @param arr * @param fn * @return []interface{} */ func Filter(arr interface{}, fn func(s interface{}) bool) []interface{} { if reflect.ValueOf(arr).Kind() != reflect.Slice { return nil } var newArr []interface{} for i := 0; i \u0026lt; reflect.ValueOf(arr).Len(); i++ { if fn(reflect.ValueOf(arr).Index(i).Interface()) == true { newArr = append(newArr, reflect.ValueOf(arr).Index(i).Interface()) } } return newArr } /** * @Description: 控制功能Undo依赖业务功能 */ type IntSet struct { data map[int]bool } func NewIntSet() IntSet { return IntSet{make(map[int]bool)} } func (set *IntSet) Add(x int) { set.data[x] = true } func (set *IntSet) Delete(x int) { delete(set.data, x) } func (set *IntSet) Contains(x int) bool { return set.data[x] } type UndoSet struct { IntSet functions []func() } func NewUndoSet() UndoSet { return UndoSet{NewIntSet(), nil} } func (set *UndoSet) Add(x int) { //重写 if !set.Contains(x) { set.data[x] = true set.functions = append(set.functions, func() { set.Delete(x) }) } else { set.functions = append(set.functions, nil) } } func (set *UndoSet) Delete(x int) { //重写 if set.Contains(x) { delete(set.data, x) set.functions = append(set.functions, func() { set.Add(x) }) } else { set.functions = append(set.functions, nil) } } func (set *UndoSet) Undo() error { if len(set.functions) == 0 { return errors.New(\u0026#34;No functions to undo\u0026#34;) } index := len(set.functions) - 1 if function := set.functions[index]; function != nil { function() set.functions[index] = nil } set.functions = set.functions[:index] return nil } /** * @Description: 定义协议 */ type UndoIOC []func() func (undo *UndoIOC) Add(function func()) { *undo = append(*undo, function) } func (undo *UndoIOC) UndoIOC() error { functions := *undo if len(functions) == 0 { return errors.New(\u0026#34;No functions to Undo\u0026#34;) } index := len(functions) - 1 if function := functions[index]; function != nil { function() functions[index] = nil } *undo = functions[:index] return nil } /** * @Description: 控制反转，将业务逻辑依赖控制逻辑。 * 应该是这样 服务想实现什么控制协议，由服务决定，控制能通用 */ type StrSet struct { data map[string]bool undo UndoIOC } func NewStrSet() StrSet { return StrSet{data: make(map[string]bool)} } func (set *StrSet) Undo() { set.undo.UndoIOC() } func (set *StrSet) Add(x string) { if !set.Contains(x) { set.data[x] = true set.undo.Add(func() { set.Delete(x) }) } else { set.undo.Add(nil) } } func (set *StrSet) Delete(x string) { if set.Contains(x) { delete(set.data, x) set.undo.Add(func() { set.Add(x) }) } else { set.undo.Add(nil) } } func (set *StrSet) Contains(x string) bool { return set.data[x] } type Painter interface { Paint() } type Clicker interface { Click() } type Widget struct { X, Y int } type Label struct { Widget //嵌入 Text string //聚合 } func (label Label) Paint() { println(\u0026#34;Paint\u0026#34;, \u0026amp;label, label.Text) } type Button struct { Label } func (button Button) Paint() { println(\u0026#34;Paint\u0026#34;, \u0026amp;button, button.Text) } func (button Button) Click() { println(\u0026#34;Click\u0026#34;, \u0026amp;button, button.Text) } type ListBox struct { Widget Texts []string Index int } func (listBox ListBox) Paint() { println(\u0026#34;Paint\u0026#34;, \u0026amp;listBox, listBox.Texts) } func (listBox ListBox) Click() { println(\u0026#34;Click\u0026#34;, \u0026amp;listBox, listBox.Texts) } /** * @Description: 选项模式 */ type Option struct { option1 string option2 string option3 int option4 float64 } func (p *Option) printOpt() { println(p.option1, p.option2, p.option3, p.option4) } /** * @Description: 第一种最复杂，最臃肿的方式进行设置 * @param option1 * @param option2 * @return *Option * @return error */ func newDefaultOption(option1 string, option2 string) (*Option, error) { return \u0026amp;Option{option1, option2, 1, 1.0}, nil } func new2Option(option1 string, option2 string, option3 int) (*Option, error) { return \u0026amp;Option{option1, option2, option3, 1.0}, nil } func new3Option(option1 string, option2 string, option4 float64) (*Option, error) { return \u0026amp;Option{option1, option2, 1, option4}, nil } func new4Option(option1 string, option2 string, option3 int, option4 float64) (*Option, error) { return \u0026amp;Option{option1, option2, option3, option4}, nil } /** * @Description: 第二种，使用两个结构体，一个传固定参数，一个传可选参数 */ type Config struct { option1 string option2 string configs *Configs } type Configs struct { option3 int option4 float64 } func NewConfig(option1 string, option2 string, configs *Configs) (*Config, error) { return \u0026amp;Config{option1, option2, configs}, nil } /** * @Description: 第三种，使用builder建造者模式 */ type OptionBuilder struct { Option err error } /** * @Description: 显式的将interface声明为Void */ type Void interface{} /** * @Description: 实现一个指针赋值的函数 * @param void * @param value */ func SetValue(void Void, value interface{}) { pvoid := reflect.Indirect(reflect.ValueOf(void)) pvoid.Set(reflect.ValueOf(value)) } func (b *OptionBuilder) setOption(option Void, value interface{}) { if b.err == nil { SetValue(option, value) } } func (b *OptionBuilder) Create(option1 string, option2 string) *OptionBuilder { b.setOption(\u0026amp;b.Option.option1, option1) b.setOption(\u0026amp;b.Option.option2, option2) return b } func (b *OptionBuilder) WithOption3(option3 int) *OptionBuilder { b.setOption(\u0026amp;b.Option.option3, option3) return b } func (b *OptionBuilder) WithOption4(option4 float64) *OptionBuilder { b.setOption(\u0026amp;b.Option.option4, option4) return b } func (b *OptionBuilder) Build() (Option, error) { return b.Option, b.err } /** * @Description: 第四种，使用Functional Options * @param *Option */ type Setting func(*Option) func Option1(op string) Setting { return func(option *Option) { option.option1 = op } } func Option2(op string) Setting { return func(option *Option) { option.option2 = op } } func Option3(op int) Setting { return func(option *Option) { option.option3 = op } } func Option4(op float64) Setting { return func(option *Option) { option.option4 = op } } func NewSetting(options ...func(*Option)) (*Option, error) { opt := Option{} for _, option := range options { option(\u0026amp;opt) } return \u0026amp;opt, nil } /** * @Description: * 1.c语言使用返回值+errno的方式来进行异常处理，后来又使用函数参数，通过入参和出参来标识 * 2.java语言使用try-catch-finally的方式来进行检查 */ func check_origin(a []int, b []int, c int) ([]int, error) { if len(a) != len(b) { return nil, errors.New(\u0026#34;len of a and len of b not equal\u0026#34;) } result := make([]int, len(a)) for i := 0; i \u0026lt; len(a); i++ { res, err := add_and_compare(a[i], b[i], c) if err != nil { return nil, err } else { result[i] = res } } return result, nil } func add_and_compare(a int, b int, c int) (n int, err error) { if a+b \u0026gt;= c { return a + b, nil } else { return a + b, errors.New(\u0026#34;a+b not bigger than c\u0026#34;) } } type Compares struct { V1 int V2 int V3 int V4 int V5 int err error } /** * @Description: 我们需要将这个函数进行改进 * @receiver c * @param a * @param b * @return error */ func (c *Compares) exception_handler1(a []int, b []int) error { if _, err := check_origin(a, b, c.V1); err != nil { return err } if _, err := check_origin(a, b, c.V2); err != nil { return err } if _, err := check_origin(a, b, c.V3); err != nil { return err } if _, err := check_origin(a, b, c.V4); err != nil { return err } if _, err := check_origin(a, b, c.V5); err != nil { return err } return nil } /** * @Description: 通过函数式编程来改进 * @param a * @param b * @param c.V1 */ func (c *Compares) exception_handler2(a []int, b []int) error { var err error check := func(a []int, b []int, data int) { if err != nil { return } _, err = check_origin(a, b, data) } check(a, b, c.V1) check(a, b, c.V2) check(a, b, c.V3) check(a, b, c.V4) check(a, b, c.V5) if err != nil { return err } return nil } /** * @Description: use struct handler exception */ type Check struct { err error } func (check *Check) check(a []int, b []int, c int) { if check.err == nil { _, check.err = check_origin(a, b, c) } } func (c *Compares) exception_handler3(a []int, b []int) error { check := Check{} check.check(a, b, c.V1) check.check(a, b, c.V2) check.check(a, b, c.V3) check.check(a, b, c.V4) check.check(a, b, c.V5) if check.err != nil { return check.err } return nil } /** * @Description: 利用流式编程实现 * @receiver c * @param a * @param b * @param m */ func (c *Compares) check(a []int, b []int, m int) { if c.err == nil { _, c.err = check_origin(a, b, m) } } func (c *Compares) checkV1(a []int, b []int) *Compares { c.check(a, b, c.V1) return c } func (c *Compares) checkV2(a []int, b []int) *Compares { c.check(a, b, c.V2) return c } func (c *Compares) checkV3(a []int, b []int) *Compares { c.check(a, b, c.V3) return c } func (c *Compares) checkV4(a []int, b []int) *Compares { c.check(a, b, c.V4) return c } func (c *Compares) checkV5(a []int, b []int) *Compares { c.check(a, b, c.V5) return c } func (c *Compares) exception_handler4(a []int, b []int) error { c.checkV1(a, b).checkV2(a, b).checkV3(a, b).checkV4(a, b).checkV5(a, b) if c.err != nil { return _errors.Wrap(c.err, \u0026#34; !!chech faild\u0026#34;) } return nil } func re_compile(data string, expr string) string { reg, err := regexp.Compile(expr) if err == nil { return reg.FindString(data) } return \u0026#34;\u0026#34; } func writeBuffer() { write_buffer := bufio.NewWriter(os.Stdout) fmt.Fprint(write_buffer, \u0026#34;hello\u0026#34;) fmt.Fprint(write_buffer, \u0026#34;gogogog\u0026#34;) write_buffer.Flush() } func readBuffer() { str_reader := strings.NewReader(\u0026#34;buffer reader test\u0026#34;) bufio_reader := bufio.NewReader(str_reader) //peek 只读不取 data, _ := bufio_reader.Peek(10) println(string(data)) //打印，读到的内容 println(bufio_reader.Buffered()) //显示缓存中的直字节数 //readString 从缓存中读取 first_black, _ := bufio_reader.ReadString(\u0026#39; \u0026#39;) println(first_black) //打印，读到的内容 println(bufio_reader.Buffered()) //显示缓存中的直字节数 //Read指定从缓存中读取固定的字节数 num_bytes := make([]byte, 6) n_bytes, err := bufio_reader.Read(num_bytes) println(n_bytes) println(num_bytes) println(err) } func atomic_plus(l *uint32, r uint32) { atomic.AddUint32(l, r) } func atomic_sub(l *uint32, r uint32) { atomic.AddUint32(l, ^uint32(r-1)) } var bytePool = sync.Pool{ New: func() interface{} { b := make([]byte, 1024) return \u0026amp;b }, } func StringBuilder(p []string, cap int) string { var b strings.Builder l := len(p) b.Grow(cap) for i := 0; i \u0026lt; l; i++ { b.WriteString(p[i]) } return b.String() } func download(url string, i int, wg *sync.WaitGroup) { println(\u0026#34;http://\u0026#34; + url + \u0026#34;/\u0026#34; + strconv.Itoa(i)) time.Sleep(time.Nanosecond) wg.Done() println(\u0026#34;done\u0026#34;, strconv.Itoa(i)) } func (p *Persion) printPersion() { fmt.Printf(\u0026#34;Name=%s,Sex=%s,Age=%d\\n\u0026#34;, p.Name, p.Sex, p.Age) } type Persion struct { Name string Sex string Age int } type data struct { } func printStr(p stringable) { println(p.toString()) } type Country struct { Name string } func (c Country) toString() string { return \u0026#34;Country Name = \u0026#34; + c.Name } type City struct { Name string } func (c City) toString() string { return \u0026#34;City Name = \u0026#34; + c.Name } type stringable interface { toString() string } ","date":"2021-02-19","img":"","permalink":"/posts/note/golang%E5%B0%8F%E8%AE%B0/","series":null,"tags":["go"],"title":"go语言小记"},{"categories":["NLP"],"content":"NLP概览 什么是NLP 自然语言处理,是探讨如何处理及运用自然语言\n自然语言认知,是让电脑明白人类的语言\n自然语言处理主要包括:文本分析,信息检索,词性标注,问答系统QA\nNLP技术 词法分析\n- 分词技术 - 词性标注part-of-speech tagging - 命名实体识别NER(识别出3大类和7小类主要用于信息提取,QA,句法分析,机翻元数据标注) 实体边界识别 基于规则和词典进行识别(字典大小,新词?) 基于统计的方法 \u0026gt;隐马尔科夫模型HMM \u0026gt;较大熵ME \u0026gt;支持向量机SVM \u0026gt;条件随机场CRF 确定实体类别(英文,中文需要先分词) - 词义消歧 句法分析\n语义分析\n常见模型 传统感知机模型\nBP神经网络:前馈神经网络(反向传播算法),是现代神经网络的基础\n输入层:数据模型的输入,也就是说我们要传入到模型中的数据\n隐藏层:用于处理数据,并将处理的结果传递给输出层\n输出层:经过隐藏层的计算过后输出的模型内容,分类信息,或者是模型的最终参数\n训练过程概述:\n正向传播:网络初始化(定义网络参数),隐藏层的输出,输出层的输出\n误差计算:通过误差计算的公式,计算出误差\n反向传播:通过计算的误差,从输出层向后传播,并在过程中更新权重参数\n偏置更新:通过计算的误差,更新隐藏层到输出层,输入层到隐藏层的权重参数\n特点:\n可以通过逐层信息传递到最后的输出\n沿着一条直线计算,直到最后一层,求出计算结果\n包含输入层,输出层和隐藏层,目的是实现输入到输出的映射\n一般包含多层,并且层与层之间是全链接的不会出现同层和跨层连接\nCNN:是一种前馈神经网络,包括卷积层(convolutional)和池化层(pooling layer)\nRNN:循环神经网络是一种节点定向连接成环的人工神经网络,这种网络的内部状态可以动态的展示时序行为(短文本)\n特点:记忆特性;接受两个参数W和当前时间的特征;参数共享(确保每一步都在做相同的事)\n网络结构和BP神经网络的对比:\nRNN的类型:\none to one:适合用于分类任务\none to many:文本生成,音乐生成\nmany to one:多分类任务\nmany to many(不同维度):翻译任务\nmany to many(同维度):命名实体识别\nLSTM:长短期记忆网络,是一种时间递归神经网络.适合于处理和预测时间序列中间隔和延迟相对较长的重要事件(长文本)\n在普通的RNN中增加了一种由门控制的保存单元状态的结构:c\n通过遗忘门,输出门,输入门\nGRU\n只要更新门和重置门,没有隐藏层(可能不太关注时序的各种关系???我不太懂)\n双向循环神经网络:\n特点:\n每个时刻有两个隐藏层\n一个Forward Layer;另一个Backward Layer\n向前传播和向后传播的参数是独立的\n##　梯度消失和梯度爆炸\n在训练RNN中最常见的问题\n解决方法:\n选择合适的激活函数\nReLu函数(最常使用)\nSigmod函数和Tanh函数(这两个的导数在大部分区域很小,容易产生梯度消散)\n选择合适的参数初始化方法不能设置为0\n权重参数=np.random.randn(w的shape)*0.01(适用于小任务,解决参数对称)\n权重参数=np.random.randn(w的shape)*np.sqrt(1/(上一层的神经元数))(主要适用于ReLu激活函数,可以缓解梯度消散)\n使用权重参数正则化\n使用BatchNormailzation\n通过规范化的操作将输出信号x规范化到均值为0,方差为1保证网络的稳定性(把偏离的参数规范到高斯分布上)\n可以加大神经网络的训练速度\n提高训练的稳定性\n缓解梯度抱着和梯度消散的问题\n使用残差网络\n在神经网络中加入以下结构:\n通过跨层连接,使得快速下降的参数能得到缓解,让神经网络的深度大大提高,同时解决了梯度消失的问题\n使用梯度裁剪\n强制的让我们的梯度变小\n算法:$if ||g||\u0026gt;v ;then g\u0026lt;\u0026ndash; gv/(||g||)$\n在可视化的层面上将,就是让我们的导数不去跨越面,温和的梯度下降\n隐马尔可夫模型实现命名实体识别 马尔科夫过程 马尔科夫过程(Markov process)是一类随机过程\n在已知目前状态(现在)的条件下,它未来的演变(将来)不依赖于它以往的演变(过去).主要研究一个系统的状态及其转移的理论.他是通过对不同状态的初始概率以及状态的转移概率的研究,来确定状态的变化趋势,从而达到预测未来的目的\n马尔科夫链(Markov chain) 是指具有马尔科夫性质的离散事件随机过程,即时间和状态参数都是离散的马尔科夫过程,是最简单的马尔科夫过程 隐马尔可夫模型(Hidden Markov Model,HMM) 一种统计分析模型,是马尔科夫链的一种,它的状态不能被直接观察到,但能通过观测向量序列观察到,每个观测向量都是通过某些概率密度分布变现为个各种状态,每一个观测向量是由一个具有响应概率密度分布的状态序列产生\n是结构最简单的动态贝叶斯网(一种有向图模型),主要用于时序数据建模(语音识别,自然语言处理)\n隐马尔可夫模型由五个要素组成,其中两个状态集合(N.M),三个概率矩阵(A.B,π)\nN:表示模型中的状态数,状态之间可以相互转移\nM:表示每个状态不同的观察符号,即输出字符的个数\nA:状态转移概率\nB:观察符号在各个状态下的概率分布\nπ:表示初始状态分布\n隐马尔可夫模型的输入和输出\n输入:HMMs的五元组(N,M,A,B,π)\n输出:一个观察符号的序列,这个序列的每个元素都是M中的元素\n使用隐马尔科夫模型实现命名实体识别 训练:通过语料进行训练,输出概率用于NE识别,这当中用了大量的贝叶斯\nNE识别:给定各种状态下不同分词的概率以及完成人工词性标注的句子求出词性标注概率最大的状态\n规则修正:对于一些特殊名词的标注进行规则修正\n标注转换:通过序列处理把实现NE标注多个词复合,求得整个序列串概率最大的标注方案\n语料 语料库 语言材料.语料是语言学研究的内容.语料是构成语料库的基本单元\n语料库中存放的是在语言的实际使用中真实出现的语言材料\n语料库是以电子计算机为载体承载语言知识的基础资源\n真实语料需要经过加工(分析和处理),才能成为有用的资源\n语料库的种类 异质\n同质\n系统\n专用\n获取途径 爬虫\n平台\n语料的处理 获取语料\n格式化文本\n特征工程\nNLP中的语言模型 语言模型是自然语言处理中的一个利器,是NLP领域一个基本又重要的任务.它的主要更能是计算一个词语序列构成一个句子的概率,或者说计算一个词语序列的联合概率,这可以用来判断一句话出现的概率高不高,是否符合我们的表达习惯,这句话是否正确\n概率语言模型 预测字符串概率,考虑动机,考虑计算方式\nUnigram models(一元文法统计模型)\nN-gram 语言模型(N元模型)\n一元文法统计模型 p(s) = p(w1)*p(w2)*p(w3)*p(w4)*p(w5)*p(w6)*p(w7)\n我们假设每个词都条件无关\n二元文法统计模型 p(s) = p(w1|)*p(w2|w1)p(w3|w2)\u0026hellip;*p(|wn)\n二元语言模型可以比一元语言模型更考虑到两个词之间的关系信息\nN元模型 $P( w1,w2,\u0026hellip;,w_m) = i\u0026hellip;m() P(w_i|w1,\u0026hellip;,w_(i-1)) = i\u0026hellip;m() P(w_i|w_(i-n+1),\u0026hellip;,w_(i-1))$\n注: n大于3时基本无法处理,参数空间太大.另外它不能表示词与词之间的关联性\n词向量(Word embedding) 即词嵌入,是自然语言处理中的一组语言建模和特征学习技术的统称,其中来自词汇表的单词或短语被映射到实数的向量\nWord2vec 是为一群用来产生词向量的相关模型.这些模型为浅而双层的神经网络,用来训练以重新构建语言学之词文本\nCBOW CBOW模型由输入层,映射层,输出层共同构成\nCBOW所构建的模型结构实际上是一个二叉树结构,应用到Word2vec中被称为Hierarchical Softmax\nSkip-gram Skip-Gram模型由输入层,映射层,输出层共同构成\nSkip-Gram所构建的模型结构实际上是一个二叉树结构,并且刚好和CBOW模型相反\n文本处理方法 数据清洗(去掉无意义的标签,url,符号等)\n分词,大小写转换,添加句首句尾,词性标注\n统计词频,抽取文本个特征,特征选择,计算特征权重,归一化\n划分训练集,测试集\n","date":"2020-10-22","img":"","permalink":"/posts/nlp/nlp%E5%9F%BA%E7%A1%80/","series":["NLP"],"tags":["NLP"],"title":"NLP基础 "},{"categories":["Java"],"content":"Servlet HTTP协议 是客户端与服务器通信的一种方式\n参考链接 request: 请求行 请求头 请求体 response: 响应行 响应头 响应体 Get: GET用于信息获取，而且应该是安全的和幂等的\n带上数据,在URL上面拼接\nwww.baidu.com name = zhanshan\nage = 18\nurl:www.baidu.com?name = zhanshan\u0026amp;age = 18\nurl可见\n传输方式\nHTTP header\n设计目的\n获取数据\n具有安全隐患,GET方法不会改变服务器端数据，所以不会产生副作用\nGET请求返回的内容可以被浏览器缓存起来\nPost: 以流的方式传输,数据无限制\nurl不可见\n传输方式\nHTTP body\n设计目的\n发送数据\n用户可能会提交一些错误的数据\n浏览器不会缓存POST请求返回的内容\n####　幂等（idempotent、idempotence）是一个数学或计算机学概念，常见于抽象代数中。\n幂等有以下几种定义：\n​\t对于单目运算，如果一个运算对于在范围内的所有的一个数多次进行该运算所得的结果和进行一次该运算所得的结果是一样的，那么我们就称该运算是幂等的。 比如绝对值运算就是一个例子，在实数集中，有abs(a) = abs(abs(a)) 。\n​\t对于双目运算，则要求当参与运算的两个值是等值的情况下，如果满足运算结果与参与运算的两个值相等，则称该运算幂等，如求两个数的最大值的函数，有在实数集中幂等，即max(x,x) = x 。\n看完上述解释后，应该可以理解GET幂等的含义了。\n幂等：如果目标是当用户打开一个链接时，他可以确信从自身的角度来看没有改变资源即可。\n非幂等：以新闻网站为例，读者对新闻发表自己的评论应该通过POST实现，因为在评论提交后站点的资源已经不同了，或者说资源被修改了。\nServletConfig 写在xml文件中,一个servlet可以有多个配置信息{以servlet为单位}，同时也可以设置全局配置信息，因为可能会部署很多个servlet容器。\n\u0026lt;servlet\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;data4\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;value4\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;!--配置信息--\u0026gt; \u0026lt;servlet-name\u0026gt;demo\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;main.netjava.com.servlet.example.demo\u0026lt;/servlet-class\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;!--全局：--\u0026gt; \u0026lt;/context-param\u0026gt; web.xml 1.servlet声明\nservlet:配置servlet\nservlet-name：逻辑名称\nservlet-class：逻辑名称对应的servlet的实际地址\nservlet_mapping:servlet的对外映射\nurl-pattern:对外映射的路径{支持模糊匹配}\nservlet支持多个url-pattern对应同一个Servlet\nservlet的优先级匹配规则：\n​\t精确路径匹配，完全匹配\n​\t最长路径匹配\n​\t扩展名匹配\n​\tdefault匹配\n​\nload-on-startup 改变Servlet的默认初始化时间\n\u0026lt;load-on-startup\u0026gt;0 \u0026lt;load-on-startup\u0026gt;\n当 它\u0026gt;=0,Servlet启动时就加载相应的操作\n当其\u0026lt;0,Servlet 在客户端第一次请求servlet才加载\n当有多个servlet时，数字越高，优先级越高\n2.servlet的配置\nservletconfig：配置信息\nservlet下的init-param：\nparam-name：配置的key\nparam-value：配置的value\n错误页面配置 \u0026lt;error-page\u0026gt; \u0026lt;error-code\u0026gt;404\u0026lt;/error-code\u0026gt; \u0026lt;location\u0026gt;/404.html\u0026lt;/location\u0026gt; \u0026lt;/error-page\u0026gt; 欢迎页面 \u0026lt;welcome-file-list\u0026gt; \u0026lt;!--可以加很多个吗、，顺序加载一个--\u0026gt; \u0026lt;welcome-file\u0026gt;postget.html\u0026lt;/welcome-file\u0026gt; \u0026lt;/welcome-file-list\u0026gt; MIME类型映射 \u0026lt;mime-mapping\u0026gt;:定义扩展文件名隐射类型{打开文件还是下载文件} \u0026lt;extension\u0026gt;:浏览器所要解析的文件的扩展名 \u0026lt;mime-type\u0026gt;:指定映射类型 \u0026lt;/mime-mapping\u0026gt; Cookie和 Session Cookie 保存浏览器客户端\n过程：浏览器提出HTTP请求，发送给服务器后，服务器生成Cookie包含在响应头中发送给浏览器，最后浏览器会把Cookie保存起来\n通过setMaxAge设置cookie有效期 如果不设置，cookie会在会话结束后在内存中被销毁\nSession:保存在服务器端\n当浏览器发起HTTP请求时，服务器会把发送过来的数据进行逻辑处理，变成Session，并且把Session id包含在Cookie中，发送给浏览器\n当下一次访问时，浏览器会根据cookie中的Session信息返回特定的http响应\n通过setMaxInactiveInterval设置过期时间 通过invalidata使Session失效 通过ServletContext的动态属性方法，共享数据 Servlet的请求转发{RequestDispatcher} forward:将当前的request和response对象交给指定的web组件处理\n必须的步骤：转发对象：\n通过HttpServletRequest获取\n通过ServletContext获取\n###ServletContext\nServlet 上下文\n每个web工程都只有一个ServletContext对象。 说白了也就是不管在哪个servlet里面，获取到的这个类的对象都是同一个。\n###如何得到对象\n//1. 获取对象 ServletContext context = getServletContext(); 有什么作用 获取全局配置参数\n获取web工程中的资源\n存取数据，servlet间共享数据 域对象\n####.可以获取全局配置参数\n\u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;address\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;绵阳\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; 获取全局参数\nServletContext context = getServletContext(); String address = context.getInitParameter(\u0026#34;address\u0026#34;); System.out.println(\u0026#34;这是获取的数据:\u0026#34;+address) ####. 可以获取Web应用中的资源\n获取资源在tomcat里面的绝对路径 先得到路径，然后自己new InpuStream\ncontext.getRealPath(\u0026#34;\u0026#34;) //这里得到的是项目在tomcat里面的根目录。 D:\\tomcat\\apache-tomcat-7.0.52\\apache-tomcat-7.0.52\\wtpwebapps\\Demo03\\ String path = context.getRealPath(\u0026#34;file/config.properties\u0026#34;); D:\\tomcat\\apache-tomcat-7.0.52\\apache-tomcat-7.0.52\\wtpwebapps\\Demo03\\file\\config.properties getResourceAsStream 获取资源 流对象\n直接给相对的路径，然后获取流对象。\n//获取web工程下的资源,转化为流对象,前面隐藏当前工程的根目录 //在我们使用相对路径时,我们应该注意,有没有参照物 //这里的参照物是tomcat里面的根目录 通过classloader去获取web工程下的资源 ServletContext的目录是.tomcat里面的根目录\nClassLoder 的路径是根目录下的WEB-INF下的classer目录\n使用ServletContext存取数据。 定义一个登陆的html页面， 定义一个form表单\n定义一个Servlet，名为LoginServlet\n针对成功或者失败，进行判断，然后跳转到不一样的网页\n###ServletContext存取值分析\n##细节：\n\u0026lt;!-- A路径： Servlet的路径 http://localhost:8080/Demo4/login B路径： 当前这个html的路径： http://localhost:8080/Demo4/login.html --\u0026gt; ​\n\u0026lt;form action=\u0026#34;login\u0026#34; method=\u0026#34;get\u0026#34;\u0026gt; 账号:\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34;/\u0026gt;\u0026lt;br\u0026gt; 密码:\u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;password\u0026#34;/\u0026gt;\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;登录\u0026#34;/\u0026gt; \u0026lt;/form\u0026gt; ###ServletContext 何时创建， 何时销毁?\n服务器启动的时候，会为托管的每一个web应用程序，创建一个ServletContext对象\n从服务器移除托管，或者是关闭服务器。\nServletContext 的作用范围 只要在这个项目里面，都可以取。 只要同一个项目。 A项目 存， 在B项目取，是取不到的？ ServletContext对象不同。\n","date":"2020-10-22","img":"","permalink":"/posts/java/servlet1/","series":["Java"],"tags":["Java"],"title":"Servlet1"},{"categories":["Java"],"content":"Cookie和Session 会话：浏览器发出http请求。服务器接受，对请求进行响应，浏览器接受http响应\nCookie 把会话数据保存在浏览器客户端\n服务器第一次访问时，服务端生成cookie，并且把这个cookie通过响应，发送给客户端，客户端把cookie保存下来，以便在最近的下一次访问中使用\n缺点\nCookie有大小和数量的限制\n明文传递有风险\n//创建Cookie对象 Cookie userNameCookie = new Cookie(\u0026#34;userName\u0026#34;,userName); Cookie userPasswordCookie = new Cookie(\u0026#34;userPassword\u0026#34;,userPassword); //返回给访问对象 resp.addCookie(userNameCookie); resp.addCookie(userPasswordCookie); /、对外部浏览器返回的响应头进行处理 Cookie[] cookies = req.getCookies(); if(cookies != null){ for(Cookie cookie:cookies){ if (cookie.getName().equals(\u0026#34;userName\u0026#34;)) { userName = cookie.getValue(); }else if (cookie.getName().equals(\u0026#34;userPassword\u0026#34;)) { userPassword = cookie.getValue(); } } } 例子一 显示最近访问的时间。 判断账号是否正确\n如果正确，则获取cookie。 但是得到的cookie是一个数组， 我们要从数组里面找到我们想要的对象。\n如果找到的对象为空，表明是第一次登录。那么要添加cookie\n如果找到的对象不为空， 表明不是第一次登录。\nif(\u0026#34;admin\u0026#34;.equals(userName) \u0026amp;\u0026amp; \u0026#34;123\u0026#34;.equals(password)){ //获取cookie last-name --- \u0026gt; Cookie [] cookies = request.getCookies(); //从数组里面找出我们想要的cookie Cookie cookie = CookieUtil.findCookie(cookies, \u0026#34;last\u0026#34;); //是第一次登录，没有cookie if(cookie == null){ Cookie c = new Cookie(\u0026#34;last\u0026#34;, System.currentTimeMillis()+\u0026#34;\u0026#34;); c.setMaxAge(60*60); //一个小时 response.addCookie(c); response.getWriter().write(\u0026#34;欢迎您, \u0026#34;+userName); }else{ //1. 去以前的cookie第二次登录，有cookie long lastVisitTime = Long.parseLong(cookie.getValue()); //2. 输出到界面， response.getWriter().write(\u0026#34;欢迎您, \u0026#34;+userName +\u0026#34;,上次来访时间是：\u0026#34;+new Date(lastVisitTime)); //3. 重置登录的时间 cookie.setValue(System.currentTimeMillis()+\u0026#34;\u0026#34;); response.addCookie(cookie); } }else{ response.getWriter().write(\u0026#34;登陆失败 \u0026#34;); } 例子二： 显示商品浏览记录。 准备工作 拷贝基础课第一天的 htmll原型文件，到工程的WebContent里面。\n在WebContent目录下新建一个jsp文件， product_list.jsp, 然后拷贝原来product_list.html的内容到jsp里面。 建好之后，jsp里面的所有ISO-8859-1 改成 UTF-8\n拷贝html标签的所有内容。 替换jsp的html标签即可\n修改product_info.htm里面的手机数码超链接地址\n\u0026lt;li class=\u0026quot;active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;product_list.jsp\u0026quot;\u0026gt;手机数码\u0026lt;span class=\u0026quot;sr-only\u0026quot;\u0026gt;(current)\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n修改首页(index.html)顶部的手机数码跳转的位置为 product_list.jsp \u0026lt;li class=\u0026quot;active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;product_list.jsp\u0026quot;\u0026gt;手机数码\u0026lt;span class=\u0026quot;sr-only\u0026quot;\u0026gt;(current)\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n#####分析\n显示浏览记录 Cookie[] cookies = request.getCookies(); Cookie cookie = CookieUtil.findCookie(cookies,\u0026#34;history\u0026#34;); //如果cookie是空的,表img01明没有浏览任何商品 if(cookie == null){ out.println(\u0026#34;你还没有浏览任何商品\u0026#34;); }else{ //不是空,表明有浏览记录 String[] ids = cookie,getValue().split(\u0026#34;#\u0026#34;); for(String id:ids){ //输出浏览记录 } } 清除浏览记录 其实就是清除Cookie， 删除cookie是没有什么delete方法的。只有设置maxAge 为0 。\nCookie cookie = new Cookie(\u0026#34;history\u0026#34;,\u0026#34;\u0026#34;); cookie.setMaxAge(0); //设置立即删除 cookie.setPath(\u0026#34;/CookieDemo02\u0026#34;); response.addCookie(cookie); Cookie总结 服务器给客户端发送过来的一小份数据，并且存放在客户端上。\n获取cookie， 添加cookie\nrequest.getCookie();\nresponse.addCookie();\nCookie分类\n会话Cookie ​\t默认情况下，关闭了浏览器，那么cookie就会消失。\n2)持久Cookie\n​\t在一定时间内，都有效，并且会保存在客户端上。\n​\tcookie.setMaxAge(0); //设置立即删除\n​\tcookie.setMaxAge(100); //100 秒\nCookie的安全问题。\n由于Cookie会保存在客户端上，所以有安全隐患问题。 还有一个问题， Cookie的大小与个数有限制。 为了解决这个问题 \u0026mdash;\u0026gt; Session .\nHttpSession 把会话数据保存在服务器端\n客户端把请求等发送给服务器，服务器根据这个请求，生成一个session，并且，把这个Session的id处理通过cookie发送给客户端，下一次客户端访问时，就可以找到这个Session\n会话 ， Session是基于Cookie的一种会话机制。 Cookie是服务器返回一小份数据给客户端，并且存放在客户端上。 Session是，数据存放在服务器端。\n常用API //得到会话ID String id = session.getId(); //存值 session.setAttribute(name, value); //取值 session.getAttribute(name); //移除值 session.removeAttribute(name); Session何时创建 ， 何时销毁?\n创建\n如果有在servlet里面调用了 request.getSession()\n销毁 session 是存放在服务器的内存中的一份数据。 当然可以持久化. Redis . 即使关了浏览器，session也不会销毁。\n销毁方式\n关闭服务器 session会话时间过期。 有效期过了，默认有效期： 30分钟。 Session的优先级\n​\tsetMaxInaxtiveInterval　＞　部署描述符配置\n​\tinvalidate使Session失效\n//创建session HttpSession session = req.getSession(); //把表单数据放入session中 String sessioname = (String) session.getAttribute(\u0026#34;userName\u0026#34;); //查看一下二次登录的session if(sessioname != null){ System.out.println(\u0026#34;second Session:\u0026#34;); } 例子三： 简单购物车。 CartServlet 代码 response.setContentType(\u0026#34;text/html;charset=utf-8\u0026#34;); //1. 获取要添加到购物车的商品id int id = Integer.parseInt(request.getParameter(\u0026#34;id\u0026#34;)); // 0 - 1- 2 -3 -4 String [] names = {\u0026#34;Iphone7\u0026#34;,\u0026#34;小米6\u0026#34;,\u0026#34;三星Note8\u0026#34;,\u0026#34;魅族7\u0026#34; , \u0026#34;华为9\u0026#34;}; //取到id对应的商品名称 String name = names[id]; //2. 获取购物车存放东西的session Map\u0026lt;String , Integer\u0026gt; iphoen7 3 //把一个map对象存放到session里面去，并且保证只存一次。 Map\u0026lt;String, Integer\u0026gt; map = (Map\u0026lt;String, Integer\u0026gt;) request.getSession().getAttribute(\u0026#34;cart\u0026#34;); //session里面没有存放过任何东西。 if(map == null){ map = new LinkedHashMap\u0026lt;String , Integer\u0026gt;(); request.getSession().setAttribute(\u0026#34;cart\u0026#34;, map); } //3. 判断购物车里面有没有该商品 if(map.containsKey(name)){ //在原来的值基础上 + 1 map.put(name, map.get(name) + 1 ); }else{ //没有购买过该商品，当前数量为1 。 map.put(name, 1); } //4. 输出界面。（跳转） response.getWriter().write(\u0026#34;\u0026lt;a href=\u0026#39;product_list.jsp\u0026#39;\u0026gt;\u0026lt;h3\u0026gt;继续购物\u0026lt;/h3\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt;\u0026#34;); response.getWriter().write(\u0026#34;\u0026lt;a href=\u0026#39;cart.jsp\u0026#39;\u0026gt;\u0026lt;h3\u0026gt;去购物车结算\u0026lt;/h3\u0026gt;\u0026lt;/a\u0026gt;\u0026#34;); 移除Session中的元素 //强制干掉会话，里面存放的任何数据就都没有了。 session.invalidate(); //从session中移除某一个数据 //session.removeAttribute(\u0026#34;cart\u0026#34;); 请求转发 定义：将当前的request和response 对象交给指定的web组件进行处理\n注意：\n请求转发时，浏览器url不会改变\n地址上显示的是请求servlet的地址。 返回200 ok\n请求次数只有一次， 因为是服务器内部帮客户端执行了后续的工作。\n只能跳转自己项目的资源路径 。\n效率上稍微高一点，因为只执行一次请求。\n可以使用上一次的request对象。\n//请求转发的写法：\ninclude{RequestDispatcher} request.getRequestDispatcher(\u0026quot;login_success.html\u0026quot;).forward(request, response);\n1) 通过HttpServletRequest 2) 通过ServletContext 使用forward //3中请求转发的方式 RequestDispatcher rd = req.getRequestDispatcher(\u0026#34;/ServletForwardExample/*\u0026#34;);//1 rd = this.getServletContext().getNamedDispatcher(\u0026#34;servletForwardExample\u0026#34;);//2 rd = this.getServletContext().getRequestDispatcher(\u0026#34;/servletForwardExample/*\u0026#34;);//3 rd.forward(req,resp); 请求重定向 sendRedirect\n通过response对象发送给浏览器一个新的地址，让其重新请求（两次请求，两次响应）\nex：网页登录跳转：\n浏览器发出登录请求\n服务器请求转发进行登录处理\n服务器把请求响应发送给客户端，同事包含另一个url的响应信息\n浏览器接收到响应信息，得到另一个url\n随即，浏览器向服务器发出跳转请求\n服务器返回跳转结果\nresp.sendRedirect(\u0026quot;/SendRedirectExample/*\u0026quot;);\n注：转发和重定向的区别\n转发的浏览器地址栏不会发生变化，重定向则会\n请求转发只能在同一个web应用下进行转发。重定向可以跨web资源和地址\n请求转发一次请求一次响应。重定向是两次转发，两次响应\n过滤器和监听器 过滤源：请求和响应\n过滤规则：自己定义\n简单地说：过滤器会在请求发送给Servlet之前先对请求进行处理，\n如果响应要发送给浏览器也需要先经过过滤器\n应用场景：\n用户认证（验证用户是否有权限）\n编解码处理\n请求压缩\n过滤器的生命周期\ninit - 初始化（只运行一次）\ndoFilter - 进行过滤操作\ndestroy - 释放资源，销毁过滤器对象（只运行一次）\npublic class TestFilter implements Filter{ // 可以像servlet配置一样，对TestFilter的init传入FilterConfig filterConfig @Override public void init(FilterConfig filterConfig) throws ServletException {} @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException {} @Override public void destroy() {} } filter配置：\n\u0026lt;filter\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;filterParam\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;euraxluo\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;filter-name\u0026gt;testFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;com.controller.filter.TestFilter\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;testFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/testFilter/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; 在写doFilter时，参数\nServletRequest servletRequest, ServletResponse servletResponse\n，不能直接处理Servlet中的HttpServletRequest req, HttpServletResponse resp\n应该使用类型转换HttpServletRequest req = (HttpServletRequest)servletRequest; 通过过滤器验证登录的逻辑部分\n//通过判断是否有session来判断是否登录 HttpSession session = req.getSession(); if(session.getAttribute(\u0026#34;userName\u0026#34;)==null){ HttpServletResponse resp = (HttpServletResponse)servletResponse; resp.sendRedirect(\u0026#34;/GetPostServlet/*\u0026#34;); }else{ filterChain.doFilter(servletRequest,servletResponse); } 如果有多个filter，会根据在部署描述符中的先后顺序来决定过滤器的顺序\n在第一filter被调用时会产生filterchain传递给dofilter函数即，\ndofilter函数的FilterChain filterChain参数指的就是Filter链，\n再dofilter执行快结束时，会检查Filterchain，如果filterchain还有其他的filter，就会继续执行其他filter。如果没有了，就会执行跳转，把过滤后的请求给servlet。\nservlet返回响应时，也要经过filter链，并且顺序是反着的\n监听器{监听事件发生后，在事件发生前后能够做出相应处理的web应用组件} 事件源：我们需要监听的东西\n注册： 把监听器放在我们需要监听的地方\n通知：如果发生了我们监听的事件，就会通知\n最后监听到事件后，对其进行处理\nservlet中的注册不直接注册到事件，而是交给servlet，开发人员只需要配置部署描述符，servlet会自己注册到事件源\n监听器分类：\n监听应用程序环境：ServletContext\n1)ServletContextListener(对创建和销毁进行监听)\n2)ServletContextAttributeListener(对属性的增删改查监听)\n监听用户请求对象:ServletRequest\n1)ServletRequestListener(对创建和销毁进行监听)\n2)ServletRequestAttributeListener(对属性的增删改查监听)\n监听用户会话对象:HTTPSession\n1)HTTPSessionListener(对创建和销毁进行监听)\n2)HTTPSessionAttributeListener(对属性的增删改查监听)\n3)HTTPSessionActivationListener(对session持久化到磁盘和重新加载到JVM时监听)\n4)HTTPSessionBindingListenner(对调用Attribute和removeAttribute的方法监听)\n使用场景：\n应用统计（用户登录统计）\n任务触发\n业务需求\n监听器可能会有很多个，和过滤器一样，顺序由部署描述符中的部署顺序决定事件注册的顺序\neg：HTTPSessionAttributeListener，ServletContextListener，ServletRequestListener\npublic class TestListener implements HttpSessionAttributeListener, ServletContextListener, ServletRequestListener {} xml部署\n\u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;com.controller.listener.TestListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; 注：监听器和过滤器和servlet的启动顺序： 监听器\n过滤器\nServlet\nservlet 并发处理 先了解一下servlet的处理过程\n经常会出现多个客户端同事对一个servlet发起请求，\n我们的处理方式一般为：\n串行处理，对每个客户端的请求依次处理\n并发处理\n客户端发送请求给服务器，服务器的servlet容器将请求转发给调度器，由调度器在工作线程池中选取一个线程，把请求交个这个线程，但不关心这个请求的servlet。多个线程可以同时指向一个servlet。但是当线程池满了过后，下一个请求就必须排队，并且排队队列可以设置上限\n总结：单实例，多线程，线程不安全\n问题：怎么保证servlet的线程安全\n变量的线程安全\n参数变量本地化(局部变量不会线程共享)\n使用同步快synchronized(加锁处理，并且要尽量减小synchronized的范围)\n属性的线程安全\nServletContext线程不安全\nHTTPSession理论上线程安全，但是我们一般还是会做加锁处理\nServletRequest线程安全\n避免在Servlet中创建线程\n多个Servlet需要同时访问一个web应用（访问外部对象）应该做加锁处理\n尽量避免使用实例变量，如果必须使用实例变量，就要用同步的操作（控制同步的范围）\nsynchronized(this){ //代码块 } ","date":"2020-10-22","img":"","permalink":"/posts/java/servlet2/","series":["Java"],"tags":["Java"],"title":"Servlet2"},{"categories":["WebSocket"],"content":"WebSocket 一、概念 1.WebSocket 是HTTP协议的补充。使用的TCP协议建立连接\n2.HTML5是指一系列新API，新协议，WebSocket也是其中之一\n二、优点 1.WebSocket是持久化协议，每次通信只需要一次连接\n2.HTTP中一个request只能有一个response\n3.连接过程：进行握手时，使用http协议对服务器发起连接请求，并且升级为websocket协议，确定后服务器建立连接，并且继续使用Websocket\n三、作用 1.实现实时信息传递的其他方式\n​\t(1).ajax轮询：让浏览器隔个几秒就发送一次请求，询问服务器是否有新信息\n​\t(2).HTTP long poll：客户端发起连接后，如果没消息，就一直不返回Response给客户端。直到有消息才返回，返回完之后，客户端再次建立连接，周而复始。\n​\t(3).缺点：\n​\tajax轮询：需要服务器有很快的处理速度和资源。（速度）\n​\tlong poll：需要有很高的并发，也就是说同时接待客户的能力。（资源大小）\n2.服务器完成协议升级后（HTTP-\u0026gt;Websocket），服务端就可以主动推送信息给客户端啦\n3.整个通讯过程是建立在一次连接/状态中，避免了HTTP的非状态性，服务端会一直知道你的信息，直到你关闭请求\n四、特点 1.建立在 TCP 协议之上，服务器端的实现比较容易。\n2.与 HTTP 协议有着良好的兼容性。默认端口也是80和443，并且握手阶段采用 HTTP 协议，因此握手时不容易屏蔽，能通过各种 HTTP 代理服务器。\n3.数据格式比较轻量，性能开销小，通信高效。\n4.可以发送文本，也可以发送二进制数据。\n5.没有同源限制，客户端可以与任意服务器通信。\n6.协议标识符是ws（如果加密，则为wss），服务器网址就是 URL。\n五、客户端 1.创建WebSocket对象： var Socket = new WebSocket(url,[protocol])\nurl = 服务器地址，protocol是可接受的子协议\n2.属性： (1)Socket.readyState//表示连接状态：0：尚未连接，1：已经连接，2：连接正在关闭，3：连接已经关闭，或不能打开。\n(2)Socket.buffererdAmount//表示send()放在队列正在队列中等待传输\n3.事件： | 对象触发的程序 | 描述 |\n| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| Socket.onopen | 连接建立时触发 |\n| Socket.onmessage | 客户端接受服务端数据时触发 |\n| Socket.onerror | 通信错误时触发 |\n| Socket.onclose | 连接关闭时触发 |\n4.方法： | 方法 | 描述 |\n| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| Socket.send() | 使用连接程序发送数据 |\n| Socket.close() | 关闭连接 |\n5.实例： 客户端前端： \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;input type=\u0026#34;button\u0026#34; onclick=\u0026#34;online()\u0026#34; value=\u0026#34;连接！\u0026#34; /\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;script\u0026gt; //初始化一个WebSocket对象 var ws = new WebSocket(\u0026#34;wss://echo.websocket.org\u0026#34;); //建立WebSocket连接成功触发事件 ws.onopen = function online() { //js的事件写法 alert(\u0026#34;我是一个消息框！\u0026#34;) ws.send(\u0026#34;Hello WebSockets!\u0026#34;);//使用send发送数据 }; //接受服务端数据时触发的数据 ws.onmessage = function(evt) { var received_msg = evt.data; alert(\u0026#34;数据已接收...\u0026#34;); ws.close(); }; //断开WebSocket时触发的数据 ws.onclose = function(evt) { alert(\u0026#34;数据已接收...\u0026#34;); }; \u0026lt;/script\u0026gt; \u0026lt;/html\u0026gt; 六、服务器端 Node.js var ws = require(\u0026#39;nodejs-websocket\u0026#39;); console.log(\u0026#39;开始建立连接...\u0026#39;) ws.createServer(function (conn) { conn.on(\u0026#39;text\u0026#39;, function (str) { console.log(\u0026#39;收到的信息为:\u0026#39; + str) conn.sendText(str) }) conn.on(\u0026#39;close\u0026#39;, function (code, reason) { console.log(\u0026#39;关闭连接\u0026#39;, code, reason) }); conn.on(\u0026#39;error\u0026#39;, function (code, reason) { console.log(\u0026#39;异常关闭\u0026#39;, code, reason) }); }).listen(8888) console.log(\u0026#39;WebSocket建立完毕\u0026#39;); java 1.Spring\npublic interface WebSocketHandler { /** * 建立连接后触发的回调 */ void afterConnectionEstablished(WebSocketSession session) throws Exception; /** * 收到消息时触发的回调 */ void handleMessage(WebSocketSession session, WebSocketMessage\u0026lt;?\u0026gt; message) throws Exception; /** * 传输消息出错时触发的回调 */ void handleTransportError(WebSocketSession session, Throwable exception) throws Exception; /** * 断开连接后触发的回调 */ void afterConnectionClosed(WebSocketSession session, CloseStatus closeStatus) throws Exception; /** * 是否处理分片消息 */ boolean supportsPartialMessages(); } 2.javax.websocket\n// 收到消息触发事件 @OnMessage public void onMessage(String message, Session session) throws IOException, InterruptedException { ... } // 打开连接触发事件 @OnOpen public void onOpen(Session session, EndpointConfig config, @PathParam(\u0026#34;id\u0026#34;) String id) { ... } // 关闭连接触发事件 @OnClose public void onClose(Session session, CloseReason closeReason) { ... } // 传输消息错误触发事件 @OnError public void onError(Throwable error) { ... } 七、完整实例（环境：tomcat8，idea） 服务器端： /** * netstat -aon | findstr 1099 * taskkill -f -pid PID */ package servlet; import javax.websocket.*; import javax.websocket.server.ServerEndpoint; import java.io.IOException; import java.util.concurrent.CopyOnWriteArraySet; //指明websocket名字 @ServerEndpoint(\u0026#34;/chat\u0026#34;) public class WS { //通过SESSION发送数据 private Session session; //静态变量，用来记录当前在线连接数。应该把它设计成线程安全的。 private static int onlineCount = 0; //concurrent包的线程安全Set，用来存放每个客户端对应的MyWebSocket对象。若要实现服务端与单一客户端通信的话，可以使用Map来存放，其中Key可以为用户标识 private static CopyOnWriteArraySet\u0026lt;WS\u0026gt; webSocketSet = new CopyOnWriteArraySet\u0026lt;WS\u0026gt;(); /* * 连接建立成功调用的方法 * @param session */ @OnOpen public void onOpen(Session session){ this.session = session; webSocketSet.add(this); //加入set中 } /** * 收到客户端消息后调用的方法 * @param message 客户端发送过来的消息 * @param session 可选的参数 */ @OnMessage public void onMessage(String message, Session session) throws IOException { System.out.println(\u0026#34;来自客户端的消息:\u0026#34; + message); //群发消息 for(WS item: webSocketSet){ try { item.sendMessage(message); } catch (IOException e) { e.printStackTrace(); continue; } } } /** * 连接关闭调用的方法 */ @OnClose public void onClose(){ webSocketSet.remove(this); //从set中删除 } /** * 发生错误时调用 * @param session * @param error */ @OnError public void onError(Session session, Throwable error){ System.out.println(\u0026#34;发生错误\u0026#34;); error.printStackTrace(); } /* 这个方法与上面几个方法不一样。没有用注解，是根据自己需要添加的方法。 * @param message * @throws IOException */ public void sendMessage(String message) throws IOException { this.session.getAsyncRemote().sendText(message); } } 浏览器端： \u0026lt;%-- Created by IntelliJ IDEA. User: Euraxluo Date: 2018/7/30 Time: 14:19 To change this template use File | Settings | File Templates. --%\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;%@ page contentType=\u0026#34;text/html;charset=UTF-8\u0026#34; language=\u0026#34;java\u0026#34; %\u0026gt; \u0026lt;html doctype=\u0026#34;html\u0026#34;\u0026gt;\u0026lt;head\u0026gt; \u0026lt;meta http-equiv=\u0026#34;content-type\u0026#34; content=\u0026#34;text/html; charset=UTF-8\u0026#34;\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;chat\u0026lt;/title\u0026gt; \u0026lt;!-- 输入框--\u0026gt; \u0026lt;link href=\u0026#34;css/vendor/bootstrap/bootstrap.min.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;http://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;js/vendor/summernote/summernote.css\u0026#34;\u0026gt; \u0026lt;style\u0026gt; * { padding: 0; margin: 0; } body{ height: 100%; border:2px solid; border-radius:5px; background-image: url(\u0026#39;images/bkg.jpg\u0026#39;); scrollbar-face-color: #22beef; } ::-webkit-scrollbar-button{ background-color: #1ccdaa; } ::-webkit-scrollbar-track{ background-color: #1296db; } ::-webkit-scrollbar-thumb{ background-color: #22beef; } \u0026lt;!----\u0026gt; .welcome { color:#fff; margin-left: -1px; background-color: #2cc1f0; border-color: #4cae4c; width: 100%; height: 70%; border-radius:10px; font-size: 30px; } header{ border:2px solid #2a6496; border-radius:8px; height:80px; width: 100%; position: relative; overflow-y: auto; margin-top: 2%; padding: 5px; } \u0026lt;!----\u0026gt; .hist{ margin-bottom: 2px; margin-left: 1px; width: 100%; overflow-y: scroll; background-image: url(\u0026#34;images/bgk2.jpg\u0026#34;); } .hist span{ background-color: #11b4e7; } .hist li{ list-style:none; margin-left: 2px; margin-top: 5px; padding: 0px; float:bottom; padding-left: 5px; padding-right: 3px; display: table; overflow: auto; min-width: 100px; max-width: 100vw; word-break: break-all; word-wrap: break-word; min-height: 100px; border:2px solid #2a6496; border-radius: 5px; background-image: url(\u0026#39;images/bgk0.jpg\u0026#39;); } .but{ height: 30px; line-height: 35px; position: fixed; bottom: 180px; width: 100%; text-align: center; color: #fff; font-size: 14px; letter-spacing: 1px; background-color: #96e6f1; } .left{ text-align: center; vertical-align: middle; cursor: pointer; white-space: nowrap; color: #fff; background-color: #5cb85c; border-color: #4cae4c; padding: 6px 12px; font-size: 14px; line-height: 1.5; border-radius: 4px; height: 30px; float: left; display: inline-block; font-weight: 400; } .right{ text-align: center; vertical-align: middle; cursor: pointer; white-space: nowrap; color: #fff; background-color: #5cb85c; border-color: #4cae4c; float: right; display: inline-block; font-weight: 400; padding: 6px 12px; font-size: 14px; line-height: 1.5; border-radius: 4px; height: 30px; } .foot{ height: 180px; line-height: 35px; position: fixed; bottom: 0; width: 100%; color: #fff; font-size: 14px; letter-spacing: 1px; background-image: url(\u0026#39;images/bgk3.gif\u0026#39;); } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;header id=\u0026#34;top\u0026#34;\u0026gt; \u0026lt;button class=\u0026#34;welcome\u0026#34; onclick=\u0026#34;printme()\u0026#34;\u0026gt;\u0026lt;strong\u0026gt;Welcome\u0026lt;/strong\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;!--状态栏--\u0026gt; \u0026lt;strong style=\u0026#34;float: left\u0026#34;\u0026gt;状态：\u0026lt;/strong\u0026gt; \u0026lt;strong id=\u0026#34;message\u0026#34; \u0026gt;\u0026lt;/strong\u0026gt; \u0026lt;/header\u0026gt; \u0026lt;div style=\u0026#34;clear: both\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;historyMsg\u0026#34; class=\u0026#34;hist\u0026#34; \u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;but\u0026#34;\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;right\u0026#34; onclick=\u0026#34;send()\u0026#34;\u0026gt;\u0026lt;strong\u0026gt;Send\u0026lt;/strong\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;left\u0026#34; onclick=\u0026#34;closeWebSocket()\u0026#34;\u0026gt;\u0026lt;strong\u0026gt;Close\u0026lt;/strong\u0026gt;\u0026lt;/button\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;foot\u0026#34;\u0026gt; \u0026lt;!--summernote--\u0026gt; \u0026lt;div id=\u0026#34;summernote\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;js/jquery.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;js/vendor/bootstrap/bootstrap.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/vendor/mmenu/js/jquery.mmenu.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/vendor/sparkline/jquery.sparkline.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;js/vendor/nicescroll/jquery.nicescroll.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;js/vendor/tabdrop/bootstrap-tabdrop.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;js/vendor/summernote/summernote.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;js/minimal.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; window.onload = windowHeight; //页面载入完毕执行函数 function windowHeight() { var h = document.documentElement.clientHeight; //获取当前窗口可视操作区域高度 var history = document.getElementById(\u0026#34;historyMsg\u0026#34;); history.style.height = (h-294-30) + \u0026#34;px\u0026#34;; //你想要自适应高度的对象 } setInterval(windowHeight, 100)//每100微秒执行一次windowHeight函数 //精简版 $(document).ready(function () { $(\u0026#39;#summernote\u0026#39;).summernote({ height: 180, focus:true, toolbar: [ [\u0026#39;style\u0026#39;, [\u0026#39;bold\u0026#39;, \u0026#39;italic\u0026#39;, \u0026#39;underline\u0026#39;, \u0026#39;clear\u0026#39;]], [\u0026#39;fontsize\u0026#39;, [\u0026#39;fontsize\u0026#39;]], [\u0026#39;color\u0026#39;, [\u0026#39;color\u0026#39;]], [\u0026#39;para\u0026#39;, [\u0026#39;ul\u0026#39;, \u0026#39;ol\u0026#39;, \u0026#39;paragraph\u0026#39;]], [\u0026#39;height\u0026#39;, [\u0026#39;height\u0026#39;]], ]/*, callbacks: { onImageUpload: function (files) { //the onImageUpload API send(sendFile(files[0])); } }*/ }); }); /* function sendFile(file) { var data = new FormData(); data.append(\u0026#34;file\u0026#34;, file); alert(data); console.log(data); $.ajax({ data: data, type: \u0026#34;POST\u0026#34;, url: \u0026#34;/upload/uploadPic.html\u0026#34;, cache: false, contentType: false, processData: false, //dataType: \u0026#34;json\u0026#34;, success: function (url) {//data是返回的hash,key之类的值，key是定义的文件名 alert(url); $(\u0026#39;#summernote\u0026#39;).summernote(\u0026#39;insertImage\u0026#39;,url,\u0026#39;image name\u0026#39;); }, error:function () { alert(\u0026#34;上传失败\u0026#34;); }, }); } */ //构建通道 var websocket = new WebSocket(\u0026#34;ws://localhost:8080/chat\u0026#34;); //连接成功建立的回调方法 websocket.onopen = function(evt){ loginMessage(\u0026#34;open\u0026#34;); }; var name=\u0026#34;root\u0026#34;; //连接发生错误的回调方法 websocket.onerror = function(evt){ loginMessage(\u0026#34;error\u0026#34;); }; //接收到消息的回调方法 websocket.onmessage = function(evt){ setMessageInnerHTML(\u0026#34;\u0026lt;li\u0026gt;\u0026lt;sanp\u0026gt;\u0026lt;strong\u0026gt;\u0026#34;+name+\u0026#34;:\u0026lt;/strong\u0026gt;\u0026lt;br\u0026gt;\u0026#34;+evt.data+\u0026#34;\u0026lt;/sanp\u0026gt;\u0026lt;/li\u0026gt;\u0026#34;); }; //连接关闭的回调方法 websocket.onclose = function(evt){ loginMessage(\u0026#34;close\u0026#34;); }; //监听窗口关闭事件，当窗口关闭时，主动去关闭websocket连接，防止连接还没断开就关闭窗口，server端会抛异常。 window.onbeforeunload = function(evt){ websocket.close(); }; //将消息显示在网页上 function loginMessage(innerHTML){ document.getElementById(\u0026#39;message\u0026#39;).innerHTML = innerHTML; } //将消息显示在网页上 function setMessageInnerHTML(innerHTML){ document.getElementById(\u0026#39;historyMsg\u0026#39;).innerHTML += innerHTML; } //将消息显示在网页上 function setMessagehistory(innerHTML){ document.getElementById(\u0026#39;historyMsg\u0026#39;).innerHTML += innerHTML;s } //关闭连接 function closeWebSocket(evt){ websocket.close(); } //发送消息 function send(evt){ var message = $(\u0026#34;#summernote\u0026#34;).summernote(\u0026#39;code\u0026#39;); $(\u0026#34;#summernote\u0026#34;).summernote(\u0026#39;code\u0026#39;,\u0026#39;\u0026#39;); var regexstr =new RegExp(\u0026#39;\u0026lt;(?!img|br/|p|/p).*?\u0026gt;\u0026#39;); //去除标签 var str=message.replace(regexstr,\u0026#34;\u0026#34;); websocket.send(str); } //发送给自己 function printme(evt){ alert(\u0026#34;Welocom to chat_room!\u0026#34;); } \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","date":"2020-10-22","img":"","permalink":"/posts/java/websocket/","series":["WebSocket"],"tags":["Java","WebSocket"],"title":"WebSocket"},{"categories":["java"],"content":"Xml Xml eXtendsible markup language 可扩展的标记语言\nXML 有什么用? 可以用来保存数据\n可以用来做配置文件\n数据传输载体\n定义xml 其实就是一个文件，文件的后缀为 .xml\n文档声明 简单声明， version : 解析这个xml的时候，使用什么版本的解析器解析\n`\u0026lt;?xml version=\u0026quot;1.0\u0026quot; ?\u0026gt;` encoding : 解析xml中的文字的时候，使用什么编码来翻译\n`\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;gbk\u0026quot; ?\u0026gt;` standalone : no - 该文档会依赖关联其他文档 ， yes\u0026ndash; 这是一个独立的文档\n`\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;gbk\u0026quot; standalone=\u0026quot;no\u0026quot; ?\u0026gt;` encoding详解 在解析这个xml的时候，使用什么编码去解析。 ---解码。 文本存储时不直接存储文字， 而是存储这些文字对应的二进制 。 那么这些文字对应的二进制到底是多少呢？ 根据文件使用的编码 来得到。\n默认文件保存的时候，使用的是GBK的编码保存。\n所以要想让我们的xml能够正常的显示中文,解决方法:\n让encoding也是GBK 或者 gb2312 .\n如果encoding是 utf-8 ， 那么保存文件的时候也必须使用utf-8\n保存的时候见到的ANSI 对应的其实是我们的本地编码 GBK。\n为了通用，建议使用UTF-8编码保存，以及encoding 都是 utf-8\n元素定义（标签） 其实就是里面的标签， \u0026lt;\u0026gt; 括起来的都叫元素 。 成对出现。 如下： \u0026lt;stu\u0026gt; \u0026lt;/stu\u0026gt;\n文档声明下来的第一个元素叫做根元素 (根标签)\n标签里面可以嵌套标签\n空标签:既是开始也是结束。 一般配合属性来用。\n\u0026lt;age/\u0026gt;\neg:\n\u0026lt;stu\u0026gt; \u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt; \u0026lt;age/\u0026gt; \u0026lt;/stu\u0026gt; 标签可以自定义。 XML 元素必须遵循以下命名规则：\n​\t1. 名称可以含字母、数字以及其他的字符\n​\t2. 名称不能以数字或者标点符号开始\n​\t3. 名称不能以字符 “xml”（或者 XML、Xml）开始\n​\t4. 名称不能包含空格\n​\t5. 命名尽量简单，做到见名知义\n简单元素 \u0026 复杂元素 简单元素 元素里面包含了普通的文字\n复杂元素 元素里面还可以嵌套其他的元素\n属性的定义 定义在元素里面， \u0026lt;元素名称 属性名称=\u0026ldquo;属性的值\u0026rdquo;\u0026gt;\u0026lt;/元素名称\u0026gt;\n\u0026lt;stus\u0026gt; \u0026lt;stu id=\u0026#34;10086\u0026#34;\u0026gt; \u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;18\u0026lt;/age\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;stu id=\u0026#34;10087\u0026#34;\u0026gt; \u0026lt;name\u0026gt;李四\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;28\u0026lt;/age\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;/stus\u0026gt; xml注释： 与html的注释一样。\n｀ ｀\n如：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- //这里有两个学生 //一个学生，名字叫张三， 年龄18岁， 学号：10086 //另外一个学生叫李四 。。。 --\u0026gt; xml的注释，不允许放置在文档的第一行。 必须在文档声明的下面。\nCDATA区 ####　非法字符\n严格地讲，在 XML 中仅有字符 \u0026ldquo;\u0026lt;\u0026ldquo;和\u0026rdquo;\u0026amp;\u0026rdquo; 是非法的。省略号、引号和大于号是合法的，但是把它们替换为实体引用是个好的习惯。\n\u0026lt; \u0026amp;lt; \u0026amp; \u0026amp;amp; \u0026#34; \u0026amp;quot; 如果某段字符串里面有过多的字符， 并且里面包含了类似标签或者关键字的这种文字，不想让xml的解析器去解析。 那么可以使用CDATA来包装。 不过这个CDATA 一般比较少看到。 通常在服务器给客户端返回数据的时候。\n\u0026lt;des\u0026gt;\u0026lt;![CDATA[\u0026lt;a href=\u0026quot;http://www.baidu.com\u0026quot;\u0026gt;我爱黑马训练营\u0026lt;/a\u0026gt;]]\u0026gt;\u0026lt;/des\u0026gt;\nXML 解析 其实就是获取元素里面的字符数据或者属性数据。\nXML解析方式(面试常问) 有很多种，但是常用的有两种。\nDOM:把所有的文件全部读取到内存中,形成树状结构.整个文档称为document对象.,属性对应Attribute对象,所有的元素节点对应Element对象,文本也可以称为Text对象 ,以上所有对象都可以称为Node节点,如果xml特别大,就会造成内存溢出.优点:可以对文档进行增删操作\nSAX:Simple API for XML 基于事件驱动,读取一行,解析一行,不会造成内存泄漏,不可以增删,只能查询\n针对这两种解析方式的API 一些组织或者公司， 针对以上两种解析方式， 给出的解决方案有哪些？\njaxp sun公司。 比较繁琐 jdom\ndom4j 使用比较广泛,对SAX进行了增强,也可以完成增删操作\nDom4j 基本用法 element.element(\u0026#34;stu\u0026#34;) ;// 返回该元素下的第一个stu元素 element.elements();// 返回该元素下的所有子元素。 创建SaxReader对象\nSAXReader reader= newSAXReader();\n指定解析的xml\nDocument document = reader.read(path|file|inputStream);\n获取根元素。\nElemennt rootElement = document.getRootElement();\n根据根元素获取子元素或者下面的子孙元素\nrootElement.element(\u0026quot;age\u0026quot;) rootElement.element(\u0026quot;stu\u0026quot;).element(\u0026quot;age\u0026quot;).getText();\ntry { //1. 创建sax读取对象 SAXReader reader = new SAXReader(); //jdbc -- classloader //2. 指定解析的xml源 Document document = reader.read(new File(\u0026#34;src/xml/stus.xml\u0026#34;)); //3. 得到元素、 //得到根元素 Element rootElement= document.getRootElement(); //获取根元素下面的子元素 age //rootElement.element(\u0026#34;age\u0026#34;) //System.out.println(rootElement.element(\u0026#34;stu\u0026#34;).element(\u0026#34;age\u0026#34;).getText()); //获取根元素下面的所有子元素 。 stu元素 List\u0026lt;Element\u0026gt; elements = rootElement.elements(); //遍历所有的stu元素 for (Element element : elements) { //获取stu元素下面的name元素 String name = element.element(\u0026#34;name\u0026#34;).getText(); String age = element.element(\u0026#34;age\u0026#34;).getText(); String address = element.element(\u0026#34;address\u0026#34;).getText(); System.out.println(\u0026#34;name=\u0026#34;+name+\u0026#34;==age+\u0026#34;+age+\u0026#34;==address=\u0026#34;+address); } } catch (Exception e) { e.printStackTrace(); } SaxReader 创建好对象 。\nDocumentElement\n看文档\n记住关键字 。\n有对象先点一下。\n看一下方法的返回值。\n根据平时的积累。 getXXX setXXX\nDom4j 的 Xpath使用 dom4j里面支持Xpath的写法。 xpath其实是xml的路径语言，支持我们在解析xml的时候，能够快速的定位到具体的某一个元素。在爬虫中经常使用.\n添加jar包依赖\njaxen-1.1-beta-6.jar\n在查找指定节点的时候，根据XPath语法规则来查找\n//要想使用Xpath， 还得添加支持的jar 获取的是第一个 只返回一个。 Element nameElement = (Element) rootElement.selectSingleNode(\u0026#34;//name\u0026#34;);//双斜杠不能少 //获取文档里面的所有name元素 List\u0026lt;Element\u0026gt; list = rootElement.selectNodes(\u0026#34;//name\u0026#34;); for (Element element : list) { System.out.println(element.getText()); } XML 约束 如下的文档， 属性的ID值是一样的。 这在生活中是不可能出现的。 并且第二个学生的姓名有好几个。 一般也很少。那么怎么规定ID的值唯一， 或者是元素只能出现一次，不能出现多次？ 甚至是规定里面只能出现具体的元素名字。\n\u0026lt;stus\u0026gt; \u0026lt;stu id=\u0026#34;10086\u0026#34;\u0026gt; \u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;18\u0026lt;/age\u0026gt; \u0026lt;address\u0026gt;深圳\u0026lt;/address\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;stu id=\u0026#34;10086\u0026#34;\u0026gt; \u0026lt;name\u0026gt;李四\u0026lt;/name\u0026gt; \u0026lt;name\u0026gt;李五\u0026lt;/name\u0026gt; \u0026lt;name\u0026gt;李六\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;28\u0026lt;/age\u0026gt; \u0026lt;address\u0026gt;北京\u0026lt;/address\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;/stus\u0026gt; DTD 文档类型定义，可以定义合法的ＸＭＬ文档构建模块.\n可以成行的声明于XML文档中,也可以作为外部引用\n可读性比较差。\n引入网络上的DTD \u0026lt;!-- 引入dtd 来约束这个xml --\u0026gt; \u0026lt;!--文档类型 根标签名字 网络上的dtd dtd的名称 dtd的路径 --\u0026gt; \u0026lt;! DOCTYPE stus PUBLIC \u0026#34;//UNKNOWN/\u0026#34; \u0026#34;unknown.dtd\u0026#34;\u0026gt; 引入本地的DTD \u0026lt;!-- 引入本地的DTD 忽略dtd的路径--\u0026gt; \u0026lt;!-- 根标签名字 引入本地的DTD dtd的位置 --\u0026gt; \u0026lt;!DOCTYPE stus SYSTEM \u0026#34;stus.dtd\u0026#34;\u0026gt; 直接在XML里面嵌入DTD的约束规则 \u0026lt;!-- xml文档里面直接嵌入DTD的约束法则 --\u0026gt; \u0026lt;!DOCTYPE stus [ \u0026lt;!ELEMENT stus (stu)+\u0026gt; \u0026lt;!ELEMENT stu (name,age)\u0026gt; \u0026lt;!ELEMENT name (#PCDATA)\u0026gt; \u0026lt;!ELEMENT age (#PCDATA)\u0026gt; \u0026lt;!ATTLIST stu id CDATA #IMPLIED\u0026gt; ]\u0026gt; \u0026lt;stus\u0026gt; \u0026lt;stu id=\u0026#34;10086\u0026#34;\u0026gt; \u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;18\u0026lt;/age\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;stu id=\u0026#34;10ds\u0026#34;\u0026gt; \u0026lt;name\u0026gt;李四\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;18\u0026lt;/age\u0026gt; \u0026lt;/stu\u0026gt; \u0026lt;/stus\u0026gt; \u0026lt;!-- \u0026lt;!ELEMENT stus (stu)\u0026gt;:stus 下面有一个元素 stu ， 但是只有一个 \u0026lt;!ELEMENT stu (name,age)\u0026gt;:stu下面有两个元素 name,age顺序必须name-age \u0026lt;!ELEMENT name (#PCDATA)\u0026gt;:name 只有PCDATA \u0026lt;!ELEMENT age (#PCDATA)\u0026gt;:age 只有PCDATA \u0026lt;!ATTLIST stu id CDATA #IMPLIED\u0026gt;:stu有一个属性名为id,字符数据CDATA,该属性可有可无 \u0026lt;!ELEMENT br EMPTY\u0026gt;:空元素,例子;\u0026lt;br /\u0026gt; --\u0026gt; 元素的个数： + 一个或多个 * 零个或多个 ? 零个或一个 属性的类型定义 CDATA : 属性是普通文字 ID : 属性的值必须唯一 元素的选择 \u0026lt;!ELEMENT stu (name , age)\u0026gt;\t\u0026lt;!--按照顺序来--\u0026gt; \u0026lt;!ELEMENT stu (name | age)\u0026gt; \u0026lt;!--两个中只能包含一个子元素--\u0026gt; Schema 其实就是一个xml ， 使用xml的语法规则， xml解析器解析起来比较方便 ， 是为了替代DTD 。\n但是Schema 约束文本内容比DTD的内容还要多。 所以目前也没有真正意义上的替代DTD\n约束文档：\n\u0026lt;!-- xmlns : xml namespace : 名称空间 / 命名空间 targetNamespace : 目标名称空间 。 下面定义的那些元素都与这个名称空间绑定上。 elementFormDefault ： 元素的格式化情况。 --\u0026gt; \u0026lt;schema xmlns=\u0026#34;http://www.w3.org/2001/XMLSchema\u0026#34; argetNamespace=\u0026#34;http://www.itheima.com/teacher\u0026#34; elementFormDefault=\u0026#34;qualified\u0026#34; \u0026gt; \u0026lt;element name=\u0026#34;teachers\u0026#34;\u0026gt; \u0026lt;complexType\u0026gt; \u0026lt;sequence maxOccurs=\u0026#34;unbounded\u0026#34;\u0026gt; \u0026lt;!-- 这是一个复杂元素 --\u0026gt; \u0026lt;element name=\u0026#34;teacher\u0026#34;\u0026gt; \u0026lt;complexType\u0026gt; \u0026lt;sequence\u0026gt; \u0026lt;!-- 以下两个是简单元素 --\u0026gt; \u0026lt;element name=\u0026#34;name\u0026#34; type=\u0026#34;string\u0026#34;\u0026gt;\u0026lt;/element\u0026gt; \u0026lt;element name=\u0026#34;age\u0026#34; type=\u0026#34;int\u0026#34;\u0026gt;\u0026lt;/element\u0026gt; \u0026lt;/sequence\u0026gt; \u0026lt;/complexType\u0026gt; \u0026lt;/element\u0026gt; \u0026lt;/sequence\u0026gt; \u0026lt;/complexType\u0026gt; \u0026lt;/element\u0026gt; \u0026lt;/schema\u0026gt; 实例文档：\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!-- xmlns:xsi : 这里必须是这样的写法，也就是这个值已经固定了。 xmlns : 这里是名称空间，也固定了，写的是schema里面的顶部目标名称空间 xsi:schemaLocation : 有两段： 前半段是名称空间，也是目标空间的值 ， 后面是约束文档的路径。 --\u0026gt; \u0026lt;teachers xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;http://www.itheima.com/teacher\u0026#34; xsi:schemaLocation=\u0026#34;http://www.itheima.com/teacher teacher.xsd\u0026#34; \u0026gt; \u0026lt;teacher\u0026gt; \u0026lt;name\u0026gt;zhangsan\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;19\u0026lt;/age\u0026gt; \u0026lt;/teacher\u0026gt; \u0026lt;teacher\u0026gt; \u0026lt;name\u0026gt;lisi\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;29\u0026lt;/age\u0026gt; \u0026lt;/teacher\u0026gt; \u0026lt;teacher\u0026gt; \u0026lt;name\u0026gt;lisi\u0026lt;/name\u0026gt; \u0026lt;age\u0026gt;29\u0026lt;/age\u0026gt; \u0026lt;/teacher\u0026gt; \u0026lt;/teachers\u0026gt; 名称空间的作用 一个xml如果想指定它的约束规则， 假设使用的是DTD ，那么这个xml只能指定一个DTD ， 不能指定多个DTD 。 但是如果一个xml的约束是定义在schema里面，并且是多个schema，那么是可以的。简单的说： 一个xml 可以引用多个schema约束。 但是只能引用一个DTD约束。\n名称空间的作用就是在 写元素的时候，可以指定该元素使用的是哪一套约束规则默认情况下 ，如果只有一套规则，那么都可以这么写\n\u0026lt;name\u0026gt;张三\u0026lt;/name\u0026gt; \u0026lt;aa:name\u0026gt;\u0026lt;/aa:name\u0026gt; \u0026lt;bb:name\u0026gt;\u0026lt;/bb:name\u0026gt; ","date":"2020-10-22","img":"","permalink":"/posts/java/xml/","series":["java"],"tags":["java"],"title":"XML"},{"categories":["无人驾驶"],"content":"无人驾驶概述\n无人驾驶能够解决的问题 车辆利用率 点对点交通 共享交通 驾驶安全 减少车祸 提高交通效率 减少堵塞\n提高路口通行效率\n无人驾驶分级 L1：定速巡航（ACC）可以纵向控制 L2：车道保持辅助（Lane Keeping）可以横向和纵向控制。人负全责 L3：可以提供简单路况下的变道，但是条件限制。自动驾驶时车负责 L4：大部分时间按由车主导，接管工具减少 L5：全区域无人驾驶 实现思路 V2X（车路协同） V2V（车）\nV2I（公共设施）\nV2P（行人）\n可以降低单车成本，提供超视距感知，车辆意图协商，车辆协同控制\n边缘计算 RSU：路侧单元\nOBU：车载单元\n5G通信能力 LTE-V协议 主车智能 感知能力\n决策能力\n高精地图（HD map）\n定位\n权责问题 RSS模型（责任敏感安全模型） 自动驾驶硬件概述 感知传感器 摄像头（用于车道线检测，交通信号灯识别）\n激光雷达（准确率高）\n毫米波雷法（观测距离远）\n超声波（近处高敏感传感器）\n定位系统传感器 IMU：实时测量自身位姿\nGNSS：GPS\n车载计算单元-IPC 高效连接计算单元内部的各个计算设备，连接外部传感器的信息输入和存储\n冗余设计，防止单点故障\n符合车规，抗电磁干扰能力\n车辆线控系统 由液压系统和真空助力泵变为电子液压系统\n自动驾驶软件概述 感知系统（位姿，目标对象，场景语义分割） 定位系统（检测，分类，跟踪，分割） 硬件 HD map：高精地图，提供精确的三维表征，地图语义信息\nINS：惯性导航\nIMU：通过当前自身状态推算下一时刻位置\nRTK：载波相位差分系统\n激光雷达，摄像头：获取信息，和高精地图进行物体匹配，获取定位\n软件 监督学习，半监督学习，强化学习\nRCNN，YOLO，SSD\n前融合，后融合\n决策规划（实时，准确） 预测 基于状态预测 Kalman Filter\nParticle Filter\n基于车道序列预测 机器学习，深度学习 行人预测 人的突发位姿变化 规划 导肮线路规划\n精细轨迹表述\n实时控制（准确性，时效性，精确性） 通过轨迹和车辆状态，来控制方向盘和油门\nOS RTOS QNX：类Unix系统\nRT Linux：加了Linux补丁，通过软实时进行监控\nFramework ROS\nYARP,MOOS,Cybertron\n阅读材料 综述文章 • 基于深度学习的自动驾驶技术综述\n• Self-Driving Cars:A Survey\n• Computer Vision for Autonomous Vehicles: Problems, Datasets and State-of-the-Art\n无人驾驶实现结构概览 • ISPRS 2017 实践 • Python plays Grand Theft Auto ","date":"2020-10-22","img":"","permalink":"/posts/driverless/%E6%97%A0%E4%BA%BA%E9%A9%BE%E9%A9%B6%E6%A6%82%E8%BF%B0/","series":null,"tags":["无人驾驶"],"title":"无人驾驶概述"},{"categories":["缓存"],"content":"缓存的使用和设计 缓存的收益与成本 收益 加速读写\n通过缓存加速读写：CPU L1/L2/L3 Cache，浏览器缓存，Ehcache缓存数据库结果 降低后端负载\n后端服务器通过前端缓存降低负载：业务端使用Redis降低后端MySQL负载 成本 数据不一致\n缓存层和数据层有时间窗口不一致，和更新策略有关 代码维护成本：多了一层缓存逻辑\n运维成本：Redis Cluster\n使用场景 降低后端负载\n用于高消耗的SQL：join结果集/分组统计结果 加速请求响应\n利用Redis/Memcache优化IO时间 大量写合并为批量写\n计数器线Redis累加再批量更新到后端数据库 缓存更新策略 LRU/LFU/FIFO算法剔除：例如maxmemory-policy\n超时剔除：例如expire\n主动更新：开发控制生命周期\n推荐结合剔除，超时，主动更新三种方案完成 三种策略比较 | 策略 | 一致性 | 维护成本 |\n| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash; | \u0026mdash;\u0026mdash;\u0026ndash; |\n| LRU/LIRS算法剔除 | 最差 | 底 |\n| 超时剔除 | 较差 | 低 |\n| 主动更新 | 强 | 高 |\nTIPS 低一致性：最大内存和淘汰策略\n高一致性：超时剔除和主动更新结合，最大内存和淘汰策略兜底\n缓存粒度控制 什么是缓存粒度 从MySQL获取用户信息\nselect * from usr where id={id} 设置用户信息缓存\n```set usr:{id} `select * from usr where id={id}```` 缓存粒度\n部分重要属性 ```set usr:{id} `select * from usr where id={id}````\n- 全部属性 ```set usr:{id} `select * from usr where id={id}````\n缓存粒度控制 通用性：全量属性更好\n占用空间：部分属性更好\n代码维护：综合考虑，是否使用这么多属性\n缓存穿透优化 缓存穿透：大量请求不命中 大量没有结果的请求通过cache访问到后端，后端也没有命中\n原因 业务代码，没有正确从后端拿到数据\n恶意攻击，爬虫{大量请求携带未知数据去访问缓存以及数据库}\n及时发现 业务的相应时间\n业务的本身问题\n监控几个指标\n总调用数\n缓存层命中数\n存储层命中数\n解决方法 缓存空对象\n如果从后端数据库中的请求结果是一个空值，我们也保存，不过设置一个过期时间（有可能后端数据库故障或者接口故障），这样减小后端数据库的压力\n问题：\n1). 需要更多的键（设置过期时间解决）\n2). 缓存层和存储层数据“短期”不一致（订阅故障消息解决）\n伪代码\npublic String getPassThrough(String key){ String cacheValue = cache.get(key); if(StringUtils.isBlank(cacheValue)){ String storgeValue = storage.get(key)//如果cache中为空，就从storage中拿数据 cache.set(key,storageValue); if(StringUtils.isBlank(storageValue)){ cache.expire(key,60*5);//如果从后端接口获取值为空，设置一个过期时间 } return storageValue; }else{ return cacheValue; } } 布隆过滤器\n数据很大不能做到实时\n利用算法，可以使用很小的内存判断一个值是否在一个大数据集中\n在请求cache之前先通过bloom filter过滤一次，判断请求是否有效\n缓存无底洞：节点增加，性能下降 原因 更多的机器!=更高的性能\n批量接口需求(mget，mset)等（节点增加，io时间增加）\n数据增长与水平扩展需求\n优化 命令优化：例如慢查询keys，hgetall\n减少网络通信次数\n降低接入成本：例如客户端长连接/连接池.NIO\n优化方案比较 | 方案 | 优点 | 缺点 | 网络IO |\n| \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| 串行mget | 编程简单少量keys满足需求 | 大量keys请求延迟严重 | O(keys) |\n| 串行IO | 编程简单少量节点满足需求 | 大量node延迟严重 | O(nodes) |\n| 并行IO | 利用并行特性延迟取决于最慢的节点 | 编程复杂超时定位问题难 | O(max_slow(node)) |\n| hash_tag | 性能最高 | 读写增加tag维护成本tag分布易出现数据倾斜 | O1 |\n缓存雪崩 缓存集中过期或者缓存服务器宕机\n缓存集中过期 在某一时间段，缓存集中过期失效，访问压力会给到后端数据库\n为不同的分类设置不同的过期时间\n同一分类的不同商品在设置过期时间时加一个随机因子\n根据请求数量和密度设置过期时间\n服务器宕机 缓存层实现高可用\n客户端降级\n提前演练\n热点key重建优化 原因 热点key在多次访问时，线程一直在做查询数据源，重建缓存的操作\n例如微博热搜\n优化目标 减少重缓存的次数\n数据尽可能一致\n减少潜在危险\n优化思路 互斥锁 在查询数据源和重建缓存这个过程中加锁，如果有线程在执行这个操作，其他线程只能等待缓存重建完毕\n伪代码： String get(String key){ String value = redis.get(key); if(value == null){ String mutexKey = \u0026#34;mutex🔑\u0026#34; + key; if(redis.set(mutexKey,\u0026#34;1\u0026#34;,\u0026#34;ex 180\u0026#34;,\u0026#34;nx\u0026#34;)){ value = db.get(key); redis.set(key,value); redis.delete(mutexKey); }else{ //其他线程休息50ms Thread.sleep(50); get(key); } } return value; } 永不过期 缓存：没有加expire\n功能层面：为每个value添加逻辑过期时间，如果发现超过逻辑过期时间，使用单独的线程去构建缓存\n我们的key永不过期，线程获取缓存不需要等待，如果中间发现value的过期时间到了，就新开一个线程去更新key。在更新完成前所有的请求获取得到的都是更新前的旧值，知道更新完成后，才会得到新值\n伪代码 String get(final String key){ V v= redis.get(key); String value = v.getValue(); long logicTimeout = v.getLogicTimeout(); if(logicTimeout \u0026gt;= System.currentTimeMills()){ String mutexKey = \u0026#34;mutex🔑\u0026#34; + key; if(redis.set(mutexKey,\u0026#34;1\u0026#34;,\u0026#34;ex 180\u0026#34;,\u0026#34;nx\u0026#34;)){ //异步更新 threadPool.execute(new Runnable(){ public void run(){ String dbValue = db.get(Key); redis.set(key,(dbValue,newLogicTimeout)); redis.delete(muteKey); } }); } } return value; } 两种方案对比 | 方案 | y优点 | 缺点 |\n| \u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| 永远不过期 | 基本杜绝热点key重建按问题 | 不保证一致性逻辑过期时间增加维护成本和内存成本 |\n| 互斥锁 | 思路简单保证一致性 | 代码复杂度增加存在死锁的风险 |\n","date":"2020-10-22","img":"","permalink":"/posts/redis/%E7%BC%93%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E8%AE%BE%E8%AE%A1/","series":["缓存"],"tags":["缓存"],"title":"缓存的使用和设计"},{"categories":["architecture design"],"content":"软件架构 软件开发过程的概述 在行业中，架构师、开发人员和产品所有者花费大量时间研究和讨论业务需求。在软件工程术语中，这被称为需求收集和分析。\n一旦我们完成了业务需求，我们坐下来讨论我们必须实现的用例。这包括尽早找出角落的情况\u0026amp;将乐高积木组装在一起。\n如果您是文档的爱好者，您可能还想编写高级设计文档。现在，我们已经了解了业务需求、用例、拐角用例等等。现在开始研究如何选择合适的技术堆栈来实现用例。\n####　概念证明 POC\nPOC帮助我们对技术和基本用例实现有一个更近、更实际的了解。我们将深入了解技术、性能或其他技术限制的利弊。\n如果我们使用的是全新的技术，那么学习曲线就会有所帮助，产品所有者、利益相关者等非技术人员也会有一些具体的东西可以使用，并以此为基础做出进一步的决定。\n现在，这只是一个工业规模的产品。如果你是一个独立开发者或一个小团队，你可以跳过POC部分，从主代码开始。\n所以，我们向利益相关者展示POC，如果每个人都满意，我们最终在GitHub上创建主回购和我们的第一个开发分支，或任何其他类似的业务喜欢的代码托管服务。\n所以，到现在为止，你应该已经意识到在第一时间获得正确的架构和web架构知识对开发人员是多么的重要。\nTier 我将从讨论软件架构中涉及的不同层次开始课程。这就像是对软件架构领域的鸟瞰，很重要的一点是要很好地理解。\n什么是一层？ 可以将层看作应用程序或服务中组件的逻辑分离。当我说分离时，我指的是组件级的物理分离，而不是代码级。\n组件的意思是什么？ 数据库\n后端应用服务器\n用户界面\n消息传递\n缓存\nSingle Tier Applications 单层应用程序是指用户界面、后端业务逻辑和数据库都驻留在同一台机器中的应用程序。\n单层应用程序的典型例子是桌面应用程序，如moffice、PC游戏或图像编辑软件，如Gimp。\n单层应用的优点 单层应用程序的主要优点是它们没有网络延迟，因为每个组件都位于同一台机器上。这就提高了软件的性能。\n没有数据请求到后端服务器不时，这将使用户体验缓慢。在单层应用中，由于数据位于同一台机器上，所以数据是很容易和快速获得的。\n尽管这在很大程度上取决于机器的功能有多强大\u0026amp;软件的硬件要求，但要衡量单层应用程序的真正性能\n此外，用户的数据保存在他的机器\u0026amp;不需要通过网络传输。这在最大程度上保证了数据安全。\n单层应用的缺点 单层应用程序的一个大缺点是业务无法控制应用程序。一旦软件交付，除非客户通过连接到远程服务器或下载并安装补丁手动更新软件，否则不可能对代码或功能进行更改。\n因此，在90年代，如果一款游戏带有漏洞代码，那么工作室便无能为力。由于软件的缺陷，他们最终不得不面对相当大的压力。产品的测试必须彻底，不能有任何差错。\n单层应用程序中的代码也很容易被修改和反向工程。对企业来说，安全性是最低限度的。\n此外，应用程序的性能和外观可能会不一致，因为它在很大程度上取决于用户机器的配置。\nTwo Tier Applications 两层应用程序包括客户机和服务器。客户端将在一台机器中包含用户界面和业务逻辑。后端服务器将是运行在不同机器上的数据库。数据库服务器由企业托管并对其进行控制。\n为什么需要两层应用程序?为什么不将业务逻辑驻留在另一台机器上并对其进行控制呢?\n优点:\n应用程序代码也不容易被第三方访问\n在某些情况下，两层应用程序会派上用场，例如，待办事项列表应用程序或类似的计划表或生产力应用程序。在这些场景中，即使代码被第三方访问，也不会对业务造成重大损害。相反，好处是由于代码和用户界面驻留在同一台机器上，因此对后端服务器的网络调用更少，从而降低了应用程序的延迟。只有当用户创建完待办事项列表并希望持久化更改时，应用程序才会调用数据库服务器。\n另一个例子便是基于浏览器和应用的在线游戏。游戏文件非常重，当用户第一次使用应用时，他们只需要在客户端下载一次。此外，它们进行网络调用只是为了保持游戏状态持久。\n经济，更少的服务器调用意味着在服务器上花费更少的钱，这自然是经济的。\n不过，这在很大程度上取决于我们的业务需求和用例，如果我们想在编写服务时选择这种类型的层。我们可以将用户界面和业务逻辑保留在客户机上，也可以将业务逻辑移动到专用的后端服务器上，这将使其成为一个三层应用程序。这是我接下来要讨论的\nTree Tier Applications 三层应用程序非常流行，并在行业中广泛使用。几乎所有的简单网站，如博客，新闻网站等都属于这一类。\n在一个三层的应用程序中，用户界面、应用程序逻辑和数据库都位于不同的机器上，因此有不同的层。他们是分开的。\n因此，如果我们以一个简单的博客为例，用户界面将使用Html, JavaScript, CSS编写，后端应用程序逻辑将运行在服务器上，如Apache \u0026amp;数据库将是MySQL。三层架构最适合简单的用例。\nN Tier Applications n层应用程序是指包含三个以上组件的应用程序。\n这些组成部分是什么?\n缓存 异步行为的消息队列 负载均衡器 用于搜索大量数据的服务器 处理大量数据的组件 运行异构技术(通常称为web服务)的组件等。 所有像Instagram, Facebook这样的社交应用，像Uber, Airbnb这样的大型行业服务，像Pokemon Go这样的在线大型多人游戏，具有奇特功能的应用都是n层应用。\n注意:n层应用程序还有另一个名称，即分布式应用程序。但是，我认为使用“分布式”这个词还不安全，因为“分布式”这个词会带来很多复杂的东西。这只会让我们感到困惑，而不是有所帮助。虽然我将在本课程中讨论分布式架构，但现在，我们将只使用术语N层应用程序。\n为什么软件应用程序有不同的层？ 解释这一点的两个软件设计原则是单一责任原则和关注点分离原则。\nSingle Responsibility Principle 单一责任原则:单一责任原则仅仅意味着给一个组件一个责任，让它完美地执行它。它可以保存数据、运行应用程序逻辑或确保消息在整个系统中的传递。\n这种方法给了我们很大的灵活性，使管理更容易。例如，升级数据库服务器时。就像安装一个新的操作系统或补丁一样，它不会影响服务的其他组件的运行\u0026amp;即使在操作系统安装过程中发生了一些问题，只有数据库组件会宕机。应用程序作为一个整体仍然会运行\u0026amp;只会影响需要数据库的特性。\n我们还可以为每个组件建立专门的团队和代码库，从而保持代码整洁。\n单一责任原则是我从来没有存储过程的原因\n存储过程使我们能够将业务逻辑添加到数据库．如果在将来我们想要插入不同的数据库怎么办？我们在哪里采取业务逻辑？到新数据库？或者我们试图重构在存储过程逻辑中的应用程序代码．\n数据库不应该保存业务逻辑，它应该只负责持久化数据。这就是单一责任原则。这就是为什么我们要为不同的组件设置不同的层。\nSeparation Of Concerns 关注点分离:分离关注点的意思是一样的，只关心你的工作\u0026amp;不要担心其他的事情。\n这些原则在服务的所有级别上发挥作用，无论是在层级还是在代码级。\n将组件分开可以使它们可重用。不同的服务可以使用相同的数据库、消息传递服务器或任何组件，只要它们之间不是紧密耦合的\n应该采用松散耦合的组件。当将来业务增长到一定程度时，这种方法使得扩展服务变得容易。\nDifference Between Layers \u0026 Tiers 注意:不要将层(tiers)与应用程序的层混淆。有些人喜欢交替使用。但在应用程序的行业层中，通常指的是用户界面层(layer)、业务层、服务层或数据访问层。 图中提到的层位于代码级别。层和层之间的区别是，层表示代码的组织，并将其分解为组件。然而，层(tier)涉及组件的物理分离。\n","date":"2020-02-03","img":"","permalink":"/posts/architecture_design/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%841-tier/","series":["软件架构"],"tags":["architecture"],"title":"软件架构1-Tier"},{"categories":["architecture design"],"content":"软件架构 什么是Web架构 Web架构包括数据库、消息队列、缓存、用户界面等多个组件，它们相互结合，形成在线服务\n这是web应用程序的典型架构，在大多数在线运行的应用程序中使用。\n如果我们对图中所涉及的组件有一个了解，那么我们总是可以在这个体系结构的基础上构建更复杂的需求。\nClient Server Architecture客户服务器结构 在讨论两层、三层和n层架构时，我们已经对客户端-服务器架构有了一些了解。现在我们来详细看看。\n客户端-服务器架构是web的基本构件。\n该体系结构在请求-响应模型上工作。客户端向服务器发送请求以获取信息\u0026amp;服务器响应它。\n你浏览的每个网站，无论是Wordpress博客还是Facebook、Twitter或银行应用程序，都是建立在客户-服务器架构上的。\n只有非常小的比例的业务网站和应用程序使用peer to peer体系结构，这与客户机-服务器不同。\nclient 客户端保存我们的用户界面。用户界面是应用程序的表示部分。它是用Html, JavaScript, CSS编写的，并负责应用程序的外观和感觉。\n用户界面在客户机上运行。客户端可以是移动应用程序、台式机或像iPad这样的平板电脑。它也可以是基于web的控制台，运行命令与后端服务器交互。\n简单地说，客户端就是我们应用程序的窗口。在业界，编写基于web的用户界面的开源技术有ReactJS、AngularJS、VueJS、Jquery等。所有这些库都使用JavaScript。\n编写前端也有很多其他的技术，我只是列出了目前最流行的几种。\n不同的平台需要不同的框架和库来编写前端。例如，运行Android的手机将需要一套不同的工具，运行苹果或Windows操作系统的手机将需要一套不同的工具\nTypes of Client Thin Client 瘦客户机是仅持有应用程序用户界面的客户机。它没有任何形式的商业逻辑。对于每个操作，客户端都向后端服务器发送一个请求。就像在三层应用程序中一样。 Thick Client( Fat client) 胖客户机持有全部或部分业务逻辑。这些是两层应用程序。我们已经讲过了，如果你还记得的话。胖客户端的典型例子是实用程序、在线游戏等\nServer web服务器的主要任务是接收来自客户端的请求，并根据从客户端收到的请求参数执行业务逻辑后提供响应。\n每一个在线运行的服务都需要一个服务器来运行。运行web应用程序的服务器通常被称为应用服务器。\n除了应用程序服务器之外，还有其他类型的服务器，它们被分配特定的任务，例如\n代理服务器\n邮件服务器\n文件服务器\n虚拟服务器\n服务器配置和类型可以根据用例的不同而不同。\n例如，如果我们运行用Java编写的后端应用程序代码，我们会选择Apache Tomcat或Jetty\n对于简单的用例，比如托管网站，我们会选择Apache HTTP服务器。\n一个web应用程序的所有组件都需要一个服务器来运行。可以是数据库、消息队列、缓存或任何其他组件。在现代应用程序开发中，甚至用户界面也单独驻留在专用服务器上\nServer-Side Rendering SSR 后端渲染技术，开发人员使用服务器在后台呈现用户界面，然后将呈现的数据发送给客户端。这种技术被称为服务器端渲染。我将在后面的课程中讨论客户端和服务器端渲染的优缺点。\n客户端渲染Vs服务器端渲染(Client-Side Vs Server-Side Rendering) 当用户从服务器请求一个网页\u0026amp;浏览器收到响应。它必须以HTML页面的形式在窗口上呈现响应\n为此，浏览器有几个组件，例如:\n浏览器引擎 渲染引擎 JavaScript解释器 网络和UI后端 数据存储等 渲染引擎构建DOM树，渲染并绘制结构。\nServer-Side Rendering\n为了避免客户端的渲染时间，开发人员经常在服务器端渲染UI，在那里生成HTML，然后直接将HTML页面发送给UI。这种技术称为服务器端呈现。它确保更快的UI渲染，避免UI加载时间在浏览器窗口，因为页面已经创建\u0026amp;浏览器不需要做很多组装和渲染工作。\n服务器端呈现方法非常适合交付静态内容，比如WordPress博客。这也有利于搜索引擎优化，因为爬虫可以很容易地阅读生成的内容。\n然而，现代网站高度依赖于Ajax。在这样的网站中，特定模块或页面部分的内容必须在运行中获取和呈现\n因此，服务器端呈现并没有多大帮助。对于每一个ajax请求，该方法不只是向客户机发送所需的内容，而是在服务器上生成整个页面。这个过程会消耗不必要的带宽，也不能提供流畅的用户体验\n这样做的一大缺点是，一旦网站上并发用户的数量增加，就会给服务器带来不必要的负载\nClient-side rendering\n客户端渲染对于现代的基于ajax的动态网站来说是最好的\n尽管我们可以利用一种混合的方法，以最大限度地利用这两种技术。我们可以使用服务器端渲染首页\u0026amp;我们网站上的其他静态内容\u0026amp;使用客户端渲染动态页面\nCommunication Between the Client \u0026 the Server 客户端和服务器之间的通信模型 请求 - 响应模型\nHTTP协议\nREST API和API端点\n使用REST API的真实世界示例\nRequest-Response Model 请求-响应模型 客户端和服务器有一个请求-响应模型。客户端发送请求，服务器用数据响应。如果没有请求，就没有响应。\nHTTP Protocol HTTP协议 整个通信都是通过HTTP协议进行的。它是在万维网上交换数据的协议。HTTP协议是一个请求-响应协议，定义了信息如何在web上传输\n它是一个无状态协议，HTTP上的每个进程都是独立执行的，并且不知道以前的进程。\nREST API \u0026 API Endpoints REST API和API端点 从现代n层web应用程序的上下文来看，每个客户端都必须到达一个REST端点才能从后端获取数据。\n后端应用程序代码实现了一个REST-API，作为与外部世界请求的接口。每一个来自客户端的请求，无论是由企业写的请求，还是使用我们数据的第三方开发人员的请求，都必须到达rest端点来获取数据。\nReal World Example Of Using A REST API 使用REST API的真实例子 例如，假设我们想要编写一个应用程序来跟踪我们所有Facebook朋友的生日，并在活动日期前几天给我们发送提醒。\n要实现这一点，第一步将是获取我们所有Facebook好友的生日数据。\n我们将编写一个客户端，它将访问Facebook社交图API，这是一个REST-API来获取数据\u0026amp;然后在数据上运行我们的业务逻辑。\n实现基于rest的API有几个优点。为了更深入地了解它，让我们深入研究它。\nREST API REST API作为客户端和服务器之间通过HTTP进行通信的接口\nWHAT IS REST? 什么是REST API REST代表具象状态转移。它是一种用于实现web服务的软件架构风格。使用REST体系结构风格实现的Web服务称为RESTful Web服务\nREST API REST API是遵循REST体系结构约束的API实现。它充当一个接口。客户端和服务器之间的通信是通过HTTP进行的。REST API利用HTTP方法来建立客户机和服务器之间的通信。REST还允许服务器缓存响应，从而提高应用程序的性能。\n客户端和服务器之间的通信是一个无状态的过程。我的意思是，客户端和服务器之间的每一次通信都像是一次新的通信\n从先前的通讯中没有留下任何信息或记忆。因此，每次客户机与后端交互时，它也必须将身份验证信息发送给它。这使后端能够确定客户端是否被授权访问数据。\n通过实现REST API，客户端可以获得与之通信的后端端点。这完全解耦了后端和客户端代码\nREST Endpoint REST Endpoint表示服务的URL。例如，https://myservice.com/getuserdetails/ {username}是一个后端端点从服务中获取特定用户的用户详细信息。\n基于rest的服务将把这个url公开给它的所有客户端，以使用上述url获取用户详细信息\nDecoupling Clients \u0026 the Backend Service 解耦客户端和后端服务 随着端点的可用性，后端服务不必担心客户的实施。它只是呼唤其多个客户＆“嘿大家，这是资源/信息的URL地址需要。当你需要它时击中它。任何客户所需授权的客户访问资源可以访问它“\n开发人员可以针对不同的客户端(手机浏览器、桌面浏览器、平板电脑或API测试工具)使用不同的代码库进行不同的实现。引入新的客户端类型或修改客户端代码对后端服务的功能没有影响,这意味着客户端和后端服务是解耦的\nApplication Development Before the REST API在REST API之前的应用程序开发 在基于rest的API接口成为行业主流之前。我们经常将后端代码与客户端紧密耦合。JSP (Java服务器页面)就是其中的一个例子。\n我们总是将业务逻辑放在JSP标记中。当逻辑扩展到不同的层时，是什么让代码重构和添加新功能变得非常困难\n此外，在相同的代码库中，我们必须编写单独的代码/类进行处理来自不同类型客户端的请求。移动客户端的不同servlet以及用于基于Web的客户端的不同之一。\n在REST api被广泛使用之后，就不需要担心客户机的类型了。只需提供端点\u0026amp;响应通常包含JSON或任何其他标准数据传输格式的数据。客户将以任何他们想要的方式处理数据。\n这为我们减少了许多不必要的工作。此外，添加新客户也变得容易得多。我们可以引入多种类型的新客户端，而不考虑后端实现\n在当今的行业格局中，几乎没有没有REST API的在线服务。想要访问任何社交网络的公共数据?使用他们的 REST API\nAPI Gateway REST-API充当网关，作为进入系统的单一入口点。它封装了业务逻辑。处理所有客户端请求，在提供对应用程序资源的访问之前，负责授权、身份验证、清除输入数据和其他必要的任务\nHTTP Push \u0026 Pull -介绍 深入了解HTTP Push \u0026amp; Pull机制。我们知道，web上的大多数通信都是通过HTTP进行的，特别是涉及到客户端-服务器架构的时候。\n在客户机和服务器之间有两种数据传输模式。HTTP推送和HTTP拉取。让我们看看他们是什么和他们做什么。\nHTTP PULL 如前所述，对于每个响应，首先必须有一个请求。客户端发送请求，服务器用数据响应。这是HTTP通信的默认模式，称为HTTP PULL机制。\n客户端在需要时从服务器提取数据。它会一直这样做来获取更新的数据。\n这里需要注意的重要一点是，对服务器的每个请求和对它的响应都会消耗带宽。服务器上的每一次攻击都会损失业务资金，并增加服务器上的负载。\n如果每次客户机发送请求时，服务器上没有可用的更新数据怎么办\n客户机并不知道这一点，因此，它自然会不断地向服务器发送请求。这是不理想的\u0026amp;浪费资源。客户机的过度拉取有可能导致服务器宕机\nHTTP PUSH 为了解决这个问题，我们有基于HTTP PUSH的机制。在这种机制中，客户端向服务器发送对特定信息的请求，这只是第一次，在这之后，只要新的更新可用，服务器就会不断地向客户端推送更新。\n客户端不需要担心向服务器发送数据请求。这节省了大量的网络带宽，并逐级降低了服务器上的负载。\n这也被称为Callback。客户端打电话给服务器询问信息。服务器回应:“嘿!!”我现在还没有这方面的信息，但是我一有时间就会给你打电话。\n一个非常常见的例子就是用户通知。我们今天几乎在所有的网络应用中都有它们。每当后台发生事件时，我们都会得到通知\n客户端使用AJAX(异步JavaScript \u0026amp; XML)以HTTP Pull机制向服务器发送请求。基于HTTP Push的机制涉及多种技术，例如\nAjax长轮询 Web Sockets HTML5 event source 消息队列 streaming over HTTP HTTP Pull - Polling with Ajax 有两种方法可以从服务器中 pulling/fetching 数据。\n首先通过触发 sending an** HTTP GET请求**发送到服务器一个事件，例如通过单击网页上的按钮或任何其他元素。 另一种是使用AJAX在不需要人工干预的情况下，定期动态获取数据。 AJAX代表异步JavaScript和XML。它的名字说明了一切，它是用来添加异步行为的网页。\n正如我们在上面的插图中看到的，不是每次点击按钮都手动请求数据。AJAX使我们能够通过在规定的时间间隔内一次又一次地自动发送请求来从服务器获取更新后的数据\n在接收到更新后，web页面的特定部分会通过回调方法动态更新。我们在新闻和体育网站上经常看到这种行为，更新的事件信息会动态地显示在页面上，而不需要重新加载。\nAJAX使用XMLHttpRequest对象将请求发送到内置在浏览器中的服务器，并使用JavaScript更新HTML DOM\nAJAX通常与Jquery框架一起用于在UI上实现异步行为。\n这种定期从服务器请求信息的动态技术称为轮询。\nHTTP Push Live yo live（TTL） 在常规的客户机-服务器通信(即HTTP PULL)中，每个请求都有一个生存时间(Time to Live, TTL)。它可能是30到60秒，根据浏览器的不同而不同。\n如果客户端在TTL内没有收到来自服务器的响应，浏览器将终止连接\u0026amp;客户端必须重新发送请求，希望它能在这次TTL结束之前收到来自服务器的数据\n打开的连接会消耗资源\u0026amp;服务器在某个时间点上可以处理的打开的连接数量是有限制的。如果连接不关闭，并引入新的连接，随着时间的推移，服务器将耗尽内存。因此，TTL用于客户机-服务器通信。\n但是，如果我们确定响应将花费比浏览器设置的TTL更长时间呢\nPersistent Connection 持续连接 持久连接是指客户端和服务器之间的网络连接，它对进一步的请求和响应保持开放，而不是在一次通信后关闭。\n在本例中，我们需要客户端和服务器之间的持久连接。\n它有助于客户端和客户端之间的HTTP推送的通信服务器 Heartbeat Interceptors 心跳拦截器 现在您可能想知道，如果浏览器每隔X秒就终止打开的到服务器的连接，那么持久连接是如何实现的\n客户端和服务器之间的连接在Heartbeat Interceptors的帮助下保持打开状态\n这些只是客户机和服务器之间的空白请求响应，以防止浏览器终止连接。\n与HTTP Pull行为相比，持久连接消耗了大量的资源。但是在一些用例中，建立持久连接对应用程序的特性至关重要。\n资源密集 例如，与常规的web应用程序相比，基于浏览器的多人游戏在特定时间内具有相当多的请求-响应活动。\n从用户体验的角度来看，它倾向于在客户机和服务器之间建立一个持久的连接。\n长连接可以通过多种技术实现，如Ajax长轮询、Web Sockets、服务器发送事件等。\nHTTP Push-Based Technologies 基于　HTTP PUSH 的技术 Web Sockets 当我们需要一个持久的双向低延迟的数据流从客户端到服务器和返回时，Web Socket连接是理想的选择。\n这类应用的典型用例是即时通讯、聊天应用、实时社交流和基于浏览器的大型多人游戏，与常规web应用相比，这些游戏具有大量的读写功能\n使用Web Sockets，我们可以让客户端-服务器连接保持打开状态，只要我们想\nbi-directional data?继续使用Web Sockets。还有一件事，Web Sockets技术不能在HTTP上工作。它在TCP上运行。服务器和客户端都应该支持web sockets，否则它将无法工作。\nWebSocket API和引入WebSocket将socket引入Web是进一步阅读Web socket的很好的资源\nAJAX – Long Polling 长轮询介于Ajax和Web Sockets之间。在这种技术中，服务器不会立即返回响应，而是保存响应，直到它找到要发送给客户端的更新。\n与轮询相比，长轮询中的连接保持打开的时间更长一些。服务器不会返回空响应。如果连接断开，客户端必须重新建立与服务器的连接．\n与常规轮询机制相比，使用这种技术的好处是，从客户机发送到服务器的请求数量要少得多。这减少了大量的网络带宽消耗。\n长轮询可以用在简单的异步数据获取用例中，当你不想时不时地轮询服务器时。\nHTML5 Event Source API \u0026 Server Sent Events Server-Sent Events实现采用了一些不同的方法。当更新可用时，服务器将自动将数据推送给客户机，而不是客户机轮询数据。从服务器传入的消息被视为Events。\n通过这种方法，一旦客户端建立了与初始请求的连接，服务器就可以向客户端发起数据传输\n这有助于消除大量的空白请求-响应周期，从而逐级降低带宽消耗。\n为了实现服务器发送的事件，后端语言应该支持技术\u0026amp;在UI上HTML5事件源API用于接收来自后端数据。\n这里需要注意的重要一点是，一旦客户端与服务器建立了连接，数据流就只有一个方向，即从服务器到客户端。\nSSE是理想的场景，如Twitter的实时feed，在UI上显示股票报价，实时通知等\nThis is a good resource for further reading on SSE Streaming Over HTTP Streaming Over HTTP 理想的情况下，我们需要流的情况下，我们需要通过HTTP将大数据分成小块。这是可能的HTML5 \u0026amp; JavaScript Streaming API。\n该技术主要用于流媒体内容，如大型图像、视频等，通过HTTP。\n因此，我们可以观看部分下载的视频，因为它继续下载，通过播放下载的块在客户端上\n为了流数据，客户端和服务器都同意遵循一些流设置。这有助于他们在HTTP请求-响应模型中确定流的开始和结束时间\nYou can go through this resource for further reading on Stream API 每一种技术都有特定的用例，Ajax通过定期轮询服务器来动态更新网页。\n长轮询(Long polling)的连接打开时间略长于轮询机制。\nWeb Sockets具有双向的数据流，而SSE促进了从服务器到客户端的数据流\nStreaming over HTTP有助于大型对象(如多媒体文件)的流媒体。\nScalability 我很确定，在软件开发领域，您已经多次遇到这个词。可伸缩性。它是什么?为什么它如此重要?为什么每个人都在谈论它?扩展系统很重要吗?当你的应用或平台出现显著的流量增长时，你的计划或应急措施是什么.例如:在web应用程序、分布式系统或云计算环境中，可伸缩性意味着什么?\n什么可伸缩性 可伸缩性意味着应用程序能够在不牺牲延迟的情况下处理和承受增加的工作负载\n例如，如果你的应用程序需要x秒来响应用户的请求。在你的应用程序上，响应每一个并发的用户请求需要相同的x秒。\n应用程序的后端基础设施不应该在一百万并发请求的负载下崩溃。在承受较大的流量负载时，它应该具有良好的可伸缩性，并且应该保持系统的延迟\nLatency 延迟 延迟是系统响应用户请求所需的时间。假设你向一个应用程序发送一个请求来获取一张图片\u0026amp;系统需要2秒的时间来响应你的请求。系统的延迟时间为2秒\n最小延迟是有效的软件系统所追求的。无论系统上的流量负载增加多少，延迟都不应该增加。这就是可伸缩性。\n如果延迟保持不变，我们可以说，应用程序可以随着负载的增加而很好地扩展，并且具有高度的可伸缩性\n让我们从Big-O符号的角度来考虑可伸缩性。理想情况下，系统或算法的复杂度应该是O(1)，它是一个常数时间，就像键值数据库一样\n一个复杂度为O(n²)的程序，其中n是数据集的大小，是不可伸缩的。随着数据集的增加，系统将需要更多的计算能力来处理这些任务。\n####　Measuring Latency测量延迟\n延迟是由用户在网站上采取的动作之间的时间差来衡量的，它可以是一个事件，比如点击一个按钮，以及系统对该事件的反应。\n这个延迟一般分为两部分:\n网络延迟 应用程序的延迟 Network Latency 网络延迟\n网络延迟是指网络将一个数据包从a点发送到b点所花费的时间。网络应该有足够的效率来处理网站上增加的流量负载。为了减少网络延迟，企业使用CDN，并试图在全球各地部署服务器，尽可能接近最终用户。\nApplication Latency应用程序延迟\n应用程序延迟是应用程序处理用户请求所需的时间。有很多方法可以减少应用程序延迟。第一步是在应用程序上运行压力和负载测试，并扫描导致系统整体变慢的瓶颈。\n为什么低延迟对于在线服务如此重要？ 延迟在决定在线业务是否赢得或失去客户方面起着重要作用。没有人喜欢在网站上等待回复。有一个众所周知的说法，如果你想测试一个人的耐心，给他一个缓慢的互联网连接.\n如果访问者在规定的时间内得到回复，那就太好了，否则他就会转到另一个网站去.\n大量的市场研究表明，应用程序的高延迟是客户离开网站的一个重要因素。如果涉及到资金，零延迟是企业想要的，只有在这是可能的情况下。\n想想大型多人在线MMO游戏，游戏内事件的轻微延迟会破坏整个游戏体验。一个拥有高延迟网络连接的玩家将会有一个较慢的反应时间，尽管他拥有一个竞技场中所有玩家的最佳反应时间.\n算法交易服务需要在几毫秒内处理事件。金融科技公司拥有运行低延迟交易的专用网络。普通的网络无法做到这一点。\n华为和Hibernia Atlantic公司在2011年开始铺设横跨大西洋的伦敦和纽约之间的光纤连接电缆，这一事实让我们认识到低延迟的重要性。3亿美元，为交易员节省了6毫秒的延迟。\nTypes Of Scalability 应用程序的扩展性需要坚实的计算能力。这些服务器应该足够强大，能够处理增加的流量负载\n横向扩展(水平扩展) 水平扩展，也称为向外扩展，意味着向现有硬件资源池添加更多的硬件。这增加了整个系统的计算能力\n现在，增加的流量流入可以很容易地处理增加的计算能力\u0026amp;假设我们有无限的资源，我们可以水平地扩展多少实际上没有限制。我们可以不断增加服务器，建立一个又一个数据中心．水平扩展也为我们提供了实时动态扩展的能力，随着我们网站的流量在一段时间内的增加和减少，而不是垂直扩展，这需要预先规划和规定的时间来完成。\n垂直扩展 垂直扩展意味着为服务器添加更强大的功能。让我们假设你的应用由一个拥有16g内存的服务器托管。为了处理增加的负载，可以将RAM增加到32g。您已经对服务器进行了垂直伸缩\n理想情况下，当应用的流量开始增长时，第一步应该是垂直扩展。垂直扩展也称为向上扩展。但在垂直扩展时，我们能做的也就这么多了。对于一台服务器，我们所能增加的容量是有限的\n在这种类型的扩展中，我们增加了运行应用的硬件的能力。这是最简单的扩展方式，因为它不需要任何代码重构，不需要任何复杂的配置和其他东西。我将在下一课中进一步讨论，当我们水平扩展应用程序时，为什么需要代码重构．\n####　云弹性Cloud Elasticity\n云计算在行业中如此流行的最大原因是它能够动态地向上和向下扩展。只使用和支付网站所需资源的能力成为了一种趋势，原因显而易见。如果站点有一个沉重的流量流入更多的服务器节点被添加\u0026amp;当它不动态添加的节点被删除。\n这种方法每天为企业节省了大量的钱。这种方法也被称为云弹性。它表明了对原始基础设施计算能力的拉伸和回归。\n在后台有多个服务器节点也可以帮助网站保持在线，即使一些服务器节点崩溃。这就是所谓的高可用性。我们将在接下来的课程中讲到。\n适合自己应用的扩展方法 ####　垂直和水平扩展的利与弊代码怎么样?\n垂直扩展比水平扩展更简单，因为我们不需要修改代码，也不需要做任何复杂的分布式系统配置。与管理分布式环境相比，它需要更少的管理、监视和管理工作。 垂直扩展的一个主要缺点是可用性风险。服务器很强大，但数量很少，总有宕机的风险\u0026amp;整个网站离线，当系统水平扩展时不会发生这种情况。它变得更加可用。 当需要在多台机器上运行时，为什么代码需要更改? 如果您需要在分布式环境中运行代码，那么它需要是无状态的。代码中不应该有任何状态。这是什么意思呢\nno static instance in the class. static instance (静态实例)保存在了应用程序数据，如果Aparticular Server下线，所有静态数据/状态都会丢失。该应用程序留在了一个状态不一致。\n今天的开发团队从一开始就采用分布式微服务架构\u0026amp;工作负载应该部署在云上。因此，工作负载(workloads)本质上是动态水平扩展的。\n水平扩展的好处包括不限制增加硬件容量。随着节点和数据中心在全球各地建立，数据可以跨不同的地理区域复制.\n哪种可扩展性方法适合你的应用 如果你的应用程序是一个实用程序或工具，预计接收最小的一致流量( consistent traffic)，它可能不是关键任务。例如，一个组织的内部工具或类似的东西。 当您知道流量负载不会显著增加时，可以继续进行垂直扩展.一台服务器就足够管理流量了. 如果你的应用是面向公众的社交应用，如社交网络、健身应用或类似的应用，那么它的流量预计将在不久的将来呈指数增长。高可用性和水平可伸缩性对您都很重要.构建并将其部署到云上\u0026amp;从一开始就要牢记水平可伸缩性。 Primary Bottlenecks that Hurt the Scalability Of Our Application 影响应用可扩展性的主要瓶颈\n数据库 考虑一下，我们的应用程序看起来是架构良好的。一切看起来不错。工作负载在多个节点上运行，并具有水平扩展的能力。但是，数据库是一个糟糕的单一整体，只有一台服务器负责处理来自工作负载的所有服务器节点的数据请求。\n这种情况是一个瓶颈。服务器节点工作得很好，在一个时间点上有效地处理数百万个请求，但这些请求的响应时间和应用程序的延迟非常高，因为只有一个数据库。它能处理的也就这么多了.\n就像工作负载可伸缩性一样，数据库也需要良好的可伸缩性。合理利用数据库分区、分片，使用多个数据库服务器使模块高效。\n应用程序架构(Application Architecture) 设计不良的应用程序体系结构可能成为一个主要的瓶颈。\n一个常见的架构错误是在需要的地方不使用异步进程和模块，而是将所有进程按顺序调度\n例如，如果用户在门户上载下载文档，则诸如发送给用户确认电子邮件的任务，向所有人发送通知等,应该异步地完成上传事件的订阅者/侦听器\n这些任务应该转发到消息服务器，而不是顺序地执行所有任务\u0026amp;让用户等待所有任务。\n####　在应用层使用缓存\n缓存可以部署在应用程序的几个层\u0026amp;它可以逐级加快响应时间。它拦截到数据库的所有请求，减少了数据库的总体负载。在整个应用程序中竭尽全力地使用缓存，以显著提高速度\n####　优化配置与设置负载均衡\n负载均衡器是我们的应用程序的入口。使用太多或太少会影响我们应用程序的延迟。\n不要将业务逻辑添加到数据库 不管别人给出什么理由，我从来都不喜欢添加业务逻辑到数据库。数据库不是存放业务逻辑的地方。它不仅使整个应用程序紧密耦合。它给它增加了不必要的负荷。\n想象一下，当迁移到一个不同的数据库时，需要重构多少代码。\n没有选择正确的数据 选择正确的数据库技术对企业来说至关重要。需要事务和强一致性?选择一个关系数据库。如果可以的话没有强一致性而需要水平可伸缩性的情况下选择一个NoSQL数据库。\n####　在代码级别\n这并不令人惊讶，但是低效率和糟糕的代码有可能破坏生产环境中的整个服务，其中包括:\n使用不必要的循环，嵌套环。 写得紧密耦合的代码。 在编写代码时不关注大o复杂性。是准备在生产中做了很多消防措施。 如何改进和测试应用程序的可伸缩性 下面是一些优化web应用程序性能的常见策略和最佳策略。如果应用程序是性能优化的，它可以承受更多的流量负载和更少的资源消耗，而不是一个应用程序的性能优化。\n现在你可能会想，为什么我要谈论性能，而不是可伸缩性.应用程序的性能与可伸缩性直接成正比。如果一个应用程序的性能不好，那么它肯定不能很好地扩展。这些最佳实践甚至可以在对应用程序进行实际的预生产测试之前实现。\n#####　优化应用程序的性能，使其能够更好地伸缩\nProfiling\n运行应用程序分析程序，代码分析程序。查看哪些进程花费的时间太长，消耗了太多的资源。找出瓶颈。摆脱他们。\n分析是对代码的动态分析。它帮助我们测量我们的代码的空间和时间复杂性，并使我们能够找出问题，如并发错误，内存错误和程序的健壮性和安全性。这个Wikipedia资源包含一个行业中使用的性能分析工具的很好的列表\nCaching\n明智的缓存。缓存无处不在。缓存所有静态内容。只有在确实需要时才访问数据库。尝试从缓存处理所有读请求。使用透写缓存。\n**CDN (Content Delivery Network) **\n使用CDN。由于来自请求用户的数据很接近，使用CDN进一步减少了应用程序的延迟。\nData Compression\n压缩数据。使用apt压缩算法压缩数据。以压缩格式存储数据。由于压缩数据占用的带宽更少，因此客户端下载数据的速度会更快。\n避免不必要的客户端服务器请求( Avoid Unnecessary Client Server Requests )\n避免客户端和服务器之间不必要的往返。尝试将多个请求合并到一个请求中。对于应用程序的性能，这些是我们应该记住的一些事情。\nTesting the Scalability Of Our Application(测试应用程序的可伸缩性) 一旦我们完成了应用程序的基本性能测试，就该进行容量规划、提供适当数量的硬件和计算能力了。\n测试应用程序可伸缩性的正确方法在很大程度上取决于我们系统的设计。没有明确的公式。测试可以在硬件和软件两级执行。不同的服务和组件需要单独和集体进行测试.\n在可扩展性测试中，会考虑不同的系统参数，如CPU使用情况、网络带宽消耗、吞吐量、在规定时间内处理的请求数、延迟、程序内存使用情况、系统在重负载下的最终用户体验等。\n在这个测试阶段，模拟流量被路由到系统，以研究系统在重负载下如何工作，应用程序在重负载下如何扩展。意外事件是为不可预见的情况而计划的。\n根据预期的流量，提供适当的硬件和计算能力，以在一定的缓冲区内平稳地处理流量。\n在应用程序上运行了几个负载和压力测试。如果您使用的是Java生态系统，像JMeter这样的工具非常适合在应用程序上运行并发用户测试。有很多基于云的测试工具可以帮助我们通过点击几下鼠标来模拟测试场景。\n企业一直在测试可伸缩性，以使他们的系统为处理流量激增做好准备。如果是体育网站，就要为运动会做好准备;如果是电子商务网站，就要为节日做好准备。\nHigh Availability(高可用) 高可用性计算基础设施是当今计算行业的标准。更重要的是，当涉及到云平台时，它是使运行在其上的工作负载具有高可用性的关键特性。\n什么是高可用 高可用性(也称为HA)是系统保持在线的能力，尽管在基础设施级别上出现了实时故障。\n高可用性确保服务的正常运行时间比正常时间长得多。它提高了系统的可靠性，确保最小停机时间。\n高可用性系统的唯一任务是保持在线和保持联系。一个非常基本的例子是有备用发电机，以确保在任何停电情况下持续供电。\n在行业中，HA通常以百分比表示。例如，当系统处于99.99999%的高可用状态时，这仅仅意味着服务将启动总主机时间的99.99999%。您可能经常在云平台的SLA(服务水平协议)中看到这一点\n高可用性对在线服务有多重要 如果社交应用出现一小段时间的下滑，那么它可能不会对商业产生太大的影响。然而，有些关键任务系统，如飞机系统、航天器、采矿机、医院服务器、金融股票市场系统，在任何时候都无法承受崩溃。毕竟，生命依赖于它。\n关键任务系统的顺利运作依赖于持续与其网络/服务器的连接。这些实例没有超级可用的基础设施就无法做到。\n此外，没有任何服务愿意宕机，不管它是否苛刻。\n为了满足高可用性的需求，系统被设计成容错的，它们的组件是冗余的。\n系统故障原因分析 在深入研究高可用性系统设计、容错和冗余之前。我将首先讨论系统失败的常见原因。\nSoftware Crashes软件崩溃\n我相信你对软件崩溃很熟悉。应用程序总是崩溃的，无论是在手机上还是在台式机上。腐败的软件文件。还记得蓝屏蓝屏的死亡窗口吗?操作系统崩溃，内存占用，进程无响应。同样，运行在云节点上的软件也会不可预测地崩溃，并导致整个节点瘫痪。\nHardware Failures硬件故障\n系统故障的另一个原因是硬件崩溃。CPU过载，RAM，硬盘故障，节点故障。网络中断。\nHuman Errors人因失误\n这是系统故障的最大原因。有缺陷的配置。谷歌犯了一个小小的网络配置错误，导致日本几乎一半的互联网瘫痪。这是一篇有趣的文章。\nPlanned Downtime计划停机\n除了计划外的崩溃，还有计划内的停机时间，包括日常维护操作、软件补丁、硬件升级等。\n这些是导致系统故障的主要原因，现在让我们讨论如何设计高可用性系统来克服这些系统停机的场景。\nFault Tolerance(容错) 有几种方法可以实现HA。其中最重要的是使系统具有容错能力。\n什么是容错 容错是系统在遭受打击后仍能正常运行的能力\n系统配备了容错系统来处理故障。容错是设计生命关键系统的基本要素。\n几个实例/节点，其中几个，运行服务脱机且一直反弹。在这些内部故障的情况下，系统可以降低水平工作，但它不会完全下线。\n系统容错的一个非常基本的例子是社交网络应用程序。在后台节点故障的情况下，app的一些服务，如图片上传、点赞等可能会停止工作。但是整个应用程序还是会运行的。这种方法在技术上也被称为失败软件(Fail Soft)\n设计高可用容错服务体系结构 为了在应用程序级别实现高可用性，整个大规模服务在体系结构上被分解为更小的松散耦合的服务，称为微服务(micro-services)。\n将一个庞大的庞然大物分割成几个微服务有很多好处，正如它所提供的那样:\n更轻松的管理 更容易开发 轻松添加新功能 易于维护 高可用性 每一个微服务都承担着运行应用程序不同功能的责任，比如图片上传、评论、即时消息等.\n因此，即使一些服务下线，应用程序作为一个整体仍然是可用的\nredundancy(冗余) Redundancy Active-Passive HA Mode(主备冗余HA模式) 冗余是复制组件或实例，让它们处于备用状态，以便在活动实例宕机时接管。这是一种故障安全的备份机制。\n在上图中，您可以看到实例处于活动状态\u0026amp;处于备用状态。在任何活动实例宕机的情况下，备用实例将接管\n这种方法也称为主备HA模式。一组初始节点是活动的，一组冗余节点是被动的，处于备用状态。在出现故障时，主动节点会被被动节点替换。\n像GPS、飞机、通信卫星这样的系统都是零停机的。这些系统的可用性是通过使组件冗余来保证的。\nGetting Rid Of Single Points Of Failure(消除单点故障) 分布式系统之所以如此流行，完全是因为有了它们，我们可以摆脱单片架构中存在的单点故障。\n大量的分布式节点相互协作，以实现单一的同步应用程序状态。\n当部署了这么多冗余节点时，系统中就不会出现单点故障。如果某个节点出现故障，冗余节点会代替它。因此，整个系统没有受到影响\n应用程序级别的单点故障意味着瓶颈。我们应该在性能测试中发现瓶颈，并尽快摆脱它们。\n#####　Monitoring \u0026amp; Automation\n系统应该实时监控，以检测任何瓶颈或单点故障。自动化使实例能够在没有任何人工干预的情况下进行自我恢复。它给了这些例子自愈的力量。\n此外，系统变得足够智能，可以根据需求动态地添加或删除实例\n由于最常见的故障原因是人为错误，自动化有助于在很大程度上减少故障。\nReplication Active-Active HA Mode(复制双活HA模式) 复制意味着让许多相似的节点一起运行工作负载。不存在备用或被动实例。当一个或几个节点宕机时，剩余的节点将承担服务的负载。可以将此视为负载平衡\n负载平衡。这种方法也称为Active Active High Availability模式。在这种方法中，系统的所有组件在任何时间点都是活动的。\nGeographical Distribution of Workload工作量的地域分布 作为自然灾害、数据中心区域停电和其他大规模故障的应急措施，工作负载分布在世界各地不同地理区域的不同数据中心。\n这避免了数据中心上下文中的单点故障。此外，由于数据与用户的距离较近，延迟也大大减少。\n所有高可用容错设计决策都是由系统的重要性决定的。组件失败的几率是多少?等。\n企业经常使用多云平台来部署他们的工作负载，以确保进一步的可用性。如果一家云服务提供商出了问题，他们还有另一家可以恢复\nHigh Availability Clustering(高可用的集群) 高可用性集群也称为故障转移集群，它包含一组相互连接运行的节点，以确保服务的高可用性。\n集群中的节点通过称为Heartbeat的私有网络连接，该网络持续监视集群中每个节点的健康状况和状态。\n集群中所有节点的单一状态是通过共享的分布式内存和分布式协调服务实现的，比如Zookeeper\n为确保可用性，HA集群使用多种技术，如磁盘,镜像/ RAID冗余独立磁盘阵列，网络连接冗余，电力冗余等。网络连接是冗余的，所以如果主网络出现故障，备用网络就会接管。\n多个HA集群一起运行在一个地理区域，确保最小停机时间和持续服务。\nmonolithic architecture(单片应用结构) 如果应用程序将整个应用程序代码包含在一个代码库中，则该应用程序具有单一的体系结构。\n单片应用是一种独立的、单层的软件应用，与微服务体系结构不同，微服务体系结构中不同的模块负责运行应用程序中各自的任务和特性\n在一个单一的web应用程序中，应用程序、UI、业务、数据访问等所有不同的层都在同一个代码库中。我们有控制器(Controller)，然后是服务层(service)，类接口的实现，业务逻辑放在对象域模型中,在服务中服务中的一点，业务逻辑和存储库/ DAO [数据访问对象]一起进行整合.\n与微服务架构相比，单块应用更容易构建、测试和部署。有时候，在业务的初始阶段，团队会选择继续使用单片架构，然后打算扩展到分布式的微服务架构.\n在目前的计算环境中，应用程序都是在云上构建和部署的。一个明智的决定是，从一开始就选择松散耦合的无状态微服务体系结构，如果您预计未来的发展速度会相当快的话。\n因为重写东西是有代价的。在紧密耦合的架构中剥离一些东西和重写一些东西需要大量的资源和时间。\n另一方面，如果你的需求很简单，为什么要写一个微服务体系结构呢?同时运行不同的模块并不是在公园里散步。\nPros Of Monolithic Architecture(单片架构的优点) Simplicity\n单片式应用程序开发、测试、部署、监控和管理都很简单，因为所有的东西都驻留在一个存储库中。处理不同的组件、让它们彼此协同工作、监控几个不同的组件和材料并不复杂。事情很简单。\n单片架构的缺点 Continuous Deployment持续部署\n对于单片应用来说，连续部署是一件痛苦的事情，因为即使是连续部署，也需要对整个应用程序进行重新部署。\nregression testing回归测试\n这样做的缺点是，在部署完成后，我们需要对整个应用程序进行彻底的回归测试，因为各层之间是紧密耦合的。一个层中的变化会显著影响其他层。\nSingle Points Of Failure单点失败\n单片应用程序只有一个故障点。如果任何一个层有错误，它有可能使整个应用程序崩溃。\nScalability Issues伸缩问题\n灵活性和可伸缩性在单一应用中是一个挑战，因为在一个层面上的改变通常需要在所有层面上进行改变和测试。随着代码大小的增加，事情可能会变得有点棘手。\nCannot Leverage Heterogeneous Technologies不能利用异构技术\n由于兼容性问题，使用单一体系结构构建复杂的应用程序非常困难，因为在单个代码库中使用异构技术非常困难。在一个代码库中同时使用Java和NodeJS是很棘手的.\nNot Cloud-Ready, Hold State不是云就绪，是保持状态\n通常，单片应用程序没有云准备好，因为它们在静态变量中保持状态。一个应用程序要想成为云原生应用，要想在云上平稳地工作和一致，就必须是分布式的和无状态的\n什么时候应该选择单片架构 单片式应用程序最适合需求非常简单的用例，应用程序被期望处理有限的流量。这方面的一个例子是一个组织的内部税务计算应用程序或类似的开放公共工具。\n在这些用例中，企业确定用户基础和流量不会随着时间的推移呈指数级增长.\n也有开发团队决定从单片架构开始，然后扩展到分布式微服务架构的例子.\n这有助于他们根据需要一步一步地处理应用程序的复杂性。这正是LinkedIn所做的\nMicroservice architecture 在微服务体系结构中，不同的功能/任务被分成将相应的 模块/codebbases 分开,彼此整体形成大型服务\n还记得单一责任和关注点分离原则吗?这两个原则都应用于微服务体系结构中\n想象一下在一个存储库中容纳每个特性。事情会有多复杂?这将是一场维护噩梦。\n此外，由于项目很大，它将由几个不同的团队管理。当模块是独立的时，它们可以被分配到各自的团队中，从而使开发过程更加顺利。\n我提到可扩展性了吗?为了扩大规模，我们需要把东西分开。当我们无法进一步扩大规模时，我们需要扩大规模。微服务体系结构天生就是可伸缩的。\n下图代表了一个微服务体系结构\n理想情况下，每个服务都有一个独立的数据库，没有单点故障和系统瓶颈。\n微服务的优点 No Single Points Of Failure 没有单点故障\n由于微服务是松散耦合的体系结构，因此不存在单点故障。即使一些服务中断，应用程序作为一个整体仍然是正常的。\nLeverage the Heterogeneous Technologies 利用异构技术\n每个组件都通过REST API Gateway接口进行交互。这些组件可以利用多语言持久性体系结构和其他异构技术，如Java、Python、Ruby、NodeJS等\nPolyglot持久性是在一个体系结构中同时使用多种数据库类型，如SQL、NoSQL。我将在数据库课中详细讨论它\nIndependent \u0026amp; Continuous Deployments 独立和持续部署\n部署可以是独立的和连续的。我们可以为每一个微服务建立专门的团队，它可以独立扩展而不影响其他服务\n#####　微服务的缺点\nComplexities In Management管理的复杂性\n微服务是一个分布式环境，其中有很多节点一起运行。管理和监控他们变得复杂。我们需要安装额外的组件来管理微服务，比如一个像Apache Zookeeper这样的节点管理器，一个用于监控节点的分布式跟踪服务等等。我们需要更多的技术资源，也许需要一个专门的团队来管理这些服务\nNo Strong Consistency 没有强烈的一致性\n在分布式环境中很难保证强一致性。最终，节点之间的事情是一致的。这种局限性是分布式设计造成的。\nWhen Should You Pick A Microservices Architecture 微服务架构最适合复杂的用例，也最适合那些像社交网络应用一样期待流量在未来呈指数增长的应用。\n一个典型的社交网络应用程序有各种各样的组件，如消息，实时聊天，实时视频流，图像上传，喜欢，分享功能等\n在一个代码库中编写每个特性，很快就会变得一团糟。\n所以，到目前为止，在整体服务和微服务的背景下，我们已经经历了三种方法\n选择单一架构 选择微服务架构 从单片架构开始，然后扩展到微服务架构。 我建议，简单一点，彻底理解需求。了解情况，只在你需要的时候做一些事情，并不断迭代地改进代码。这是正确的方法。\nIntroduction \u0026 Types of Data(数据的介绍和类型) 数据库是持久化数据所需的组件。数据可以有多种形式:结构化、非结构化、半结构化和用户状态数据\n在深入研究数据库之前，让我们先快速了解一下数据的分类\nStructured Data\n结构化数据是符合特定结构的数据类型，通常以规范化的方式存储在数据库中。\n在处理结构化数据之前，不需要在其上运行任何类型的数据准备逻辑。可以对这类数据进行直接交互\n结构化数据的一个例子是存储在数据库行中的客户的个人详细信息。客户id将是整数类型，名称将是带有一定字符限制的字符串类型，等等\n所以，有了结构化数据，我们知道我们在处理什么。因为客户名是String类型的，所以不用太担心错误或异常，我们可以在它上面运行String操作。\n结构化数据通常由查询语言(如SQL(结构化查询语言))管理。\nUnstructured Data\n非结构化数据没有明确的结构。它通常是异构类型的数据，包括文本、图像文件、视频、多媒体文件、pdf、Blob对象、word文档、机器生成的数据等。\n这类数据在数据分析中经常遇到。在这里，数据从多个来源(如物联网设备、社交网络、门户网站、行业传感器等)流入分析系统\n我们不能直接处理非结构化数据。最初的数据是非常原始的，我们必须让它通过一个数据准备阶段，根据一些业务逻辑将其分离，然后在其上运行分析算法\nSemi-structured Data(半结构化数据)\n半结构化数据是结构化和非结构化数据的混合体。半结构化数据通常以XML或JSON等数据传输格式存储，并根据业务需求进行处理\nUser state\n包含用户状态的数据是用户在网站上执行的活动信息\n例如，在浏览一个电子商务网站时，用户会浏览几个产品类别，改变偏好，在价格下降的提醒列表中添加几个产品。\n所有这些活动都是用户状态。因此，下次当用户登录时，他可以从上次停止的地方继续。这不会让人觉得你是在重新开始\u0026amp;之前的活动都已经消失了。\n存储用户状态提高了浏览体验和业务的转化率。所以，现在我们清楚了不同类型的数据。让我们看看不同类型的数据库。\n有多种不同类型的数据库，它们具有特定的用例。为了对数据库领域有一个全面的了解，我们将快速地浏览它们。\nRelational Database 这是行业中最常见和最广泛使用的数据库类型。关系数据库保存包含关系的数据。一对一，一对多，多对多，多对一等等。它有一个关系数据模型。SQL是用于与关系数据库交互的主要数据查询语言。MySQL是关系数据库中最流行的例子。好了! !我明白，但什么是关系\nRelational\n假设你是一个顾客，从网上书店买了五本不同的书。当您在书店上创建一个帐户时，您将被分配一个客户id，例如C1。现在C1[You]链接到5本书B1, B2, B3, B4, B5.\n这是一对多的关系。在最简单的形式中，一个表将包含所有客户的详细信息\u0026amp;另一个表将包含库存中的所有产品。客户表中的一行将对应于产品库存表中的多行.\n在从数据库中提取id为C1的用户对象时，我们可以通过关系模型轻松地找到C1购买了哪些书\ndata consistency(数据一致性) 此外，关系数据库还确保以规范化的方式保存数据.在非常简单的术语中，归一化数据意味着一个唯一的数据实体只在一个地方(表)中,它以最简单的原子形式存在，并且不会在整个数据库中传播。\n这有助于维护数据的一致性。以后，如果我们想更新数据，我们只在那个地方更新每个取回操作都会得到更新后的数据。\n将数据分散到整个数据库的不同表中。我们必须随时更新实体的新值。这很麻烦，而且会变得不一致。\nACID Transactions 除了规范化和一致性，关系数据库也保证了ACID事务\nACID – Atomicity, Consistency, Integrity, Durability.(原子性、一致性、完整性、持久性) acid事务意味着系统中的事务发生，例如，一个金融交易，它将完美地执行，而不影响任何其他流程或交易\n事务完成后，系统将有一个新的持久一致的状态。或者，如果事务期间发生了任何错误，比如一个小系统故障，整个操作就会回滚\n当事务发生时，系统状态a为初始状态，事务结束后系统状态B为最终状态。这两种状态都是一致和持久的。\n关系数据库确保系统在任何时候都处于状态A或状态B。没有中间状态。如果有任何故障，系统返回到状态A。如果事务顺利执行，系统就会从状态A过渡到状态B。\n####　什么时候应该选择关系数据库\n如果你正在编写一个股票交易、银行或金融应用程序，或者你需要存储大量的关系，例如，在编写一个像Facebook这样的社交网络时。然后，您应该选择一个关系数据库。这是为什么\n当你选择关系数据库，你在选择这些东西\nTransactions \u0026amp; Data Consistency事务与数据一致性\n如果你正在编写一个与金钱或数字有关的软件，那么交易，ACID，数据一致性对你来说是非常重要的\n关系数据库在事务和数据一致性方面表现突出。他们遵守ACID规则，已经存在了很长一段时间并且是经过战斗考验的\nLarge Community 大社区\n此外，他们有一个更大的社区。经验丰富的技术工程师很容易找到，你不需要花太多的时间去寻找他们\nStoring Relationships存储关系\n如果你的数据有很多关系，比如你的哪些朋友住在一个特定的城市?你的哪个朋友已经在你今天打算去的餐厅吃过饭了?等。没有什么比关系数据库更适合存储这类数据了.\n关系数据库是用来存储关系的。他们已经尝试和测试，并被行业巨头使用，如Facebook作为主要面向用户的数据库。\nPopular Relational Databases流行的关系数据库\n行业中使用的一些流行的关系数据库是MySQL——它是一个开源的关系数据库，用C和c++编写，自1995年以来就出现了.\n其他的则是Microsoft SQL Server，这是微软用C、c++编写的一种专有的RDBMS。MariaDB, Amazon Aurora，谷歌Cloud SQL等\nNoSQL Databases NoSQL数据库没有SQL，它们更像是为Web 2.0构建的基于json的数据库。它们是为高频读写而构建的，通常需要在社交应用程序中，如Twitter、实时体育应用程序、在线大规模多人游戏等。\nNoSQL数据库与关系数据库的区别 现在，一个明显的问题会出现在我们的脑海中:当关系数据库运行良好，经过战斗测试，被业界接受，并且没有重大的持久性问题时，为什么需要NoSQL数据库呢\nScalability\n基于SQL的关系数据库的一个很大的限制是可伸缩性。扩展关系数据库并不是一件小事。它们必须分片或复制，才能在集群中平稳运行。简而言之，这需要仔细的思考和人为的干预.\n相反，NoSQL数据库能够动态地添加新的服务器节点并继续工作，无需任何人工干预，只需轻轻一敲手指.\n如今的网站需要快速的读写能力。社交网络上有数百万，甚至数十亿的用户相互联系\n每微秒都会产生大量数据，我们需要一个基础设施来管理这种指数级增长。\nClustering\nNoSQL数据库被设计成在集群上智能运行。我说的智能，是指在人类干预最小的情况下。\n今天，服务器节点甚至具有自我修复能力。很流畅。基础设施足够智能，可以从故障中自我恢复。\n尽管所有这些创新并不意味着老式的关系数据库不够好\u0026amp;我们不再需要它们了\n关系数据库仍然很有用，而且仍然很受欢迎。它们有一个特定的用例。我们已经在“何时选择关系数据库”一节中讨论了这个问题。\n此外，NoSQL数据库不得不牺牲强大的一致性、ACID事务和更多的东西来横向扩展集群和跨数据中心\n使用NoSQL数据库的数据更趋向于最终一致性，而不是强一致性.\n因此，这显然意味着NoSQL数据库不是解决问题的灵丹妙药。这是完全好的，我们不需要银弹。我们不是在猎杀狼人，我们是在完成一项更艰巨的任务，将世界连接到网上.\n在接下来的课程中，我将详细讨论NoSQL数据库的底层设计，以及为什么它们必须牺牲强一致性和事务。\nNoSQL数据库的特点 在介绍中，我们了解到NoSQL数据库是构建在分布式环境中的集群上运行的，支持Web 2.0网站。现在，让我们来看看NoSQL数据库的一些特性。\nNoSQL数据库的优点 首先，学习曲线比关系数据库要短。在使用关系数据库时，我们会花大量的时间学习如何设计良好的标准化表、建立关系、尽量减少连接等\nSchemaless\n在设计关系数据库的模式时，需要非常关注，以避免在将来遇到任何问题\n可以将关系数据库看作一个严格的校长。所有的东西都要放在合适的地方，要整洁，东西要一致。但是NoSQL数据库有点放松。\n没有严格强制的模式，可以随意处理数据。你总是可以改变东西，传播东西。实体没有关系。因此，事情是灵活的\u0026amp;你可以按照自己的方式去做。\n不一定! !这种灵活性有利有弊。它非常灵活，对开发人员友好，没有连接和关系等，这使得它很好。\nNoSQL数据库的缺点 inconsistency 不一致性\n但它同时也带来了实体不一致的风险。由于实体分布在整个数据库中，因此必须在所有地方更新实体的新值。\n如果不这样做，则会导致实体不一致。这对于关系数据库来说不是问题，因为它们保持数据的规范化。一个实体只驻留在一个地方。\n不支持ACID事务\n此外，NoSQL分布式数据库不提供ACID事务。虽然有一些人主张这样做，但并没有得到全球的支持。它们只是被限制在一个特定的实体层次结构或一个小区域，在那里它们可以锁定节点来更新它们。\n结论 我第一次使用NoSQL数据存储是使用谷歌云数据存储。\n我觉得一个好处是，我们不必是数据库设计方面的专家才能编写应用程序。事情相对简单，因为没有管理连接、关系、n+1查询问题等的压力。\n只需用它的Key获取数据。你也可以称它为实体的id。这是一个常量O(1)操作，这使得NoSQL数据库非常快。\n在过去，我设计了很多具有复杂关系的MySQL数据库模式。我认为使用NoSQL数据库要比使用关系数据库容易得多\n如果我们需要对后端进行一些额外的调用，以在单独的调用中获取数据，这没什么区别。我们总是可以缓存频繁访问的数据来克服这个问题\nPopular NoSQL Databases 业界常用的NoSQL数据库有MongoDB、Redis、Neo4J、Cassandra。\n何时选择NoSQL数据库 Handling A Large Number Of Read Write Operations处理大量读写操作\n当需要快速扩展时，可以使用NoSQL数据库。什么时候需要快速扩张.\n当你的网站上有大量的读写操作时，NoSQL数据库最适合这些场景。由于它们能够动态地添加节点，因此它们能够以最小的延迟处理更多并发流量和大量数据\nFlexibility With Data Modeling数据建模的灵活性\n第二个提示是，在开发的初始阶段，当您不确定数据模型和数据库设计时，预计事情会快速变化。NoSQL数据库为我们提供了更多的灵活性。\nEventual Consistency Over Strong Consistency最终一致性优于强一致性\n当我们可以放弃强一致性的时候，当我们不需要事务的时候，最好选择NoSQL数据库\n一个很好的例子是一个社交网络网站，如Twitter,当一个名人的推特被爆红，全世界的人都在点赞和转发。在一段时间内，点赞数的上升或下降有关系吗\n如果系统显示的点赞数不是500万个，而是500万零250个，这位名人肯定不会在意\n当一个大型应用程序部署在遍布全球的数百个服务器上时，地理上分布的节点需要一些时间才能达成全球共识\n在他们达成共识之前，实体的价值是不一致的。在一段时间后，实体的值最终变得一致。这就是最终一致性。\n尽管这种不一致并不意味着存在任何类型的数据丢失。这只是意味着，数据需要很短的时间通过海底的互联网电缆在全球范围内传播，以达成全球共识，并变得一致.\n我们一直都在经历这种行为。尤其是在YouTube上。通常你会看到一个视频有10个点击量和15个赞。这怎么可能。实际的浏览量已经超过了赞数。它只是视图的计数不一致，需要很短的时间来更新。我将在后面的课程中更详细地讨论最终一致性\nRunning Data Analytics运行数据分析\nNoSQL数据库也最适合数据分析用例，在这些用例中，我们必须处理大量涌入的数据。\n有专门用于用例的数据库，如时间序列数据库、宽列数据库、面向文档的数据库等。我将在后面的课程中详细讨论它们。\nNoSQL比SQL更高效吗? 从技术基准的角度来看，关系数据库和非关系数据库的性能是一样的\n不仅仅是技术，而是我们如何使用技术来设计我们的系统，从而影响性能.所以，不要被所有的炒作弄糊涂了。理解您的用例，然后相应地选择技术\n性能，这完全取决于应用程序和数据库设计。如果我们使用更多的SQL连接。回应不可避免地需要更多的时间\n如果我们去掉所有的关系和连接，SQL就变得和NoSQL一样了。\n为什么流行的技术栈总是选择NoSQL数据库? 但为什么流行的技术堆栈总是选择NoSQL数据库？例如（MongoDB，ExpressJS，Angularjs / Reactjs，Nodejs）堆栈\n大多数在线应用程序都有通用的用例。这些技术栈已经把它们覆盖了。这背后也有商业原因。\n现在，网上有大量的教程\u0026amp;大量推广流行的技术堆栈。有了这些资源，初学者可以很容易地掌握它们并编写他们的应用程序，而不是独自研究其他技术\n不过，我们并不总是需要坚持使用流行的堆栈。我们应该选择最适合我们用例的东西。没有基本规则，选择适合你的。\nPolyglot Persistence(Polyglot持久性) Polyglot持久性意味着使用几种不同的持久性技术来满足应用程序中不同的持久性需求。\n假设我们正在编写一个像Facebook一样的社交网络\nRelational Database\n为了存储关系，比如用户的朋友，朋友的朋友，他们喜欢什么摇滚乐队，他们有什么共同的食物偏好等，我们会选择一个关系数据库，如MySQL。\nKey Value Store\n对于所有频繁访问的数据的低延迟访问，我们将使用像Redis或Memcache这样的键值存储来实现缓存。我们可以使用相同的Key-value数据存储来存储用户会话。现在我们的应用已经大获成功，非常受欢迎，我们有数百万活跃用户。\nWide Column Database宽列数据库\n为了理解用户行为，我们需要建立一个分析系统来对用户生成的数据进行分析。我们可以使用像Cassandra或HBase这样的宽列数据库来实现这一点\nACID Transactions \u0026amp; Strong ConsistencyACID事务\u0026amp;强一致性\n我们的应用程序的受欢迎程度似乎没有停止，它正在飙升。现在，企业希望在我们的门户网站上投放广告。为此，我们需要建立一个支付系统。同样，我们将选择一个关系数据库来实现ACID事务并确保强一致性。\nGraph Database\n现在，为了增强我们的应用的用户体验，我们必须开始向用户推荐内容，以保持他们的粘性。图形数据库最适合实现推荐系统。好了，到现在为止，我们的应用程序有多个功能，每个人都喜欢它。如果用户可以在我们的门户网站上搜索其他用户、业务页面和其他内容，并与他们建立联系，那该有多酷\nDocument Oriented Store面向文档的存储\n为了实现这一点，我们可以使用一个开源的面向文档的数据存储，比如ElasticSearch。该产品在行业中很受欢迎，因为它在网站上实现了可伸缩的搜索功能。我们可以将所有与搜索相关的数据持久化到弹性存储中。\n因此，这就是我们如何使用多个数据库来满足不同的持久性需求。不过，这种方法的一个缺点是使所有这些不同的技术协同工作的复杂性增加了。构建、管理和监控多种语言的持久性系统需要付出大量的努力。如果有更简单的东西呢?这样我们就不用自己动手收拾东西了\nMulti-Model Databases 到目前为止，数据库只支持一种数据模型，它可以是关系数据库、图形数据库或具有特定数据模型的任何其他数据库\n但是随着多模型数据库的出现，我们能够在单个数据库系统中使用不同的数据模型\n多模型数据库支持多种数据模型，如图、面向文档、关系等，而不是只支持一种数据模型\n它们还避免了在一个服务中管理多个持久性技术的需要。它们逐级降低了操作复杂性。对于多模型数据库，我们可以通过一个单一的API利用不同的数据模型\nPopular Multi-Model Databases 目前流行的多模型数据库有Arango DB、Cosmos DB、Orient DB、Couchbase等。\n到目前为止，我们已经清楚NoSQL数据库是什么以及什么时候选择它们。现在让我们来理解一些概念，比如最终一致性、强一致性，它们是理解分布式系统的关键\nEventual Consistency(最终一致性) 最终一致性是一种一致性模型，它使数据存储具有高可用性。它也被称为乐观复制\u0026amp;是分布式系统的关键。那么，它究竟是如何工作的呢?我们将通过用例来理解这一点。\n想想一个流行的微博客网站，它分布在世界各地，比如亚洲、美洲和欧洲。此外，每个地理区域都有多个数据中心区:北、东、西、南。此外，每个分区都有多个集群，集群中运行多个服务器节点\n因此，我们有许多分布在世界各地的数据存储节点，微博站点使用这些节点来持久化数据。\n因为有这么多的节点在运行，所以不存在单点故障。数据存储服务高可用。即使有几个节点宕机，持久化服务作为一个整体仍然是正常的\n好吧，现在让我们假设一个名人在网站上发布了一个帖子，全世界的人都开始喜欢它。\n在某一时刻，日本的一名用户对该帖子的点赞次数从100次增加到101次。在同一时间，在不同地理区域的美国用户点击了这篇文章，他看到的赞数是100，而不是101\n这很简单，因为Post Like计数器的新更新值需要一些时间才能从日本转移到美国，并更新在那里运行的服务器节点。\n尽管计数器在那个时间点的值是101，但美国用户看到的是旧的不一致的值。\n但当他在几秒钟后刷新他的网页时，Like计数器的值显示为101。因此，数据最初是不一致的，但最终在部署在世界各地的服务器节点上得到一致。这就是最终一致性\n让我们更进一步，如果在同一时间点，日本和美国的用户都喜欢这个帖子，而另一个地理区域的用户说欧洲的用户访问这个帖子。\n不同地理区域内的节点都有不同的post值。他们需要一些时间才能达成共识\n最终一致性的好处是，系统可以动态地添加新节点，而不需要阻塞其中任何一个节点，这些节点对最终用户来说都是可用的，可以随时进行更新\n世界各地的数百万用户可以同时更新这些值，而不必等待系统在所有节点上达成一个共同的最终值，然后才进行更新。这个特性使系统具有高可用性。\n最终一致性适用于值的准确性不太重要的用例，如上面讨论的用例。\n最终一致性的其他用例可能是在保持在线观看Live视频流的用户数量时。当处理大量的分析数据时,数据上下偏差不要紧\n但在某些情况下，数据必须精准如银行和股票市场。我们只是不能让我们的系统最终是一致的，我们需要强一致性。\nStrong Consistency(强一致性) 强一致性仅仅意味着数据在任何时候都必须是强一致性的。世界上所有的服务器节点在任何时候都应该包含相同的实体值。实现这种行为的唯一方法是在更新时锁定节点\n让我们继续上一课中关于最终一致性的例子。为了保证系统的强一致性，当日本用户喜欢该帖子时，必须锁定不同地理区域的所有节点，以防止并发更新。这意味着在某一时刻，只有一个用户可以更新发布的Like计数器值。\n所以，一旦日本的用户将Like计数器从100更新到101。值将在所有节点上全局复制。一旦所有节点达成一致，锁就被解除\n现在，其他用户可以喜欢这篇文章。如果节点需要一段时间才能达成共识，它们就必须等待到那时\n当然，这在社交应用中是不理想的。但是，请考虑一个股票市场应用程序，其中用户在某个时间点看到同一只股票的不同价格，并同时更新它。这会造成混乱\n因此，为了避免这种混乱，我们需要我们的系统是强一致性的。更新时必须锁定节点\n将所有请求排队是使系统具有强一致性的一个好方法。这个实现超出了本课程的范围。尽管我们将讨论一个叫做CAP的定理，它是实现这些一致性模型的关键。\n因此，到目前为止，我确信您已经意识到，选择强一致性模型会影响系统的高可用性。\n当系统被一个用户更新时，不允许其他用户同时执行更新。这是实现一致的ACID事务的强度。\nACID Transaction Support 像NoSQL数据库这样的分布式系统可以横向扩展，但却不支持全局的ACID事务\u0026amp;这是由于它们的设计。NoSQL技术发展的全部原因就是它的高可用性和可扩展性。如果我们每次都要锁定节点，就会变得像SQL一样。\n因此，NoSQL数据库不支持ACID事务，而那些声称支持ACID事务的数据库有适用于它们的条款和条件。\n通常，事务支持仅限于地理区域或实体层次结构。该技术的开发人员确保所有强一致性实体节点都位于相同的地理区域，从而使ACID事务成为可能\nCAP Theorem CAP代表(Consistency, Availability, Partition Tolerance)一致性、可用性、分区容错性。我们已经详细讨论了一致性和可用性。分区容错意味着容错。系统可以容忍故障或分区。即使有几个节点坏了，它也能继续工作.\n这个定理有很多定义，你可以在网上找到，在一致性、可用性和分区容忍度这三个概念中，我们必须选择两个。我觉得这有点让人困惑。我将试着给这个定理一个更简单的解释\nCAP定理简单地指出，在网络故障的情况下，当系统的几个节点宕机时，我们必须在可用性和一致性之间做出选择\n如果我们选择Availability可用性，这意味着当一些节点故障时，其他节点对用户可用以进行更新。在这种情况下，系统是不一致的，因为宕机的节点没有更新新的数据。当它们重新联机时，如果用户从它们获取数据，它们将返回它们停止时的旧值\n如果我们选择Consistency一致性，在这种情况下，我们必须锁定所有节点以进行进一步的写操作，直到故障的节点重新联机。这将确保系统的强一致性，因为所有节点将具有相同的实体值。\n在可用性和一致性之间做出选择很大程度上取决于我们的用例和业务需求。我们已经详细讨论过了。此外，从两个系统中选择一个的局限性是由于分布式系统的设计。我们不能同时拥有可用性和一致性\n分布在全球各地的节点需要一些时间才能达成共识。除非我们传输数据的速度比时间快或以时间的速度，否则不可能有零延迟\n####　Document Oriented Database\n面向文档的数据库是NoSQL数据库的主要类型。它们在独立的文档中以面向文档的模型存储数据。数据通常是半结构化以类似json的格式存储。\n数据模型与我们的应用程序代码中的数据模型相似，因此开发人员更容易存储和查询数据\n面向文档的存储适合敏捷软件开发方法，因为在使用它们时，更容易根据不断变化的需求进行更改\nPopular Document Oriented Databases 行业中使用的一些流行的面向文档的存储有MongoDB、CouchDB、OrientDB、谷歌Cloud Datastore、Amazon Document DB\n何时选择面向文档数据库 如果您使用的是半结构化数据，则需要一个灵活的模式，它会经常变化。当你开始编写应用程序时，你并不确定数据库模式。随着时间的推移，事情可能会发生变化。你需要一些灵活的东西，你可以随着时间的推移改变最少的麻烦。选择一个面向文档的数据存储\n面向文档的数据库的典型用例如下:\n实时信息源 实时体育应用程序 编写产品目录 库存管理 存储用户评论 基于web的多人游戏 作为NoSQL数据库家族中的一分子，这些数据库提供了水平可伸缩性，高性能读写，因为它们迎合了CRUD——创建、读取、更新、删除用例。在没有太多关系逻辑的情况下，我们需要的只是数据的快速持久化和检索。\nGraph Database 图形数据库也是NoSQL数据库系列的一部分。他们存储数据在节点/顶点和边缘以关系的形式。\n图形数据库中的每个节点代表一个实体。它可以是一个人，一个地方，一个企业等。边缘代表实体之间的关系。\n既然已经有了基于SQL的关系数据库，为什么还要使用图形数据库来存储关系呢?\nFeatures Of A Graph Database 首先是形象化。想象一下惊悚侦探电影中的钉板，钉在木板上的几个图像通过线连接起来。它确实有助于形象化实体是如何关联的,事物是如何组合在一起的。 第二个原因是低延迟。在图数据库中，关系的存储方式与关系数据库的存储方式略有不同。图数据库的速度更快，因为它们中的关系不是在查询时计算出来的，因为这是在关系数据库中的连接的帮助下发生的。这里的关系以边的形式保存在数据存储中，我们只需要获取它们。在查询时不需要运行任何类型的计算。 适合图形数据库的应用程序的一个很好的现实示例是谷歌Maps。节点表示城市，边表示城市之间的连接.现在，如果我必须寻找不同城市之间的道路，那么在运行查询时，我不需要通过连接来确定城市之间的关系。我只需要取回已经存储在数据库中的边\n图数据库的理想用例是构建社会、知识、网络图。编写基于ai的应用、推荐引擎、欺诈分析应用、存储基因数据等。\n####　Key Value Database\n键值数据库也是NoSQL家族的一部分。这些数据库使用简单的键值方法来存储和快速获取数据，延迟最小\n#####　Features Of A Key Value Database\nKey-value数据库的一个主要用例是在应用程序中实现缓存，因为它们确保了最小的延迟。\nKey作为一个唯一的标识符，并且有一个与之相关联的值。该值可以像文本块一样简单，也可以像对象图一样复杂。\nKey-value数据库中的数据可以在常量时间O(1)中获取，不需要查询语言来获取数据。这只是一个简单的不需要动脑筋的获取操作。这确保了最小的延迟\n流行的KV存储 业界常用的键值数据存储有Redis、Hazelcast、Riak、Voldemort和Memcache。\n何时选取 如果你有一个用例，你需要以最小的麻烦和后端处理快速获取数据，那么你应该选择一个键值数据存储。键值存储在超级快速获取数据的场景中非常有效\n键值存储在超级快速获取数据的场景中非常有效。键值数据库的典型用例如下:\n缓存 持久的用户状态 持久的用户会话 管理实时数据 实施队列 在线游戏和Web应用程序中创建排行榜 实施PUB子系统 Time Series Database 时间序列数据库为跟踪和持久的时间序列数据进行了优化\n时间序列数据 它是包含与事件发生时间相关的数据点的数据。对这些数据点进行跟踪、监视，然后根据特定的业务逻辑最终进行聚合。时间序列数据通常来自物联网设备、自动驾驶汽车、行业传感器、社交网络、股市金融数据等。好吧! !但是，为什么需要存储如此大量的时间序列数据呢\n#####　为何存储时间序列数据\n研究来自应用程序的数据流有助于我们跟踪系统的行为。它帮助我们研究用户模式、异常现象以及事物如何改变时间。\n时间序列数据主要用于运行分析，根据分析结果推断结论和制定未来的业务决策。运行分析还可以帮助产品不断发展\n一般数据库不是用来处理时间序列数据的。随着物联网的出现，这些数据库变得非常流行，并被行业巨头采用。\n常用的时间序列数据库 业界常用的时间序列数据库有DB、Timescale DB、Prometheus等\n何时选用 如果你有一个用例，你需要在很长一段时间内实时地管理数据，那么时间序列数据库就是你所需要的\n正如我们所知，时间序列数据库是用来处理实时流数据的。它的典型用例是从物联网设备获取数据。管理用于运行分析和监控的数据。编写一个实时处理股票价格变化的自主交易平台等\nWide-Column Database 宽列数据库属于NoSQL数据库家族,主要用于处理海量数据,技术上称为大数据 宽列数据库非常适合分析用例 它们具有高性能和可伸缩的架构 另外,宽列数据库也称为面向列的数据库,它将数据存储在具有动态列数的记录中 一条记录可以包含数十亿列\n常用的宽列数据库 目前流行的宽列数据库有Cassandra、HBase、谷歌BigTable、Scylla DB等。\n何时选用 如果你有一个用例需要处理大数据，吸收数据或对其进行分析，那么宽列数据库非常适合这个场景\n宽列数据库用于管理大数据，同时确保可伸缩性、性能和高可用性\nCaching 缓存是任何应用程序性能的关键。它确保了低延迟和高吞吐量。具有缓存的应用程序肯定会比没有缓存的应用程序做得更好，这是因为与没有实现缓存的应用程序相比，它返回响应的时间更短。\n在web应用程序中实现缓存仅仅意味着从基于磁盘硬件的数据库中复制频繁访问的数据，并将其存储在RAM随机访问内存硬件中。\n基于ram的硬件比基于磁盘的硬件提供更快的访问。正如我前面所说的，它确保了低延迟和高吞吐量。吞吐量指的是网络调用的数量，即客户端和服务器之间在规定的时间内的请求-响应\n####　缓存动态数据\n使用缓存，我们可以缓存静态数据和动态数据。动态数据是变化更频繁的数据，它有一个过期时间或TTL生存时间。TTL结束后，数据从缓存中清除，新更新的数据保存在缓存中。这个过程被称为缓存失效。\n缓存静态数据 静态数据包括图像，字体文件，CSS和其他类似的文件。这是一种不经常更改的数据，可以很容易地在客户端浏览器或本地内存中缓存。此外，在cdn上，内容分发网络\n缓存还有助于应用程序在网络中断期间保持预期的行为\n我如何确定我的应用程序中是否需要缓存 首先，使用缓存总是一个好主意，而不是不使用它。这没有什么坏处。它可以在应用程序的任何层使用\u0026amp;对于它可以和不能应用在哪里没有基本规则。\n缓存最常见的用法是数据库缓存。通过截取路由到数据库的数据请求，缓存有助于减轻对数据库的压力。\n然后，缓存返回所有经常访问的数据。因此，逐级降低数据库上的负载。\n应用程序体系结构中可以使用缓存的不同组件 在我们的应用程序的架构中，我们可以在多个地方使用缓存。在客户端浏览器中使用缓存来缓存静态数据。它与数据库一起用于拦截所有的数据请求，在REST API实现中等等。\n除了这些地方，我建议你去寻找规律。我们总是可以缓存经常访问的内容在我们的网站上，从任何组件。当它可以被缓存时，不需要反复计算。\n想想关系数据库中的join。它们因反应缓慢而臭名昭著。更多的join意味着更多的延迟。通过存储需要的数据，缓存可以避免每次运行连接的需要。现在，想象一下这个机制会对我们的应用程序提速多少.\n而且，即使数据库坏了一段时间。用户不会注意到它，因为缓存将继续服务于数据请求。\n我们可以在缓存中存储用户会话。它可以在应用程序的任何层实现，可以在操作系统级、网络级、CDN或数据库\n你可能还记得，我们在数据库课上讨论过键值数据存储。它们主要用于在web应用程序中实现缓存\n它们可以用于微服务体系结构中的跨模块通信，保存所有服务共同访问的共享数据。它充当微服务通信的骨干。\n通过缓存的键值数据存储也广泛用于内存数据流处理和运行分析。\n通过缓存降低应用程序部署成本 例如开发并部署在云上的一个以股票为基础的游戏应用程序\n游戏中有几只公司的股票在股票市场上上市，算法会每秒钟触发这些股票的价格运动，如果不是在这之前。\n最初，只要价格发生变化，我就将更新后的股票价格保存在数据库中，以便在一天结束时创建一个股价运动时间表。但是这么多的数据库写入花费了我一大笔钱。每小时的写作数量简直是疯了。\n最终，我决定不在数据库中保存每秒钟更新的价格，而是使用Memcache来保存股票价格。然后定期运行批处理操作来更新数据库。\nMemcache比基于磁盘的数据库访问要便宜得多。缓存处理所有的股票价格请求，直到批处理操作运行，数据库才有更新的值\n对于现实生活中的金融科技应用来说，这个调整可能并不理想，但它帮助我节省了一大笔钱\u0026amp;我能够运行游戏更长的时间\n所以,伙计们! !这是一个可以利用缓存机制来降低成本的实例。您可能不希望将每个信息都持久化到数据库中，而希望使用缓存来存储不太关键的信息。\n现在让我们来看看一些缓存策略，我们可以利用这些策略来进一步提高应用程序的性能。\n####　Caching Strategies\n服务于特定用例的缓存策略有不同的种类。它们是缓存搁置，透读缓存，透写缓存和回写缓存\nCache Aside 这是最常见的缓存策略。在这种方法中，缓存与数据库一起工作，试图尽可能地减少对它的命中\n数据是在缓存中惰性加载的。当用户发送对特定数据的请求时，系统首先在缓存中查找它。如果存在，则直接从它返回。如果不是，则从数据库中获取数据，更新缓存并返回给用户。\n这种策略最适用于读量大的工作负载。这包括不经常更新的数据类型，例如门户中的用户概要数据。用户名、帐号等\n该策略中的数据直接写入数据库。这意味着缓存中的数据和数据库中的数据可能不一致。为了尽量减少读写不一致的情况.缓存上的数据有一个TTL Time To Live。在规定的时间之后，缓存中的数据将失效。\nRead-Through 这个策略与缓存搁置策略非常相似。与Cache Aside策略的一个微妙区别是，在Read-through策略中，缓存始终与数据库保持一致。\n缓存库或框架承担了与后端保持一致性的责任;这种策略中的信息也是惰性加载的，只有当用户请求时才会加载到缓存中。当第一次请求信息时，它会导致缓存丢失。然后后端必须在向用户返回响应时更新缓存,开发人员总是可以将用户最希望请求的信息预加载到缓存中\nRead-Through和Cache-Aside很相似，不同点在于程序不需要再去管理从哪去读数据（缓存还是数据库）。相反它会直接从缓存中读数据，该场景下是缓存去决定从哪查询数据。当我们比较两者的时候这是一个优势因为它会让程序代码变得更简洁。\nWrite-Through Write-Through下所有的写操作都经过缓存，每次我们向缓存中写数据的时候，缓存会把数据持久化到对应的数据库中去，且这两个操作都在一个事务中完成。因此，只有两次都写成功了才是最终写成功了。这的确带来了一些写延迟但是它保证了数据一致性。\n同时，因为程序只和缓存交互，编码会变得更加简单和整洁，当你需要在多处复用相同逻辑的时候这点变的格外明显。\n在这个策略中，写入数据库的每一个信息都要经过缓存。在数据写入数据库之前，缓存会用数据更新。这保持了缓存和数据库之间的高一致性，尽管它在写操作期间增加了一点延迟，因为数据要在缓存中另外更新。这适用于编写繁重的工作负载，如在线大型多人游戏。\n此策略通常与其他缓存策略一起使用，以实现最佳性能。\n当使用Write-Through的时候一般都配合使用Read-Through。\nWrite-Through适用情况有：\n需要频繁读取相同数据 不能忍受数据丢失（相对Write-Behind而言）和数据不一致 Write-Through的潜在使用例子是银行系统。\nWrite-Back Write-Back和Write-Through在“程序只和缓存交互且只能通过缓存写数据”这一点上很相似。不同点在于Write-Through会把数据立即写入数据库中，而Write-Back会在一段时间之后（或是被其他方式触发）把数据一起写入数据库，这个异步写操作是Write-Back的最大特点。\n数据库写操作可以用不同的方式完成，其中一个方式就是收集所有的写操作并在某一时间点（比如数据库负载低的时候）批量写入。另一种方式就是合并几个写操作成为一个小批次操作，接着缓存收集写操作（比如5个）一起批量写入。\n异步写操作极大的降低了请求延迟并减轻了数据库的负担。同时也放大了数据不一致的。比如有人此时直接从数据库中查询数据，但是更新的数据还未被写入数据库，此时查询到的数据就不是最新的数据。\n这种策略有助于极大地优化成本。在Write-back缓存策略中，数据直接写入缓存，而不是写入数据库。缓存根据业务逻辑延迟一段时间后将数据写入数据库.\n如果应用程序中有相当多的写操作。开发人员可以减少写数据库的频率，以减少负载和相关的成本。\n这种方法的一个风险是，如果缓存在更新DB之前失败，数据可能会丢失。同样，这个策略与其他缓存策略一起使用，以充分利用这些策略\nMessage Queues 消息队列，顾名思义，是一个将消息从源路由到目的地的队列，也可以说是从发送方路由到接收方的队列。\n由于它是一个队列，它遵循FIFO(先进先出)策略。先发送的消息先传递。虽然消息有一个优先级，使队列成为优先队列，但现在让我们保持简单。\n消息队列的特点 消息队列促进了异步行为。在AJAX课程中，我们已经了解了什么是异步行为。异步行为允许模块在后台相互通信，而不会妨碍它们的主要任务\n消息队列促进了跨模块通信，这是面向服务或微服务体系结构中的关键。它允许在异构环境中进行通信。它们还为消息提供临时存储，直到消息被消费者处理和使用为止\n以电子邮件为例，邮件的发送者和接收者不需要同时在线才能互相交流。发送方发送电子邮件，邮件暂时存储在邮件服务器上，直到收件人联机并读取邮件\n消息队列使我们能够运行后台进程、任务、批处理作业。说到后台进程，让我们借助一个用例来理解这一点。\n想象一个用户在门户网站上注册。在他注册后，他立即被允许导航到应用程序的主页，但注册过程还没有完成。系统必须向用户注册的电子邮件id发送确认邮件。然后用户需要点击确认邮件来确认注册事件。\n但网站不能让用户等待，直到它发送电子邮件给用户。他要么被允许导航到主页，要么被弹开。因此，这个任务被分配给一个消息队列作为一个异步后台进程。当用户继续浏览网站时，它会向用户发送一封电子邮件进行确认。\n这就是如何使用消息队列向web应用程序添加异步行为。消息队列也用于实现通知系统，就像Facebook通知一样。我将在接下来的课程中讨论这个问题。\n运行批处理作业的消息队列 现在来看看批处理作业。您还记得在上一节缓存课中讨论的场景吗?在该场景中，我讨论了如何使用缓存来降低应用程序部署成本\n在数据库中定期更新股票价格的批处理作业是由消息队列运行的。\n所以，我们现在有了一个基本的了解，有一个消息发送者，也被称为生产者，还有一个消息接收者，也被称为消费者\n生产者和消费者不需要驻留在同一台机器上进行通信，这是非常明显的\n在通过队列路由消息的过程中，我们可以根据业务需求定义几个规则。我曾指出，为消息添加优先级。队列的其他重要特性包括消息确认、重试失败消息等\n谈到队列的大小，没有明确的大小，它可以是一个无限的缓冲区，这取决于业务所拥有的基础设施\n现在，我们将研究行业中广泛使用的消息传递模型，从发布订阅消息路由模型开始，该模型在当今的在线领域中非常流行。同时，这也是我们消费信息的方式。\nPublish Subscribe Model 发布订阅模型 发布-订阅模型是指多个消费者从单个或多个生产者接收到相同消息的模型。\n现实世界的报纸服务是发布-订阅模式的一个很好的类比，在这种模式中，消费者订阅报纸服务，服务每天将新闻传递给其服务的多个消费者\n在网络世界中，我们经常订阅应用程序中的各种主题，以不断地获得任何特定部分的最新更新。无论是体育、政治还是经济等等\nexchange(交换器) 要实现pub-sub模式，消息队列有exchanges，根据交换器类型和所设置的规则，交换器进一步将消息推送到队列中。交换器就像电话交换器一样，通过基于某种逻辑的基础设施将消息从发送者路由到接收者。\n消息队列中有不同类型的exchange，其中一些是direct,topic,、headers,fanout.。为了更深入地了解这些不同的交换类型是如何工作的，RabbitMQ 的这篇文章很值得一读。\n并不一定每个消息队列技术都具有相同的交换类型。这些只是我在这里讨论的一般情况。技术可以改变一切。此外，技术并不重要，你现在需要的只是对事物如何工作的一个概念\n因此，我们将选择扇出交换类型来广播来自队列的消息。交换将消息推送到队列中，消费者将收到消息。交换和队列之间的关系称为绑定\npoint to point route 点对点的线路 点对点通信是一个非常简单的用例，来自生产者的消息只被一个消费者使用\n尽管基于业务需求，我们可以在这个消息传递模型中设置多个组合，比如在队列中添加多个生产者和消费者。但是在一天结束的时候，生产者发送的信息只会被一个消费者消费。因此被称为“点对点排队模型”。它不是消息的广播，而是实体对实体的通信。\nMessaging Protocols 在处理消息队列时，有两个常用的协议。AMQP高级消息队列协议\u0026amp; STOMP简单或面向流文本的消息协议。\n常用技术 谈到业界广泛使用的队列技术，有RabbitMQ、ActiveMQ、Apache Kafka等。\nNotification Systems \u0026 Real-time Feeds with Message Queues (通知系统\u0026实时消息队列) 我们将深入了解如何在消息队列的帮助下设计通知系统和实时提要。然而，这些模块在当今的Web 2.0应用程序中非常复杂。它们包括机器学习、理解用户行为、推荐新的相关信息以及与之整合的其他模块等。我们不会深入到那样的复杂程度，因为这不是必须的\n假设我们正在使用关系数据库编写一个像Facebook这样的社交网络，我们将使用一个消息队列将异步行为添加到应用程序中。\n在应用程序中，用户将拥有许多朋友和追随者。这是一个多对多的关系，就像一个社交图。一个用户有很多朋友，他会成为很多用户的朋友。就像我们在图形数据库课上讨论的那样\n所以，当用户在网站上创建一个帖子时，我们会将它持久化到数据库中。将有一个User表和另一个Post表。因为一个用户会创建多个帖子，所以用户和他的帖子之间是一对多的关系。\n同时，由于我们将帖子持久化到数据库中，我们必须将用户创建的帖子显示在他的朋友和关注者的主页上，甚至在需要的时候发送通知。\n简单方法 在不使用消息队列的情况下实现此功能的一种简单方法是，对于网站上的每个用户，如果他的任何连接有新的更新，则定期短时间轮询数据库\n为此，首先，我们将找到用户的所有连接，然后逐个检查每个连接，如果他们创建了一个新的帖子\n如果有，查询将拉出由用户的连接创建的所有新文章，并显示在其主页上。我们也可以发送通知给用户，在用户表的通知计数器列的帮助下跟踪那些的计数\u0026amp;添加一个额外的AJAX轮询查询从客户端为新的通知\n缺点\n首先，我们经常轮询数据库，这是昂贵的。它将消耗大量的带宽，也将给数据库带来很多不必要的负载\n第二个缺点是，在用户连接的主页上显示的用户帖子将不是实时的。在数据库被轮询之前，帖子不会显示。我们可以称之为实时，但并不是真正的实时\n消息队列设计 这一次当用户创建一个新帖子时，它将拥有一个分布式事务。一个事务将更新数据库，另一个事务将发送负载到消息队列。有效负载指的是用户发布的消息的内容。\n通知系统和实时提要(real-time feeds)与数据库建立持久连接，以促进数据的实时流。我们已经谈过了\n消息队列在接收到消息时将立即异步地将消息推送到在线用户的连接中。它们不需要定期轮询数据库以检查用户是否创建了一个帖子。\n我们也可以使用消息队列临时存储和一个TTL时间来等待用户的连接上线\u0026amp;然后将更新推送给他们。我们还可以使用单独的Key-value数据库来存储将通知推送到用户连接所需的用户详细信息。比如他关系网的id之类的。这将避免甚至轮询数据库以获取用户连接的需要\nHandling Concurrent Requests With Message Queues(使用消息队列处理并发请求) 当全世界数以百万计的用户同时更新一个实体时，我们可以将所有更新请求排在一个高吞吐量消息队列中。然后我们可以用先进先出的方法一个接一个地处理它们\n这将使系统高可用性，开放更新，同时仍然保持一致.\n尽管这种方法的实现并不像听起来那么简单，但在分布式实时环境中实现任何东西都不是那么简单。\nFacebook的LIVE视频流服务处理 Facebook的LIVE视频流服务处理并发用户请求的方法，也是利用队列来有效处理流量激增的一个很好的例子\n在这个平台上，当一个受欢迎的人去LIVE时，LIVE流媒体服务器上的用户请求会激增。为了避免服务器上的传入负载，Facebook使用缓存来拦截流量.\n但是，由于数据是实时流的，在请求到达之前，缓存通常没有填充实时数据。现在，这将很自然地导致缓存丢失\u0026amp;请求将继续访问流服务器\n为了避免这种情况，Facebook将所有用户请求排成队列，请求相同的数据。它从流服务器获取数据，填充缓存，然后从缓存处理排队的请求\nRise Of Data-Driven Systems 数据驱动系统的崛起 我们今天的世界很大程度上是由数据驱动的，并正朝着完全由数据驱动的方向发展。随着物联网的出现，实体有了一定程度的自我意识，它们正在以前所未有的速度在线生成和传输数据。它们能够相互沟通，无需任何人为干预就能做出决定\n物联网数据 物联网设备的主要大规模应用领域是工业传感器、智慧城市、电子设备、可穿戴医疗身体传感器等\n为了管理大量的流式数据，我们需要有复杂的后端系统，从中收集有意义的信息，并归档/清除没有意义的数据\n我们拥有的数据越多，我们的系统发展得就越好。今天的企业依赖于数据。他们需要客户数据来制定未来的计划和预测。他们需要了解用户的需求和他们的行为。所有这些都使企业能够创造更好的产品，做出更明智的决定，运行有效的广告活动，向他们的客户推荐新产品，获得更好的市场洞察等\n所有这些对数据的研究最终会导致更多以客户为中心的产品和更高的客户忠诚度。\n跟踪服务效率 处理流入数据的另一个用例是跟踪服务效率，例如，从数百万客户使用的物联网设备获得一切正常的信号\n所有这些用例使得流处理成为业务和现代软件应用的关键。时间序列数据库是我们讨论过的一种技术，它可以对从物联网设备获取的实时数据进行持久化和查询\nData Ingestion(数据获取) 数据摄入是一个集合术语，指从几个不同的来源收集数据流，并使其准备由系统处理的过程。\n在数据处理系统中，数据从物联网设备和其他来源摄取到要分析的系统中。它通过数据流水线路由到不同的组件/层，算法在其上运行，最终归档。\nLayers Of Data Processing Setup(数据处理初始化层) 此整个数据处理初始化中有几个阶段/层，如：\n数据收集层 数据查询层Data处理层 数据可视化层 数据存储层 数据安全层 Data Standardization 从几个不同来源流进来的数据不是同构的结构格式。我们已经学习了不同类型的数据，结构化的，非结构化的，半结构化的。因此，您已经对什么是非结构化异构数据有了一个概念\n来自网络服务、社交网络、物联网设备、工业机器等的数据以不同的速度和大小流入系统。每个数据流都有不同的语义\n因此，为了使数据统一并适合处理，必须首先收集数据并将其转换为标准化格式，以避免将来出现任何处理问题。这个数据标准化的过程发生在数据收集和准备层\nData Processing 数据转换为标准格式后，将被路由到数据处理层，在那里根据业务需求对数据进行进一步处理。它通常分为不同的流，路由到不同的目的地。\nData Analysis 路由后，将对数据进行分析，包括执行不同的分析模型，如预测建模、统计分析、文本分析等。所有的分析事件都发生在数据分析层。\nData Visualization 一旦分析工作完成，我们就能从中获得有价值的情报。所有的信息都被路由到数据可视化层，然后呈现给涉众，通常是在一个基于web的仪表盘中。Kibana是数据可视化工具的一个很好的例子，在行业中非常流行\nData Storage \u0026 Security 移动数据极易受到安全漏洞的影响。数据安全层保证了数据的安全移动。说到数据存储层，顾名思义，它在持久化数据方面很有用\n因此，这是如何为业务用例处理和分析大量数据的要点。这只是鸟瞰。数据分析领域非常深入，每一层的深入详细的微观视图需要专门的数据分析课程。\nDifferent Ways Of Ingesting Data \u0026 the Challenges Involved(吸收数据的不同方式和所涉及的挑战) Different Ways To Ingest Data(吸收数据的不同方式) 有两种主要的获取数据的方式，实时(real-time)和定期(intervals)运行的批量(batches)。从两者中选择哪一个完全取决于业务需求\n在通过可穿戴物联网传感器读取心跳、血压等医疗数据的系统中，实时数据摄入通常是首选，因为时间至关重要。此外，在处理金融数据的系统中，如股票市场事件等。这是时间、生命和金钱紧密相连的几个例子，我们需要尽快获得信息。\n相反，在读取趋势的系统中，我们总是可以批量获取数据。例如，当估计一个地区在一段时间内的体育受欢迎程度时\n让我们谈谈开发人员在消化大量数据时必须面对的一些挑战。我添加这一课只是为了让你对整个过程有一个更深入的了解。在下一课中，我还将讨论应用程序开发领域中数据流的一般用例。\nChallenges with Data Ingestion (数据吸收的挑战) slow process\n数据吸收是一个缓慢的过程。为什么?我之前提到过。当数据从几个不同的来源流入系统时，来自每个不同来源的数据都有不同的格式、不同的语法和附加的元数据。数据作为一个整体是异构的。它必须转换成一种常见的格式，如JSON或其他能够被分析系统很好地理解的格式\n数据转换是一个冗长乏味的过程。这需要大量的计算资源和时间。流动的数据必须在管道中分几个阶段进行处理，然后向前移动\n此外，在每一个阶段，数据都必须经过认证和验证，以满足组织的安全标准。在传统的数据清理过程中，获取手头有用的信息需要花费数周甚至数月的时间。传统的数据摄取系统，如ETL已经不再有效\nwhy slow\n现代数据处理技术和框架正在不断发展，以打破传统数据处理系统的局限性。在传统的系统中，实时数据摄取是不可能的\n从实时处理中获得的分析信息并不是那么准确和全面，因为分析持续地运行在有限的数据集上，而不是考虑整个数据集的批处理方法。所以，基本上，我们花越多的时间研究数据，我们得到的结果就越准确\n当我们学习数据处理的Lambda和Kappa架构时，您将了解更多这方面的知识\nComplex \u0026 Expensive(复杂和昂贵的) 整个数据流过程是资源密集型的。在将数据输入系统之前，必须进行大量的工作来准备数据。而且，这不是一个次要的过程，需要一个专门的团队来完成这样的工作\n工程团队经常遇到这样的情况:市场上可用的工具和框架不能满足他们的需求，他们别无选择，只能从基本框架编写一个定制的解决方案\nGobblin是LinkedIn的一个数据摄取工具。LinkedIn曾一度有15个数据吸收管道在运行，这给数据管理带来了一些挑战。为了解决这个问题，LinkedIn在内部编写了Gobblin。\n来自外部源的数据的语义有时会发生变化，因为它们并不总是在我们的控制之下，这就需要在后端数据处理代码中进行更改。如今，行业中的物联网机器正在持续快速发展\n这些是我们在设置数据处理和分析系统时必须牢记的因素\nMoving Data Around Is Risky(移动数据是危险的) 当数据被四处移动时，就有可能出现漏洞。移动数据是脆弱的。它要经过几个不同的准备阶段\u0026amp;工程团队必须投入额外的努力和资源，以确保他们的系统在任何时候都符合安全标准\nData Ingestion Use Cases(数据摄取用例) Moving Big Data Into Hadoop(将大数据转移到Hadoop) 这是最流行的数据摄取用例。如前所述，来自物联网设备、社交应用和其他来源的大数据流通过数据管道，转移到最流行的分布式数据处理框架Hadoop进行分析和处理。\nStreaming Data from Databases to Elasticsearch Server(将数据从数据库流传输到Elasticsearch Server) Elasticsearch是一个开源框架，用于在web应用程序中实现搜索。它是一个事实上的行业搜索框架，仅仅因为它的先进功能，并且它是开源的。这些特性使企业能够在需要时编写自己的定制解决方案\n过去，我和几个朋友用Java、Spring Boot和Elastic search编写了一个产品搜索服务软件。说到它的设计，我们会将大量的产品数据从传统的存储解决方案流和索引到Elastic搜索服务器，以使产品出现在搜索结果中\n打算在搜索中显示的所有数据都从主存储复制到Elastic搜索存储中。此外，由于新数据被持久化在主存储中，它会实时异步地传递到Elastic服务器以进行索引\nLog Processing(日志处理) 如果您的项目不是爱好项目，那么它很可能运行在集群中。当我们谈到运行大规模服务时，单片系统已经成为过去式。这么多微服务同时运行。一段时间内会产生大量的日志。而日志是回溯时间、跟踪错误和研究系统行为的唯一方法。\n因此，为了全面地研究系统的行为，我们必须将所有的日志流传输到一个中心位置。在ELK (Elastic LogStash Kibana)堆栈等解决方案的帮助下，将日志输入到中央服务器上运行分析\nStream Processing Engines for Real-Time Events(实时事件的流处理引擎) 实时流媒体和数据处理是处理实时信息(如体育)的系统的核心组件。架构设置必须足够高效，能够吸收数据，分析数据，实时分析行为，并快速将更新信息推送给粉丝。毕竟，整个行业都依赖于此。\n消息队列(如Kafka)、流计算框架(如Apache Storm、Apache Nifi、Apache Spark、Samza、Kinesis等)被用于实现在线应用中的实时大规模数据处理特性\n这篇文章十分好Netflix’s real-time streaming platform Data Pipelines 数据管道是数据处理基础设施的核心组件。它们促进了数据从一个点到另一个点的高效流动\u0026amp;还使开发人员能够对实时的数据流应用过滤器。\nFeatures Of Data Pipelines(数据管道的特点) 确保数据流畅。 使业务能够在流式传输时应用过滤器和业务逻辑 避免数据流中的任何瓶颈和冗余。 促进数据的并行处理。 避免数据已损坏。 这些管道按照工程团队预定义的一组规则工作，数据可以在没有任何人工干预的情况下进行相应的路由。整个数据提取、转换、组合、验证、从多个数据流聚合到一个数据流等流程都是完全自动化的\n传统上，我们使用ETL系统来管理所有的数据移动，但它们的一个主要限制是它们并不真正支持处理实时流数据。随着新时代由数据管道驱动的数据处理基础设施的发展，什么是可能的\nETL Extract\n是指从单个或多个数据源提取数据\nTransform\n意味着将提取的异构数据转换为基于业务设置的规则的标准化格式。\nLoad\n指将转换后的数据移动到数据仓库或另一个数据存储位置，以进一步处理数据\nETL流与数据摄取流相同。它只是整个数据的移动是分批完成的，而不是通过数据管道实时流\n同时，这并不意味着批处理方法已经过时。实时和批处理数据处理技术都是基于项目需求的.\n当我们在接下来的课程中学习分布式数据处理的Lambda和Kappa架构时，您将对它有更深入的了解.\n在上一课中，我介绍了一些流行的数据处理工具，如Apache Flink、Storm、Spark、Kafka等。所有这些工具都有一个共同之处，它们通过数据管道在分布式环境中促进集群中的数据处理.\nDistributed Data Processing 分布式数据处理是指将大量数据分散到多个不同的节点上，在集群中运行，进行并行处理\n所有节点执行并行分配的任务，通过一个节点协调器相互协作。Apache Zookeeper是业界非常流行的事实上的节点协调器。\n由于节点是分布的，任务是并行执行的，这使得整个设置具有相当大的可伸缩性和高可用性。工作负载可以水平和垂直缩放。数据在集群中进行冗余和复制，以避免任何类型的数据丢失 与在集中式数据处理系统上运行相比，在分布式环境中处理数据有助于以更少的时间完成任务\nDistributed Data Processing Technologies(分布式数据处理技术) MapReduce – Apache Hadoop\nMapReduce是一个编程模型，用于管理集群中多台不同机器之间的分布式数据处理，将任务分布到多台机器上，并行运行工作，管理系统中不同部分的所有通信和数据传输\n编程模型的Map部分涉及根据参数对数据进行排序，Reduce部分涉及汇总排序后的数据\nMapReduce编程模型最流行的开源实现是Apache Hadoop。该框架被业内所有大腕用来管理系统中的大量数据。Twitter使用它进行分析。它被Facebook用来存储大数据。\nApache Spark\nApache Spark是一个开源的集群计算框架。它为批处理和实时流处理提供高性能。它可以与不同的数据源一起工作，并促进在集群中并行执行工作\nSpark具有集群管理器和分布式数据存储功能。集群管理器可以方便集群中运行的不同节点之间的通信，而分布式存储可以方便大数据的存储。Spark与Cassandra、HDFS、MapReduce File System、Amazon S3等分布式数据存储进行无缝集成。\nApache Storm\nApache Storm是一个分布式流处理框架。在行业中，它主要用于处理大量的流数据。它有几个不同的用例，如实时分析、机器学习、分布式远程过程调用等\nApache Kafka\nApache Kafka是一个开源的分布式流处理和消息传递平台。它是用Java和Scala编写的，由LinkedIn开发\nKafka的存储层涉及分布式可伸缩的PUB /子消息队列。它有助于读取和写入数据流，如消息传递系统\nKafka在行业中被用来开发实时功能，如通知平台、管理大量数据流、监控网站活动和指标、消息传递、日志聚合。\nHadoop是批处理数据的首选，而Spark, Kafka \u0026amp; Storm是处理实时流数据的首选\n####　Lambda Architecture(λ架构)\nLambda是一种分布式数据处理体系结构，它利用批处理和实时流数据处理方法来解决批处理方法产生的延迟问题。在将结果呈现给最终用户之前，它会连接这两种方法的结果\n考虑到如今企业拥有的海量数据，批处理确实需要时间，但这种方法的准确性很高，结果也很全面\n相反，实时流数据处理提供了快速的洞察力。在这种情况下，分析是在一小部分数据上运行的，因此与批处理方法相比，结果不是那么准确和全面\nLambda体系结构充分利用了这两种方法。\nLayers Of the Lambda Architecture Batch Layer Speed Layer Serving layer 批处理层处理通过批处理数据获得的结果。\n速度层从实时流数据处理中获取数据，\n服务层结合从批处理和速度层获得的结果。\nKappa Architecture 在Kappa体系结构中，所有的数据都通过一个数据流管道流动，而Lambda体系结构具有不同的数据流层，它们汇聚成一个\n该体系结构通过单个流管道将实时和批处理的数据流动，降低了不必管理处理数据的单独层的复杂性\nLayers Of Kappa Architecture Kappa只有两层。speed layer是流处理层，serving layer是最后一层\nKappa不是Lambda的替代品。这两个体系结构都有它们的用例\n如果系统中的批处理和流分析结果相当相同，Kappa是首选。如果不是，则首选Lambda\n尽管整个分布式数据处理方法看起来非常平滑和高效，但重要的是我们不要忘记，设置和管理分布式数据处理系统是一件重要的事情。完善这一制度需要多年的努力。此外，分布式系统不能保证数据的强一致性\nEvent Driven Architecture (事件驱动架构) 在编写现代Web 2.0应用程序时，你可能会遇到反应式编程(Reactive programming)、事件驱动架构(Event-driven architecture)、阻塞(Blocking)和非阻塞(Non-blocking)等概念。\n你可能也注意到像NodeJS, Play, Tornado, Akka这样的技术。与传统技术相比，IO在现代应用开发中越来越受欢迎。\nBlocking 在web应用程序中，阻塞意味着执行流程被阻塞，等待进程完成。直到流程完成，它才能继续。假设我们在一个函数中有一个10行代码块，每一行都会触发另一个执行特定任务的外部函数\n当然，当执行流进入主函数时，它将从最上面的第一行开始执行代码。它将运行第一行代码并调用外部函数\n此时，直到外部函数返回响应。流程被阻塞。流程不会进一步移动，它只是等待响应。除非我们通过注释和将任务移到一个单独的线程来添加异步行为。但在常规场景中，就像常规的基于crud的应用程序一样，这是不会发生的。\nNon-Blocking 现在来谈谈非阻塞方法。在这种方法中，flow不会等待调用的第一个函数返回响应。它只是继续执行下一行代码。与阻塞方法相比，这种方法有点不太一致，因为函数可能不会返回任何东西或抛出错误，但仍然会执行下一个序列中的代码.\n非阻塞方法简化了IO输入输出密集型操作。除了磁盘和其他基于硬件的操作，通信和网络操作也属于IO操作\nEvent-Driven Architecture 在应用程序中，通常有两种进程:CPU密集型进程和IO密集型进程。IO在web应用程序的上下文中意味着事件。大量IO操作意味着在一段时间内会发生大量事件。一个事件可以是任何事情，从一条tweet到一个按钮的点击，一个HTTP请求，一个接收到的消息，一个变量值的改变等等\n我们知道Web 2.0实时应用程序有很多事件。例如，客户端和服务器之间有很多请求-响应，通常在在线游戏、消息应用程序等。发生得太频繁的事件被称为一连串事件。\n非阻塞架构也被称为反应式架构或事件驱动架构。事件驱动架构在现代web应用程序开发中非常流行。\n像NodeJS这样的技术，像Play、Akka这样的Java生态系统中的框架。io在本质上是非阻塞的，是为现代高io可伸缩的应用而构建的。\n它们能够以最小的资源消耗处理大量并发连接。现代应用程序需要一个完全异步的模型来扩展。这些现代web框架在分布式环境中提供了更可靠的行为。它们被构建成在集群上运行，处理大规模并发场景，解决通常在集群环境中出现的问题。它们使我们在编写代码时不用担心处理多线程、线程锁、高IO导致的内存不足等问题\n随着Web 2.0的出现，技术行业的人们觉得有必要改进这些技术，使其足够强大，以实现现代Web应用程序用例。Spring框架将Spring Reactor模块添加到核心Spring repo中。开发者写了NodeJS, Akka。io,玩等等。\n因此，您可能已经意识到响应式事件驱动的应用程序很难用基于线程的框架实现。当处理线程、共享的可变状态时，锁使事情变得复杂得多。在事件驱动的系统中，一切都被视为流。抽象级别很好，开发人员不必担心管理底层内存\n我相信你们已经很清楚这里应用的数据流用例，比如处理大量的交易事件、处理不断变化的股票市场价格、在线购物应用程序上的用户事件等。\nNodeJS是一个单线程非阻塞框架，用来处理更多IO密集型任务。它有一个事件循环架构\n与此同时，我想断言这样一个事实，即非阻塞技术的出现并不意味着传统技术已经过时。每个技术都有它的用例\nNodeJS不适合CPU密集型任务。CPU密集型操作是指需要大量计算能力的操作，如图形渲染、运行ML算法、在企业系统中处理数据等。为了这些目的而选择NodeJS将是一个错误。\nWeb Hooks 假设您已经编写了一个API，它提供关于Baseball最新独家事件的信息。现在你的API被很多第三方服务使用，他们从API中获取信息，添加他们自己的风格并呈现给用户\n但时不时地有这么多API请求，只是为了检查是否发生了特定的事件，这会让你的服务器崩溃。服务器几乎跟不上请求。消费者无法知道服务器上还没有可用的新信息，或者还没有发生事件。他们只是一直轮询API。这最终会在服务器上堆积不必要的负载，并可能导致服务器崩溃.\n有什么办法可以减少服务器的负载吗,这就是web hooks\nwebhook更像是回调函数。“就像一旦有了新消息，就会打电话给你一样。”你继续你的工作.\nwebhook允许两个服务在没有中间件的情况下进行通信。它们拥有基于事件的机制。\n使用 Web Hooks 要使用webhook，消费者需要用唯一的API Key向服务注册一个HTTP端点。这就像一个电话号码。事件发生时，打这个号码给我。我不会再给你打电话了\n当新信息在后端可用时。服务器向消费者的所有注册端点发出一个HTTP事件，通知它们新的更新.\n浏览器通知就是webhook的一个很好的例子。网站发布新内容时，会通知我们，而不是时不时地访问网站获取新信息\nShared Nothing Architecture(无共享架构) 在使用分布式系统时，您将经常听到“无共享架构”这个术语。当几个模块相互配合工作时。它们通常共享RAM，也称为共享内存。它们共享磁盘，也就是共享数据库。然后他们什么都不分享。模块或服务不共享任何内容的系统体系结构称为共享无内容体系结构\n共享无任何体系结构意味着消除所有单点故障。每个模块都有自己的内存和磁盘。因此，即使系统中的几个模块发生故障，其他模块也不会受到影响。它还有助于提高可伸缩性和性能\n###　Hexagonal Architecture(六角结构)\n该体系结构由三个组件组成\nPorts Adapters Domain 该体系结构的重点是使应用程序的不同组件:独立、松散耦合和易于测试\n应用程序的设计应该是这样的:它可以由人工测试、自动化测试、模拟数据库、模拟中间件、有\u0026amp;没有UI、无需对代码做任何更改或调整\n体系结构模式将域置于其核心，即业务逻辑。在外部，外层有端口和适配器。端口就像一个API，作为一个接口。应用程序的所有输入都通过界面\n当使用jsp和存储过程时，我们仍然拥有分层的架构，UI层是独立的，持久化层是独立的，但业务逻辑与这些层是紧密耦合的。\n相反，六边形模式有它的立场非常清楚，有一个内部组件持有业务逻辑\u0026amp;然后是外部层，端口和适配器，涉及数据库、消息队列、api和其他东西。\nPeer to Peer Architecture(p2p架构) P2P架构是区块链技术的基础。我们都在我们生命中的某些时候使用它来通过Torrent下载文件。所以，我猜你有点想到它是什么。您可能意识到种子，Leeching等的条款。\nA Peer to Peer (P2P) Network P2P网络是一种网络，其中也称为节点也可以在不需要中央服务器的情况下彼此通信。缺少中央服务器规定了单点故障的可能性。 网络中的所有计算机都具有平等的权利。节点同时充当播种器和leecher。所以，即使一些计算机/节点下降，网络和通信也仍然工作.\n一个播种者是一个节点，它在自己的系统上托管数据，并提供带宽上传数据到网络，一个Leecher是一个节点，下载数据从网络。\nA Central Server Mean 一个消息传递应用程序。当两个用户沟通,第一个用户发送一条消息从他的设备,服务器上的消息传递服务,将消息路由到目的地,也就是说,用户的设备接收消息.\n服务器是中心服务器。这些系统也被称为集中式系统\n缺点\n首先，中央服务器可以访问您的所有消息。它可以阅读它，与同伴分享它，嘲笑它等等。因此，通信并不是真正安全的。尽管企业说整个信息管道都是加密的。但数据泄露还是会发生，政府可以获取我们的数据。数据被卖给第三方以牟取暴利。你认为这些通讯应用程序真的安全吗?处于食物链顶端的国家安全、企业官员是否应该使用这些中央服务器消息应用程序进行通信\n其次，如果发生自然灾害，比如地震、僵尸攻击数据中心、大规模基础设施故障或组织破产等情况。我们被困住了，没有办法与世界各地的朋友交流。想想。\n第三，假设你开始在社交媒体上创建内容，你有一个相当坚实的追随者，你每周花费100多个小时来发布有史以来最好的内容，并经过多年的努力才达到这个成功点。但突然有一天，公司突然对你说。嘿! !干得好，但是……由于某些我们不能谈论的原因，我们必须释放你的数据。我们只是不喜欢你的内容。Shift + Del，呼…你所有的数据都像精灵一样消失了。你接下来要做什么?如果你已经是一个内容创造者或活跃在社交媒体上，这种情况就会发生\nP2P架构的工作模式 P2P对等体架构的设计围绕网络中的几个节点设计为同样充当客户端和服务器。\n与TCP IP交换数据，就像在client-server模型中的HTTP协议上发生。P2P设计具有覆盖网络，用于通过TCP IP，使用户能够直接连接。它负责所有复杂性和沉重的举重。节点/对等体在此覆盖网络中索引和可发现。\n在节点之间传输大文件的方法是将文件按非顺序分割成大小相等的块\n一个系统托管75千兆字节的大文件。网络中的其他节点，需要文件，找到包含该文件的系统。然后，他们将文件下载在块中，同时重新托管下载的块，使其更可供其他用户使用。这种方法被称为分段的P2P文件传输\n根据这些对等点在网络中相互连接的方式，将网络分为结构化、非结构化或混合模型\nUnstructured Network 在一个非结构化的网络节点/对等体中继续随机连接。因此，没有结构，没有规则。只需连接和发展网络即可.\n在这个体系结构设计中，没有节点的索引。为了搜索数据，我们必须扫描网络的每个节点。复杂度是O(n)其中n是网络中的节点数。这是非常耗费资源的\n假设这个网络连接着十亿个系统。然后有一个文件只存储在网络中的一个系统中。在非结构化网络中，我们必须对网络中的每个系统进行搜索以找到文件\n因此，如果在一个系统中搜索一个文件，比方说，需要1秒，而在整个网络中搜索则需要10亿秒。\n非结构化网络的一些协议是Gossip, Kazaa和Gnutella。\nStructured Network 与非结构化网络相比，对等网络的结构化P2P对等体保持了节点或拓扑的适当索引，这使得更容易搜索其中的特定数据。\n这种网络实现了分布式哈希表来索引节点这个索引就像一本书的索引，我们在其中查找某一特定信息，而不是搜索它的每一页。\nBitTorrent就是这类网络的一个例子\nHybrid Model(混合模式) 大多数区块链初创公司具有混合模型。一个混合模型意味着cherry-picking来自P2P,client-server等的混合模型,它是一个网络，包含p2p和client-server模型\n正如我们所知，在p2p网络中，一个单独的实体并不拥有所有的控制权。因此，为了建立控制，我们需要建立自己的服务器。为此，我们需要一个client-server模型。\nP2P网络提供了更多的可用性。要关闭区块链网络，你必须关闭全球范围内的所有节点。\nP2P应用程序可以扩展到月球，而无需将负载放在单个实体或节点上。在理想的环境中，网络中的所有节点都平等地共享带宽和存储空间;当新用户使用该应用程序时，系统会自动扩展。\n随着越来越多的人与你的数据进行交互，节点也会增加。数据存储和带宽成本为零，你不需要花钱购买第三方服务器来存储你的数据。没有第三方干预，数据是安全的。只和你想要分享的朋友分享。\n在当今时代，对去中心化网络的狂热正在逐渐流行起来。我不能否认这是一个具有巨大潜力的颠覆性技术。区块链 加密货币就是一个例子。它已经席卷了金融领域.\n例子:\nTradepal 比特币、Peercoin等点对点数字加密货币。 GitTorrent(一个分散的GitHub，使用BitTorrent和比特币)。 Twister(一个分散的微博服务，使用WebTorrent作为媒体附件)。 Diaspora(实现联邦架构的分散式社会网络)。 联邦体系结构是去中心化体系结构的扩展，用于去中心化的社交网络，这是我接下来要讨论的\nDecentralized Social Networks(分散的社交网络) 简单地说，去中心化的社交网络拥有遍布全球的服务器，由像你我这样的个人托管。没有人对网络有自主的控制权，每个人都有平等的发言权\n去中心化网络不需要面对任何可扩展性问题。去中心化网络的可扩展性与网络中加入和活跃用户的数量成正比\n我们从自己的系统中托管数据，而不是将其发送到第三方服务器。没有人会偷听我们的谈话，也没有人有权随心所欲地修改你的数据\n你可能听说过BYOD(Bring Your Own Device)这个词——自带设备。去中心化的社交网络要求你带上你自己的数据\n在这些网络中，用户数据层是独立的\u0026amp;它们运行在专门为去中心化网络设计的标准化协议上。数据格式和协议在网络和应用程序中是一致的\n所以，如果你想脱离某个特定的社交网络。你不会丢失你的数据;你的数据不会消失。你可以随身携带你的数据并将其输入到你接下来注册的应用程序中\n网络上活跃着分散的社交网络，如Minds,** Mastodon**, Diaspora, Friendica,** Sola**等。\n特点 Bring Your Own Data\n正如我在前面提到的，您可以在无数的应用程序中随身携带数据。这是区块链经济的一个非常独特的特点，尤其是在电子游戏中。玩家购买的游戏内货币或内容(游戏邦注:如剑、力量等)可以在基于去中心化协议的其他游戏中使用。即使游戏工作室将游戏下线，购买的游戏内道具仍然具有价值。真正意义上来说，购买的东西会一直伴随你。\n数据安全 不要再窃听私人组织对我们的数据。我们决定与谁分享我们的数据。数据对每个人都是加密的，包括网络的技术团队。不为个人利益出售我们的数据\n对网络当事人进行经济补偿 像Diaspora, Sola, Friendica这样的网络已经推出了一些功能，可以在经济上补偿所有参与网络的各方。\n用户会因为他们在网上分享的精彩内容而得到补偿。人们分享他们的计算能力来托管网络，并根据网络的经济政策以代币或股权或任何形式获得补偿。\n参与网络审核的团队，编写新功能的开发者，通过在网络上发布内容相关的广告或平台上基于令牌的经济来获得补偿\nInfrastructure Ease(简单化基础设施) 单个实体不必承担基础设施的全部成本，因为它是分散的。网络崩溃的可能性几乎为零。单独的开发人员可以构建很酷的东西，而不用担心服务器成本。数据就像区块链分类帐一样在节点间复制。所以，即使有几个节点故障，我们的数据也不会丢失\n这些社交网络的协议和软件都是开源的，所以社区可以不断改进代码，不断构建令人惊叹的功能\nActivityPub就是一个例子，它是一个开放的去中心化的社交网络协议。它提供了一个API来修改和访问网络上的内容。同时，为了与联盟中的其他pods进行交流\n金融科技行业的去中心化正在成为常态。\nFederated Architecture(联邦架构) 联邦体系结构是分散体系结构的扩展。它支持像Mastodon, Minds, Diaspora等社交网络\n语联邦在一般意义上是指一组相互交换信息的半自治实体。一个真实世界的例子是一个国家的不同的州，由州政府管理。他们是部分自治的，行使权力来保持事情顺利运行。然后，这些邦政府与中央政府共享信息，形成一个完全的自治政府\n这只是一个例子。从技术角度来看，联邦模型正在不断的研究、发展和进化中。没有标准的规则。开发人员和架构师可以有自己的设计。毕竟，它是分散的。不受任何单一实体的控制\n如何在去中心化的社交网络中实现联邦架构 如下图所示。联邦网络有称为服务器或pods的实体。大量的节点订阅pods。网络中有几个互相链接的豆荚，它们互相分享信息。\n这些pods可以由个人托管，因为这是在去中心化的网络中理想实现的。随着新的pods被托管和引入到网络中，网络不断增长\n以防几个pods之间的联系暂时中断。网络还在运行。节点仍然可以通过它们订阅的节点彼此通信\npods的需求是什么\nPods可以帮助发现节点。在点对点网络中，没有办法发现其他节点\u0026amp;如果没有一个集中的节点注册表或其他东西，我们只能坐在黑暗中.\n另一种方法是通过网络进行扫描，并尝试发现其他节点。那是一项非常费时且乏味的工作。为什么不直接用pod来代替呢\nHow to Pick the Right Server-Side Technology(如何选择合适的服务器端技术) 对于一个用例X，你应该总是选择一个技术y，这是没有经验法则的。一切都取决于我们的业务需求。每个用例都有其独特的需求。没有完美的技术，每件事都有它的优点和缺点。你可以随心所欲地创造。没有什么规则能阻止我们前进。好吧，说到这里。根据我的开发经验，我列出了一些应用程序开发领域的一般场景，或者可以说是常见的用例，以及适合这些场景的后端技术\nReal-time Data Interaction(实时数据交互) 如果你正在构建一个应用程序，需要与后端服务器实时交互，如流数据来回。例如，即时消息应用、基于浏览器的大型多人游戏、实时协作文本编辑器或像Spotify、Netflix等音频视频流应用\n您需要客户机和服务器之间的持久连接，还需要在后端采用非阻塞技术。我们已经详细讨论了这两个概念。\n一些让我们能够编写这些应用程序的流行技术是NodeJS, Python有一个叫做Tornado的框架。如果你在Java生态系统中工作，你可以查看Spring Reactor, Play, akka .io。\n一旦你开始研究这些技术，仔细研究开发者文档中给出的架构和概念。您将进一步了解事物是如何工作的，可以利用哪些其他技术和概念\nUber使用NodeJS编写他们的核心行程执行引擎。使用它，他们可以轻松地管理大量的并发连接。\nPeer to Peer Web Application 如果你打算构建一个点对点的web应用程序，例如，P2P分布式搜索引擎或P2P直播电视广播服务，类似于LiveStation。\n看看JavaScript, DAT, IPFS之类的协议。FreedomJS是一个构建P2P网络应用的框架，可以在现代浏览器中运行。 这是一个很好的阅读Netflix关于流媒体数据的点对点技术的研究 。\nCRUD-based Regular Application(CRUD常规应用) 如果你有简单的用例，如基于crud的常规应用，如在线电影预订门户，税务申报应用等。CRUD(创建、读取、更新、删除)是当今企业构建的最常见的web应用形式。\n无论是在线预订门户，应用程序收集用户数据或社交网站等，都在后端有一个MVC (Model View Controller)架构。尽管视图部分随着React、Angular、Vue等UI框架的兴起做了一些调整。\n模型视图控制器模式保持不变。一些帮助我们实现这些用例的流行技术是Spring MVC，\nSimple, Small Scale Applications(简单，小规模的应用) 如果您打算编写一个不涉及太多复杂的应用程序，如博客、简单的在线表单、与门户的IFrame中运行的社会媒体集成的简单应用程序。这包括基于网页浏览器的策略，航空公司，足球经理类游戏。你可以选择PHP。PHP最适合用于这类场景。我们也可以考虑其他的web框架，如Spring boot, Ruby on Rails，它们减少了冗余、配置和开发时间，并促进了快速开发。但与托管其他技术相比，PHP托管的成本要低得多\nCPU \u0026 Memory Intensive Applications(CPU和内存密集型应用) 你是否需要在后台运行CPU密集型，内存密集型，繁重的计算任务，如大数据处理，并行处理，运行监控和分析大量的数据?\n在运行CPU和内存密集型任务的系统中，性能是关键。处理大量数据有其成本。一个高延迟和内存消耗的系统可以摧毁一个科技公司的经济。\n此外，常规的web框架和脚本语言并不意味着数字密集运算。\n业界常用的技术是编写高性能、可扩展的分布式系统\nc++中，它具有便于低级内存操作的特性。在编写分布式系统时，为开发人员提供对内存的更多控制。大多数加密货币都是使用这种语言编写的。\nRust是一种类似于c++的编程语言。它是为高性能和安全并发而构建的。它最近在开发者圈中获得了很大的人气\nJava、Scala和Erlang也是不错的选择。大多数大型企业系统都是用Java编写的\nErlang是一种函数式编程语言，内置了对并发、容错和分发的支持。它促进了大规模可伸缩系统的开发。\nGo是谷歌开发的一种编程语言，用于多核机器和处理大量数据\nJulia是一种动态编程语言，用于高性能和运行计算和数值分析\nKey Things To Remember When Picking the Tech Stack(选择技术堆栈时要记住的关键事情) 我从头开始写了无数个项目，花了无数个小时浏览网页，浏览技术和框架，以选择符合我需求的正确技术。\n选择正确的技术堆栈是我们业务成功的关键。没有别的办法。我想我们都很清楚这个事实。一旦我们选择了技术和编码，就不应该回头看。我们当然负担不起。\nBe Thorough with the Requirements(彻底满足需求) 我们应该非常清楚我们要建设什么。事情不应该是模糊的。如果我们不清楚需求，我们就无法选择正确的技术。一旦我们去打猎，我们应该清楚我们要找的是什么\n例如，在寻找数据库时，我们应该清楚是要存储关系数据，还是面向文档、半结构化或完全没有结构。\n我们是否在处理大量的数据，而这些数据预计将呈指数增长?或者，预计数据将以可控制的速度增长到一定限度?\n单一的架构是否能很好地满足我们的需求，还是我们需要将应用程序分割成几个不同的模块?\n将应用程序拆分为几个模块，在服务中使用异构技术，可以帮助我们在事情不顺利的情况下摆脱特定的技术。\nSee If What We Already Know Fits the Requirements(看看我们已经知道什么符合要求) 用我们已经掌握的技术构建新的应用程序会更容易。我们不需要经历随着新技术而来的陡峭的学习曲线.\n而且，当我们使用我们所熟悉的技术时，事情会比较清晰。了解事实真相，熟悉错误、异常和修复它们的知识，有助于我们快速发布特性.\n想象一下，一项你从未见过的新技术引发了一个异常，而且你也无法在网上找到解决方案。你是困。没有人帮助你，你听到的都是蟋蟀的叫声\nDoes the Tech We Have Picked Has An Active Community? How Is the Documentation \u0026 the Support(我们所选择的技术是否拥有一个活跃的社区) 我们选择的技术应该有一个活跃的社区。查看GitHub, StackOverflow等社区的参与情况。文档应该流畅，易于理解\n社区越大越好。拥有一个活跃的社区意味着更新工具、库、框架等\n看看是否有官方的技术支持?如果我们被困在路上，应该会有救援的。正确的\nIs the Tech Being Used by Big Guns in Production(这一技术在生产中被使用了吗) 如果我们所选择的技术正在被行业中的大人物所使用，那么这就证明了它是经过实战考验的。它可以在生产中毫无顾虑地使用\n我们可以肯定的是，我们将不会面临任何固有的可伸缩性、安全性或任何其他设计相关的技术问题。因为，代码库会不断地被新更新、漏洞和设计修复所修补\n我们可以浏览这些公司的工程博客，了解他们是如何实现这项技术的\nCheck the License. Is It Open Source(检查许可证。它是开源的吗) 选择开源技术可以帮助我们编写自己的定制功能，以防原始解决方案没有这些功能。我们不需要依靠技术的创造者来创造新功能\n此外，在资金方面，我们无需支付任何费用使用该产品。开源技术也有一个更大的社区，因为代码对所有人开放，任何人都可以派生它，开始编写新的功能或修复现有的已知bug。\nAvailability Of Skilled Resources on the Tech(技术资源的可用性) 一旦我们的业务开始增长。我们将需要一只手以快速的速度移动，并在规定的时间内推出新功能。在我们选择的技术领域，有足够的技术资源是很重要的.\n例如，总是很容易找到一个MySQL管理员或Java开发人员，而不是寻找一个相对较新的技术熟练的资源.\n","date":"2020-02-03","img":"","permalink":"/posts/architecture_design/%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%842/","series":["软件架构"],"tags":["architecture"],"title":"软件架构2"},{"categories":["tools"],"content":"标准流程图源码格式： st=\u0026gt;start: 开始框 op=\u0026gt;operation: 处理框 cond=\u0026gt;condition: 判断框 sub1=\u0026gt;subroutine: 子流程 io=\u0026gt;inputoutput: 输入输出框 e=\u0026gt;end: 结束框 st-\u0026gt;op-\u0026gt;cond cond(yes)-\u0026gt;io-\u0026gt;e cond(no)-\u0026gt;sub1(right)-\u0026gt;op 标准流程图源码格式（横向）： st=\u0026gt;start: 开始框 op=\u0026gt;operation: 处理框 cond=\u0026gt;condition: 判断框(是或否?) sub1=\u0026gt;subroutine: 子流程 io=\u0026gt;inputoutput: 输入输出框 e=\u0026gt;end: 结束框 st(right)-\u0026gt;op(right)-\u0026gt;cond cond(yes)-\u0026gt;io(bottom)-\u0026gt;e cond(no)-\u0026gt;sub1(right)-\u0026gt;op 流程圖 graph TD A[方形] --\u0026gt;B(圆角) B --\u0026gt; C{条件a} C --\u0026gt;|a=1| D[结果1] C --\u0026gt;|a=2| E[结果2] F[竖向流程图] graph LR A[方形] --\u0026gt;B(圆角) B --\u0026gt; C{条件a} C --\u0026gt;|a=1| D[结果1] C --\u0026gt;|a=2| E[结果2] F[横向流程图] UML时序图源码样例： 对象A-\u0026gt;对象B: 对象B你好吗?（请求） Note right of 对象B: 对象B的描述 Note left of 对象A: 对象A的描述(提示) 对象B--\u0026gt;对象A: 我很好(响应) 对象A-\u0026gt;对象B: 你真的好吗？ UML时序图源码复杂样例： Title: 标题：复杂使用 对象A-\u0026gt;对象B: 对象B你好吗?（请求） Note right of 对象B: 对象B的描述 Note left of 对象A: 对象A的描述(提示) 对象B--\u0026gt;对象A: 我很好(响应) 对象B-\u0026gt;小三: 你好吗 小三--\u0026gt;\u0026gt;对象A: 对象B找我了 对象A-\u0026gt;对象B: 你真的好吗？ Note over 小三,对象B: 我们是朋友 participant C Note right of C: 没人陪我玩 UML标准时序图样例： %% 时序图例子,-\u0026gt; 直线，--\u0026gt;虚线，-\u0026gt;\u0026gt;实线箭头 sequenceDiagram participant 张三 participant 李四 张三-\u0026gt;王五: 王五你好吗？ loop 健康检查 王五-\u0026gt;王五: 与疾病战斗 end Note right of 王五: 合理 食物 \u0026lt;br/\u0026gt;看医生... 李四--\u0026gt;\u0026gt;张三: 很好! 王五-\u0026gt;李四: 你怎么样? 李四--\u0026gt;王五: 很好! 甘特图样例： %% 语法示例 gantt dateFormat YYYY-MM-DDtitle 软件开发甘特图 section 设计 需求 :done, des1, 2014-01-06,2014-01-08 原型 :active, des2, 2014-01-09, 3d UI设计 : des3, after des2, 5d 未来任务 : des4, after des3, 5d section 开发 学习准备理解需求 :crit, done, 2014-01-06,24h 设计框架 :crit, done, after des2, 2d 开发 :crit, active, 3d 未来任务 :crit, 5d 耍 :2d section 测试 功能测试 :active, a1, after des3, 3d 压力测试 :after a1 , 20h 测试报告 : 48h ","date":"2020-01-10","img":"","permalink":"/posts/tools/typora%E7%94%BB%E5%9B%BE/","series":null,"tags":["typora"],"title":"Typora画图"},{"categories":["BigData"],"content":"Hbase 基本概念 Hbase 能做什么\n海量数据存储 准实时查询 HBase在实际业务场景中的应用\n交通:gps,摄像头信息 金融:交易信息 电商:交易信息,浏览信息,物流信息 HBase特点\n容量大:Hbase单表可以有百亿行,百万列,数据矩阵的横纵维度所支持的数据量级都十分具有弹性 面向列:HBase是面向列的存储和权限控制,并支持独立检索.列式存储,其数据在表中是按照某列存储的,这样在查询只需要少数几个字段的时候,能大大减少读取的数据量.并且 可以动态增加列 多版本:HBase每一列的数据存储有多个Version 稀疏性:为空的列并不占用存储空间,表可以设计的很稀疏 扩展性:底层依赖于HDFS(只需要增加机器就可以扩大容量) 高可靠性:WAL机制保证了数据写入时不会因集群异常而导致写入数据丢失;HBase底层使用的HDFS,会有备份 高性能:底层的LSM数据结构和Rowkey有序排列等架构的独特设计,使得HBase具有非常高的写入性能.region切分,主键索引和缓存机制使得HBase在海量数据下具备-定的随机读取性能,该性能针对Rowkey的查询能够达到毫秒级别 HBase数据模型 列簇:\n一张表列簇不会超过5个,多个会增加磁盘交互,降低性能 每个列簇中的列数没有限制 列只有插入数据后存在 列在列簇中是有序的 基本操作\nhbase(main):001:0\u0026gt; create \u0026#39;test\u0026#39;,\u0026#39;info\u0026#39; 0 row(s) in 11.7610 seconds =\u0026gt; Hbase::Table - test hbase(main):002:0\u0026gt; put \u0026#39;test\u0026#39;,\u0026#39;0001\u0026#39;,\u0026#39;info:username\u0026#39;,\u0026#39;euraxluo\u0026#39; 0 row(s) in 6.6130 seconds hbase(main):003:0\u0026gt; scan \u0026#39;test\u0026#39; ROW COLUMN+CELL 0001 column=info:username, timestamp=1577270839695, value=euraxluo 1 row(s) in 0.6160 seconds hbase(main):004:0\u0026gt; put \u0026#39;test\u0026#39;,\u0026#39;0001\u0026#39;,\u0026#39;info:age\u0026#39;,\u0026#39;12\u0026#39; 0 row(s) in 0.3720 seconds hbase(main):005:0\u0026gt; scan \u0026#39;test\u0026#39; ROW COLUMN+CELL 0001 column=info:age, timestamp=1577270880203, value=12 0001 column=info:username, timestamp=1577270839695, value=euraxluo 1 row(s) in 0.0240 seconds hbase(main):006:0\u0026gt; describe \u0026#39;test\u0026#39; Table test is ENABLED test COLUMN FAMILIES DESCRIPTION {NAME =\u0026gt; \u0026#39;info\u0026#39;, BLOOMFILTER =\u0026gt; \u0026#39;ROW\u0026#39;, VERSIONS =\u0026gt; \u0026#39;1\u0026#39;, IN_MEMORY =\u0026gt; \u0026#39;false\u0026#39;, KEEP_DELETED_CELLS =\u0026gt; \u0026#39;FALSE\u0026#39;, DATA_BLOCK_ENCODING =\u0026gt; \u0026#39;NONE\u0026#39;, TTL =\u0026gt; \u0026#39;FOREVER\u0026#39;, COMPRESSION =\u0026gt; \u0026#39;NONE\u0026#39;, MIN_VERSIONS =\u0026gt; \u0026#39;0\u0026#39;, BLOCKCACHE =\u0026gt; \u0026#39;true\u0026#39;, BLOCKSIZE =\u0026gt; \u0026#39;65536\u0026#39;, REPLICATION_SCOPE =\u0026gt; \u0026#39;0\u0026#39;} 1 row(s) in 0.3110 seconds hbase(main):007:0\u0026gt; get \u0026#39;test\u0026#39;,\u0026#39;0001\u0026#39;,\u0026#39;info:age\u0026#39; COLUMN CELL info:age timestamp=1577283627980, value=12 hbase(main):008:0\u0026gt; truncate \u0026#39;test\u0026#39; Truncating \u0026#39;test\u0026#39; table (it may take a while): - Disabling table... - Truncating table... 0 row(s) in 4.2500 seconds hbase(main):009:0\u0026gt; disable \u0026#39;test\u0026#39; 0 row(s) in 9.8040 seconds hbase(main):010:0\u0026gt; is_enabled \u0026#39;test\u0026#39; false 0 row(s) in 0.1060 seconds hbase(main):011:0\u0026gt; drop \u0026#39;test\u0026#39; 0 row(s) in 5.0910 seconds 安装(Hadoop,ZooKeeper,HBase,Kafka 单机伪分布式安装过程及注意事项) 参考链接1 参考链接2 tar包地址 hadoop hbase zookeeper hadoop-native kafka /etc/profile export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL export JAVA_HOME=/home/software/app/jdk1.8.0_202 export CLASSPATH=.:${JAVA_HOME}/jre/lib/rt.jar:${JAVA_HOME}/lib/dt.jar:${JAVA_HOME}/lib/tools.jar export PATH=$JAVA_HOME/bin:$PATH export SCALA_HOME=/home/software/app/scala-2.12.8 export PATH=$SCALA_HOME/bin:$PATH export MAVEN_HOME=/home/software/app/apache-maven-3.3.9 export PATH=$MAVEN_HOME/bin:$PATH export HADOOP_HOME=/home/software/app/hadoop-2.6.0-cdh5.7.0 export CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath):$CLASSPATH export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH export HADOOP_OPTS=\u0026#34;-Djava.library.path=$HADOOP_HOME/lib\u0026#34; export ZOOKEEPER_HOME=/home/software/app/zookeeper-3.4.10 export PATH=$ZOOKEEPER_HOME/bin:$PATH export HBASE_HOME=/home/software/app/hbase-1.2.0-cdh5.7.0 export PATH=$HBASE_HOME/bin:$PATH export KAFKA_HOME=/home/software/app/kafka #_2.12-0.10.2.0 export PATH=$KAFKA_HOME/bin:$PATH export JAVA_OPTS=\u0026#34;-server -Xms256m -Xmx512m -XX:PermSize=128m -XX:MaxPermSize=256m\u0026#34; 安装JDK 略过,就是解压,然后配置环境变量 Hadoop 安装配置过程: 选择 app 目录存放这些软件\n解压缩 tar -zxvf hadoop-2.6.0-cdh5.7.0.tar.gz -C app\n配置环境变量\n解压缩 native 文件,因为我们的lib文件夹是空的 tar -xvf hadoop-native-64-2.6.0.tar -C hadoop-2.6.0-cdh5.7.0.tar.g/lib/native/ ; tar -xvf hadoop-native-64-2.6.0.tar -C hadoop-2.6.0-cdh5.7.0.tar.g/lib\n写配置文件:\n\u0026lt;!-- app/hadoop-2.6.0-cdh5.7.0/etc/hadoop/coite.xml--\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hadoop.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/home/software/hadoop_tmp\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.defaultFS\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:9001\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;!-- app/hadoop-2.6.0-cdh5.7.0/etc/hadoop/hdfs-site.xml--\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.replication\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;1\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.namenode.name.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///home/software/hadoop_tmp/dfs/name\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.datanode.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///home/software/hadoop_tmp/dfs/data\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;!-- \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.checkpoint.data.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///home/software/hadoop_tmp/dfs/fcd\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;fs.checkpoint.edits.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;file:///home/software/hadoop_tmp/dfs/fce\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; --\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;dfs.permissions.enabled\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;false\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; [software]# cat app/hadoop-2.6.0-cdh5.7.0/etc/hadoop/slaves localhost [software]# cat app/hadoop-2.6.0-cdh5.7.0/etc/hadoop/hadoop-env.sh |grep JAVA_HOME # The only required environment variable is JAVA_HOME. All others are # set JAVA_HOME in this file, so that it is correctly defined on export JAVA_HOME=/home/software/app/jdk1.8.0_202 关闭防火墙\nfirewall-cmd --state systemctl stop firewalld.service firewall-cmd --state 测试\nhdfs namenode -format\u0026gt;{ 查看有无报错 } start-dfs.sh\u0026gt;{ 查看日志有无报错 } jps\u0026gt;{ 21366 DataNode 7958 Jps 20888 NameNode 21869 SecondaryNameNode } 最后去网页上查看存活节点数 Hadoop 伪分布式问题 17/09/22 14:53:21 WARN hdfs.DFSClient: DataStreamer Exception org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /input/data.txt._COPYING_ could only be replicated to 0 nodes instead of minReplication (=1). There are 0 datanode(s) running and no node(s) are excluded in this operation. 解决方案: 看它的报错信息好像是节点没有启动，但是我的节点都启动起来了，使用jps也能查看到节点信息。 使用hadoop dfsadmin -report命令查看磁盘使用情况，发现出现以下问题： Configured Capacity: 0 (0 B)Present Capacity: 0 (0 B)DFS Remaining: 0 (0 B)DFS Used: 0 (0 B)DFS Used%: NaN%Under replicated blocks: 0Blocks with corrupt replicas: 0Missing blocks: 0-------------------------------------------------Datanodes available: 0 (0 total, 0 dead) 节点下存储空间都是空的，问题应该就是出现在这了。 查阅资料发现造成这个问题的原因可能是使用hadoop namenode -format格式化时格式化了多次造成那么spaceID不一致，解决方案： 1、停止集群（切换到/sbin目录下） stop-all.sh 2、删除在hdfs中配置的data目录（即在core-site.xml中配置的hadoop.tmp.dir对应文件件）下面的所有数据; rm -rf /root/training/hadoop-2.7.3/tmp 3、重新格式化namenode(切换到hadoop目录下的bin目录下) hdfs namenode -format 4、重新启动hadoop集群（切换到hadoop目录下的sbin目录下） start-all.sh Zookeeper 安装配置 解压缩tar -zxvf zookeeper-3.4.10.tar.gz -C app\n写配置 zoo1.cfg,zoo2.cfg,zoo3.cfg\ncat app/zookeeper-3.4.10/conf/zoo1.cfg\ndataDir=/home/software/zookeeper/zoo1 clientPort=2191 server.1=127.0.0.1:8801:7701 server.2=127.0.0.1:8802:7702 server.3=127.0.0.1:8803:7703 cat app/zookeeper-3.4.10/conf/zoo2.cfg\ndataDir=/home/software/zookeeper/zoo2 clientPort=2192 server.1=127.0.0.1:8801:7701 server.2=127.0.0.1:8802:7702 server.3=127.0.0.1:8803:7703 cat app/zookeeper-3.4.10/conf/zoo3.cfg\ndataDir=/home/software/zookeeper/zoo3 clientPort=2193 server.1=127.0.0.1:8801:7701 server.2=127.0.0.1:8802:7702 server.3=127.0.0.1:8803:7703 配置myid文件\necho \u0026#34;1\u0026#34; \u0026gt; zoo1/myid echo \u0026#34;2\u0026#34; \u0026gt; zoo2/myid echo \u0026#34;3\u0026#34; \u0026gt; zoo3/myid 启动zookeeper服务\nzkServer.sh start app/zookeeper-3.4.10/conf/zoo1.cfg zkServer.sh start app/zookeeper-3.4.10/conf/zoo2.cfg zkServer.sh start app/zookeeper-3.4.10/conf/zoo3.cfg 检查是否启动成功\n10626 QuorumPeerMain 10568 QuorumPeerMain 13450 Jps 10732 QuorumPeerMain 21366 DataNode 20888 NameNode 21869 SecondaryNameNode zkCli.sh -server 127.0.0.1:8802 HBASE配置 解压缩 tar -zxvf hbase-1.2.0-cdh5.7.0.tar.gz -C app\n配置\n[software]# cat app/hbase-1.2.0-cdh5.7.0/conf/hbase-env.sh | grep ^export export JAVA_HOME=/home/software/app/jdk1.8.0_202 export HBASE_OPTS=\u0026#34;-XX:+UseConcMarkSweepGC\u0026#34; export HBASE_MASTER_OPTS=\u0026#34;$HBASE_MASTER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m\u0026#34; export HBASE_REGIONSERVER_OPTS=\u0026#34;$HBASE_REGIONSERVER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m\u0026#34; export HBASE_MANAGES_ZK=false \u0026lt;!--app/hbase-1.2.0-cdh5.7.0/conf/hbase-site.xml --\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.rootdir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://localhost:9001/hbase\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.cluster.distributed\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.zookeeper.quorum\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;127.0.0.1:2191,127.0.0.1:2192,127.0.0.1:2193\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.tmp.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/home/software/hbase/data\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 启动start-hbase.sh\n检验\n21361 HMaster 10626 QuorumPeerMain 21366 DataNode 20888 NameNode 10568 QuorumPeerMain 21512 HRegionServer 10732 QuorumPeerMain 21869 SecondaryNameNode 20638 Jps #查看网页: http://47.107.44.224:60010/master-status Kafka 安装配置 参考链接 解压 tar -zxvf kafka_2.12-0.10.2.0.tgz -C app\n环境变量\nexport KAFKA_HOME=/home/software/app/kafka #_2.11-2.3.1 export PATH=$KAFKA_HOME/bin:$PATH #export JAVA_OPTS=\u0026#34;-server -Xms256m -Xmx512m -XX:PermSize=128m -XX:MaxPermSize=256m\u0026#34; 修改配置\napp/kafka/config/server1.properties\nbroker.id=1 log.dirs=/home/software/kafka/logs1 zookeeper.connect=localhost:2191,localhost:2192,localhost:2193 advertised.listeners=PLAINTEXT://47.107.44.224:9011 listeners=PLAINTEXT://172.17.50.121:9011 app/kafka/config/server2.properties\nbroker.id=2 log.dirs=/home/software/kafka/logs2 zookeeper.connect=localhost:2191,localhost:2192,localhost:2193 advertised.listeners=PLAINTEXT://47.107.44.224:9012 listeners=PLAINTEXT://172.17.50.121:9012 app/kafka/config/server3.properties\nbroker.id=3 log.dirs=/home/software/kafka/logs3 zookeeper.connect=localhost:2191,localhost:2192,localhost:2193 advertised.listeners=PLAINTEXT://47.107.44.224:9013 listeners=PLAINTEXT://172.17.50.121:9013 启动\nkafka-server-start.sh kafka/config/server1.properties \u0026amp; kafka-server-start.sh kafka/config/server2.properties \u0026amp; kafka-server-start.sh kafka/config/server3.properties \u0026amp; 检验\n# 创建一个topic kafka-topics.sh --create --zookeeper localhost:2191,localhost:2192,localhost:2193 --replication-factor 1 --partitions 1 --topic testing # 查看topic list kafka-topics.sh --list --zookeeper localhost:2192 # 运行生产者 kafka-console-producer.sh --broker-list localhost:9011,localhost:9012,localhost:9013 --topic testing #运行消费者 kafka-console-consumer.sh --bootstrap-server localhost:9011 --topic testing --from-beginning ","date":"2019-12-20","img":"","permalink":"/posts/database/hbase%E5%9F%BA%E7%A1%80/","series":null,"tags":["Hbase","database"],"title":"Hbase基础-概念和安装"},{"categories":["redis"],"content":"本文介绍了redisApi以及数据结构\nRedis的API以及数据结构详解 数据结构和内部编码 面向接口编程的思想\nredisObject type（对外的数据类型）\nencoding（内部编码方式）\nptr（数据指针）\nvm（虚拟内存）\nstring（二进制安全） 特性：可以包含任何数据，图片或者序列化对象，一个键最大存储512m\nraw\nint\nembstr\nhash（键值对集合，即map类型） 特性：适合存储对象，并且可以像数据库的update一样，只修改某一个属性值\n使用场景：存储，读取，修改用户属性\nhashtable\nziplist\nlist（双向链表） 特性：增删快，提供了操作某一段元素的API\n使用场景：消息队列，排行榜\nlinkedlist\nziplist\nset（哈希表，元素不重复） 特性：添加，删除，查找的复杂度都是O1；提供了集合运算的API\n使用场景：利用唯一性，统计访问网站的独立ip；好友推荐时，标签交集达到阈值就推荐\nhashtable\nintset\nzset（将set中的元素增加一个score，元素按score有序排列） 特性：数据插入时，已经进行天然排序\n使用场景：排行榜；带权重的消息队列\nskiplist\nziplist\nredis单线程 特点： 在一个时间只会进行一个操作\n拒绝长（慢）命令：\nkeys,flushall,flushdb,show lua script,mutil/exec,operate big value(collection)\n有些命令会启新的线程： fysnc file descriptor,close file descriptor\nredis使用单线程的原因： 纯内存\n非阻塞IO\n避免线程切换和竞态消耗\n字符串 键值结构 key：字符串\nvalue：字符串，整型，json串，位图\n使用场景 缓存\n计数器\n分布式锁\nAPI get key，获取key对应的value (O1)\nset key value，设置key-value (O1)\ndel key，删除 key-value (O1)\nincr key，key自增1 (O1)\ndecr key，key 自减1 (O1)\nincrby key k ，key 自增 k (O1)\ndecrby key k，key 自减 k (O1)\n实战 记录网站每个用户个人主页的访问量 incr userid：pageview\n缓存视频的基本信息(数据源在MySQL中) public VideoInfo get(long id){ String redisKey = redisPrefix + id;//定义一个rediskey VedeoInfo vedeoInfo = redis.get(redisKey); if(videoInfo == null){ videoInfo = mysql.get(id); if(videoInfo != null){ redis.set(key=redisKey,value=serialize(videoInfo)); } } } 分布式id生成器 多个服务并发获取自增id\nincr id\n其他命令 set key value，不管key是否存在，都设置 (O1)\nsetnx key value，key不存在，才设置（add操作）(O1)\nset key value xx，key存在，才设置（update 操作） (O1)\nsetex key seconds value，set key value + EXPIRE key seconds (O1)\nmget k1 k2 \u0026hellip; kn,批量获取key，原子操作（On）\nmset k1 v1 k2 v2 \u0026hellip;,批量设置key-value（On）\ngetset key newvalue，设置新的value，并返回旧的value（O1）\nappend key value，将value追加到旧的value中（O1）\nstrlen key，返回字符串的长度（O1）\nincrbyfloat key -1，增加key对应的值 -1.0（O1）\ngetrange key start end，获取key对应value的指定下标的字符，（O1）\nsetrange key index value，设置key对应的value，指定index下标的字符换成 value （O1）\n哈希 键值结构 key\nfield:value ：是很多的键值对\n#key： userid：1 #field:value email:xxxx@xx.com name:euraxluo Password:sasasasasa id:1 中存储一个个属性值以及对应的value\n和string比较 string要实现这个方式，需要把这些键值对序列化后存到redis中，取出来的时候也要反序列化。并且属性是空值，也要序列化进去，但是我们的哈希中，如果这个属性没有，可以不写\n特点 在value中，存储了一个更小的redis\nfield不能相同，value可以相同\nAPI hget key field，获取hash key 对应的field的value （O1）\nhset key field value，设置hash key 对应的field的value（O1）\nhdel key field,删除hash key 对应field的value（O1）\nhexists key field，判断hash key 是否有field（O1）\nhlen key ,获取hash key field的数量（O1）\nhmset key field1 value1 field2 value2 \u0026hellip;fieldN valueN，批量设置hash key 的一批field value（On）\nhmget key field1 field2 ..fieldN,批量获取hash key 的一批field的值（O1）\n实战 记录每个用户主页的访问量 hash key为user:1:info的数据，为pageview属性设置自增\nhincriby user:1:info pageview count\n缓存视频的基本信息 public VideoInfo get(long id){ String redisKey = redisPrefix + id;//定义一个rediskey Map\u0026lt;String,String\u0026gt; hashMap = redis.hgetAll(redisKey); VideoInfo videoInfo = transformMapToVideo(hashMap); if(videoInfo == null){ videoInfo = mysql.get(id); if(videoInfo != null){ redis.hmset(key=redisKey,value=transformVideoToMap(videoInfo)); } } } 其他命令 hgetall key，返回hash key对应的所有field和value（On）\nhvals key，返回hash key对应的所有field的key（On）\nhkeys key，返回hash key 对应的所有field （On）\nhsetnx key field value,设置hash key对应的field的value，如field已经存在，则失败（O1）\nhinrcby key field intCounter，hash key对应的field的value自增intCount（O1）\nhinrcbyfloat key field floatCount，hincrby浮点数（O1）\n列表 键值结构 key-value（有序队列）\n可以从左右两端进行添加，弹出\n特点 有序\n可以重复\n左右两边插入弹出\nAPI rpush key v1 v2 \u0026hellip; vn,从列表右端插入值（1~n） （O1-On） vn ... v3 v2 v1\nlinsert key before|after value newValue,在list指定的值前|后插入newValue（O1-On）\nlpop key，从左边弹出一个item（O1）\nrpop key，从右边弹出一个item（O1）\nlrem kay count value，根据count的值，从列表中删除|count|个和value的值相等的项，count\u0026gt;0表示从左到右（On）\nltrim key start end，保留start-end索引范围的列表项（On）\nlrange key start end ，获取列表指定索引范围的全部item，包含end（On）\nlindex key index，获取列表指定索引的item（On）\nllen key，获取列表长度（O1）\nlset key index newValue，设置列表指定索引的项为newValue（On）\n实战 时间轴功能 有你关注的人更新了微博：lpush\n时间轴是一个lrange的结果\n微博是一个个对象，可以存放在hashmap或者string中\nlpush中存储了对象中的关键uid，可以通过关键的uid，去取微博内容\n其他命令 blpop keys timeout,依次检查ksys，弹出第一个非空列表的头元素，当没有任何元素时，连接被阻塞，直到等待超时（timeout），或者发现可弹出元素为止（O1）\nblpop keys timeout,依次检查ksys，弹出第一个非空列表的右边元素，当没有任何元素时，连接被阻塞，直到等待超时（timeout），或者发现可弹出元素为止（O1）\nTIPS LPUSH + LPOP = Stack，左入左出是栈\nLPUSH + RPOP = Queue，左入右出是队列\nLPUSH + LTRIM = Capped Collection，限制长度的列表\nLPUSH + BRPOP = Message Queue，左入阻塞式右出是消息队列\n集合 键值结构 key：string\nvalue：集合\n特点 无序\n无重复\n集合间操作\nAPI sadd key elements，向集合kay添加elements，返回添加成功数（O1）\nsrem key elements，将集合kay中的elements移除掉，返回移除成功数（O1）\nscard key，返回集合大小（O1）\nsismember key elements，判断elements是否在集合中（O1）\nsrandmenmber key count，从集合key中挑出count个元素，不会删掉这些元素（O1~On）\nspop key ，从集合中随机弹出一个元素（O1）\nsmembers key，无序返回集合中的所有元素（On）\nsscan key cursor count，增量式迭代从cursor开始迭代，返回count个结果。返回值是一个数组，第一个元素，指示了下一次迭代的游标，如果为0，完全迭代。第二个元素是迭代结果\n实战 抽奖系统，把参与了这个抽奖的用户放进这个集合\n赞，踩，转发，把参与了这个操作的用户放进这个新闻的集合中\ntag，用户标签，可以把用户的标签放进集合中，也可以把用户放进这个标签对应的集合中，这两个是一个事务\n集合运算API sdiff key1 key2,差集\nsinter key1 key2，交集\nsunion key1 key2，并集\nsdiff|sinter|sunion + store destkey,将运算结果保存在destkey中，下次就可以不用计算了\nTIPS SADD = Tagging，可以用类做标签\nSPOP/SRANDMEMBER = Random item，可以用来做随机的场景\nSADD + SINTER = Social Graph，可以用来做社交的场景\n有序集合 键值结构 key：string\nvalue： score:value\n按照score进行排序\n特点 无重复元素\n按照score排序\nvalue中存储着element+score\nAPI zadd key score element[score element\u0026hellip;]，添加score和element，score可以重复（OlogN）\nzrem key elements，删除元素 (O1)\nzscore key element，获取key中element对应的分数（O1）\nzincrby key increScore element，为key中element对应的score加increScore（O1）\nzcard key，返回key中的元素个数（O1）\nzrange key start stop [WITHSCORES]，返回key中排序结果start~end的升序结果，是否和score一起输出（O log(N)+m,N:元素个数,m:end-start）\nzrangebyscore key minScore maxScore [WITHSCORES],返回key中score在minScore~maxScore范围的结果（O log(N)+m,N:元素个数）\nzcount key minScore maxScore，返回有序集合中，在指定分数范围内的个数 （O log(N)+m,N:元素个数）\nzremrangebyrank key start end，删除指定排名内的升序元素（O log(N)+m,N:元素个数,m:end-start）\nzremrangebyscore key minScore maxScore，删除指定分数范围内的升序元素（O log(N)+m,N:元素个数）\n实战 排行榜 score可以是时间戳，销售数，点赞数\n其他API zrevrank key，返回从高到低的排名 （OlogN）\nzrevrange key start end [withscore]，从降序的结果中按照start~end返回结果，（O log(N)+m,N:元素个数,m:end-start）\nzrevrangebyscore，从降序的结果中按照分数返回结果，（O log(N)+m,N:元素个数,m:end-start）\nzinterstore destination numkeys key[key\u0026hellip;]，计算给定的一个或多个有序集的交集，其中给定 key 的数量必须以 numkeys 参数指定，并将该交集(结果集)储存到 destination 。默认结果集中某个成员的 score 值是所有给定集下该成员 score 值之和.（O(NK)+O(Mlog(M))， N 为给定 key 中基数最小的有序集， K 为给定有序集的数量， M 为结果集的基数。）\nzunionstore destination numkeys key[key\u0026hellip;]，计算给定的一个或多个有序集的并集，其中给定 key 的数量必须以 numkeys 参数指定，并将该并集(结果集)储存到 destination 。默认结果集中某个成员的 score 值是所有给定集下该成员 score 值之 和 。（O(NK)+O(Mlog(M))， N 为给定 key 中基数最小的有序集， K 为给定有序集的数量， M 为结果集的基数。）\n","date":"2019-03-10","img":"","permalink":"/posts/redis/redis%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","series":["redis"],"tags":["redis"],"title":"Redis API及数据结构"},{"categories":["redis"],"content":"Redis Cluster 背景 并发量 \u0026lt;10万dps\n数据量 单机内存\u0026lt;256G\n带宽 网卡限制\n解决方式 提高机器配置\n分布式\n数据分布 | 分布方式 | 特点 | 典型产品 |\n| \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026ndash; |\n| 哈希分布 | 数据分散度高数据分布业务无关无法顺序访问支持批量操作 | 一致性哈希MemcacheRedis Cluster缓存产品 |\n| 顺序分布 | 数据分散度易倾斜键值业务相关可顺序访问支持批量操作 | BigTableHBase |\n哈希分布 节点取余：hash(key)%nodes 客户端分片：哈希+取余\n节点扩容：扩容时需要数据迁移\n翻倍扩容：扩容时最好多倍扩容\n一致性哈希 有一个token环，节点在token环上，会为每个key分配一个token，在依据token在环上顺时针寻找最近的节点\n客户端分片：哈希+顺时针选择节点\n节点伸缩：扩容时减少影响的范围\n翻倍伸缩：保证最小迁移数据和保证负载均衡\n虚拟槽分区 预设虚拟槽：每个槽映射一个数据子集，一般比节点数大\n良好的哈希函数：CRC16\n服务端管理节点，槽，数据：例如Redis Cluster\n搭建集群 Redis Cluster架构 节点，很多节点，都负责读写\nmeet，使用raft协议，是互相通信的基础\n指派槽，把节点指派槽，才能正常读写\n复制，保证高可用\n安装 配置安装 节点配置 port ${port} daemonize yes dir \u0026#34;path/to/run\u0026#34; dbdilename \u0026#34;dump-${port}.rdb\u0026#34; logfile \u0026#34;${port}.log\u0026#34; cluster-enabled \u0026lt;yes/no\u0026gt;: 使redis实例作为集群的一个节点 cluster-config-file nodes-${port}.conf: 集群配置文件 cluster-require-full-coverage no,部分节点不可用，依然提供服务 meet操作 cluster meet ip port\n当前节点开启meet\nredis-cli -h 127.1 -p 7000 cluster meet 127.1 7001 redis-cli -h 127.1 -p 7000 cluster meet 127.1 7002 redis-cli -h 127.1 -p 7000 cluster meet 127.1 7003 redis-cli -h 127.1 -p 7000 cluster meet 127.1 7004 redis-cli -h 127.1 -p 7000 cluster meet 127.1 7005 Cluster 配置详解 cluster-enabled \u0026lt;yes/no\u0026gt;: 使redis实例作为集群的一个节点\ncluster-config-file nodes-${port}.conf: 集群配置文件\ncluster-node-timeout \u0026lt;milliseconds\u0026gt;: 这是集群中的节点能够失联的最大时间，超过这个时间，该节点就会被认为故障。如果主节点超过这个时间还是不可达，则用它的从节点将启动故障迁移，升级成主节点。注意，任何一个节点在这个时间之内如果还是没有连上大部分的主节点，则此节点将停止接收任何请求。\ncluster-slave-validity-factor \u0026lt;factor\u0026gt;: 如果设置成０，则无论从节点与主节点失联多久，从节点都会尝试升级成主节点。如果设置成正数，则cluster-node-timeout乘以cluster-slave-validity-factor得到的时间，是从节点与主节点失联后，此从节点数据有效的最长时间，超过这个时间，从节点不会启动故障迁移。假设cluster-node-timeout=5，cluster-slave-validity-factor=10，则如果从节点跟主节点失联超过50秒，此从节点不能成为主节点。注意，如果此参数配置为非0，将可能出现由于某主节点失联却没有从节点能顶上的情况，从而导致集群不能正常工作，在这种情况下，只有等到原来的主节点重新回归到集群，集群才恢复运作。\ncluster-migration-barrier \u0026lt;count\u0026gt;:主节点需要的最小从节点数，只有达到这个数，主节点失败时，它从节点才会进行迁移。更详细介绍可以看本教程后面关于副本迁移到部分。\ncluster-require-full-coverage \u0026lt;yes/no\u0026gt;:在部分key所在的节点不可用时，如果此参数设置为”yes”(默认值), 则整个集群停止接受操作；如果此参数设置为”no”，则集群依然为可达节点上的key提供读操作。\n分配槽 cluster addslots slot [slot ...]\n分配槽，一共6个节点，三主三从：\nredis-cli -h 127.1 -p 7000 cluster addslots {0...5461} redis-cli -h 127.1 -p 7001 cluster addslots {5462...10922} redis-cli -h 127.1 -p 7002 cluster addslots {10923...16383} 使用脚本来分配槽\nstart=$1 end=$2 port=$3 for slot in `seq ${start} ${end}` do echo \u0026#34;slot:${slot}\u0026#34; redis-cli -p ${port} cluster addslots ${slot} done if [${end}==16383] then redis-cli -p ${port} cluster info fi 设置主从 cluster replicate node-id设置不会更改的node-id\n设置从节点去复制主节点\nredis-cli -h 127.1 -p 7003 cluster replicate ${node-id-7000} redis-cli -h 127.1 -p 7004 cluster replicate ${node-id-7001} redis-cli -h 127.1 -p 7005 cluster replicate ${node-id-7002} 使用脚本分配主从\na=$1 b=$2 c=$3 d=$4 master_arr=($(seq ${a} 1 ${b})) slave_arr=($(seq ${c} 1 ${d})) for index in `seq 0 $(( ${#master_arr[*]}-1))` do nodeid=`redis-cli -p ${slave_arr[index]} cluster nodes |grep ${master_arr[index]}` redis-cli -h 127.1 -p ${slave_arr[index]} cluster replicate ${nodeid:0:41} done 最好把主从端口配置在文件中，通过脚本读取运行\n工具安装 ruby环境安装 下载ruby wget https://cache.ruby-lang.org/ruby/2.3/ruby-2.3.1.tar.gz\n安装ruby tar -xvf ruby-2.3.1.tar.gz ./configure -prefix=/usr/local/ruby make make install cd /usr/local/ruby cp bin/ruby /usr/local/bin 安装rubygem redis wget http://rubygems.org/downloads/redis-3.3.0.gem gem install -l redis-3.3.0.gem gem list --check redis gem 安装redis-trib.rb cp ${REDIS_HOME}/src/redis-trib.rb /usr/local/bin\n通过redis-trib搭建集群 配置开启redis节点 redis-server redis-8000.conf redis-server redis-8001.conf redis-server redis-8002.conf redis-server redis-8003.conf redis-server redis-8004.conf redis-server redis-8005.conf 一键开启集群 ./redis-trib.rb creat --replicas 1{每个master的slave数量} [ip：port...]{前面都是master，后面的都是slave}\n","date":"2019-03-10","img":"","permalink":"/posts/redis/rediscluster-1/","series":["redis"],"tags":["redis"],"title":"Redis Cluster"},{"categories":["redis"],"content":"集群伸缩 伸缩原理 伸：增加节点 缩：节点下线\n集群伸缩：槽和数据在节点之间的移动\n扩容集群 准备新节点 打开集群模式\n配置和其他节点统一\n启动后是孤立的节点\n加入集群meet 在集群节点中配置：cluster meet 127.1 \u0026lt;newnodeport\u0026gt;\n使用redis-trib.rb：\nredis-trib.rb ad-node new_host:new_port existing_host:existing_port --slave --master_id \u0026lt;arg\u0026gt;{扩展参数是配置为从节点}\n为它迁移槽和数据可以实现扩容\n可以作为从节点负责故障转移\n迁移槽和数据 1). 对目标节点发送cluster setslot \u0026lt;slot\u0026gt; importing \u0026lt;sourceNodeId\u0026gt;,让目标节点准备导入槽的数据\n2). 对源节点发送cluster setslot \u0026lt;slot\u0026gt; migrating \u0026lt;targetNodeId\u0026gt;,让源节点准备迁出槽\n3). 源节点循环执行cluster getkeysinslot \u0026lt;slot\u0026gt; \u0026lt;count\u0026gt;,每次获取count个属于槽的键\n4). 在源节点上执行migrate \u0026lt;targetIp\u0026gt; \u0026lt;targetPort\u0026gt; key 0{对应数据库，master只有db0} \u0026lt;timeout\u0026gt;,死循环，知道所有的key迁移完成\n5). 重复执行3)~4)知道槽下所有的key迁移到目标节点\n6). 向集群中的所有主节点发送cluster setslot \u0026lt;slot\u0026gt; node \u0026lt;targetNode\tId\u0026gt;,通知槽已经重新分配给目标节点\n伪代码：\ndef move_slot(source,target,slot): #目标节点准备导入槽 target.cluster(\u0026#34;setslot\u0026#34;,slot,\u0026#34;importing\u0026#34;,source,nodeID); #源节点准备导出槽 source.cluster(\u0026#34;setslot\u0026#34;,slot,\u0026#34;migrating\u0026#34;,target,nodeId); while true: #批量从源节点获取key keys = source.cluster(\u0026#34;getkeysinslot\u0026#34;,slot,pipeline_size) if keys.length == 0 #键列表为空，退出循环 break #批量迁移key到目标节点 source.call(\u0026#34;migrate\u0026#34;,target.host,target.port,\u0026#34;\u0026#34;,0,timeout,\u0026#34;keys\u0026#34;,[keys]) #向集群所有主节点通知槽slot被分配给目标节点 for node in nodes: if node.flag == \u0026#34;slave\u0026#34;: continue node.cluster(\u0026#34;setslot\u0026#34;,slot,\u0026#34;node\u0026#34;,target.nodeId) 在集群中添加两个节点7006，7007，7007 slaveof 7006 #生成配置 sed \u0026#39;s/7000/7006/g\u0026#39; redis-7000.conf \u0026gt; redis-7006.conf sed \u0026#39;s/7000/7007/g\u0026#39; redis-7000.conf \u0026gt; redis-7007.conf #启动孤立节点 redis-server redis-7006.conf redis-server redis-7007.conf #加入集群 redis-cli -p 7000 cluster meet 127.1 7006 redis-cli -p 7000 cluster meet 127.1 7007 #配置主从 redis-cli -p 7007 cluster replicate \u0026lt;7006.nodeId\u0026gt; #reshard redis-trib.rb reshard 127.1:7000 #输入迁移槽个数 #输入目标节点Id #选择all或者done，确定源node #是否继续 #查看分配的slot的结果 redis-cli -p 7000 cluster nodes |grep master 缩容集群 下线迁移槽 下线7006，7007 #添加节点时，7006从三个node上获取槽，因此槽分为三段 #迁移槽 redis-trib.rb reshard --from \u0026lt;7006.nodeId\u0026gt; --to \u0026lt;7000.nodeId\u0026gt; --slots \u0026lt;slotsNums\u0026gt; \u0026lt;127.1:7006\u0026gt;{在哪一个端口执行} #同意迁移计划 redis-trib.rb reshard --from \u0026lt;7006.nodeId\u0026gt; --to \u0026lt;7001.nodeId\u0026gt; --slots \u0026lt;slotsNums\u0026gt; \u0026lt;127.1:7006\u0026gt;{在哪一个端口执行} #同意迁移计划 redis-trib.rb reshard --from \u0026lt;7006.nodeId\u0026gt; --to \u0026lt;7002.nodeId\u0026gt; --slots \u0026lt;slotsNums\u0026gt; \u0026lt;127.1:7006\u0026gt;{在哪一个端口执行} #同意迁移计划 忘记节点 忘记7006，7007 #忘记节点,先下线从节点 redis-trib.rb del-node 127.1:7000 \u0026lt;7007.nodeId\u0026gt; #忘记节点,再下线主节点 redis-trib.rb del-node 127.1:7000 \u0026lt;7006.nodeId\u0026gt; ","date":"2019-03-10","img":"","permalink":"/posts/redis/rediscluster-2/","series":["redis"],"tags":["redis"],"title":"Redis Cluster 2"},{"categories":["redis"],"content":"RedisCluster 客户端使用 moved重定向 对任意节点发送键命令\n节点会计算槽和对应节点确定这个键是否指向自身\n如果指向自身，就执行命令，返回key所在的槽\n否则就回复moved异常，客户端拿到这个moved后，重定向节点，重新发送命令\nASK重定向 解决槽迁移时客户端的查询问题\n对源节点发送键命令\n节点发现正在进行槽迁移，回复客户端ask转向\n客户端对目标节点Asking，发送命令\n目标节点返回响应结果\n两者的区别 两者都是客户端重定向\nmoved：槽已经确定迁移\nask：槽还在迁移中\nsmart客户端 目标：追求性能（不能使用代理模式）\n从集群中选取一个可运行节点，使用cluster slots 初始化槽和节点映射\n将cluster slots的结果映射到本地，为每个节点都创建一个连接池\n准备执行命令\n执行命令 通过key哈希模16383，得到slot，通过本地映射得到节点，再通过连接池去连接\n如果连接出错，可能槽迁移，也可能是连接异常，如果槽迁移，那么\n我们随机访问一个活跃节点，节点会返回moved异常\n我们得到槽迁移的结果，更新我们的slot和nodes的映射（确定槽迁移）\n然后再去连接目标节点\n如果命令发送多次未成功，显示异常Too many cluster redirection\njiedisCluster使用 Set\u0026lt;HostAndPort\u0026gt; nodeList = new HashSet\u0026lt;HostAndPort\u0026gt;(); nodeList.add(new HostAndPort(HOST1,PORT1)); nodeList.add(new HostAndPort(HOST2,PORT2)); nodeList.add(new HostAndPort(HOST3,PORT3)); nodeList.add(new HostAndPort(HOST4,PORT4)); nodeList.add(new HostAndPort(HOST5,PORT5)); nodeList.add(new HostAndPort(HOST6,PORT6)); JedisCluster redisCluster = new JedisCluster(nodeList,timeout,poolConfig); TIPS 单例：内置了所有节点的连接池，并可以用来做故障转移\n无需手动借还连接池\n合理设置commons-pool\n整合spring //工厂 import redis.client.jedis.JedisCluster; public class JedisClusterFactory{ private JedisCluster jedisCluster; private List\u0026lt;String\u0026gt; hostPoetList; private int timeout; private Logger logger = LoggerFactory.getLogger(JedisClusterFactory.class) public void init(){ JedisPoolConfig jedisPoolConfig = new JedisPoolConfig(); Set\u0026lt;HostAndPort\u0026gt; nodeSet = new HashSet\u0026lt;HostAndPort\u0026gt;(); for(String hostPort:hostPortList){ String[] arr = hostPort.split(\u0026#34;:\u0026#34;); if(arr.length != 2){ continue; } nodeSet.add(new HostAndPort(arr[0],Integer.parseInt(arr[1]))); } try{ jedisCluster = new JedisCluster(nodeSet,timeout,jedisPoolConfig); }catch(Exception e){ logger.error(e.getMessage(),e); } } public void destroy(){ if(jedisCluster != null){ try{ jedisCluster.close(); }catch(IOException e){ logger.error(e.getMessage(),e); } } } public JedisCluster getJedisCluster(){ return jedisCluster; } public void setHostPortList(List\u0026lt;String\u0026gt; hostPortList){ this.hostPortList = hostPortList; } public void setTomeout(int timeout){ this.timeout = timeout; } } \u0026lt;bean id=\u0026#34;jedisClusterFactory\u0026#34; class=\u0026#34;path/to/factoryClass\u0026#34; init-method=\u0026#34;init\u0026#34; destory-method=\u0026#34;destory\u0026#34;\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;bean id=\u0026#34;jedisCluster\u0026#34; factory-bean=\u0026#34;jedisClusterFactory\u0026#34; factory-method=\u0026#34;getJedisCluster\u0026#34;\u0026gt; \u0026lt;/bean\u0026gt; 多节点命令实现 伪代码\nMap\u0026lt;String,JedisPool\u0026gt; jedisPoolMap = jedisCluster.getClusterNodes(); for(Entry\u0026lt;String,JedisPool\u0026gt;entry:jedisPoolMap.entrySet()){ //获取每个节点的Jedis连接 Jedis.jedis = entry.getValue().getResource(); //只删除主节点数据 if(!isMater(jedis)){ continue; } //finally close } Redis Cluster的故障转移 其他主节点对集群进行监控\n故障发现 通过ping/pong 消息实现故障发现，不需要sentinel\n主观下线：某个节点认为另一个节点不可用\n客观下线：当半数以上持有槽的主节点都标记为某节点主管下线\n故障恢复 从节点资格检查\n1). 每个从节点坚检查与故障主节点的断线时间\n2). 超过cluster-node-timeout*cluster-slave-validity-factory就取消资格\n3). cluster-slave-validity-factory默认为10\n准备选举时间\n1). 给偏移量最大的节点最长的选举时间\n2). 把最接近master节点的从节点的选举延迟时间设置为最短\n选举投票\n1). 收集到master节点数/2+1票就可以替换主节点\n替换主节点\n1). slaveof no one当前从节点取消复制变为主节点\n2). 执行clusterDelSlot撤销故障主节点负责的槽,并执行clusterAddSlot把这些槽分配给自己\n3). 向集群中广播自己的pong消息,表明自己已经替换了故障从节点\nRedisCluster开发运维 集群完整性 cluster-require-full-converge默认为yes\n集群中16384个槽全部可用：保证集群完整性\n节点故障或者正在故障转移，集群下线(error)CLUSTERDOWN The cluster is down\n大多数业务无法容忍，cluster-require-full-converge设置为no\n带宽 消息发送频率：节点发现与其他节点最后通信时间超过cluster-node-timeout会直接发送ping消息\n消息数据量:slots槽数组（2KB空间）和整个集群1/10的状态数据（10个节点状态数据约1kb）\n节点部署的机器规模：集群分布的机器越多且每台机器划分的节点数越均匀，则集群内整体的可用带宽越高\n优化 避免大集群：避免多业务使用一个集群，大业务可以多集群\ncluster-node-timeout：和带宽和故障转移速度都有关，需要均衡\n尽量均匀分配到多机器上，保证高可用和带宽\nPub/Sub广播 publish在集群中每个节点广播：加重带宽 优化 如果需要Pub/Sub，单独开启一套Redis Sentinel 集群倾斜 数据倾斜：内存在每个节点中分布不均 节点和槽分配不均\n1). redis-trib.rb info ip:port查看节点，槽，键值分布\n2). redis-trib.rb rebalance ip:port进行均衡\n不同槽对应键值数量差异较大\n1). CRC16正常情况下比较均匀\n2). 可能存在hash_tag\n3). cluster countkeysinslot {slot}获取槽对应键值个数\n包含bigkey\n1). 在从节点运行redis-cli --bigkeys\n2). 优化：优化数据结构\n内存相关配置不一致（例如每个节点哈希优化不一致）\n1). hash-max-ziplist-value,set-max-intset-entries的配置\n2). 定期检查配置的一致性\n客户端缓冲区大小\n哈希表大小\n请求倾斜：某些节点访问量很高 热点key：重要的key或则bigkey\n1). 避免bigkey\n2). 热键不要用hash_tag\n3). 当一致性需求不高时，可以使用本地缓存+MQ\n读写分离 只读连接：集群模式的从节点不接受任何读写请求\n1). 在从节点get会重定向到负责槽的主节点\n2).readonly命令可以读：连接连接命令\n读写分离：更加复杂\n1). 同样的问题：复制延迟，读取过期数据，从节点故障\n2). 修改客户端：cluster slaves {nodeId}\n3). 不建议使用\n数据迁移 官方迁移工具：redis-trib.rb import --from ip:port{源节点} --copy ip:port{集群节点}\n1).只能从单机迁移到集群\n2).不支持在线迁移：source需要停写\n3).不支持断点续传\n4).单线程迁移：影响速度\n在线迁移\n有一个中转站，这个中转站会伪装成slave节点去拿到全量更新数据\n1).redis-migrate-tool，唯品会\n2).redis-port，豌豆荚\n集群vs单机 集群的限制\n1). key批量操作支持有限，mget，mset必须在一个slot\n2). key事务和lua支持有限：操作的key必须在一个节点\n3). key时数据库分区的最小粒度：不支持bigkey分区\n4). 不支持多个数据库：集群模式下只有一个db 0\n5). 复制只支持直接复制，不能更改复制的拓扑结构（树）减小压力\nRedis Cluster：满足容量和性能的扩展性，很多业务不需要\n1). 客户端性能会降低\n2). 命令无法跨节点用：mget。keys，scan，flush，sinter等\n3).Lua和事务无法跨节点使用\n4).客户端维护复杂\nRedis Sentinel：满足高可用\n总结 Redis Cluster的分区规则\n搭建集群的步骤\n集群伸缩的步骤\nsmart客户端操作redis集群\n集群自动故障转移\n","date":"2019-03-10","img":"","permalink":"/posts/redis/rediscluster-3/","series":["redis"],"tags":["redis"],"title":"Redis Cluster 3"},{"categories":["redis"],"content":"Redis Sentinel 主从复制的问题 手动故障转移\n写能力和存储能力受限\nRedis Sentinel架构 有多个Sentinel节点\n不用来存储数据\n多个节点判断master节点的故障，进行故障转移\n保证高可用，即便一个Sentinel节点挂点也没事\n客户端只会记录sentinel的地址（因为sentinel会进行故障转移，master节点地址不固定）\n一套sentinel可以监控多套master-slave，利用master-name作为标识\nSentinel的故障转移 多个sentinel发现并确认master有问题\n选举出一个sentinel作为领导\n选出一个slave作为新的master\n通知其余slave成为新的master的slave\n通知客户端主从变化\n等待老的master复活成为新的master的slave\n安装与配置 主从配置：\nsed \u0026quot;s/6380/6381/g\u0026quot; redis-6380.conf \u0026gt; redis-6381.conf\n查看：\ncat redis-6381.conf|grep -v \u0026quot;#\u0026quot; |grep -v \u0026quot;^$\u0026quot;\nSentinel配置\nport ${port} dir \u0026#34;\u0026#34; logfile \u0026#34;${port}.log\u0026#34; sentinel monitor mastername 127.1 port{主节点端口} 2{故障发现个数} #判断失败时间 30000毫秒 sentinel down-after-milliseconds mastername 30000 #并发度 sentinel parallel-syncs mastername 1 sentinel failover-timeout mastername 180000 客户端与sentinel连接 高可用 服务端高可用\n客户端高可用\n实现原理 获取全部的sentinel节点\n我需要给sentinel我想连接的mastername\n遍历sentinel节点集合，获取一个可用的sentinel节点\n通过APIget-master-addr-by-name来获取真正的master节点地址\n通过role/role replication验证得到的master节点是否是真正的master\njedisAPI JedisSentinelPool sentinelPool = new JedisSentinelPool(masterName,sentinelSet,poolConfig,timeout); Jedis jedis = null; try{ jedis = redisSentinelPool.getResource(); }catch(Exception e){ logger.error(e.getMessage(),e); }finally{ if(jedis != null) jedis.close(); } redis-py from redis.sentinel import Sentinel sentinel = Sentinel([(\u0026#34;localhost\u0026#34;,26379),(\u0026#34;localhost\u0026#34;,26380),(\u0026#34;localhost\u0026#34;,26381)],socket_timeout=0.1) #获取主节点ip sentinel.discover_master(\u0026#39;mymaster\u0026#39;) #获取从节点ip sentinel.discover_slaves(\u0026#39;mymaster\u0026#39;) 如果你的Redis一直杀不死 检查是否开了守护进程\n检测使用kill -9 能否杀死\n关闭守护进程，利用/etc/init.d/redis-sentinel stop进行关闭\n故障转移 from redis.sentinel import Sentinel as St import redis as rd import time st = St([(\u0026#34;localhost\u0026#34;,26379),(\u0026#34;localhost\u0026#34;,26379),(\u0026#34;localhost\u0026#34;,26379)],socket_timeout=0.1) key = \u0026#34;master\u0026#34; i = 0 while(True): try: masterhost,masterport = st.discover_master(\u0026#39;mymaster\u0026#39;) i +=1 time.sleep(1) client = rd.StrictRedis(host=masterhost,port=masterport) setResult = client.set(key,\u0026#34;value: %d\u0026#34;%i) time.sleep(1) if i%3==0: print(client.get(key)) except Exception as e: print(e) 运行这个程序后，kill -9 掉master\n查看脚本的输出，最后查看sentinel和各个server的日志\ntail -f redis-sentinel-26379.log\n我们可以看到，投票，重写配置，主从辅助，部分复制等等一系列的过程\nsentinel的定时任务 每10秒每个sentinel对master和slave执行info命令 发现slave节点\n确定主从关系\n每2秒每个sentinel通过master节点的channel交换信息（是不是把master作为一个频道，那如果master挂掉了怎么办） 通过__sentinel__:hello频道交换信息\n交互对节点的看法和自身的信息\n3.每1秒每个sentinel对其他sentinel和redis执行ping\n心跳检测，失败判定依据\n是故障检测的基础\n主观下线 每个sentinel节点对Redis节点失败的偏见\nsentinel down-after-milliseconds mastername 30000{超过多久未收到回复}\n客观下线 所有sentinel节点对redis节点失败“达成共识”（超过quorum个统一，建议sentinel/2+1）\nsentinel monitor mastername ip port quorum{法定人数}\n故障转移 领导者选举 原因：只有一个sentinel节点完成故障转移\n选举：通过sentinel is-master-down-by-addr 命令\n这个命令会发出自己对master的主观判断，并且要求将自己设置为领导者\n收到命令的sentinel如果没有同意其他sentinel发出的请求，就会同意这个请求，否则拒绝\n如果sentinel节点超过sentinel集合半数且超过quorum数，那么它将成为领导者\n如果此过程有多个sentinel节点成为了领导者，那么将等待一段时间重新进行选举\nsentinel领导者节点实现故障转移 从slave节点中选出一个合适的节点作为新的master\n对上面的slave节点执行slaveof no one命令让其成为master节点\n向剩余的slave节点发送命令，让它们成为新master节点的slave节点，复制规则和parallel-syncs参数有关{快速复制还是顺序复制}\n更新原来的master节点为slave，并对其保持关注，当其恢复后命令他去复制master\n怎么选择合适的slave节点 选择slave-priority{slava优先级}最高的节点，如果存在返回，不存在继续\n选择复制偏移量最大的slave节点{复制的最完整}，如果存在返回，不存在继续\n选择runID最小的slave节点\nTIPS 节点运维，节点的上下线 节点下线 机器性能不足\n节点故障\n机器故障，过保\nsentinel failover \u0026lt;masterName\u0026gt;,让一个sentinel节点去完成故障转移\n节点临时下线还是永久下线\n节点上线 主节点上线，使用sentinel failover\n从节点上线，slaveof，sentinel节点可以感知\nsentinel上线，配置sentinel monitor mastername 127.1 port quorum\n高可用读写分离 从节点的作用 是一个副本，高可用的基础\n读写分离\n依赖三个消息用于监控slave节点资源池 +switch-master：切换主节点（从节点晋升主节点）\n+convet-to-slave：切换从节点（主节点降为从）\n+sdown：主观下线\n实际部署 在同一局域网不同物理机部署redis Sentinel节点\nredis sentinel 的sentinel节点个数最好为奇数，quorum最好是（节点个数/2+1）\n客户端初始化时连接的是sentinel节点集合，但是sentinel只是配置中心，不是代理模式\n当客户端监控到switch-master时，会重新进行redis连接初始化\n","date":"2019-03-10","img":"","permalink":"/posts/redis/redissentinel/","series":["redis"],"tags":["redis"],"title":"Redis Sentinel"},{"categories":["redis"],"content":"Redis基础学习 Redis是一个key-value存储系统。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set \u0026ndash;有序集合)和hash（哈希类型）。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。\nRedis 是一个高性能的key-value数据库。 redis的出现，很大程度补偿了memcached这类key/value存储的不足，在部 分场合可以对关系数据库起到很好的补充作用。它提供了Python，Ruby，Erlang，PHP客户端，使用很方便,Redis支持主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。从盘可以有意无意的对数据进行写操作。由于完全实现了发布/订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布记录。\n安装和基本命令 安装： Ubuntu18.04：sudo apt-get install redis-server\n安装redis后会自动安装redis-cli\n也可以安装图形工具\nsudo snap install redis-desktop-manager\n基本操作 检查Redis服务器系统进程 ps -aux |grep redis\n通过启动命令检查Redis服务器状态 netstat -nlt|grep 6379\n访问Redis 最简启动\nredis-server\n指定配置文件启动\nredis-server config/redis-6380.conf\n验证\nps -ef|grep redis\nnetstat -antpl | grep redis\nredis-cli -h ip -p port ping\n访问\nredis-cli -a euraxluo -h 127.1 -p 6379\n基本命令 0.keys* 时间复杂度是On\nkeys xx?\nkeys xx*\nkeys xx[x-x]*\n1.判断一个key是否存在 O1 exists key\n2.设置key的过期时间O1 expire key seconds#在seconds秒后过期\nttl key#查看key剩余的过期时间\npersist key#去掉key的过期时间\n查看过期时间\n127.1:6380\u0026gt; set k1 v1 OK 127.1:6380\u0026gt; expire k1 20 (integer) 1 127.1:6380\u0026gt; ttl k1 (integer) 14 127.1:6380\u0026gt; ttl k1 (integer) 1 127.1:6380\u0026gt; ttl k1 (integer) -2（-2表示key不存在，已经过期了） 去掉key过期时间\n127.1:6380\u0026gt; set k1 v1 OK 127.1:6380\u0026gt; ttl k1 (integer) -1 127.1:6380\u0026gt; expire k1 20 (integer) 1 127.1:6380\u0026gt; ttl k1 (integer) 18 127.1:6380\u0026gt; persist k1 (integer) 1 127.1:6380\u0026gt; ttl k1 (integer) -1(-1表示key存在，并且没有设置过期时间) 3.查看key的数据类型O1 type key\n4. 添加一条记录 set k1 \u0026#34;helloworld\u0026#34; get k1 5.添加一条数字记录 set k2 1 #让数字自增 incr k2 get k2 6.添加一个列表记录 #添加列表第一个元素 lpush k3 a #在最左边添加第二个元素 lpush k3 b #在最右边添加第三个元素 rpush k3 c #打印这个列表，按从左到右的顺序，规定起点和终点 lrange k3 0 3 7.添加一个哈希记录 #添加name hset k4 name \u0026#34;euraxluo\u0026#34; #添加email hset k4 email \u0026#34;euraxluo@qq.com\u0026#34; #打印key为name的记录的value hget k4 name #获取整个哈希表 hgetall k4 8.给哈希一次一次添加多个值 #一次添加多个k-v HMSET k5 username euraxluo password pwd age 21 #答应哈希表中，key为username，age对应的value HMGET k5 username age #打印完整的哈希表 HGETALL k5 9.删除记录 #查看所有的key列表 keys × #删除k1,k5 del k1 k5 10.其他设置 #使用密码 sudo vi /etc/redis/redis.conf #取消注释requirepass，设置密码为euraxluo requirepass euraxluo #设置远程访问，注释bind #bind 127.0.0.1 #重启redis sudo /etc/init.d/redis-server restart #使用密码，指定host来登录服务器 redis-cli -a euraxluo -h 127.1 python操作redis 参考博客![https://www.cnblogs.com/koka24/p/5841826.html]\nimport redis 连接数据库 try: r = redis.Redis(host=\u0026#39;127.0.0.1\u0026#39;,password=\u0026#39;euraxluo\u0026#39;,port=6379,db=0) r.keys() print(\u0026#34;connected success.\u0026#34;) except: print(\u0026#34;could not connect to redis.\u0026#34;) connected success. 通过连接池连接 try: pool = redis.ConnectionPool(host=\u0026#39;127.0.0.1\u0026#39;,password=\u0026#39;euraxluo\u0026#39;,port=6379,db=0) r = redis.Redis(connection_pool=pool) r.keys() print(\u0026#34;connected success.\u0026#34;) except: print(\u0026#34;could not connect to redis.\u0026#34;) connected success. 通过python操作redis #bytes to str def b2s(value): return bytes.decode(value) string操作 set(name, value, ex=None, px=None, nx=False, xx=False) ex，过期时间（秒） px，过期时间（毫秒） nx，如果设置为True，则只有name不存在时，当前set操作才执行,同setnx(name, value) xx，如果设置为True，则只有name存在时，当前set操作才执行 r.set(\u0026#39;k2\u0026#39;,\u0026#39;10秒\u0026#39;,10,nx=True)#添加一个记录，过期时间为20秒，如果k2不存在，就执行这个操作 r.psetex(\u0026#39;k3\u0026#39;, 2000, \u0026#39;2000毫秒\u0026#39;)#设置过期时间为毫秒 r.setex(\u0026#39;k1\u0026#39;,2,\u0026#34;2s later\u0026#34;)#过期时间为秒 b2s(r.get(\u0026#39;k3\u0026#39;))#获取值 '2000毫秒' 批量添加记录：mset({key:value,*args});批量获取值：mget(key,*args) r.mset({\u0026#39;k7\u0026#39;:\u0026#39;value5\u0026#39;,\u0026#39;k8\u0026#39;:\u0026#39;value6\u0026#39;})#批量添加记录 r.mget(\u0026#39;k1\u0026#39;,\u0026#39;k2\u0026#39;,\u0026#39;k3\u0026#39;,\u0026#39;k4\u0026#39;,\u0026#39;k5\u0026#39;,\u0026#39;k6\u0026#39;,\u0026#39;k7\u0026#39;,\u0026#39;k8\u0026#39;)#批量获取值 [b'2s later', b'10\\xe7\\xa7\\x92', b'2000\\xe6\\xaf\\xab\\xe7\\xa7\\x92', None, None, None, b'value5', b'value6'] getset(name,value) 设置新值，打印旧值 r.getset(\u0026#39;k7\u0026#39;,\u0026#39;new\u0026#39;) b'value5' getrange(key, start, end) 根据字节获取子序列 r.getrange(\u0026#39;k8\u0026#39;,0,-2) b'value' setrange(name, offset, value) 修改字符串内容，从指定字符串索引开始向后替换，如果新值太长时，则向后添加 r.set(\u0026#34;name\u0026#34;,\u0026#34;zhangsan\u0026#34;) r.setrange(\u0026#34;name\u0026#34;,1,\u0026#34;z\u0026#34;) print(r.get(\u0026#34;name\u0026#34;)) #输出:zzangsan r.setrange(\u0026#34;name\u0026#34;,6,\u0026#34;zzzzzzz\u0026#34;) print(r.get(\u0026#34;name\u0026#34;)) #输出:zzangszzzzzzz b'zzangsan' b'zzangszzzzzzz' setbit(name, offset, value)对二进制表示位进行操作;getbit(name, offset) 获取name对应值的二进制中某位的值(0或1) name，redis的name offset，位的索引（将值对应的ASCII码变换成二进制后再进行索引） value，值只能是 1 或 0 str=\u0026#39;123\u0026#39; r.set(\u0026#39;k1\u0026#39;,str) for i in str: print(i,ord(i),bin(ord(i)))#1字符串，ascii码，ascii二进制表示 1 49 0b110001 2 50 0b110010 3 51 0b110011 r.setbit(\u0026#39;k1\u0026#39;,6,1)#把第7位变成1 r.get(\u0026#39;k1\u0026#39;) b'323' r.getbit(\u0026#39;k1\u0026#39;,6) 1 bitcount(key, start=None, end=None) 获取对应二进制中1的个数 key:Redis的name start:字节起始位置 end:字节结束位置 r.bitcount(\u0026#39;k1\u0026#39;,start=0,end=0) 4 strlen(name) 返回name对应值的字节长度 r.set(\u0026#39;k2\u0026#39;,\u0026#34;飒飒\u0026#34;)#一个中文3个字节 r.strlen(\u0026#39;k2\u0026#39;) 6 incr(self, name, amount=1)自增整数，incrbyfloat(self, name, amount=1.0)自增浮点数，decr(self, name, amount=1)自减整数 r.incr(\u0026#34;k1\u0026#34;,amount=2)#可以对str类型的整数进行自增 325 r.set(\u0026#39;k2\u0026#39;,\u0026#39;123.1\u0026#39;) r.incrbyfloat(\u0026#39;k2\u0026#39;,amount=1.1)#可以对str类型的浮点数进行自增 #r.decrbyfloat(\u0026#39;k2\u0026#39;,amount=1.1) 没有这个东西 124.2 r.decr(\u0026#39;k1\u0026#39;, amount=1) 324 append(name,value) r.append(\u0026#34;k3\u0026#34;,\u0026#34;str\u0026#34;)#返回的是append后的value的长度 r.get(\u0026#39;k3\u0026#39;) b'2000\\xe6\\xaf\\xab\\xe7\\xa7\\x92str' HASH操作 redis中的Hash在内存中一个name对应一个dic来存储\nhset(name,key,value)在name对应的hash中设置一个k-v;hget(name,key);hgetall(name) r.hset(\u0026#39;h1\u0026#39;,\u0026#39;name\u0026#39;,\u0026#39;euraxluo\u0026#39;) r.hgetall(\u0026#39;h1\u0026#39;) {b'name': b'euraxluo'} hmset(name,mapping) 在name对应的hash中用dic来填充;hmget(name, keys, *args) 从hash中获取多个key值 dic={\u0026#34;name\u0026#34;:\u0026#34;euraxluo\u0026#34;,\u0026#34;age\u0026#34;:\u0026#34;13\u0026#34;} r.hmset(\u0026#39;h1\u0026#39;,dic) r.hgetall(\u0026#39;h1\u0026#39;) {b'name': b'euraxluo', b'age': b'13'} hlen(name)获取hash中键值对的个数、hkeys(name)获取hash中所有的key的值、hvals(name)获取hash中所有的value的值 r.hlen(\u0026#39;h1\u0026#39;) 2 r.hkeys(\u0026#39;h1\u0026#39;) [b'name', b'age'] r.hvals(\u0026#39;h1\u0026#39;) [b'euraxluo', b'13'] hexists(name, key) 检查name对应的hash是否存在当前传入的key r.hexists(\u0026#39;h1\u0026#39;,\u0026#39;sex\u0026#39;) False hdel(name,*keys) 删除指定name对应的keys对应的k-v r.hdel(\u0026#39;h1\u0026#39;,\u0026#39;sex\u0026#39;) 0 r.hdel(\u0026#39;h1\u0026#39;,\u0026#39;age\u0026#39;) 1 hincrby(name, key, amount=1) 自增hash中key对应的值，不存在则创建key=amount(amount为整数) dic={\u0026#34;name\u0026#34;:\u0026#34;euraxluo\u0026#34;,\u0026#34;age\u0026#34;:\u0026#34;13\u0026#34;,\u0026#39;test\u0026#39;:\u0026#39;13.1\u0026#39;} r.hmset(\u0026#39;h2\u0026#39;,dic) r.hincrby(\u0026#39;h2\u0026#39;,\u0026#39;age\u0026#39;,amount=2) r.hgetall(\u0026#39;h2\u0026#39;) {b'name': b'euraxluo', b'age': b'15', b'test': b'13.1'} hincrbyfloat(name, key, amount=1.0) 自增hash中key对应的值，不存在则创建key=amount(amount为浮点数) r.hincrbyfloat(\u0026#39;h2\u0026#39;,\u0026#39;test\u0026#39;,amount=2.1) r.hgetall(\u0026#39;h2\u0026#39;) {b'name': b'euraxluo', b'age': b'15', b'test': b'15.2'} hscan(name, cursor=0, match=None, count=None) 增量式迭代获取，对于数据大的数据非常有用，hscan可以实现分片的获取数据，并非一次性将数据全部获取完，避免内存被撑爆\nname，redis的name cursor，游标（基于游标分批取获取数据） match，匹配指定key，默认None 表示所有的key count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 r.hscan(\u0026#39;h2\u0026#39;,cursor=1,match=\u0026#39;*e*\u0026#39;,count=2) (0, {b'name': b'euraxluo', b'age': b'15', b'test': b'15.2'}) hscan_iter(name, match=None, count=None) 利用yield封装hscan创建生成器，实现分批去redis中获取数据\nmatch，匹配指定key，默认None 表示所有的key count，每次分片最少获取个数，默认None表示采用Redis的默认分片个数 for i in r.hscan_iter(\u0026#39;h2\u0026#39;,match=\u0026#39;*e*\u0026#39;,count=2):print(i) (b'name', b'euraxluo') (b'age', b'15') (b'test', b'15.2') List操作 redis中的List在在内存中按照一个name对应一个List来存储。\nlpush(name,values)在name对应的list中添加元素，每个新的元素都添加到列表的最左边;rpush(name, values) 表示从右向左操作 r.lpush(\u0026#39;l1\u0026#39;,\u0026#39;a\u0026#39;) 2 lpushx(name,value)在name对应的list中添加元素，只有name已经存在时，值添加到列表的最左边; rpushx(name, value) 表示从右向左操作 r.lpushx(\u0026#39;l1\u0026#39;,\u0026#39;b\u0026#39;) 3 llen(name)name对应的list的元素个数 r.llen(\u0026#39;l1\u0026#39;) 3 linsert(name, where, refvalue, value))在name对应的列表的某一个值前或后插入一个新值 name，redis的name where，BEFORE或AFTER refvalue，标杆值，即：在它前后插入数据 value，要插入的数据 r.linsert(\u0026#39;l1\u0026#39;,\u0026#39;BEFORE\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c1\u0026#39;) r.linsert(\u0026#39;l1\u0026#39;,\u0026#39;AFTER\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c2\u0026#39;) 5 lset(name, index, value)对name对应的list中的某一个索引位置重新赋值 name，redis的name index，list的索引位置 value，要设置的值 r.lset(\u0026#39;l1\u0026#39;,\u0026#39;0\u0026#39;,\u0026#39;c\u0026#39;) r.lrange(\u0026#39;l1\u0026#39;,0,-1) [b'c', b'b', b'c2', b'a', b'c'] lrem(name, num, value)在name对应的list中删除指定的值 name，redis的name value，要删除的值 num， num=0，删除列表中所有的指定值； num=2,从前到后，删除2个； num=-2,从后向前，删除2个 r.lrem(\u0026#39;l1\u0026#39;,2,\u0026#39;c\u0026#39;) 2 lpop(name)在name对应的列表的左侧获取第一个元素并在列表中移除，返回值则是第一个元素;rpop(name) 表示从右向左操作 r.lpop(\u0026#39;l1\u0026#39;) r.lrange(\u0026#39;l1\u0026#39;,0,-1) [b'c2', b'a'] ltrim(name, start, end)在name对应的列表中移除没有在start-end索引之间的值 name，redis的name start，索引的起始位置 end，索引结束位置 r.ltrim(\u0026#39;l1\u0026#39;,0,-2) r.lrange(\u0026#39;l1\u0026#39;,0,-1) [b'c2'] rpoplpush(src, dst)从一个列表取出最右边的元素，同时将其添加至另一个列表的最左边 src，要取数据的列表的name dst，要添加数据的列表的name r.lpush(\u0026#39;l2\u0026#39;,\u0026#39;c\u0026#39;) r.rpop(\u0026#39;l1\u0026#39;) r.rpoplpush(\u0026#39;l2\u0026#39;,\u0026#39;l1\u0026#39;) r.lrange(\u0026#39;l1\u0026#39;,0,-1) [b'c'] blpop(keys, timeout)将多个列表排列，按照从左到右去pop对应列表的元素;brpop(keys, timeout)，从右向左获取数据 keys，redis的name的集合 timeout，超时时间，当元素所有列表的元素获取完之后，阻塞等待列表内有数据的时间（秒）, 0 表示永远阻塞 r.lpush(\u0026#34;l3\u0026#34;, \u0026#39;11\u0026#39;, \u0026#39;22\u0026#39;, \u0026#39;33\u0026#39;) r.lpush(\u0026#34;l4\u0026#34;, \u0026#39;44\u0026#39;, \u0026#39;55\u0026#39;, \u0026#39;66\u0026#39;) r.brpop([\u0026#39;l3\u0026#39;,\u0026#39;l4\u0026#39;],timeout=1) (b'l3', b'33') lindex(name, index)在name对应的列表中根据索引获取列表元素 r.lindex(\u0026#39;l3\u0026#39;,1) b'22' 增量迭代 由于redis类库中没有提供对列表元素的增量迭代，如果想要循环name对应的列表的所有元素，那么就需要：\n1、获取name对应的所有列表\n2、循环列表\n但是，如果列表非常大，那么就有可能在第一步时就将程序的内容撑爆，所有有必要自定义一个增量迭代的功能：\ndef list_iter(name): \u0026#34;\u0026#34;\u0026#34; 自定义redis列表增量迭代 :param name: redis中的name，即：迭代name对应的列表 :return: yield 返回 列表元素 \u0026#34;\u0026#34;\u0026#34; list_count = r.llen(name) for index in range(list_count): yield r.lindex(name, index) for item in list_iter(\u0026#39;l3\u0026#39;):print(item) b'33' b'22' b'11' b'33' b'22' b'11' b'33' b'22' b'11' b'33' b'22' b'11' b'33' b'22' b'11' b'33' b'22' b'11' b'33' b'22' b'11' b'33' b'22' b'11' Set操作，Set集合就是不允许重复的列表 sadd(name,values) name对应的集合中添加元素 r.sadd(\u0026#39;s2\u0026#39;,\u0026#34;value1\u0026#34;,\u0026#34;2sasa\u0026#34;,\u0026#34;2sasa\u0026#34;,\u0026#34;2ssss\u0026#34;) 1 scard(name) 获取name对应的集合中元素个数 r.scard(\u0026#39;s1\u0026#39;) 0 sdiff(keys, *args)在第一个name对应的集合中且不在其他name对应的集合的元素集合 r.sdiff(\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;)#s1对应的集合中且不在其他name对应的集合的元素集合 set() sdiffstore(dest, keys, *args)获取第一个name对应的集合中且不在其他name对应的集合，再将其新加入到dest对应的集合中 r.sdiffstore(\u0026#39;s3\u0026#39;,\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;) r.smembers(\u0026#39;s3\u0026#39;) set() sinter(keys, *args)获取多个name对应集合的并集 r.sinter(\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;) set() sinterstore(dest, keys, *args)获取多一个name对应集合的并集，再讲其加入到dest对应的集合中 r.sinterstore(\u0026#39;s4\u0026#39;,\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;) r.smembers(\u0026#39;s4\u0026#39;) set() sismember(name, value)检查value是否是name对应的集合的成员 r.sismember(\u0026#39;s1\u0026#39;,\u0026#39;value1\u0026#39;) False smembers(name)获取name对应的集合的所有成员 r.smembers(\u0026#39;s1\u0026#39;) set() smove(src, dst, value)将某个成员从一个集合中移动到另外一个集合 r.smove(\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;,\u0026#39;ssss\u0026#39;) r.smembers(\u0026#39;s2\u0026#39;) {b'2sasa', b'2ssss', b'ssss', b'value1'} spop(name)从集合的右侧（尾部）移除一个成员，并将其返回 r.spop(\u0026#39;s1\u0026#39;) r.smembers(\u0026#39;s1\u0026#39;) set() srandmember(name, numbers)从name对应的集合中随机获取 numbers 个元素 r.srandmember(\u0026#39;s2\u0026#39;,\u0026#39;2\u0026#39;) [b'2ssss', b'2sasa'] srem(name, values)在name对应的集合中删除某些值 r.srem(\u0026#39;s2\u0026#39;,\u0026#39;2ssss\u0026#39;) r.smembers(\u0026#39;s2\u0026#39;) {b'2sasa', b'ssss', b'value1'} sunion(keys, *args)获取多一个name对应的集合的并集 r.sunion(\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;,\u0026#39;s3\u0026#39;) {b'2sasa', b'ssss', b'value1'} sunionstore(dest,keys, *args)获取多一个name对应的集合的并集，并将结果保存到dest对应的集合中 r.sunionstore(\u0026#39;d4\u0026#39;,\u0026#39;s1\u0026#39;,\u0026#39;s2\u0026#39;,\u0026#39;s3\u0026#39;) r.smembers(\u0026#39;d4\u0026#39;) {b'2sasa', b'ssss', b'value1'} sscan(name, cursor=0, match=None, count=None);sscan_iter(name, match=None, count=None)同字符串的操作，用于增量迭代分批获取元素，避免内存消耗太大 for i in r.sscan_iter(\u0026#39;s2\u0026#39;,match=\u0026#39;*v*\u0026#39;,count=2):print(i) b'value1' 有序集合，在集合的基础上，为每元素排序 元素的排序需要根据另外一个值来进行比较，所以，对于有序集合，每一个元素有两个值，即：值和分数，分数专门用来做排序。\nzadd(name, mapping, nn,nx)在name对应的有序集合中添加元素 zadd(\u0026#39;zz\u0026#39;, \u0026#39;n1\u0026#39;, 1, \u0026#39;n2\u0026#39;, 2) 或 zadd(\u0026#39;zz\u0026#39;, n1=11, n2=22) dic={\u0026#39;n1\u0026#39;:1,\u0026#39;n2\u0026#39;:2} r.zadd(\u0026#39;zz\u0026#39;,dic) 2 zcard(name)获取name对应的有序集合元素的数量 r.zcard(\u0026#39;zz\u0026#39;) 2 zcount(name, min, max)获取name对应的有序集合中分数 在 [min,max] 之间的个数 r.zcount(\u0026#39;zz\u0026#39;,0,1) 1 zincrby(name, value, amount)自增name对应的有序集合的 name 对应的分数 r.zincrby(\u0026#39;zz\u0026#39;,value=\u0026#39;n3\u0026#39;,amount=1) 1.0 zrange( name, start, end, desc=False, withscores=False, score_cast_func=float)按照索引范围获取 name对应的有序集合的元素 name，redis的name start，有序集合索引起始位置（非分数） end，有序集合索引结束位置（非分数） desc，排序规则，默认按照分数从小到大排序 withscores，是否获取元素的分数，默认只获取元素的值 score_cast_func，对分数进行数据转换的函数 r.zrange(\u0026#39;zz\u0026#39;,0,-1,desc=True,withscores=True)#desc=true,排序规则从大到小 [(b'n2', 2.0), (b'n3', 1.0), (b'n1', 1.0)] zrevrange(name, start, end, withscores=False, score_cast_func=float) 从大到小排序 r.zrevrange(\u0026#39;zz\u0026#39;,0,-1,withscores=True) [(b'n2', 2.0), (b'n3', 1.0), (b'n1', 1.0)] zrangebyscore(name, min, max, start=None, num=None, withscores=False, score_cast_func=float 按照分数范围获取name对应的有序集合的元素 zrevrangebyscore(name, max, min, start=None, num=None, withscores=False) 从大到小排序 r.zrangebyscore(\u0026#39;zz\u0026#39;,1,2,withscores=True) [(b'n1', 1.0), (b'n3', 1.0), (b'n2', 2.0)] zrank(name, value) 获取某个值在 name对应的有序集合中的排行（从 0 开始）\nzrevrank(name, value)，从大到小排序 r.zrank(\u0026#39;zz\u0026#39;,\u0026#39;n3\u0026#39;)#n3最大 1 zrangebylex(name, min, max, start=None, num=None) 当有序集合的所有成员都具有相同的分值时，有序集合的元素会根据成员的 值 （lexicographical ordering）来进行排序，而这个命令则可以返回给定的有序集合键 key 中， 元素的值介于 min 和 max 之间的成员\n对集合中的每个成员进行逐个字节的对比（byte-by-byte compare）， 并按照从低到高的顺序， 返回排序后的集合成员。 如果两个字符串有一部分内容是相同的话， 那么命令会认为较长的字符串比较短的字符串要大\nname，redis的name min，左区间（值）。 + 表示正无限； - 表示负无限； ( 表示开区间； [ 则表示闭区间 min，右区间（值） start，对结果进行分片处理，索引位置 num，对结果进行分片处理，索引后面的num个元素 zrevrangebylex(name, max, min, start=None, num=None) 从大到小排序 dic={\u0026#39;aa\u0026#39;:0,\u0026#39;ba\u0026#39;:0,\u0026#39;ca\u0026#39;:0,\u0026#39;da\u0026#39;:0,\u0026#39;ea\u0026#39;:0,\u0026#39;fa\u0026#39;:0} r.zadd(\u0026#39;z1\u0026#39;,dic) r.zrangebylex(\u0026#39;z1\u0026#39;, \u0026#34;-\u0026#34;, \u0026#34;[fa]\u0026#34;) [b'aa', b'ba', b'ca', b'da', b'ea', b'fa'] zrem(name, values) 删除name对应的有序集合中值是values的成员 r.zrem(\u0026#39;z1\u0026#39;, \u0026#39;fa\u0026#39;, \u0026#39;ea\u0026#39;) 2 zremrangebyrank(name, min, max) 根据排行范围删除 r.zremrangebyrank(\u0026#39;zz\u0026#39;,0,1) 2 zremrangebyscore(name, min, max)根据分数范围删除 r.zremrangebyscore(\u0026#39;z1\u0026#39;,0,3) 4 zremrangebylex(name, min, max)根据值返回删除 ZREMRANGEBYLEX 删除名称按字典由低到高排序成员之间所有成员。\n不要在成员分数不同的有序集合中使用此命令, 因为它是基于分数一致的有序集合设计的,如果使用,会导致删除的结果不正确。\n待删除的有序集合中,分数最好相同,否则删除结果会不正常。\ndic={\u0026#39;aa\u0026#39;:0,\u0026#39;ba\u0026#39;:0,\u0026#39;ca\u0026#39;:0,\u0026#39;da\u0026#39;:0,\u0026#39;ea\u0026#39;:0,\u0026#39;fa\u0026#39;:0} r.zadd(\u0026#39;z2\u0026#39;,dic) r.zremrangebylex(\u0026#39;z2\u0026#39;,\u0026#39;[aa\u0026#39;,\u0026#39;(ea\u0026#39;) r.zrangebylex(\u0026#39;z2\u0026#39;,\u0026#39;-\u0026#39;,\u0026#39;+\u0026#39;) [b'ea', b'fa'] zscore(name, value)获取name对应有序集合中 value 对应的分数 r.zscore(\u0026#39;z2\u0026#39;,value=\u0026#39;ea\u0026#39;) 0.0 zinterstore(dest, keys, aggregate=None)获取两个有序集合的交集，如果遇到相同值不同分数，则按照aggregate进行操作 r.zinterstore(\u0026#39;z1\u0026#39;,\u0026#39;z2\u0026#39;,aggregate=\u0026#39;MAX\u0026#39;) 0 zunionstore(dest, keys, aggregate=None)获取两个有序集合的并集，如果遇到相同值不同分数，则按照aggregate进行操作 aggregate的值为: SUM MIN MAX\nr.zinterstore(\u0026#39;z1\u0026#39;,\u0026#39;z2\u0026#39;,aggregate=\u0026#39;MAX\u0026#39;) 0 zscan(name, cursor=0, match=None, count=None, score_cast_func=float) zscan_iter(name, match=None, count=None,score_cast_func=float) 同字符串相似，相较于字符串新增score_cast_func，用来对分数进行操作\n其他常用操作 delete(*names)根据name删除redis中的任意数据类型,返回值为删除的个数 r.delete(\u0026#34;k4\u0026#34;,\u0026#39;k2\u0026#39;,\u0026#39;k3\u0026#39;) 1 exists(name)若 name 存在返回 1 ，否则返回 0 。 r.exists(\u0026#39;11\u0026#39;) 0 keys(pattern=\u0026rsquo;*\u0026rsquo;)根据pattern获取redis的name KEYS * 匹配数据库中所有 key 。 KEYS h?llo 匹配 hello ， hallo 和 hxllo 等。 KEYS h*llo 匹配 hllo 和 heeeeello 等。 KEYS h[ae]llo 匹配 hello 和 hallo ，但不匹配 hillo r.keys(\u0026#34;*\u0026#34;) [b'name', b'l3', b'k7', b's2', b'z2', b'z3', b'k1', b'h2', b'd4', b'l4', b'zz', b'l1', b'k8', b'h1', b'l2'] expire(name ,time)为某个redis的某个name设置超时时间 r.expire(\u0026#39;name\u0026#39;,2) True rename(src, dst)对redis的name重命名为 r.rename(\u0026#39;zz\u0026#39;,\u0026#39;z3\u0026#39;) True move(name, db))将redis的某个值移动到指定的db下 print(r.hkeys(\u0026#39;h1\u0026#39;)) r.move(\u0026#39;h1\u0026#39;,1) r.hkeys(\u0026#39;h1\u0026#39;) [b'name'] [b'name'] randomkey()随机获取一个redis的name（不删除） r.randomkey() b'l3' type(name) 获取name对应值的类型 r.type(\u0026#39;d4\u0026#39;) b'set' scan(cursor=0, match=None, count=None) scan_iter(match=None, count=None) 同字符串操作，用于增量迭代获取key\n","date":"2019-03-10","img":"","permalink":"/posts/redis/redis%E5%9F%BA%E7%A1%80/","series":["redis"],"tags":["redis"],"title":"Redis基础学习"},{"categories":["redis"],"content":"Redis的主从复制 单机部署的问题 机器故障（高可用）\n容量瓶颈（分布式）\nQPS瓶颈（分布式）\n主从复制的作用 为一个数据提供了副本\nslave从master复制一个备份库\nmaster可以有多个slave\n一个slave只能有一个master\n数据流向是单向的，由master\u0026ndash;\u0026gt;slave\n扩展读性能，可以实现读写分离\n主从复制实现 slaveof slaveof 127.1 6380\n取消复制\nslaveof no one\n配置 #配置这个redis服务复制ip:port这个redis作为他的slave slaveof ip port #只读,必须保证从和主的内容一致 slave-read-only yes 两种方式的比较 | 方式 | 命令 | 配置 |\n| \u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026ndash; |\n| 优点 | 无需重启 | 统一配置 |\n| 缺点 | 不便于管理 | 需要重启 |\n使用配置的方式实现主从复制，需要重启原来的redis服务器 config redis-cli -h 127.1 -p 6379 shutdown\nconfig ps -ef |grep redis-server\nxl 3963 1 0 3月09 ? 00:03:17 redis-server *:6380 xl 19626 18759 0 13:41 pts/0 00:00:00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn redis-server config redis-cli -h 127.1 -p 6380 shutdown\nconfig ps -ef |grep redis-server\nxl 19649 18759 0 13:41 pts/0 00:00:00 grep --color=auto --exclude-dir=.bzr --exclude-dir=CVS --exclude-dir=.git --exclude-dir=.hg --exclude-dir=.svn redis-server config redis-server redis-6379.conf\nconfig redis-server redis-6380.conf\nconfig redis-cli -h 127.1 -p 6379 info replication\n# Replication role:master connected_slaves:0 master_replid:8e2a95428f7fa32eb6936a052b31bcaee64d43d3 master_replid2:0000000000000000000000000000000000000000 master_repl_offset:0 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 config redis-cli -h 127.1 -p 6380 info replication\n# Replication role:slave master_host:127.0.0.1 master_port:6380 master_link_status:down master_last_io_seconds_ago:-1 master_sync_in_progress:0 slave_repl_offset:1 master_link_down_since_seconds:1552282946 slave_priority:100 slave_read_only:1 connected_slaves:0 master_replid:231a9e1dffed58138ccdd5d7d48b85b332edf79b master_replid2:0000000000000000000000000000000000000000 master_repl_offset:0 second_repl_offset:-1 repl_backlog_active:0 repl_backlog_size:1048576 repl_backlog_first_byte_offset:0 repl_backlog_histlen:0 查看run_id:redis-cli -p 6379 info server |grep run\n通过偏移量监控主从复制 redis-cli -p 6379 info replication\nmaster_repl_offset:偏移量\nslave0:ip=127.1,port=6379,state=online,offset=从库的偏移量，log=1\n通过对两个偏移量的比对，可以检测主从复制的状态 全量复制 全量复制的开销 bgsave时间\nRDB文件网络传输时间\n从节点清空数据时间\n从节点加载RDB时间\n可能的AOF重写时间\n全量复制的问题 网络不稳定时，丢包或者网络断开连接，数据丢失，这时候需要再进行全量复制，开销巨大\n部分复制 repl_back_buffer 默认为1mb，但是实际我们会设置的较大\n故障处理 故障不可避免\n自动故障转移\nslave故障 将读取客户端指向存活的其他slave master故障 把写入客户端指向一个slave\n更改这个slave：slaveof no one,恢复其写入能力\n把其他的slave：slaveof new master,指向这个新的master\n故障自动转移 sentinel实现自动故障转移 TPIS 读写分离 读写分离：读流量分摊到从节点\n可能的问题\n复制数据延迟（可以通过监控偏移量解决）\n读到过期数据（操作key时才校验是否过期，定时采样校验是否过期）\n从节点故障\n主从配置不一致 maxmemory不一致：丢失数据\n数据结构优化参数不一致(例如hash-max-ziplist-entries)：造成内存不一致\n规避全量复制 第一次全量复制 第一次时不可避免\n使用小主节点（减小maxmemory）\n在低压，低峰时进行全量复制\n节点运行ID不匹配 大多出现在主节点重启时（会使run_id变化）\n利用故障转移，使用哨兵或者集群\n复制缓冲区不足 网络中断时，却无法进行部分复制（repl_back_buffer过小）\n可以通过增大缓冲区（配置rel_backlog_size）,大小可以通过网络增强计算（每秒写入dps*(故障排除-故障发生)再计算大小）\n规避复制风暴 单主节点复制风暴 主节点重启后，多从节点请求全量复制\n可以更改复制拓扑，减轻主节点的复制压力，使用树形结构分散压力\n单机器复制风暴 一个机器上全是master节点，当机器宕机时，压力会很大\n可以通过让其他slave作为新的master来解决，当然也可以使用哨兵或者集群\n","date":"2019-03-10","img":"","permalink":"/posts/redis/redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","series":["redis"],"tags":["redis"],"title":"Redis的主从复制"},{"categories":["redis"],"content":"Redis的持久化 Redis持久化作用 什么是持久化 redis的所有数据保存在内存中，对数据的更新回异步的保存在磁盘中\n持久化方式 快照 MySQL Dump\nRedis RDB\n日志 MySQL Binlog\nHbase HLog\nRedis AOF\nRDB持久化 什么是RDB redis可以通过命令，把当前数据库的状态保为一个RDB文件（二进制）\n也可以通过命令把硬盘上的RDB载入到redis中\n同时RDB文件也是一个复制的媒介\n触发机制 save 通过save命令让redis生成rdb文件，生成成功返回‘OK’\n同步命令，阻塞命令，会导致服务器阻塞\n会替换老的rdb文件\n复杂度On\nbgsave 接收到bgsave后，redis利用linux的fork()命令产生一个子进程，让产生的子进程去生成RDB文件，返回‘Backgroud saving started’\nfork()函数也是一阻塞命令，一般情况下很快\n会替换老的rdb文件\n复杂度On\nsave与bgsave比较 | 命令 | save | bgsave |\n| \u0026mdash;- | \u0026mdash;- | \u0026mdash;- |\n| io类型 |同步 | 异步 |\n| 是否阻塞 | 是 | 是 |\n| 时间复杂度 | On | On |\n| 优点 | 不会消耗额外内存 |不阻塞客户端命令 |\n| 缺点 | 阻塞客户端命令 |需要fork()，消耗内存 |\n自动生成快照 策略 满足以下三个条件就会触发创建RDB文件的行为（bgsave）\n900 1chages\n300 10chages\n60 10000chages\n缺点 生成快照的频率有些时候可能过高了（写量过高的情况） 配置 #自动策略，一般不配置，不使用自动生成快照 save 900 1 save 300 10 save 60 10000 #文件名，一般按照端口号区分 dbfilename dump-${port}.rdb #rdb,log,aof文件的位置，选择一个大内存的目录，或者需要按照端口进行分盘 dir ./ #如果bgsave出现错误是否立刻停止 stop-writes-on-bgsave-error yes #是否采用压缩格式 rdbcompression yes #是否进行校验和验证 rdbchecksum yes 注意 全量复制时，主数据库会自动生成RDB\ndebug reload，不清空数据库的重启\nshutdown，关机时会自动生成rdb文件\n耗时，耗性能\n不可控，易丢失以前的数据（宕机与上一次dump之间的操作）\nAOF持久化 什么是AOF 每执行一条命令，就会在AOF文件中追加写入\n恢复时，把AOF文件载入执行\n执行命令时，会把命令刷新到缓冲区，通过不同的策略，同步到AOF文件中\nAOF的执行策略 always 每个命令都会从缓冲区fsync到AOF中 everysec 每一秒从缓冲区fsync到AOF中\n可以保护硬盘\n刷新频率可以配置\nno 由操作系统决定什么时候fsync 三种策略比较 | 命令 | always | everysec | no |\n| \u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash; |\n| 优点 | 不丢失数据 | 每秒一次fsync | 不用管 |\n| 缺点 | IO开销大 | 丢失一秒数据 | 不可控 |\nAOF重写 策略 从内存中重写\n会把一些过期的命令删除\n会把一些可以化简的命令化简\n会把一些等值的命令合并\n优点 减少硬盘占用量\n加快恢复速度\n实现方式 bgrewriteaof 异步操作，主进程fork一个子进程，会从内存中完成AOF重写 AOF重写配置 auto-aof-rewrite-min-size，AOF文件重写需要的最小尺寸\nauto-aof-rewrite-percentage，AOF文件增长率\nAOF统计指标 aof_current_size,AOF当前尺寸\naof_base_size，AOF上次启动和重写的尺寸\n同时满足以下两条公式 aof_current_size\u0026gt;auto-aof-rewrite-min-size\n(aof_current_size-aof_base_size/aof_base_size)\u0026gt;auto-aof-rewrite-min-size\nAOF配置 #是否打开aof appendonly yes #文件名字，使用端口进行区分 appendfilenam \u0026#34;appendonly-${port}.aof\u0026#34; #每秒aof appendfsync everysec #使用大的盘 dir /bigdiskpath #是否进行append操作，是否允许丢失数据(在重写期间关闭append操作) no-appendfsync-on-rewrite yes #增长率 auto-aof-rewrite-percentage 100 #最小尺寸 auto-aof-rewrite-min-size 64mb #在加载时是否忽略文件错误 aof-load-truncated yes conf文件内容\nhead *.aof#查看文件头部 *2#有两个指令 $6#下一行有6个字节 SELECT#指令 $1#下一行有1个字节 0#select 0 ，选择0号数据库 $3 set $5 hello RDB和AOF的抉择 RDB,AOF比较 | 命令 | RDB | AOF |\n| \u0026mdash;\u0026mdash;\u0026mdash;- | \u0026mdash;\u0026mdash; | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; |\n| 启动优先级 | 低 | 高 |\n| 体积 | 小 | 大 |\n| 恢复速度 | 快 | 慢 |\n| 数据安全性 | 丢数据 | 根据策略决定 |\n| 轻重 | 重 | 轻 |\nRDB最佳策略 关掉RDB\n集中管理\n主从库，从库打开，密度不要太大\nAOF最佳策略 开：缓存还是存储，根据功能决定是否需要这个功能\nAOF重写集中管理\neverysec\n最佳策略 小分片\n根据缓存或者存储决定是否需要这个功能\n监控：硬盘，内存，负载，网络\n足够的内存\n持久化的常见问题 fork操作的问题 是一个同步操作\n与内存量息息相关；内存越大，耗时越长（也与机器类型有关，虚拟机，物理机）\ninfo：latest_fork_usec\n改善fork 优先使用物理机或者高效支持fork操作的虚拟化技术\n控制Redis实例最大可用内存：maxmemory\n合理配置Linux内存分配策略，让机器确保有足够的内存再fork：vm.overcommit_memory=1（默认为0，会导致内存不够时，fork阻塞）\n降低fork频率，放宽AOF重写自动触发时机，避免不必要的全量复制（全量复制会bgsave）\n子进程外开销和优化 CPU 开销：RDB和AOF文件生成，属于CPU密集型\n优化：不做CPU绑定，不和CPU密集型应用部署，单机部署时，保证不进行大量的rdb和aof文件生成\n内存 开销：fork内存开销，copy-on-write\n优化：单机部署时，不做大量的重写；在主进程io少时去做fork；关闭大内存分配echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enable\n硬盘 开销：AOF，RDB文件写入，可以结合iostat，iotop分析\n优化：不要和高硬盘负载服务部署在一起（存储服务，消息队列）；根据写入量决定磁盘的类型（ssd）；单机多实例持久化文件目录可以考虑分盘；no-appendfsync-on-rewrite = yes\nAOF追加阻塞 在AOF从缓冲区刷盘时，会启动一个线程来完成这个事，主线程会监控同步时间，如果同步时间超过2秒，即刷盘操作2秒还没有完成，主线程就会阻塞，直到刷盘完成\n问题 主进程不能阻塞\n刷盘时可能不止丢失1秒的数据\n定位 看日志，会出现（disk is busy?）提示\ninfo Persistence，可以通过aof_delayed_fsync:nums,查看出现这种情况的次数\n优化 不要和高硬盘负载服务部署在一起（存储服务，消息队列）\n根据写入量决定磁盘的类型（ssd）\n单机多实例持久化文件目录可以考虑分盘\nno-appendfsync-on-rewrite = yes\n","date":"2019-03-10","img":"","permalink":"/posts/redis/redis%E6%8C%81%E4%B9%85%E5%8C%96%E7%AD%96%E7%95%A5/","series":["redis"],"tags":["redis"],"title":"Redis的持久化"},{"categories":["redis"],"content":"Redis高级特性初识 慢查询 客户端请求的生命周期 客户端发送命令\n入队列\n执行命令（慢查询在这一阶段）\n返回客户端\n（客户端超时，不一定是慢查询，慢查询只是客户端超时的一个可能）\n配置 slowlog-max-len，固定长度\nslowlog-log-slower-than，慢查询阈值（单位微秒）\n=0，记录所有命令\n\u0026lt;0，不记录任何命令\n#1. 第一次开启配置 config get slowlog-max-len = 128 config get slowlog-log-slower-than = 10000 #2. 修改默认配置重启 #3. 动态配置 config set slowlog-max-len = 128 config set slowlog-log-slower-than = 10000 API 慢查询会把命令放在内存中\nslowlog get [n]：获取慢查询队列\nslowlog len ：获取慢查询队列长度\nslowlog reset：清空慢查询队列\n定期持久化查询\nTIPS slowlog-max-len 不要设置的过大，默认为10ms，通常设置为1ms\nslowlog-log-slower-than 不要设置过小，通常设置为1000左右\n理解命令生命周期\npipeline 流水线 n次通信时间=n次命令时间+n次网络时间\n使用pipeline：1次网络+n次命令\n客户端实现 maven:\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;redis.clients\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jedis\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9.0\u0026lt;/version\u0026gt; \u0026lt;type\u0026gt;jar\u0026lt;/type\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; 没有使用pipeline\nJedis jedis = new Jedis(\u0026#39;127.1\u0026#39;,6379); for(int i=0;i\u0026lt;10000;i++){ jedis.hset(\u0026#34;hashkey:\u0026#34;+i,\u0026#34;field\u0026#34;+i,\u0026#34;value\u0026#34;+i); } 使用pipeline\nJedis jedis = new Jedis(\u0026#39;127.1\u0026#39;,6379); for(int i=0;i\u0026lt;100;i++){ Pipeline pipeline = jedis.pipelined(); for(int j=i*100;j\u0026lt;(i+1)*100;j++){ pipeline.hset(\u0026#34;hashkey:\u0026#34;+i,\u0026#34;field\u0026#34;+i,\u0026#34;value\u0026#34;+i); } pipeline.syncAndRetuenAll(); } 与原生M操作对比 M操作是原子的，而pipeline命令在队列中会被拆分为很多子命令，不是原子的\nTIPS 注意每次pipeline携带数据量\npipeline每次只能作用在一个redis节点上\nM操作与pipeline的区别\n发布订阅 角色 发布者\n订阅者\n频道\n通信模型 发布者向一个频道发布消息\n订阅者可以订阅多个频道\n订阅者不能收到他订阅之前的消息\nAPI pushlish channel message，返回订阅者个数\nsubscribe [channel] ,订阅一个或多个\nunsubscribe [channel] ,取消一个或多个订阅\npsubscribe [pattern] ，订阅指定的模式\npunsubscribe [pattern],退订指定的模式\npubsub channels，列出至少有一个订阅者的频道\npubsub numsub [channel\u0026hellip;]，列出给定频道的订阅者数量\n发布订阅与消息队列 发布订阅会让所有的客户端都受到消息\n消息队列通过阻塞和list达到让多个客户端收到队列中的不同内容\n消息队列类似于抢红包\nBitMap 因为redis可以直接操作位\nAPI setbit key offset value，给位图指定索引设置值,返回offset之前的值（不要突然在很小的位图上做很大的偏移量）\ngetbit key offset，获取位图指定索引的值\nbitcount key [start end]，获取位图指定范围（start到end，单位为字节，如果不指定就是获取全部）位值为1的个数\nbitop op destkey key [key\u0026hellip;]，做多个Bitmap的and(交)，or(并)，not(非)，xor(异或)操作并将结果保存在destkey中\nbitpos key targetBit [start] [end]，计算位图指定范围start~end，单位为字节，如果不指定就是获取全部，第一个偏移量对应的值等于targetBit的位置\n实战 独立用户统计 假设1亿总用户， 5千万独立用户用户 如果userid是整形，则使用set实现存储需要 32*50000000=200MB\nBitMap：1*1亿=12.5MB\n如果只有10万独立用户 如果userid是整形，则使用set实现存储需要 32*100000=4MB\nBitMap：1*1亿=12.5MB\nTIPS type=string，最大512MB，可能需要拆分\n注意setbit偏移量，可能有很大的耗时\n位图不是绝对的好，需要在合适的场景使用合适的数据结构\nHyperLogLog 基于HypeLogLog算法：可以在极小的空间完成独立数量统计\n本质还是字符串\nAPI pfadd key element [element\u0026hellip;]，向hyperloglog添加元素\npfcount key [key\u0026hellip;]，计算hyperloglog的独立总数\npfmerge destkey sourcekey [sourcekey\u0026hellip;],合并多个hyperloglog\n实战 添加百万独立用户\nelements=\u0026#34;\u0026#34; key=\u0026#34;2019_03_09:users\u0026#34; for i in `seq 1 1000000` do elements=\u0026#34;${elements} uuid-\u0026#34;${i} if [[$((i%1000)) == 0]] then redis-cli pfadd ${key} ${ellements} elements=\u0026#34;\u0026#34; fi done 内存消耗为15kb\nTIPS 是否能容忍错误？（错误率 0.81%）\n是否需要单条数据？（不能）\n是否需要很小的内存解决问题？\nGEO GEO是什么 GEO（地理信息定位）：存储经纬度，计算两地距离，范围计算\n实战 需要计算两地距离，以及需要存储用户的位置的场景\nAPI geo key longitude latitude member [longitude latitude member\u0026hellip;]，增加地理位置信息（经纬度，名称）\ngeopos key member [member \u0026hellip;]，通过名称获取地理位置信息\ngeodist key member1 menber2 [m/km/mi(英里)/ft(尺)],获取两个地理位置的距离\ngeoradius key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [ASC|DESC] [COUNT count] ,获取指定位置范围内的地理位置的信息集合(O(N+logM)， 其中 N 为指定半径范围内的位置元素数量， 而 M 则是被返回位置元素的数量) 代码示例\nredis\u0026gt; GEORADIUS Sicily 15 37 200 km WITHDIST WITHCOORD 1) 1) \u0026#34;Palermo\u0026#34; 2) \u0026#34;190.4424\u0026#34; 3) 1) \u0026#34;13.361389338970184\u0026#34; 2) \u0026#34;38.115556395496299\u0026#34; 2) 1) \u0026#34;Catania\u0026#34; 2) \u0026#34;56.4413\u0026#34; 3) 1) \u0026#34;15.087267458438873\u0026#34; 2) \u0026#34;37.50266842333162\u0026#34; TIPS since 3.2+\ntype geoKey = zset\n没有删除API,可以使用zrem key member\n","date":"2019-03-10","img":"","permalink":"/posts/redis/redis%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/","series":["redis"],"tags":["redis"],"title":"Redis高级特性初识别"},{"categories":["ROS"],"content":"利用enve使用在ros中使用python3 因为ros的python有很多依赖需要使用C，python3的支持不太好。我们可以让当前的环境变量依然是python2，为ros创建一个py3的enve来给它使用\n查看版本： pip -V pip3 -V python -V python3 -V 我的pip和python都是py2.7的\n接下来在你的工作空间中创建enve\nmkdir -p catkin_ws/src cd catkin_ws pip3 install virtualenv #先安装 virtualenv -p /usr/bin/python3 venv#创建一个名为enve的python3环境 source venv/bin/activate #激活enve #创建成功，你应该会看到shell的变化，你可以在这里试一下pip和python，会发现已经变成python3了。 deactivate #关闭enve SLAM 同时定位建模 移动机器人的主要任务：定位，建模，路径规划\nslam 建模工具包： Gmapping，Karto，Heotor，Gartographer\nROS支持的定位工具包： 自适应蒙特卡罗定位：AMCL\n导航工具包集 Navigation：Local，Global\nGlobal：Dijkstra，A×\nLocal;DWA\nSLAM中的MAP： 本质也是一个msg\nTopic：/map\nType：nav_msgs/OccupancyGrid(栅格地图)\nGmapping Topic 输入：base到odom的tf， /scan\n输出：\n定位信息：map_frame\u0026gt;odom的tf消息\nmapping:topic -/map _msg\nKarto topic 输入和Gmapping一样\n输出：map_frame -\u0026gt;odom\nNavigation matepkg ","date":"2019-03-10","img":"","permalink":"/posts/ros/ros%E5%9F%BA%E7%A1%80/","series":["ROS"],"tags":["ROS"],"title":"ROS基础学习1"},{"categories":["ROS"],"content":"ROS 工作空间:组织和管理功能包的文件夹 catkin workspace\nbuild (cmake,catkin缓存中间件)\nsrc(package 源代码)\npackage1(是catkin编译的基本单元)\npackage2\nfolder\npackage3\npackage3\ndevel(目标文件)\n头文件\n动态连接库\n静态连接库\n可执行文件\ncatkin(编译工具) catkin ROS定制的编译构建系统\n是对CMake的扩展\n常用命令:\ncatkin_make: 初始化,建立工作空间\neg:\nmkdir -p ~/catkin_ws/src cd ~/catkin_ws/ catkin_make 编译\neg:\ncd ~/catkin_ws #回到工作空间 catkin_make source ~/catkin/devel/setup.bash #编译完成后需要使用source进行刷新 package 功能包 是ROS软件的基本组织形式(一个个package)\ncatkin编译的基本单元\n一个package可以包含多个节点(可执行文件),但是至少必须含有CMakeLists.txt和package.XML才能认为这是一个pkg\nCMakeLists.txt 规定了catkin编译的规则(源文件,依賴項，目標文件)\neg:\ncmake_mininum_required() #指定catkin的最低版本 project() #指定軟件包的name find_package() #指定編譯時需要的依賴項 add_message_files()/add_service_files()/add_action_files()#添加消息文件/服務文件/動作文件 generate_message() #指定catkin信息給編譯系統生成cmake文件 add_library()/add_executable() #指定生成庫文件，可執行文件 target_link_libraries() #指定可執行文件鏈接那些庫 catkin_add_gtest() #添加單元測試 install() #生成可安裝目標 如果編譯過程中出現問題，一般都是這個文件的原因\npackage.XML 包的自我描述：定义了package的属性,包名,版本号,作者,依賴等\n\u0026lt;package\u0026gt;\u0026lt;!--root--\u0026gt; \u0026lt;name\u0026gt;\u0026lt;!--包名--\u0026gt; \u0026lt;version\u0026gt;\u0026lt;!--版本号--\u0026gt; \u0026lt;description\u0026gt;\u0026lt;!--包描述--\u0026gt; \u0026lt;maintainer\u0026gt;\u0026lt;!--维护者--\u0026gt; \u0026lt;licsense\u0026gt;\u0026lt;!--软件许可--\u0026gt; \u0026lt;buildtool_depend\u0026gt;\u0026lt;!--编译工具--\u0026gt; \u0026lt;build_depend\u0026gt;\u0026lt;!--编译时的依賴--\u0026gt; \u0026lt;run_depend\u0026gt;\u0026lt;!--运行时的依賴--\u0026gt; \u0026lt;/package\u0026gt; 你也可能会看到manifest.xml,这是rosbuild编译系统使用的信息清單,类似catkin的package.XML\n代码文件: 源文件src(.cpp/python module),頭文件include(.h),腳本scripts(.sh/.py) 自定義通信格式：消息msg(.msg),服務srv(.srv),動作action(*.action) lauch文件(*.lauch):使多个可执行文件一起运行 配置文件:config(*.yaml) 这样一来,我们的package目录结构就变成了: package\nCMakeList.txt\npackage.XML\nscript\n.py/.sh\ninclude\n*.h\nsrc\n*.cpp/python modulel\nmsg\n*.msg\nsrv\n*.srv\naction\n*.action\nlauch\n*.lauch\nconfig\n*.yaml\nros文件系统 常用操作:\nrospack 查找某个pkg的地址\nrospack find pkg_name\n列出本地全部的pkg\nrospack list\nroscd 跳转到pkg的路径下\nroscd pkg_name\nrosls 列举某个pkg下的文件信息\nrosls pkg_name\nrosed 编辑pkg下的文件\nrosed pkg_name file_name\ncatkin_create_pkg 创建一个pkg\ncatkin_create_pkg \u0026lt;pkg_name\u0026gt; [deps]\ndeps指的是这个pkg需要安装哪些依賴\nrosdep 安裝某個pkg所需要的依賴\nrosdep install [pkg_name]\n主要给下载的pkg安装所需要的依賴\n例子： #下載tree sudo apt insall tree #建立一個帶src的文件目錄 mkdir -p catkin_ws/src #cd 到workspace cd catkin_ws/ #tree查看文件結構 tree #初始化 catkin_make #显示1級目录 tree -L 1 #cd到src cd src #新建一个pkg catkin_create_pkg test1 #查看文件结构 tree #在建立pkg时制定依賴(cpp依賴,py依賴,通信依賴,导航依賴) catkin_create_pkg test2 roscpp rospy std_msgs nav_msgs 最后,我们的文件目录是:\ncatkin_ws\nbuild\ndevel\nsrc\nCMakeList.txt\ntest1\nCMakeList.txt\npackage.XML\ntest2\nCMakeList.txt\ninclude\ntest2\npackage.xml\nsrc\n对于外部克隆下载的文件: #cd 到工作空间 cd ~/catkin_ws/src #下载或者克隆 git clone ``` cd ~/catkin_ws #安装依賴 rosdep install [pkg_name] #编译 catkin_make #刷新环境(一般选择在配置文件中加入这句话) source ~/catkin_ws/devel/setup.bash 最后一句如果:echo \u0026quot;source ~/catkin_ws/devel/setup.bash\u0026quot; \u0026gt;\u0026gt; ~/.bashrc\n这样,我们每次打开一个新的终端,就会刷新一下source\nmetapackage ros官网称作stack(软件包集),其实指的是自己没有很多内容,大量依賴了其他的包的(link包?)\n主要的一些metapackage:\nnavigation:导航相关\nmoveit:控制机械臂\nimage_pipeline:图像获取,处理\nvision_opencv:ROS与openCV交互的功能包集\nturtlebot:turtlebot机器人相关的包\npr2_robot:pr2机器人驱动功能包集\nROS通信架构 master 节点管理器,管理node之间的通信\n每个节点node启动时都需要向master注册\nnode1\u0026ndash;注册\u0026ndash;\u0026gt;master\u0026mdash;-\u0026gt;node2\n我们在启动ROS时:\n先启动master: roscore\n可以启动master(节点管理器),rosout(日志输出),parameter server(参数服务器)\n启动node的一些相关命令: 启动node\nrosrun [pkg_name] [node_name]\n列出当前运行的node的详细信息\nrosnode info [node_name]\n结束运行node:\nrosrun kill [node_name]\n多个node需要启动时:\n使用roslaunch,可以同时启动master和多个node\nroslaunch [pkg_name] [file_name.launch]\n其中file_name.launch的写法如下:\n\u0026lt;launch\u0026gt; \u0026lt;node\u0026gt;\u0026lt;!--需要启动的node及其参数--\u0026gt; \u0026lt;include\u0026gt;\u0026lt;!--包含其他launch文件--\u0026gt; \u0026lt;machine\u0026gt;\u0026lt;!--指定运行的機器--\u0026gt; \u0026lt;env_loader\u0026gt;\u0026lt;!--设置环境变量--\u0026gt; \u0026lt;param\u0026gt;\u0026lt;!--定义参数到参数服务器--\u0026gt; \u0026lt;arg\u0026gt;\u0026lt;!--定义参数传到launch文件中--\u0026gt; \u0026lt;remap\u0026gt;\u0026lt;!--设置参数映射--\u0026gt; \u0026lt;group\u0026gt;\u0026lt;!--设置命名空间--\u0026gt; \u0026lt;/launch\u0026gt; eg:roslaunch pr2_bingup pr2.launch\n通信方式 Topic(主题) ROS中的異步通信方式\nnode之间通过publish-subscribe通信\nnodeA\u0026ndash;发\u0026ndash;\u0026gt; /Topic \u0026ndash;订阅\u0026ndash;\u0026gt; nodeB\neg:\nnode1(camera)\n/camera-rgb\n/camera-depth\n这些节点的msg都通过publish上传到topic\nnode2\ndiplay\n从topic订阅\nnode3\nimage_proless\n从topic订阅\n总结 異步通信 通過使用publish()方法,直接发送到topic\n多對多通信 可以发送多个msg到topic\n也可以有多个node从topic上订阅消息\ntopic通信有严格的格式要求,即Message(是topic内容要求的数据类型,定义在*.msg中) 你可以把message看作一种数据类型,也就是一个对象,publish则时操作这种数据对象的一个类\nmsg 基本的msg包括:\nbool,int8,int16,int32,int64,uint,float32,float64,string,time,duration,header,array[],array[C]\nmsg是一个类或者说结构体,例如/camera_rgb的msg格式\nstd_msgs/Header header uint32 seq time stamp string frame_id uint32 height uint32 width string encoding uint8 is_bigendian uint32 step uint8[] data rostopic list 列出当前的全部topic\nrostopic info /topic_name 显示某个topic的属性信息\nrostopic echo /topic_name 显示某个topic的内容\nrostopic pub /topic_name\u0026hellip; 向topic发送内容\nrosmsg list 列出系统上所有的msg\nrosmag show /msg_name 显示某个msg内容\n如果两个node,在运行时会占用大量的资源,并且不是每一刻都需要对进行通信,使用service更好\nService(服务) ROS中的同步通信方式(阻塞等待reply)\nNode之間可以通過request-reply的方式通信\nNodeA(Client)\u0026ndash;Req\u0026ndash;\u0026gt;|\u0026lt;\u0026ndash;Reply\u0026ndash; /Service \u0026lt;===\u0026gt;NodeB(Server)\nservice通信方式使用的通信格式是srv\n定义在*.srv中,和msg类似\neg:\nmy_pkg/srv/DetectHuman.srv bool start_detect#请求的格式 --- my_pkg/HumanPose[] pose_data #返回的是一个坐标数组 my_pkg/msg/HumanPose.msg(里面嵌套了一个msg) std_msgs/Header header string uuid int32 number_of_joints my_pkg/JointPose[] joint_data my_pkg/msg/JointPose.msg string joint_name geometry_msgs/Pose pose float32 Confidence rosserice list 列出当前所有活跃的service\nrosserice info /service_name 显示某个service的属性信息\nrosserice call /service_name args 调用某个service,args是参数\nrossrv list 列出系统上所有的srv\nrossrv show srv_name 显示出某个srv内容\nParameter Service(参数服务器) 用于存储各种不常改变的参数,配置,以字典的形式存储,可以用命令行,launch,node来读取\nrosparam list 列出所有参数\nrosparam get param_key 显示出某个参数的值\nrosparam set param_key 设置某个参数的值\nrosparam dump file_name 保存参数到文件\nrosparam load file_name 从文件读取参数\nrosparam delete param_key 删除参数\nAction(动作) 一种问答通信机制，带有连续反馈，可以在任务过程中终止运行，基于ROS的消息机制实现\n类似service,带有状态反馈的通信方式\n通常用在长时间,可抢占(可打断)的任务中\n同理action时Action通信使用的数据格式,定义在*.action中\neg:/action/DoDishes.action(分为三部分)\n#Define the goal (client发出) uint32 dishwasher_id #Specify which dishwasher we want to use --- #Define the result (只回答一次,server发出) uint32 total_dishes_cleaned --- #Define a feedback message (实时回传多次,server发出) float32 percent_complete 举一个洗碗机的例子:\nClient\u0026ndash;goal(洗碗机的Id)\u0026ndash;\u0026gt;Server\nServer\u0026ndash;feedback(洗碗的进度)\u0026ndash;\u0026gt;Client\nServer\u0026ndash;result(洗碗的数量,时间)\u0026ndash;\u0026gt;Client\n常用的API goal:发布任务目标\ncancel:请求取消任务\nstatus:通知客户端当前的状态\nfeedback:周期反馈任务运行的监控数据\nresult:向客户端发送任务的执行结果，只发布一次\nROS常用的工具 仿真工具: Gazebo,CV-rep,Carsim 调试,可视化工具:Rviz,rqt Rviz(The Robot Visualization tool) rqt 是一个可视化工具,常用的工具有:\nrqt_graph(查看通信结构,msg的流向) rqt_plot(曲线绘制的工具,可以看到,信息中的数据的变化) rqt_console(查看日志) 命令行工具:rostopic,rosbag\u0026hellip; rosrun :可以运行node rosbag:可以记录和回放数据流 使用方法:\n/topic1 | /topic2\u0026ndash;\u0026gt;record\u0026ndash;\u0026gt;*.bag文件\u0026ndash;\u0026gt;play\u0026ndash;\u0026gt; /topic1 | /topic2\nrosbag record [topic-names] 记录某些topic到bag中\nrosbag record - a(a=all) 记录全部的topic\nrosbag play [bag-files] 回放topic\neg:\nrosbag record /camera/rgb/image_raw roscore rosbag play *.bag(bag-files) rostopic list #查看回放有哪一些topic rostopic info /camera/rgb/image_raw #查看回放中的这个topic rosrun image_view image_view image:=/camera/rgb/image_raw #run这个节点,查看回放的图像 专用工具:Moveit(机械臂) Client Library 提供ROS编程的库(roscpp,rospy,roslisp等),类似接口,但是在API的基础上进行了封装\n","date":"2019-03-10","img":"","permalink":"/posts/ros/ros%E5%85%A5%E9%97%A8/","series":["ROS"],"tags":["ROS"],"title":"ROS基础学习2"},{"categories":["Shell"],"content":"shell 基础 在终端输入:sh进入脚本界面\nhelloworld 编辑内容\n#!/bin/bash echo \u0026#34;hello world!\u0026#34; 保存退出:\nw ~/helloworld.sh\n运行:\nchmod +x ~/helloworld.sh cd ~ ./helloworld.sh 执行结果:\nhello world!\n分析: 第一行中#!是一个约定的标记,告诉系统脚本需要使用什么解释器来执行,即使用哪一种shell\n这种在第一行指定了解释器信息的方式,需要让脚本作为可执行程序执行\n还有第二种运行方式,即作为解释器参数,这时,第一行的解释器信息,失效\neg:python test.py\nshell 变量 显式赋值:\na=\u0026quot;abc\u0026quot;\n用语句:\nfor file in `ls /etc/` 或者\nfor file in $(ls /etc)\n使用变量: 使用一个定义过的变量:\nfile=\u0026#34;test\u0026#34; echo $file echo ${file} 花括弧是为了帮助解释器识别变量的边界:\nfor skill in Ada Coffe Action java;do echo \u0026#34;I am good at ${skill}Script\u0026#34; done 只读变量 使用readonly :\n#!/bin/bash myUrl=\u0026#39;http://euraxluo.github.io\u0026#39; readonly myUrl 删除变量 unset:\nunset variable_name\n变量被删除后不能再次使用,unset 命令不能删除只读变量\n#!/bin/sh myUrl=\u0026#34;http://euraxluo.github.io\u0026#34; myname=\u0026#34;Euraxluo\u0026#34; readonle myname unset myname unset myUrl echo $myUrl echo $myname 字符串: 单引号 单引号字符串的限制：\n单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；\n单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。\nstr='this is a string'\n双引号 双引号的优点：\n双引号里可以有变量\n双引号里可以出现转义字符\nyour_name=\u0026#39;euraxluo\u0026#39; str=\u0026#34;Hello, I know you are \\\u0026#34;$your_name\\\u0026#34;! \\n\u0026#34; echo -e $str 拼接字符串 mynam=\u0026#34;euraxluo\u0026#34; str1=\u0026#34;hello \u0026#34;word\u0026#34; ! from \u0026#34;$myname str2=\u0026#34;hello word ! from $myname\u0026#34; echo $str1 echo $str2 str1=\u0026#39;hello \u0026#39;word\u0026#39; ! from \u0026#39;$myname str2=\u0026#39;hello word ! from $myname\u0026#39; echo $str1 echo $str2 获取字符串长度 在变量名前加#\nstring=\u0026#34;abc\u0026#34; echo ${#string} 提取子字符串 截取字符变量的前5位 expr substr “$a” 1 8\necho $a|cut -c1-8\nstring=\u0026#34;hello world euraxluo\u0026#34; #1 echo `expr substr \u0026#34;$string\u0026#34; 1 5` #2 echo $string | cut -c1-5 按指定的字符串截取 从左向右截取最后一个string后的字符串\n${varible##*string}\n从左向右截取第一个string后的字符串\n${varible#*string}\n从右向左截取最后一个string后的字符串\n${varible%%string*}\n从右向左截取第一个string后的字符串\n${varible%string*}\n“*”只是一个通配符可以不要\nstring=\u0026#34;hello world euraxluo\u0026#34; #1 echo ${string##*ld} #2 echo ${string#*l} #3 echo ${string%%w*} #4 echo ${string%wo*} 查找子字符串 查找r u 的位置:\nstring=\u0026#34;hello world euraxluo\u0026#34; echo `expr index \u0026#34;$string\u0026#34; ru` shell数组 bash支持一维数组（不支持多维数组），并且没有限定数组的大小\n定义数组 数组名=(值1 值2 ... 值n)\neg:\nvalues=( value1 value2 value3 ) echo $values echo ${value[1]} 读取数组 通过下标读取\n${数组名[下标]}\n读取全部元素\necho ${数组名[@]}\n获取数组的长度 # 取得数组元素的个数 length=${#array_name[@]} # 或者 length=${#array_name[*]} # 取得数组单个元素的长度 lengthn=${#array_name[n]} 注释: 单行注释:\n在每行开头加上#\n多行注释:\n1:\n每一行加个#符号太费力了，可以把这一段要注释的代码用一对花括号括起来，定义成一个函数，没有地方调用这个函数，这块代码就不会执行，达到了和注释一样的效果。 2:\n:\u0026lt;\u0026lt;EOF 注释内容... 注释内容... 注释内容... EOF 或者\n:\u0026lt;\u0026lt;\u0026#39; 注释内容... 注释内容... 注释内容... \u0026#39; 自动复制脚本\n#!/bin/sh #\t`find /home/euraxluo/Documents/工作报告/bags -mmin +1240 -exec rm -f () \\;` 这是删除21h前的 #\tdf 查看硬盘地址，我的是/run/media/euraxluo/72c7944d-f7e1-4cb9-a431-6b0285044d79/ #\t/home/euraxluo/Documents/工作报告/bags 是我的 bag存放地址 if [ ! -d \u0026#34;/run/media/euraxluo/72c7944d-f7e1-4cb9-a431-6b0285044d79\u0026#34; ];then echo \u0026#34;硬盘还没插\u0026#34; else echo \u0026#34;删除一天前拷贝过来的文件\u0026#34; `find /home/euraxluo/Documents/工作报告/bags -mtime 1 -exec rm -f {} \\;` echo \u0026#34;硬盘插入，自动拷贝中！\u0026#34; for var in `cd /run/media/euraxluo/72c7944d-f7e1-4cb9-a431-6b0285044d79/ \u0026amp;\u0026amp; ls *.bag` do strcp=\u0026#34;cd /run/media/euraxluo/72c7944d-f7e1-4cb9-a431-6b0285044d79/ \u0026amp;\u0026amp; cp -i $var /home/euraxluo/Documents/工作报告/bags/${var##*/}\u0026#34; `awk \u0026#34;BEGIN { cmd=\\\u0026#34;$strcp\\\u0026#34;; print \u0026#34;n\u0026#34; | cmd; }\u0026#34;` done echo \u0026#34;拷贝完成\u0026#34; `cd /home/euraxluo/Documents/工作报告/bags` fi 批量修改文件后缀的shell\n#!/bin/bash # -*- coding: UTF-8 -*- oldext=\u0026#34;apng\u0026#34; newext=\u0026#34;png\u0026#34; dir=$(eval pwd) for file in $(ls $dir | grep .$oldext) do name=$(ls $file | cut -d. -f1) mv $file ${name}.$newext done echo \u0026#34;change apng=====\u0026gt;png done!\u0026#34; ","date":"2019-03-10","img":"","permalink":"/posts/shell/shell%E5%9F%BA%E7%A1%80/","series":["Shell"],"tags":["Shell"],"title":"Shell 基础"},{"categories":["Shell"],"content":"shell进阶 破壳漏洞\nenv x='() { :;}; echo shellshocked' bash –c \u0026quot;echo test\u0026quot;检查,如果输出了两行,那么需要升级bash的版本\n解释器的类型\n系统中的shells使用cat /etc/shells查看:\n/bin/sh /bin/dash /bin/bash /bin/rbash /usr/bin/tmux /usr/bin/screen /bin/zsh /usr/bin/zsh 设置解释器的类型 #!/bin/bash在文件的开头使用,内核会根据\u0026quot;#!\u0026ldquo;后的解释器来确定该用那个程序解释这个脚本中的内容\n脚本的编辑 vim帮助我们编辑脚本 我的vimrc内容\n1 set tabstop=4 2 set shiftwidth=4 3 set expandtab 4 set number 5 autocmd BufNewFile *.py,*.cc,*.sh,*.java exec \u0026#34;:call SetTitle()\u0026#34; 6 func SetTitle() 7 if expand(\u0026#34;%:e\u0026#34;) == \u0026#39;sh\u0026#39; 8 call setline(1,\u0026#34;#!/bin/bash\u0026#34;) 9 call setline(2,\u0026#34;# Author: Euraxluo\u0026#34;) 10 call setline(3,\u0026#34;# Email: Euraxluo@outlook.com\u0026#34;) 11 call setline(4,\u0026#34;# Time:\u0026#34; .strftime(\u0026#34;%F %T\u0026#34;)) 12 call setline(5,\u0026#34;# Description: \u0026#34;) 13 call append(line(\u0026#34;.\u0026#34;), \u0026#34;\\# File Name: \u0026#34;.expand(\u0026#34;%\u0026#34;)) 14 endif 15 autocmd BufNewFile * normal G 16 endfunc 脚本的执行\nsh/bash scripts.sh chown +x ./scripts.sh \u0026amp;\u0026amp; ./scripts.sh source scripts.sh . scripts.sh cat oldboyedu.sh |bash # 效率较低\n其中`source` 和`.` 都是在当前的shell中执行一个文件中的命令 而`sh`会新建一个进程去执行一个文件中的命令 sh和bash的关系: ```bash which sh \u0026gt; /bin/sh ll /bin/sh \u0026gt; lrwxrwxrwx 1 root root 4 Jul 25 21:47 /bin/sh -\u0026gt; bash 变量 环境变量\nenv/declare/set/export -p 这四个命令 输出的结果有些不同\n配置文件的读取顺序:\n① /etc/profile\n② ~/.bash_profile\n③ ~/.bashrc\n④ /etc/bashrc\n普通变量\na=1 b=\u0026#39;1\u0026#39; c=\u0026#34;1\u0026#34; a=1 echo \u0026#34;$a\u0026#34; \u0026gt; 1 echo \u0026#34;${b}\u0026#34; \u0026gt; 1 echo \u0026#34;$c\u0026#34; \u0026gt; 1 连续普通字符串内容赋值给变量，不管用什么引号或者不用引号，它的内容是什么，打印变量就输出什么\n位置变量\n$0 获取当前执行shell脚本的文件名,执行时带路径,则包括路径 $n 获取当前执行shell脚本的第n个参数,n:1\u0026hellip;9,如果n大于9用大括号括起来{10} $# 获取当前执行的shell脚本后面接的参数的个数 $*/$@ 获取当前shell的所有传参的参数 \u0026ldquo;$*\u0026rdquo; 将所有的参数视为单个字符串 \u0026ldquo;$@\u0026rdquo; 将所有的参数视为不同的独立字符,多用于传递参数 #./test.sh 1s asa 2 3 4 5 6 set -v #用于调试 set -x test(){ mm=$1 echo $mm } echo $* + echo 1s asa 2 3 4 5 6 1s asa 2 3 4 5 6 test $* + test 1s asa 2 3 4 5 6 + mm=1s echo \u0026#34;$*\u0026#34; + echo \u0026#39;1s asa 2 3 4 5 6\u0026#39; 1s asa 2 3 4 5 6 test \u0026#34;$*\u0026#34; + test \u0026#39;1s asa 2 3 4 5 6\u0026#39; + mm=\u0026#39;1s asa 2 3 4 5 6\u0026#39; + echo 1s asa 2 3 4 5 6 1s asa 2 3 4 5 6 echo $@ + echo 1s asa 2 3 4 5 6 1s asa 2 3 4 5 6 echo \u0026#34;$@\u0026#34; + echo 1s asa 2 3 4 5 6 1s asa 2 3 4 5 6 test \u0026#34;$@\u0026#34; + test 1s asa 2 3 4 5 6 + mm=1s 进程状态变量\n$? 获取上一个指令的执行状态返回值(0成功,非零为失败) $$ 获取当前执行的shell脚本的PID $! 获取上一个后台工作的进程的PID $_ 获取在此之前执行的命令或脚本的最后一个参数 export命令\n说明:\n在当前shell窗口及子shell窗口生效\n在新开的shell窗口不会生效，生效需要写入配置文件\n反引号赋值\ntime=`data` echo $time \u0026gt; Fri Jan 3 21:44:04 CST 2020 TIPS\n变量名通常要大写。\n变量可以在自身的Shell及子Shell中使用。\n常用export来定义环境变量。\n执行env默认可以显示所有的环境变量名称及对应的值。\n输出时用“$变量名”，取消时用“unset变量名*”。\n书写crond定时任务时要注意，脚本要用到的环境变量最好先在所执行的Shell脚本中重新定义。\n如果希望环境变量永久生效，则可以将其放在用户环境变量文件或全局环境变量文件里。\n只有在变量的值中有空格时,才需要使用引号,单引号和双引号的区别在于是否能解析特殊符号\n如果内容是纯数字简单连续的字符(不喊空格)时,可以不使用引号\n没有特殊情况时,字符串一律使用双引号定义赋值\n当变量中的内容需要原样输出时,使用单引号\n希望变量的内容是命令的解析结果时,要使用反引号或者$()把命令括起来在赋值\n变量子串 说明 表达式 说明 ${v} 返回变量$v的内容 ${#v} 返回$v的长度 ${v:offset} 返回在变量${v}中，从位置offset之后开始提取子串到结尾 ${v:offset:lenght} 在变量${v}中，从位置offset之后开始提取长度为length的子串 ${v#word} 从变量${v}开头开始删除最短匹配的word子串 ${v##word} 从变量${v}开头开始删除最长匹配的word子串 ${v%word} 从变量${v}结尾开始删除最短匹配的word子串 ${v%%word} 从变量${v}结尾开始删除最长匹配的word子串 ${parameter/pattem/string} 使用string代替第一个匹配的pattern ${parameter//pattem/string} 使用string代替所有匹配的pattern 范例\n# ${v:offset:lenght} mm=0123456 echo ${mm:1:0} \u0026gt; echo ${mm:1:1} \u0026gt; 1 echo ${mm:1:2} \u0026gt; 12 echo ${mm:1:-1} \u0026gt; 12345 # ## 与 # file=/dir1/dir2/dir3/my.file.txt \u0026gt; file=/dir1/dir2/dir3/my.file.txt echo ${file#*/} \u0026gt; dir1/dir2/dir3/my.file.txt echo ${file##*/} \u0026gt; my.file.txt echo ${file#*.} \u0026gt; file.txt echo ${file##*.} \u0026gt; txt # %% 与 % echo ${file%/*} \u0026gt; /dir1/dir2/dir3 echo ${file%%/*} \u0026gt; echo ${file%.*} \u0026gt; /dir1/dir2/dir3/my.file echo ${file%%.*} \u0026gt; /dir1/dir2/dir3/my # // 与 / echo ${file/dir/path} \u0026gt; /path1/dir2/dir3/my.file.txt echo ${file//dir/path} \u0026gt; /path1/path2/path3/my.file.txt # // split 字符串 list=1,2,3,4,5 echo ${list//,/ } \u0026gt; 1 2 3 4 5 array=(${list//,/ }) echo \u0026#34;${array[*]}\u0026#34; \u0026gt; 1 2 3 4 5 特殊扩展变量\n说明\n表达式 说明 ${v:+word} (v != \u0026lsquo;\u0026rsquo;) ?word : ${v:-word} (v != \u0026lsquo;\u0026rsquo;) ? :word ${v:?word} (v != \u0026lsquo;\u0026rsquo;) ? :(word;exit -1) ${v:=word} (v != \u0026lsquo;\u0026rsquo;) ? :(word;v=word) ${v-word} (v not exist) ?word :v 条件表达式\n文件判断 常用文件测试操作符 说明 -d文件，d的全拼为directory 文件存在且为目录则为真，即测试表达式成立 -f文件，f的全拼为file 文件存在且为普通文件则为真，即测试表达式成立 -e文件，e的全拼为exist 文件存在则为真，即测试表达式成立。注意区别于“-f”，-e不辨别是目录还是文件 -r文件，r的全拼为read 文件存在且可读则为真，即测试表达式成立 -s文件，s的全拼为size 文件存在且文件大小不为0则为真，即测试表达式成立 -w文件，w的全拼为write 文件存在且可写则为真，即测试表达式成立 -x文件，x的全拼为executable 文件存在且可执行则为真，即测试表达式成立 -L文件，L的全拼为link 文件存在且为链接文件则为真，即测试表达式成立 fl -nt f2，nt 的全拼为 newer than 文件fl比文件f2新则为真，即测试表达式成立。根据文件的修改时间来计算 fl -ot f2，ot 的全拼为 older than 文件fl比文件f2旧则为真，即测试表达式成立。根据文件的修改时间来计算 字符串判断 常用字符串测试操作符 说明 -n \u0026ldquo;字符串\u0026rdquo; 若字符串的长度不为0,则为真，即测试表达式成立，n可以理解为no zero -Z \u0026ldquo;字符串\u0026rdquo; 若字符串的长度为0,则为真，即测试表达式成立，z可以理解为zero的缩写 \u0026ldquo;串1\u0026rdquo;== \u0026ldquo;串2\u0026rdquo; 若字符串1等于字符串2,则为真，即测试表达式成立，可使用\u0026rdquo;==\u0026ldquo;代替\u0026rdquo;=\u0026quot; \u0026ldquo;串1\u0026rdquo;!= \u0026ldquo;串*2\u0026rdquo; 若字符串1不等于字符串2,则为真，即测试表达式成立，但不能用\u0026quot;!==\u0026ldquo;代替\u0026rdquo;!=\u0026quot; 1.对于字符串的测试，一定要将字符串加双引号之后再进行比较。 2.空格非空 整数判断\n在**[]以及test**中使用的比较符号 在**(())和[[]]**中使用的比较符号 说明 -eq ==/= 相等，全拼为equal -ne != 不相等，全拼为not equal -gt \u0026gt; 大于，全拼为greater than -ge \u0026gt;= 大于等于，全拼为greater equal -lt \u0026lt; 小于，全拼为丨ess than -le \u0026lt;= 小于等于，全拼为less equal 逻辑符号\n在**[]和test**中使用的操作符 说明 在**[[]]和(())**中使用的操作符 说明 -a [ 条件A -a 条件B ]A与B都要成立，整个表达式才成立 \u0026amp;\u0026amp; and，与，两端都为真，则结果为真 -o [ 条件A -o 条件B]A与B都不成立，整个表达式才不成立 || or，或，两端有一个为真，则结果为真 ！ 非 ! not，非，两端相反，则结果为真 if条件语句 file=$1 if [ -d $file ] then echo \u0026#34;$file is a dir\u0026#34; elif [ -f $file ] then echo \u0026#34;$file is a file\u0026#34; else echo \u0026#34;end\u0026#34; fi case条件语句\n# . ./test.sh -a 1 -b 2 -c 3 -d 4 -1 # \u0026gt; # 2 # 3 # 4 # e p(){ str=$1 echo \u0026#34;$1\u0026#34; } main(){ while getopts \u0026#34;🅰️b:c:d:e:\u0026#34; OPT do case $OPT in a) p $OPTARG;; b) p $OPTARG;; c) p $OPTARG;; d) p $OPTARG;; e) p $OPTARG;; :) p $OPTARG;; ?) p $OPTARG;; esac done } main \u0026#34;$@\u0026#34; for循环\n列表for循环\n# . ./test.sh 1 2 3 # 1 lenght: 1 # 13 lenght: 2 # 43 lenght: 2 # 4 lenght: 1 # 0 lenght: 1 # 5 lenght: 1 array=(1 13 43 4 0 5) main(){ for i in ${array[*]} do echo \u0026#34;$i lenght: ${#i}\u0026#34; done } main \u0026#34;$@\u0026#34; 不带列表for循环\n# . ./test.sh 1 2 3 # 1 # 2 # 3 # 1 # 2 # 3 for i do echo $i done ## 效果等同于: for i in $* do echo $i done C风格for循环\narray=(1 13 43 4 0 5) for((i=0;i\u0026lt;${#array[@]};i++)) do echo ${array[$i]} done while循环\n#while :创建守护进程 #临时监听81端口,达到服务器的效果 # nc -l 81 while true do echo \u0026#34;ok\u0026#34;|nc -l 81 done 文件读取\n迭代获取文件的每一行\n#1 while read line do echo $line done \u0026lt; $1 #2 cat $1| while read line do echo $line done #3 exec \u0026lt; $1 while read line do echo $line done 迭代获取每一个单词\nline=\u0026#34;sasa sas as as asas\u0026#34; array=($line) for word in ${array[@]}; do echo $word; done 迭代获取每一个字符\nword=\u0026#34;wordwordword\u0026#34; for ((i=0;i\u0026lt;${#word};i++)) do echo ${word:$i:1} done 统计文章的行数和词数,字节数\nexec \u0026lt; $1 lines=1 total_words=0 bytes=0 while read line do echo \u0026#34;$lines:\u0026#34;$line words=1 array=($line) for word in ${array[@]}; do echo \u0026#34;$words:\u0026#34;$word; for ((i=0;i\u0026lt;${#word};i++)) do echo ${word:$i:1}; done ((words++)) ((total_words+=words)) done ((bytes+=${#line})) ((lines++)) done echo \u0026#34;lines:$lines;total_words:$total_words;bytes:$bytes(with out \u0026#39; |\\r|\\n\u0026#39;)\u0026#34; 分割字符串转为数组 使用{str//,/ }处理\nstr=\u0026#34;1,2,3,4,5\u0026#34; arr=(${str//,/}) echo ${arr[@]} 使用tr\nstr=\u0026#34;1,2,3,4,5\u0026#34; arr=(`echo $str | tr \u0026#39;,\u0026#39; \u0026#39; \u0026#39;`) echo ${arr[@]} awk\nstr=\u0026#34;1,2,3,4,5\u0026#34; arr=($(echo $str|awk \u0026#39;BEGIN{FS=\u0026#34;,\u0026#34;;OFS=\u0026#34; \u0026#34;}{print $1,$2,$3,$4,$5}\u0026#39;)) echo ${arr[@]} IFS\nstr=\u0026#34;1,2,3,4,5\u0026#34; IFS=\u0026#34;,\u0026#34; arr=(str) echo ${str[@]} array 定义数组arr=(001 002 003)\n定义数组arr=([1]=321 [3]=ewq)\n命令执行结果赋值`\ndir=(`ls`) dir=($(ls)) 数组长度${#arr[@]}\n获取所有元素${arr[@]}\n获取所有的下标${!arr[@]}\n根据索引(下标)获取元素${arr[1]}\n遍历数组 for i in ${arr[@]};do echo $i;done\n遍历数组for i in ${!arr[@]};do echo ${arr[$i]};done\n遍历数组\nfor i in `eval echo {1..${#arr[@]}}`;do echo ${arr[$i]};done 增加元素arr[3]=004\n修改元素arr[3]=005\n删除元素unset arr[2]\nmap 定义mapdeclare -A map=([key1]=value1 [key2]=value2 [key3]=value3) 获取所有元素${map[@]} 获取所有keys${!map[@]} 根据key获取value${map[key1]} 修改元素map[key1]=\u0026quot;new value\u0026quot; 遍历mapfor i in ${!map[@]};do echo ${map[$i]};done ","date":"2019-03-10","img":"","permalink":"/posts/shell/shell%E8%BF%9B%E9%98%B6%E4%B8%8E%E6%80%BB%E7%BB%93/","series":["Shell"],"tags":["Shell"],"title":"Shell 进阶"},{"categories":["redis"],"content":"Redis的特点 速度快 使用内存\n使用C语言\n单线程\n持久化 对数据的更新，异步保存到磁盘上 多种数据结构 strings/Blobs/Bitmaps\nHash Tables\nLinked Lists\nSets\nSorted Sets\nBitMaps\nHyperLogLog(超小内存唯一值计数)\nGEO\n多语言支持 功能丰富 发布topic\n支持lua脚本\n支持简单的事务\n支持pipeline\n高可用，分布式 Redis初识 缓存\n计数器\n消息队列系统\n排行榜\n实时系统\n社交队列\nRedis 可执行文件介绍 redis-server：redis服务器\nredis-cli：rdis命令行服务端\nredis-benchmark：性能测试\nredis-check-aof： aof修复工具\nredis-check-dump：rdb文件检查工具\nredis-sentinel：sentinel服务器\n启动方式 最简启动 启动\nredis-server\n验证\nps -ef|grep redis\nnetstat -antpl | grep redis\nredis-cli -h ip -p port ping\n配置启动 daemonsize:是否以守护进程的方式启动\nport:redis对外端口号\nlogfile:redis系统日志\ndir:redis工作目录\n#redis是单进程，但是一般电脑是多线程的，所以我们可以开多个redis进程，通过不同的端口来访问 mkdir -p /home/redis/config cp /etc/redis/redis.conf /home/redis/config/redis.conf #查看修改配置 cd /home/redis/conf cat redis.conf|grep -v \u0026#34;#\u0026#34; |grep -v \u0026#34;^$\u0026#34; \u0026gt; redis-6380.conf 配置说明 INCLUDES 多个人进行开发维护，需要多个配置文件，可以在此通过 include /path/to/local.conf 配置进来，而原本的 redis.conf 配置文件是一个汇总。\n注意，如果此配置写在redis.conf 文件的开头，那么后面的配置会覆盖引入文件的配置，如果想以引入文件的配置为主，那么需要将 include 配置写在 redis.conf 文件的末尾。\nMODULES 通过 loadmodule path/to/my_module.so引入自定义模块\nNETWORK ①、bind:绑定redis服务器网卡IP，默认为127.0.0.1,即本地回环地址。这样的话，访问redis服务只能通过本机的客户端连接，而无法通过远程连接。如果bind选项为空的话，那会接受所有来自于可用网络接口的连接。\n②、port：指定redis运行的端口，默认是6379。由于Redis是单线程模型，因此单机开多个Redis进程的时候会修改端口。\n③、timeout：设置客户端连接时的超时时间，单位为秒。当客户端在这段时间内没有发出任何指令，那么关闭该连接。默认值为0，表示不关闭。\n④、tcp-keepalive ：单位是秒，表示将周期性的使用SO_KEEPALIVE检测客户端是否还处于健康状态，避免服务器一直阻塞，官方给出的建议值是300s，如果设置为0，则不会周期性的检测。\nGENERAL ①、daemonize:设置为yes表示指定Redis以守护进程的方式启动（后台启动）。默认值为 no\n②、pidfile:配置PID文件路径，当redis作为守护进程运行的时候，它会把 pid 默认写到 /var/redis/run/redis_6379.pid 文件里面\n③、loglevel ：定义日志级别。默认值为notice，有如下4种取值：\ndebug（记录大量日志信息，适用于开发、测试阶段）\nverbose（较多日志信息）\nnotice（适量日志信息，使用于生产环境）\nwarning（仅有部分重要、关键信息才会被记录）\n④、logfile ：配置log文件地址,默认打印在命令行终端的窗口上\n⑤、databases：设置数据库的数目。默认的数据库是DB 0 ，可以在每个连接上使用select \u0026lt;dbid\u0026gt; 命令选择一个不同的数据库，dbid是一个介于0到databases - 1 之间的数值。默认值是16.\nSNAPSHOTTING 这里的配置主要用来做持久化操作。\n①、save：这里是用来配置触发 Redis的持久化条件，也就是什么时候将内存中的数据保存到硬盘。默认如下配置：\nsave 900 1：表示900 秒内如果至少有 1 个 key 的值变化，则保存\nsave 300 10：表示300 秒内如果至少有 10 个 key 的值变化，则保存\nsave 60 10000：表示60 秒内如果至少有 10000 个 key 的值变化，则保存\n当然如果你只是用Redis的缓存功能，不需要持久化，那么你可以注释掉所有的 save 行来停用保存功能。可以直接一个空字符串来实现停用：save \u0026quot;\u0026quot;\n②、stop-writes-on-bgsave-error ：默认值为yes。当启用了RDB且最后一次后台保存数据失败，Redis是否停止接收数据。这会让用户意识到数据没有正确持久化到磁盘上，否则没有人会注意到灾难（disaster）发生了。如果Redis重启了，那么又可以重新开始接收数据了\n③、rdbcompression ；默认值是yes。对于存储到磁盘中的快照，可以设置是否进行压缩存储。如果是的话，redis会采用LZF算法进行压缩。如果你不想消耗CPU来进行压缩的话，可以设置为关闭此功能，但是存储在磁盘上的快照会比较大。\n④、rdbchecksum ：默认值是yes。在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。\n⑤、dbfilename ：设置快照的文件名，默认是 dump.rdb\n⑥、dir：设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名。使用上面的 dbfilename 作为保存的文件名。\nREPLICATION ①、slave-serve-stale-data：默认值为yes。当一个 slave 与 master 失去联系，或者复制正在进行的时候，slave 可能会有两种表现：\n1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时，或者数据可能是空的在第一次同步的时候\n2) 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，slave 都将返回一个 \u0026ldquo;SYNC with master in progress\u0026rdquo; 的错误\n②、slave-read-only：配置Redis的Slave实例是否接受写操作，即Slave是否为只读Redis。默认值为yes。\n③、repl-diskless-sync：主从数据复制是否使用无硬盘复制功能。默认值为no。\n④、repl-diskless-sync-delay：当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。 这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段 时间以期更多的从站到达。延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动。默认值为5。\n⑤、repl-disable-tcp-nodelay：同步之后是否禁用从站上的TCP_NODELAY 如果你选择yes，redis会使用较少量的TCP包和带宽向从站发送数据。但这会导致在从站增加一点数据的延时。 Linux内核默认配置情况下最多40毫秒的延时。如果选择no，从站的数据延时不会那么多，但备份需要的带宽相对较多。默认情况下我们将潜在因素优化，但在高负载情况下或者在主从站都跳的情况下，把它切换为yes是个好主意。默认值为no。\nSECURITY ①、rename-command：命令重命名，对于一些危险命令例如：\nflushdb（清空数据库）\nflushall（清空所有记录）\nconfig（客户端连接后可配置服务器）\nkeys（客户端连接后可查看所有存在的键）\n作为服务端redis-server，常常需要禁用以上命令来使得服务器更加安全，禁用的具体做法是是：\nrename-command FLUSHALL \u0026quot;\u0026quot;\n也可以保留命令但是不能轻易使用，重命名这个命令即可：\nrename-command FLUSHALL abcdefg\n这样，重启服务器后则需要使用新命令来执行操作，否则服务器会报错unknown command。\nCLIENTS ①、maxclients ：设置客户端最大并发连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件。 描述符数-32（redis server自身会使用一些），如果设置 maxclients为0 。表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息\nMEMORY MANAGEMENT ①、maxmemory：设置客户端最大并发连接数，默认无限制，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件。描述符数-32（redis server自身会使用一些），如果设置 maxclients为0 。表示不作限制。当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息。\n②、maxmemory-policy ：当内存使用达到最大值时，redis使用的清楚策略。有以下几种可以选择：\n1）volatile-lru 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used )\n2）allkeys-lru 利用LRU算法移除任何key\n3）volatile-random 移除设置过过期时间的随机key\n4）allkeys-random 移除随机ke\n5）volatile-ttl 移除即将过期的key(minor TTL)\n6）noeviction noeviction 不移除任何key，只是返回一个写错误 ，默认选项\n③、maxmemory-samples ：LRU 和 minimal TTL 算法都不是精准的算法，但是相对精确的算法(为了节省内存)。随意你可以选择样本大小进行检，redis默认选择3个样本进行检测，你可以通过maxmemory-samples进行设置样本数。\nAPPEND ONLY MODE ①、appendonly：默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式， 可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入appendonly.aof文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。默认值为no。\n②、appendfilename ：aof文件名，默认是\u0026quot;appendonly.aof\u0026quot;\n③、appendfsync：aof持久化策略的配置；no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快；always表示每次写入都执行fsync，以保证数据同步到磁盘；everysec表示每秒执行一次fsync，可能会导致丢失这1s数据\n④、no-appendfsync-on-rewrite：在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。 设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。默认值为no。\n⑤、auto-aof-rewrite-percentage：默认值为100。aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。\n⑥、auto-aof-rewrite-min-size：64mb。设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写。\n⑦、aof-load-truncated：aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项，出现这种现象 redis宕机或者异常终止不会造成尾部不完整现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。默认值为 yes。\nLUA SCRIPTING ①、lua-time-limit：一个lua脚本执行的最大时间，单位为ms。默认值为5000.\nREDIS CLUSTER ①、cluster-enabled：集群开关，默认是不开启集群模式。\n②、cluster-config-file：集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。 这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件。请确保与实例运行的系统中配置文件名称不冲突。默认配置为nodes-6379.conf。\n③、cluster-node-timeout ：可以配置值为15000。节点互连超时的阀值，集群节点超时毫秒数\n④、cluster-slave-validity-factor ：可以配置值为10。在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了， 导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period 如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移\n⑤、cluster-migration-barrier ：可以配置值为1。master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。\n⑥、cluster-require-full-coverage：默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。 设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致。\n","date":"2019-03-08","img":"","permalink":"/posts/redis/redis%E9%85%8D%E7%BD%AE/","series":["redis"],"tags":["redis"],"title":"Redis基础配置"},{"categories":["TensorFlow"],"content":"TensorFlow 基础 计算密集型(tensorflow) cpu计算\nio密集型(Django,Scrapy) http请求\n线性回归回顾 准备好特征和lable y = x*0.7+0.8\n2.建模.随机初始化一个权重w,一个偏置b\ny_predict = wx+b\n求损失函数 less化损失函数\n(y-y_predict)^2/x.shape[0]\n4.梯度下降优化损失函数,我们需要查阅tensorflowAPI,制定合适的eta\n变量作用域 tf.variable_scope\n让变量显示可观测 收集变量 tf.summary.scalar(name=\u0026rsquo;\u0026rsquo;,tensor) #收集单值变量,name是变量名,tensor为值\ntf.summary.histogram(name=\u0026rsquo;\u0026rsquo;,tensor) #收集高纬度的变量参数\ntf.summary.image(name=\u0026rsquo;\u0026rsquo;,tensor) #收集输入的图片张量能显示图片\n合并变量写入事件文件 merged = tf.summary.merge_all()\nsummary = sess.run(merged) #每次迭代都需要运行\nFileWriter.add_summary(summary,i) #表示第几次的值\n模型的保存和加载 tf.train.Save(var_list = None,max_to_keep = 5)\nvar_list:指定将要保存和还原的变量.他可以作为一个dict或一个列表传递\nmax_to_keep:指示要保留的最近检查点文件的最大数量.创建新文件时,会删除较旧文件,默认为5,即保留最近的5个检查点文件\n定义命令行参数 先定义有哪些参数需要在运行时指定\n程序中获取定义命令行参数\n使用时 python *.py --name=参数 [--DEFINE_name=参数]\nimport os import tensorflow as tf #定义参数的名字,默认值,说明 tf.app.flags.DEFINE_integer(\u0026#34;max_step\u0026#34;,100,\u0026#34;模型的训练步数\u0026#34;) tf.app.flags.DEFINE_string(\u0026#34;model_dir\u0026#34;,\u0026#34;\u0026#34;,\u0026#34;模型文件的加载路径\u0026#34;) #定义获取命令行参数的名字 FLAGS = tf.app.flags.FLAGS def mylg(): g3 = tf.get_default_graph() with tf.variable_scope(\u0026#34;data\u0026#34;): # 准备特征和lablel x = tf.random_normal([1000,1],mean=1.75,stddev=0.5,name=\u0026#34;X_data\u0026#34;) y = tf.matmul(x,[[0.7]]) + 0.8#举证相乘必须是二维的 with tf.variable_scope(\u0026#34;model\u0026#34;): # 设置模型 w = tf.Variable(tf.random_normal([1,1],mean=0.0,stddev=1.0),name=\u0026#34;w\u0026#34;,trainable=True) #trainable设置这个变量是否变化 b = tf.Variable(0.5,name=\u0026#39;b\u0026#39;) y_predict = tf.matmul(x,w) + b with tf.variable_scope(\u0026#34;loss\u0026#34;): #写损失函数 loss = tf.reduce_mean(tf.square(y-y_predict)) with tf.variable_scope(\u0026#34;train\u0026#34;): train = tf.train.GradientDescentOptimizer(0.01).minimize(loss) #1. 收集tensor tf.summary.scalar(\u0026#34;loss\u0026#34;,loss) tf.summary.histogram(\u0026#39;weight\u0026#39;,w) tf.summary.histogram(\u0026#39;bias\u0026#39;,b) #2. 合并变量 merged = tf.summary.merge_all() #初始化变量 init = tf.global_variables_initializer() #定义一个保存模型的实例 saver = tf.train.Saver() with tf.Session(graph=g3) as sess: sess.run(init) filewriter = tf.summary.FileWriter(\u0026#39;/home/python/jupyter/TensorFlow\u0026#39;,graph=g3) #加载模型 if os.path.exists(FLAGS.model_dir+\u0026#34;/checkpoint\u0026#34;): saver.restore(sess,FLAGS.model_dir+\u0026#34;/model\u0026#34;) for i in range(FLAGS.max_step): sess.run(train) summary = sess.run(merged) filewriter.add_summary(summary,i) if i%20==0: print(\u0026#34;第%d次优化的参数权重为%f,偏置为%f\u0026#34;%(i,w.eval(),b.eval())) if i%200==0: saver.save(sess,FLAGS.model_dir+\u0026#34;/model\u0026#34;)#保存模型 mylg() graph图 创建一张图包含了一组op和tensor,上下文环境\n没创建一个图就会包含一个内存地址\n一个Session运行一张图 tf.InteractiveSession()#开启Session一个上下文环境\ng = tf.Graph() with g.as_default(): c = tf.constant(11.0) a = tf.constant(5.0) b = tf.constant(6.0) sum1 = tf.add(a,b) mul = tf.multiply(a,b) g2 = tf.get_default_graph() #config=tf.ConfigProto(log_device_placement=True) 可以查看运行在那些cpu with tf.Session(graph=g2,config=tf.ConfigProto(log_device_placement=True)) as sess: print(sess.run(sum1))## run()方法 print(sess.run([a,b])) print(sum1.eval()) 重载 默认会把运算符重载为op\nd = tf.constant(1.0) e = 11.0 sum2 = d+e with tf.Session() as sess: print(sess.run(sum2))## run()方法 实时的提供数据进行训练 在程序执行时,不确定输入的shape\nplaceholder #占位符\nplt = tf.placeholder(tf.float32,[None,3])#样本数不固定,三列 print(plt)#打印这个张量 #使用 with tf.Session() as sess: print(sess.run(plt,feed_dict={plt:[[1,2,3],[4,5,6]]}))## run()方法 张量的动态形状和静态形状 Numpy:把原来的数据通过reshape直接改变\n静态形状： 创建一个张量，初始化状态的形状：\ntf.Tensor.get_shape:获取静态形状 tf.Tensor.set_shape():更新Tensor对象的静态形状 动态形状: 一种描述原始张量在执行过程中的一种形状(动态变化)\ntf.reshape:创建一个具有不同形状的新张量 plt.set_shape([3,3])#把plt的shape从[?,3]变成[3,3] with tf.Session() as sess: print(sess.run(plt,feed_dict={plt:[[1,2,3],[4,5,6],[7,8,9]]}))## run()方法 变量 变量也是一种op,是一种特殊的张量,能够进行持久化,他的值就是张量,默认被训练\nvar = tf.Variable(tf.random_normal([2,3],mean=0.0,stddev=1.0))#均值为0,标准差为1 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) print(sess.run(var)) Tensorboard 数据序列化-\u0026gt;events文件 TensorBoard通过读取TensorFlow的事件文件来运行\n生成文件: tf.summary.FileWriter(\u0026lsquo;dir-path\u0026rsquo;,graph=g?)\n返回一个filewriter\n开启: tensorboard \u0026ndash;logdir=\u0026rsquo;/dir-path\u0026rsquo;\nd = tf.constant(1.0) e = tf.constant(1.0) sum2 = d+e var = tf.Variable(tf.random_normal([2,3],mean=0.0,stddev=1.0))#均值为0,标准差为1 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) print(sess.run(var)) print(sess.run(sum2))## run()方法 filewriter = tf.summary.FileWriter(\u0026#39;/home/python/jupyter/TensorFlow\u0026#39;,graph=sess.graph) 文件读取 队列与队列管理器 在训练样本的时候,希望数据有序读取 tf.FIFOQueue(capacity,dtypes,name=\u0026lsquo;fifo_queue\u0026rsquo;) 先进先出队列,按顺序出队列\ncapacity:整数,可能存储在此队列中的元素数量的上限\ndtypes:DType对象列表,长度dtypes必须等于每个队列元素中的张量数,dtype的元素形状,决定了后面进队元素的形状\ntf.RandomShuffleQueue 随机出队列\n异步读取,队列管理器 tf.train.QueueRunner(queue,enqueue_ops=None)创建一个QueueRunner\n线程协调器,实现一个简单的机制来协调一组线程的终止 tf.train.Coordinator()\nrequest_stop()\nshould_stop()检查是否要求停止\njoin(threads = None,stop_grace_period_secs=120)\n读取文件的流程 1.构建文件队列 将输出字符串到管道队列中\ntf.train.string_input_producer(string_tensor,shuffle = True)\nstring_tensor 含有文件名的1阶张量\nnum_epochs 过几遍数据,默认无线过数据\nreturn:具有输出字符串的队列\n2.构造文件阅读器,读取队列内容(都是用read(file_queue)这个方法,从文件中读取指定数量内容) tf.TextLineReader(阅读文本文件csv,默认按行读取)\ntf.FixedLengthRecordReader(record_bytes):读取每个记录是固定数量的二进制文件\nrecord_bytes:整形,指定每次读取的字节数 tf.TFRecordReader: 读取TFRecords文件\n3.读取每个队列文件的每一个样本 tf.decode_csv(records,record_defaults=None,field_delim=None,name=None)\n将csv转换为张量,与tf.TextLineReader搭配使用\nrecords:tensor型字符串,每个字符串是csv中的记录行\nfield_delim:默认分隔符\u0026quot;,\u0026quot;\nrecord_defauts:参数决定所得每一列张量的类型,并设置一个值,在输入字符串中缺少使用默认值\ntf.decode_raw(bytes,out_type,little_endian=None,name=None)\n将字节转换为一个数字向量表示,字节为一字符类型的张量,二进制读取为uint8\n4.批处理 tf.train.batch([sentence],batch_size=30,num_threads=1,capacity=30)\n​\nimport tensorflow as tf import os def myqueu(): # 1. 定义队列 Q = tf.FIFOQueue(1000,tf.float32) # 2. 定义子线程操作 var = tf.Variable(0.0) data = tf.assign_add(var,tf.constant(1.0)) enq = Q.enqueue(data) # 3. 定义队列管理器,指定线程数 qr = tf.train.QueueRunner(Q,enqueue_ops=[enq]*4) #初始化变量 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) #开启线程协调管理器 coord = tf.train.Coordinator() threads = qr.create_threads(sess,coord=coord,start=True) for i in range(300): print(sess.run(Q.dequeue())) coord.request_stop() coord.join(threads) def convread(filelist): # 1.构造队列 file_queue = tf.train.string_input_producer(filelist) # 2.构造阅读器 reader = tf.TextLineReader() key, value = reader.read(file_queue) # 3.对每一行解码 records = [[\u0026#34; \u0026#34;],]#以字符串读取每一行,默认值是\u0026#34; \u0026#34; sentence = tf.decode_csv(value,record_defaults=records) #开启批处理 sentence_batch = tf.train.batch([sentence],batch_size=30,num_threads=1,capacity=30) return sentence#返回句子 if __name__ == \u0026#34;__main__\u0026#34;: #构造文件列表 file_name = os.listdir(\u0026#34;../data/\u0026#34;) filelist = [os.path.join(\u0026#34;../data/\u0026#34;,file) for file in file_name] #读取文件 sentence_batch = convread(filelist) #开启会话 with tf.Session() as sess: #定义一个线程协调器 coord = tf.train.Coordinator() #开启读取文件的线程 threads = tf.train.start_queue_runners(sess,coord=coord) print(sess.run(sentence_batch)) #回收子线程 coord.request_stop() coord.join(threads) ","date":"2019-02-22","img":"","permalink":"/posts/tensorflow/tensorflow%E5%9F%BA%E7%A1%80/","series":["TensorFlow"],"tags":["TensorFlow"],"title":"TensorFlow 基础"},{"categories":["TensorFlow"],"content":"TensorFlow 线性回归 TensorFlow是一个编程系统,使用图(graphs)来表示计算任务,图(graphs)中的节点称之为op(operation),一个op获得0个或者多个Tensor,执行计算,产生0个或者多个Tensor.Tensor看做是一个n维的数组或者列表.图必须在会话Session里被启动\n##基本概念\n使用图(graphs)来表示计算任务\n在被称为会话(Session)的上下文(context)中执行图\n使用张量(tensor)表示数据\n通过变量(Vatria)维护状态\n使用feed和fetch可以为任意的操作赋值或者从中获取数据\n张量(Tensor)\n在TensorFlow中,张量的维度被描述为\u0026quot;阶\u0026quot;,但是,张量的阶和矩阵的阶并不是同一个概念,张量的阶,是张量维度的一个数量的描述\nx=3\t#零阶张量:纯量 v=[1.,2.,3.]\t#一阶张量:向量 t=[[1,2,3],[4,5,6]]\t#二阶张量:矩阵 m=[[[1],[2],[3]],[[4],[5],[6]],[[7],[8],[9]]]\t#三阶张量:立方体 图(Graph)\n代表模型的数据流,由ops和tensor组成.其中op是操作,也就是节点,而tensor是数据流,也就是边\n算法会表示为计算图(computational graphs),也称之为数据流图.我们把计算图看作为一种有向图,张量就是通过各种操作在有向图中流动\n会话(Session)\n在TensorFlow中,要想启动一个图的前提是要创建一个会话(Session),TensorFlow的所有对图的操作,都必须放在会话中进行\n基础使用: op和Session import tensorflow as tf #创建两个常量op c1 = tf.constant([[1,2]]) c2 = tf.constant([[2],[1]]) #创建一个矩阵乘法op matmulop = tf.matmul(c1,c2) print(matmulop) Tensor(\u0026quot;MatMul:0\u0026quot;, shape=(1, 1), dtype=int32) #定义一个会话,启动图 sess = tf.Session() #调用sess的run方法来运行矩阵乘法op #run(matmulop)触发了图中的3个op result = sess.run(matmulop) print(result) sess.close() [[4]] #利用with省去这个麻烦 with tf.Session() as sess: #调用sess的run方法执行矩阵乘法op result = sess.run(matmulop) print(result) [[4]] 变量 #添加一个变量op x = tf.Variable([1,2]) #添加一个常量op c = tf.constant([2,1]) #增加一个减法op sub = tf.subtract(x,c)#x-c #增加一个加法op add = tf.add(x,sub)#x+(x-c) #初始化所有变量 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) print(sess.run(sub)) print(sess.run(add)) [-1 1] [0 3] 实现迭代自增 #创建一个变量初始化为0 state = tf.Variable(0,name=\u0026#39;cont\u0026#39;) #创建一个让state加1的op new_state = tf.add(state,1) #赋值op update = tf.assign(state,new_state)#把new_state的值给到state \u0026#39;\u0026#39;\u0026#39; tf.assign(ref, value, validate_shape=None, use_locking=None, name=None) 函数完成了将value赋值给ref的作用。 注意: 1. ref 必须是tf.Variable创建的tensor，如果ref=tf.constant()会报错！ 2. shape（value）==shape（ref） \u0026#39;\u0026#39;\u0026#39; #变量初始化op init = tf.global_variables_initializer() #使用Session运行这些op with tf.Session() as sess: sess.run(init) for _ in range(6): print(sess.run(state)) sess.run(update) 0 1 2 3 4 5 Fetch 同时运行多个op,得到他们的结果 def session_run(*args): #初始化所有变量 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) #调用sess的run方法执行矩阵乘法op result = sess.run(args) print(result,end=\u0026#39; \u0026#39;) with tf.Session() as sess: sess.run(init) result = sess.run([new_state,update]) print(\u0026#39;feed:\u0026#39;,result) with tf.Session() as sess: sess.run(init) print(\u0026#39;not fetch\u0026#39;,end=\u0026#39;: [\u0026#39;) print(sess.run(state),end=\u0026#39;,\u0026#39;) print(sess.run(update),end=\u0026#39;]\\n\u0026#39;) print(\u0026#39;session_run\u0026#39;,end=\u0026#39;: \u0026#39;) session_run(new_state,update)#达到了和fetch一样的效果 feed: [1, 1] not fetch: [0,1] session_run: (1, 1) Feed #创建两个32位浮点型的占位符op placeholder1 = tf.placeholder(tf.float32) placeholder2 = tf.placeholder(tf.float32) feed_output = tf.multiply(placeholder1,placeholder2) with tf.Session() as sess: result=sess.run(feed_output,feed_dict={placeholder1:[8.],placeholder2:[9.1]}) print(result) [72.8] demo import tensorflow as tf import numpy as np #使用numpy生成特征和真实值 X = np.random.rand(100) y = X*0.1 + 0.2 #创建两个op变量,用来构造一个线性模型 b = tf.Variable(0.) w = tf.Variable(0.) predic = w*X+b #设置我们的代价函数(均方差) loss = tf.reduce_mean(tf.square(y - predic)) #定义我们的优化器(梯度下降) gd_optimizer = tf.train.GradientDescentOptimizer(0.2)#学习率 #创建一个op,用来最小化代价函数 train = gd_optimizer.minimize(loss) #初始化变量 init = tf.global_variables_initializer() with tf.Session() as sess: sess.run(init) for step in range(200): sess.run(train) if step%20 == 0: print(step,sess.run([w,b])) 0 [0.055094976, 0.10045407] 20 [0.10424501, 0.19765908] 40 [0.10235276, 0.1987026] 60 [0.101303995, 0.19928093] 80 [0.10072273, 0.19960146] 100 [0.10040057, 0.19977911] 120 [0.10022201, 0.19987758] 140 [0.10012304, 0.19993214] 160 [0.1000682, 0.19996239] 180 [0.1000378, 0.19997916] ","date":"2019-02-22","img":"","permalink":"/posts/tensorflow/tensorflow%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/","series":["TensorFlow"],"tags":["TensorFlow"],"title":"TensorFlow 线性回归"},{"categories":["notes"],"content":"C++ 小记 CMAKE 工程构建工具 简单的使用 文件名大小写敏感 语法 cmake_minimum_required(VERSION 2.8)#设置cmake的版本 set(CMAKE_BUILD_TYPE Debug )#设置为debug模式 #项目名 PROJECT(HELLO) #设置某文件夹为头文件 include_directories(\u0026#34;include\u0026#34;) #设置一个头文件，把hello.cpp编译为libfile add_library(libfile src/hello.cpp) SET(SRC_LIST “fu nc.c”) #设置可执行二进制文件的输出路径和库的输出路径 SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin) SET(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib) ADD_EXECUTABLE(hello main.c;func.c;$\\{RC_LIST\\}) target_link_libraries(hello libfile)#链接一个lib #设置编译的源文件在编译当前目录的bin下 ADD_SUBDIRECTORY (src bin)#修改为 SUBDIRS(src) 结果放在src中 #安装 DESTDIR= install: mkdir -p $(DESTDIR)/usr/bin install -m 755 hello $(DESTDIR)/usr/bin 更像一个工程 Hello - src - CMakeLists.txt - build #进去此目录进行外部编译 =》 cmake .. \u0026amp; make - CMakeLists.txt project(hello) add_executable(hello hello.c) set(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/bin) set(EXECUTABLE_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib) map和set 底层使用的是红黑树\n查找是使用二分搜索（红黑树保有顺序性）\n各种操作都是nlog\nunordered_map,unordered_set 底层都是哈希表\n不保有顺序性，但是查找操作是O1\n","date":"2019-02-21","img":"","permalink":"/posts/note/c++%E5%B0%8F%E8%AE%B0/","series":["notes"],"tags":["notes"],"title":"C++ 小记"},{"categories":["NLP"],"content":"word2vec !(http://www.cnblogs.com/neopenx/p/4571996.html)( 是个巨佬) !(https://blog.csdn.net/itplus/article/details/37969817 )\n概率语言模型 概率语言模型 预测字符串概率,考虑动机,考虑计算方式\nUnigram models(一元文法统计模型)\nN-gram 语言模型(N元模型\nN元模型 $P( w1,w2,\u0026hellip;,w_m) = i\u0026hellip;m() P(w_i|w1,\u0026hellip;,w_(i-1)) = i\u0026hellip;m() P(w_i|w_(i-n+1),\u0026hellip;,w_(i-1))$\n注: n大于3时基本无法处理,参数空间太大.另外它不能表示词与词之间的关联性\n神经概率语言模型 在论文《A neural probabilistic language model》中提出的一种模型.该模型的重要工具是词向量\n词向量: 对词典D中的任意词w,指定一个固定长度的实值向量$v(w)\\in R^m$v(w)就称为w的词向量,m为词向量的长度\n概述 训练样本: (Context(w),w) 包括前n-1个词分别的向量,假定每个词向量大小m\n投影层： (n-1)*m 首尾拼接起来的大向量\n输出: 输出是一棵二叉树,它以语料中出现过的词当做叶子节点.以各词在语料中的出现次数当做权值垢找出来的Huffman树\ny_w = (y_w1,y_w2,y_w3,\u0026hellip;y_wN,)\n表示上下文为Context(w)时,下一个词恰好为词典中的第i个词的概率\n归一化: $$p(w|Context(w)) = \\frac{e^{yw,iw}}{\\sum^{N}_{i=1}e^{yw,iw} }$$\n哈弗曼树 最优二叉树,节点会有权重,指示词的常用频次\n使用哈弗曼树\n把高频词放在距离根节点近的地方,在测试时,我们每次预测每一层的正概率和负概率\nCBOW 根据上下文的词语预测当前词语的出现概率的模型\n$$L = \\sum_{w\\in c}logp(w|Context(w))$$\n词向量=哈弗曼编码,经过不断地训练,哈弗曼编码不断改变\n权重参数=通过每层的概率计算,最终指向这个词会有一个似然函数,其中的某个参数,就是sigmod函数中的theta\n对最终的似然函数求最大==\u0026gt;最大化问题\u0026ndash;\u0026gt;梯度上升\nNegative Sampling 为了解决,树空间过大\n思想:\n保证频次越高的词,越容易被采样出来\n不使用哈弗曼树进行预测,使用负采样,降低计算复杂度\nSkip-gram seq2seq seq2seq是一个Encoder-Decoder结构的网络,它的输入是一个序列,输出也是一个序列\nEncoder中将一个可变长度的信号序列变为固定长度的向量表达\nDecoder将这个固定长度的向量变成可变长度的目标的信号序列\n输入序列和输出序列的长度是可变的\n可以用于翻译,聊天机器人,句法分析,文本摘要\nencoder 过程 取得输入的文本,进行enbedding\n传入到LSTM中进行训练\n记录状态,并输出当前cell的结果\n依次循环,得到最终结果\ndecoder过程 在encoder最后一个时间步长的隐藏层之后输入到decoder的第一份cell里\n通过激活函数得到候选的文本\n筛选出可能性最大的文本作为下一个时间步长的输入\n依次输入,得到目标\n注意力机制 注意力机制是在序列到序列模型中用于注意编码器状态的最常用方法,它同时还可用于回顾序列模型的过去状态\n注意力机制不仅能用来处理编码器或前面的隐藏层,它同样还能用来获得其他特征的分布 为什么需要注意力机制 减小处理高纬度输入数据的计算负担,通过结构化的选取输入的子集,降低数据维度\n让任务处理系统更专注于找到输入数据中显著的与当前输出相关的有用信息.从而提高输出的质量\nAttention模型的最终目的是帮助类似编解码器这样的框架,跟好的学到多种内容模态的相互关系,从而更好的表示这些信息,克服其无法解释从而很难设计的缺陷\n聊天机器人根据对话的产生方式 基于检索的模型\n基于生成式的模型\n基于检索的模型 在数据库中存储问答对\n使用语句匹配的形式查找答案\n答案相对固定,且很少出现语法错误\n不会出现新的语句\n基于生成式模型 不依赖预先设定的问答库\n通常基于机器翻译技术\n需要大量的语料进行训练\nEncoder-Decoder模式\n混合模式 兼具检索模式和生成模式\n检索模式产生候选数据集\n生成模式产生最终答案\n我们的系统架构 ","date":"2019-02-21","img":"","permalink":"/posts/nlp/chatbot%E6%A8%A1%E5%9E%8B/","series":["NLP"],"tags":["NLP"],"title":"ChatBot模型基础"},{"categories":["notes"],"content":"![reference])(https://blog.csdn.net/shuchuan0409/article/details/101615221 )\n第一步：\n执行 sudo apt-get update 更新apt-get，耗时可能会比较久\n第二步：安装谷歌浏览器\n直接下载谷歌浏览器最新版：wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb 安装：dpkg -i google-chrome-stable_current_amd64.deb\n如果不出意外，上面这一步一般都不会安装成功（但是也要执行），这个时候我们需要执行 ：apt-get install -f 用来下载兼容或者必须的一些软件包\n等下载完成以后再重新安装谷歌浏览器，这个时候要记下谷歌浏览器的版本号，这是个很重要的信息，下面安装chromedriver的时候需要使用\nUnpacking google-chrome-stable (77.0.3865.90-1) 里面的77.0.3865.90-1就是谷歌浏览器的版本号\n第三步：\n安装xvfb 安装这个工具是为了让我们可以无界面运行谷歌浏览器，直接apt-get安装即可\nsudo apt-get install xvfb\n第四步：安装chromedriver\n下载chromedriver的安装包，直接访问地址：http://chromedriver.storage.googleapis.com/index.html 去下载自己浏览区对应的版本，如果找不到自己浏览器对应的版本，就找个比较接近的版本就行了，比如我这边的谷歌版本号是77.0.3865.90，但是网站上并没有找个版本对应的驱动\n我这边就下载了77.0.3865.40这个版本，点击去找到linux对应的下载地址，直接使用wget进行下载\nwget http://chromedriver.storage.googleapis.com/77.0.3865.40/chromedriver_linux64.zip 下载后解压到当前目录下,如果没有安装unzip，就使用apt-get install unzip 安装解压工具\nunzip 你下载的zip文件\n移动文件夹到usr文件夹下面，并创建软链接，升级为全局变量\nmv -f chromedriver /usr/local/share/chromedriver\nln -s /usr/local/share/chromedriver /usr/local/bin/chromedriver\nln -s /usr/local/share/chromedriver /usr/bin/chromedriver\n到此安装结束，我们执行 chromedriver \u0026ndash;version 可以查看安装的版本号\n","date":"2019-02-21","img":"","permalink":"/posts/note/chromedriver-%E5%AE%89%E8%A3%85/","series":null,"tags":["chromedriver"],"title":"chromedriver-安装"},{"categories":["notes"],"content":"首先是梯子 校园网改ipv6连接谷歌 1.修改SDN服务器\n在ipv6的sdn中设置这两个记录，也可以只设置一个\n2001:4860:4860::8888 2001:4860:4860::8844 linux:修改/etc/resolv.conf\n2.修改hosts\nwindows路径：%SystemRoot%\\system32\\drivers\\etc\\hosts\nlinux:/etc/hosts\nipv6 hosts 入门： 进入colab 因为我有基础，所以直接跳过了机器学习速成课部分，做了我在calab的第一个实验: 图像风格转换\n连接Colab和google drive !apt-get install -y -qq software-properties-common python-software-properties module-init-tools !add-apt-repository -y ppa:alessandro-strada/ppa 2\u0026gt;\u0026amp;1 \u0026gt; /dev/null !apt-get update -qq 2\u0026gt;\u0026amp;1 \u0026gt; /dev/null !apt-get -y install -qq google-drive-ocamlfuse fuse from google.colab import auth auth.authenticate_user() from oauth2client.client import GoogleCredentials creds = GoogleCredentials.get_application_default() import getpass !google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} \u0026lt; /dev/null 2\u0026gt;\u0026amp;1 | grep URL vcode = getpass.getpass() !echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} 然后会出现一个链接，点进去取得key，输入并回车 然后新建一个文件夹并挂载\n!mkdir -p Euraxluo !google-drive-ocamlfuse Euraxluo 如果报错：use the 'nonempty' mount option 在第二局加参数 !google-drive-ocamlfuse Euraxluo -o nonempty Euraxluo是我建立的文件夹的名字 这下挂载就可以用了\n","date":"2019-02-21","img":"","permalink":"/posts/note/colab%E7%9A%84%E4%BD%BF%E7%94%A8/","series":null,"tags":["Colab"],"title":"Colab的使用"},{"categories":["notes"],"content":"C语言小计 Unix C 内核-》系统调用-》shell/共用函数库-》应用程序\n系统调用和库函数\n库函数会调用系统调用来实现自己的算法\n公用函数库构建在系统调用之上，应用程序既可以使公用函数库，也可以使用系统调用\n口令文件：/etc/passwd 字段结构：\n登录名：加密口令：UID：GID：注释字段：起始目录：sell\n文件系统：\n/是root目录 /和空字符不能出现在文件名字中，斜线用来分隔开构成路径名的各文件名，空字符用来终止一个路径名 工作目录：每个进程都有一个工作目录，所有的相对路径名都从工作目录开始解释，进程可以使用chdir()更改工作目录,以/开始的路径名是绝对路径名 登陆时工作目录设置为起始目录，从口令文件中取得 输入输出\n不带缓冲区的io：open,read,write,lseek,close stdout \u0026gt; file可以把标准输出或者符号左边的字符重定向到文件 进程\n每个进程都有一个pid，pid_t保证可以用long保存\n进程控制：fork,waitpid,exec(exec函数有很多变体)\nsignal，用于通知进程发生了某种情况；进程会：\n忽略信号\n按系统默认方式处理\n提供一个函数，信号捕捉（类似错误处理？）\n时间值\n用户cpu时间：执行用户指令所用的时间 系统cpu时间：该进程执行内核程序经历的时间 时钟时间：进程运行的时间总量 CPU时间 = time_t + clock_t 问题：若日历时间放在带符号的32位int中，哪一年会溢出？怎么扩展 文件IO（不带缓冲的IO） 不带缓冲：指的是每个read和write都调用系统调用，这些函数不是ISO C的组成部分\n幻数：没来由的，不利于维护的数字，最好define\ndefine STDIN_FILENO 0 define STDOUT_FILENO 1 define STDERR_FILENO 3 open(path，oflag),oflag常量很多，说明了文件的打开描述\nopenat(path，oflag),oflag常量很多，说明了文件的打开描述\ncreat(path,mode)mode指示文件访问权限\nclose(int fd)关闭一个文件的同时还会释放该进程加在这个文件上的所有记录锁\noff_t/-1 = lseek(int fd,off_t offset,int whence)偏移量设置函数\nwhence == SEEK_SET,off_t = begin()+offset,文首绝对偏移量 whence == SEEK_CUR,off_t = off_t + offset,相对当前位置偏移 whence == SEEK_END,off_t = end() + offset,文尾相对位置偏移 od -c file查看文件的实际内容,-c以字符方式\nssize_t read(int fd,void *buf,size_t nbytes)从文件中中读取数据，void *通用指针\nshell提供一种方法，从标准输入上打开一个文件用于读，在标准输出上创建/重写一个文件。因此很多程序可以不必打开输出和输入文件\n预读技术：检测到正在顺序读取时，系统试图读入比应用所要求的更多数据\nioctl(int fd,int request,...):io杂物箱\n很多的设备的驱动程序可以自定义自己的一组ioctl\n/dev/fd\n这个目录的目录项时0,1,2，这些等效于/dev/stdin,/dev/stdout,/dev/stderr，打开/dev/fd/n等效于复制描述符\n文件共享 数据结构 记录表：每个进程在进程表中都有一个记录项，记录项中包含一个文件描述符\na. 文件描述标志（close_no_exec）\nb. 指向一个文件表项的指针\n内核为所有的打开文件都维持一张文件表\na. 文件状态标志（r,w,a,async）\nb. 当前文件偏移量\nc. 指向该文件v节点的指针\n每个打开文件或设备都有一个v节点结构\n原子操作 追加，在打开文件时设置O_APPEND标志，使得内核在每次写操作之前，都会将文件的当前偏移量设置到文件尾端处\npwrite()/pread(int fd,void *buf,size_t nbytes,off_t offset)相当于调用lseek后调用read\n调用pread时，无法中断其定位和读操作 不更新当前文件的偏移量 dup()/dup2(int fd,int fd2)复制文件描述符，相当于调用了close(fd2),fcntl(fd,F_DUPFD,fd2)\n延迟写：数据-》缓冲区-》queue-》disk 为了保证实际文件系统与缓冲区中内容的一致性，Unix系统提供了sync，fsync，fdatasync\nfsync(int fd):只对fd起作用，并且会更新文件的属性，并且等待写操作结束才返回 fdatasync(int fd)：和fsync类似，但是只影响文件的数据部分，不更新文件的数据部分 void sync(void)：将修改过的快缓冲区排入写队列，马上返回，并不等待实际写磁盘操作结束 fchtl(int fd,int cmd) 复制一个已有的文件描述符 获取/设置文件描述符标志 获取/设置文件状态标志 获取/设置异步IO所有权 获取/设置记录锁 文件中的空洞 普通文件会包含空洞，是由于所设置的偏移量超过了文件的尾端，并写入了某些数据后造成的\nls -l file:可以查看文件的大小 文件和目录 stat函数 stat(pathname,buf):返回与此命名文件有关的信息结构\nfstat(fd,buf)：获得已在描述符fd上打开文件的信息结构\nlstat(pathname,buf)：当命名文件是一个是一个符号链接时，返回链接文件的有关信息，而不是由该符号链接引用的文件的信息\nfstatat(fd,pathname,buf,flag)为一个相对于当前打开目录(fd指示)的路径名返回文件统计信息\n文件类型：stat结构的st_mode 普通文件：普通文件内容的解释是由处理该文件的应用程序进行 二进制可执行文件除外，遵循一种标准化的格式 目录文件：包含了其他文件的名字以及指向这些文件信息的指针 对一目录文件具有读权限的任一进程都可以读该目录的内容 只有内核可以直接写目录文件 进程只有通过特定的函数才能更改目录 块特殊文件（block）：提供对设备带缓冲的，每次访问以固定长度为单位进行 字符特殊文件（character）;提供对设备不带缓冲的访问 系统中的设备要么是字符特殊文件，要么是块特殊文件 FIFO:用于进程之间的通信，也叫管道 套接字：用于进程间的网络通信 符号链接:指向另一个文件 消息队列：进程间通信对象(IPC) 信号量:进程间通信对象(IPC) 共享存储对象:进程间通信对象(IPC) 用户id和组id 实际用户ID实际组ID 我们实际上是谁 有效组ID有效组ID附属组ID 用于文件访问权限的检查 保存的设置用户ID保存的设置组ID 由exec函数保存 每个文件都有一个所有者和组所有者，所有者由stat结构中的st_uid指定，组所有者则由st_gid指定\n文件的访问权限 为了在一个目录中创建一个新文件，必须对改目录具有写权限和执行权限 为了在open()函数中对一个文件指定O_TRUNC标志，必须对该文件具有写权限 为了删除以恶搞现有的文件，必须对包含该文件的目录具有写权限和执行权限，对该文件本身不需要读和写权限 如果用7个exec函数中的任意一个执行某个文件，都必须对该文件具有执行权限，该文件还必须是一个普通文件 在使用open和creat创建一个文件时，新文件的用户ID设置为进程的有效用户ID 权限测试 当open函数打开一个文件时，内核以进程的有效ID和有效组ID为基础执行其访问权限测试。\naccess(pathname,mode)\nfaccessat(fd,pathname,mode,flag),计算相对于打开目录(fd指示)的pathname\nmode: R_OK,W_OK,X_OK\n权限 umask(mode_t cmask) 000 任何用户可以读文件 002 阻止其他用户写入文件 027 阻止同组成员写入你的文件，以及其他用户的rwx权限 chmod(pathname,mode)更改指定文件的权限 fchmod(fd,mode)针对打开的文件进行操作 fchmodat(fd,pathname,made,flag)，fd为AT_FDCWD时和chmod一致，flag改变fchmodat的行为 chmod函数更新的是i节点最近一次被更改的时间，ls -l 列出来的是文件最后被修改的时间 fchown,fchownat,lchown,chown(pathname,owner,group)可用于更改文件的用户ID和组ID 文件和目录处理 truncate/ftruncate(fd,off_t length);截断函数，将一个现有的文件长度截断为length，如果之前该文件以前的长度大于length，则langth、以外的数据就不能再访问。如果以前的长度小于length，文件长度将增加。 link/linkat(efd,existingpath,nfd,*newpath,flag),创建newpath，引用existingpath，如果newpath已经存在，则返回出错。 renameat/rename(oldname,newname);如果oldname是指文件，为此文件重命名。link文件的话，重命名此文件，不是链接的文件 futimens,utimes,utimensat(fd,path,times,flag)修改一个文件的访问和修改时间 mkdirat，mkdir(fd,pathname,mode):这两个函数创建一个新的空目录，所指定的文件的访问权限mode由进程的文件模式创建屏蔽字修改 rmdir(const char*pathname)删除一个空目录，空目录是只包含.和..两项的目录 对某目录具有访问权限的任意用户都可以读该目录，但是，为了防止文件系统产生混乱，只有内核才能写目录。一个目录的的写权限位和执行权限决定了在该目录能否创建新文件以及删除文件，但是不代表可以写目录 DIR *fdopendir(int fd)表示可以把打开文件描述符转换成目录处理函数需要的DIR结构 标准I/O库 标准输入流，标准输出流，标准错误流。一个进程预定义了3个流，并且可以自动的被进程所使用\n缓冲\n全缓冲：填满标准I/O缓冲区后才进行实际I/O操作，一般用于驻留在磁盘上的文件\n在一个流上第一次执行I/O操作时，I/O函数通常调用malloc函数获得需要的缓冲区\nflush:冲洗，标准I/O缓冲区的写操作，当填满一个缓冲区时，I/O例程会自动的冲洗\n行缓冲：当在输入和输出中遇到换行符时，标准I/O执行I/O操作，当流涉及一个终端时，通常使用行缓冲\n限制:缓冲区的长度固定的，所以有时没有遇到换行符，也会进行I/O操作\n不带缓冲：标准错误流通常不带缓冲，使得他们的错误可以尽快显示出来\nsetbuf(fp,buf)打开或或关闭缓冲机制，开启后一般为全缓冲\nsetvbuf(fp,buf,mode,size)通过设置mode精确的说明所需的缓冲类型\nfflush(fp)，强制冲洗一个流\nFILE *fopen(pathname,type,)打开路径名为pathname的一个文件\nFILE *freopen(pathname,type,fp)重定向流，在一个指定的流上打开文件，若流已经打开，则先关闭\nfdopen(fd,type)获取一个已有的文件描述符，并使一个标准I/O流与该描述符相结合，此函数常用于由管道创建和网络通信函数返回的描述符\n当以读和写类型打开一个文件时，如果中间没有fflush，fseek，fsetpos或rewind，那么在输出的后面不能直接跟随输入\n以读和写打开一个文件时，当中间没有fseek,fsetpos,rewind,或者一个输入操作没有到达文件尾端，则在输入操作之后不能直接跟随输出\n读和写流\n每次一个字符的I/O，getc,fgetc,getchar一次读或者写一个字符，如果流是带缓冲的，则标准I/O函数处理所有的缓冲 每次一行的I/O，fgets,fputs,每行以一个换行符终止，当调用fgets时，应说明能处理的最大行 direct I/O，fread,fwrite每次I/O操作读或写某种数量的对象，每个对象具有指定的长度，常用于读写二进制文件 压送回流，ungetc(int c,FILE fp),压送回流的字符又可以 ","date":"2019-02-21","img":"","permalink":"/posts/note/c%E8%AF%AD%E8%A8%80%E5%B0%8F%E8%AE%A1/","series":null,"tags":["C"],"title":"C语言小计"},{"categories":["notes"],"content":"BIO (block io) 同步阻塞IO\n线程池:伪异步IO,实际上也是同步阻塞IO\nNIO(同步非阻塞)\nselector会主动轮询,与客户端建立通信(channel)\n每一个server会有一个selector\nAIO(异步非阻塞)\n当客户端通知我(回调),我再去连接\n单线程模式:所有的IO操作都由同一个NIO线程处理\n主线程组,从单线程模型\n主从线程组模型,具有一个主线程族和从线程组,主线程组去建立channel,从线程组会去进行处理\n","date":"2019-02-21","img":"","permalink":"/posts/note/io%E6%A8%A1%E5%9E%8B%E5%B0%8F%E8%AE%B0/","series":["notes"],"tags":["NIO"],"title":"IO模型小记"},{"categories":["notes"],"content":"java跨平台 实现java跨平台只需要在相应的平台安装对应的虚拟机，我们就可以使用统一的接口进行开发。\njava通过不同的系统，不同的版本，不同的位数，来屏蔽不同的系统指令集的差异，对外提供统一的接口\njava中int数据占几个字节 java中有几种基本数据类型？8种\n基本类型：byte 二进制位数：8 包装类：java.lang.Byte 最小值：Byte.MIN_VALUE=-128 最大值：Byte.MAX_VALUE=127 基本类型：short 二进制位数：16 包装类：java.lang.Short 最小值：Short.MIN_VALUE=-32768 最大值：Short.MAX_VALUE=32767 基本类型：int 二进制位数：32 包装类：java.lang.Integer 最小值：Integer.MIN_VALUE=-2147483648 最大值：Integer.MAX_VALUE=2147483647 基本类型：long 二进制位数：64 包装类：java.lang.Long 最小值：Long.MIN_VALUE=-9223372036854775808 最大值：Long.MAX_VALUE=9223372036854775807 基本类型：float 二进制位数：32 包装类：java.lang.Float 最小值：Float.MIN_VALUE=1.4E-45 最大值：Float.MAX_VALUE=3.4028235E38 基本类型：double 二进制位数：64 包装类：java.lang.Double 最小值：Double.MIN_VALUE=4.9E-324 最大值：Double.MAX_VALUE=1.7976931348623157E308 基本类型：char 二进制位数：16 包装类：java.lang.Character 最小值：Character.MIN_VALUE=0 最大值：Character.MAX_VALUE=65535 面向对象的特征 封装 将对象封装成一个高度自洽相对封闭的个体，对象状态(属性)由这个对象自己的行为(方法)来读取和改变\n抽象 抽象就是找出一些事物的相似和共性之处，然后把他们抽象为类\n继承 把这个已经存在的类所定义的内容作为自己的内容，并可以加入若干新的内容，或修改原来的方法使之更适合特殊的需要\n多态 指程序中定义的引用变量所指向的具体类型和通过该引用变量发出的方法调用只有在程序运行时才确定\n","date":"2019-02-21","img":"","permalink":"/posts/note/java%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AE%B0/","series":["notes"],"tags":["notes"],"title":"java面试笔记"},{"categories":["notes"],"content":"pattern:斑图\n是一种构型，是一种系统，不关心是使用的什么物质去实现\n把各种方法论抽取出来\ncomplexity:复杂性科学\n按照复杂性思维去设计虚拟世界\n仿真 层次 初始条件的影响 时间之箭？ 因果箭头 movie：黑客帝国，盗梦空间，时间之箭，超体，蝴蝶效应，前目的地\nbook：失控\n我们需要对抗的是复杂系统\n根据用户去决定复杂系统\n设计的系统？ 涌现的系统？\n区块链：ai，算法管理社会\n奇点，技术奇点\n","date":"2019-02-21","img":"","permalink":"/posts/note/%E5%A4%8D%E6%9D%82%E7%B3%BB%E7%BB%9F/","series":["notes"],"tags":["notes"],"title":"pattern:斑图"},{"categories":["Python"],"content":"TCP的三次握手和四次挥手\n三次握手: 为什么需要三次握手? 客户端:我可以发东西给你(确保客户端的发送能力) 服务器:我可以收到,你能收到么?(确保服务器的接受和发送) 客户端:我能收到!(确保能收到)\n连接建立!\n如果是四次握手? 没必要啊,第三次已经确认可以收到消息了\n如果是两次握手? 当网络阻塞时,客户端会发送两次,第一次请求到达服务器的时间慢于第二次 如果当时通信结束,服务器又收到了第一次阻塞的消息,如果是两次握手,就会分配资源 然而客户端已经完成了通信,不需要再连接了,会造成资源的浪费和安全隐患\n四次挥手: 客户端:我说完了,我想停止发送请求了 服务器:我知道你要停止发送了,我会停止接受消息 ( 服务器停止接受消息,但是可能还有很多待发送的消息\n客户端:收到服务器的确认信息,于是默不作声,等待服务器发送完他的消息\n) 服务器:我的东西全发完啦!,我想要停止发送消息啦! 客户端:我知道你也要停止发送了,我也要停止接收消息(实际上还等了两个最大周期才真正停止接收消息) ( 服务器:收到了客户端的确认消息,于是停止发送消息 )\n关于tcp的博客 使用tcp和udp让进程之间进行通信\nip地址：用來標記網絡上的主機 動態端口：1024-65535的端口，用完就回收\ntcp socket client的基本流程\nimport socket ##創建socket s = socket.socket(socket.af_inet,socket.sock_stream) ##使用 ipaddr = (\u0026#34;ip\u0026#34;,port)#服务器的ip addr s.connect(ipaddr)#连接服务器 ### 发送数据 send_msg = \u0026#34;sasa\u0026#34; s.send(send_msg.encode(\u0026#34;utf-8\u0026#34;)) ### 接受数据 recvData = s.rec(1024)#一次接收的字符数 print(\u0026#34;recved msg:\u0026#34;,recvData.decode(\u0026#34;\u0026#34;utf-8)) ##關閉 s.close() tcp server的基本过程\n# socket创建套接字 tcp = socket.socket(socket.AF_INET,socket.SOCK_STREAM) # 绑定端口 tcp.bind((\u0026#34;127.1\u0026#34;,7788)) # 设置为被动监听 tcp.listen(128) while True: #等待客户端的连接 #tcp套接字,现在用来被动接听 # accept阻塞等待链接 new_client_socket,client_addr = tcp.accept()#阻塞等待一个客户端进行conect,返回元组: 新的套接字,(客户端的ip,端口) #有客户端connect后,阻塞解除,返回connect的一个客户端的addr,以及已经和客户端完成连接的套接字,接下来的收发都是用这个新的socket while True: # 处理请求,先收,再发,因此,这里会阻塞等待这个new_client_socket接收到消息 recv_data = new_client_socket.recv(1024) print(recv_data) #当recv解阻塞时,有两种情况,1.客户端发送了消息 ;2.客户端调用了close() #通过判断recv_data是否为空,那么判断出客户端断开了链接 if recv_data: #收到消息后,我们返回一下,非必要的 new_client_socket.send(\u0026#34;服务器返回的消息\u0026#34;.encode(\u0026#39;utf-8\u0026#39;)) else: break new_client_socket.close() tcp.close() 創建一個udp socket\nimport socket ##創建 send_data = input(\u0026#34;input:\u0026#34;) s = socket.socket(socket.AF_INET,socket.SOCK_DGRAM) #bind a port,接受方可以不绑定 s.bind(\u0026#34;\u0026#34;,7890) ##使用 #s.sendto(b\u0026#34;test\u0026#34;,(\u0026#34;127.1\u0026#34;,8888))#需要使用二进制第二个参数是元组 s.sendto(send_data.encode(\u0026#34;utf-8\u0026#34;),(\u0026#34;127.1\u0026#34;,8888))#需要编码 s.close()#关闭 socket.socket(AddressFamily,Type) AddressFamily:協議族 Type:套接字類型\n绑定端口接收数据\nimport socket def main(): #创建套接字 udp = socket.socket(socket.AF_INET,socket.SOCK_DGRAM) #绑定端口 localaddr = (\u0026#34;\u0026#34;,7788) udp.bind(localaddr) #接收数据 recv_data = udp.recvfrom(1024)#可以接收的最大字节数 #打印接受的数据 #会接收到一个元组二进制流,发送方地址 msg = recv_data[0] sendaddr = recv_data[1] print(\u0026#34;%s:%s\u0026#34;%str(sendaddr),msg.decode(\u0026#34;utf-8\u0026#34;))#需要解码 #关闭套接字 udp.close() if __name__ == \u0026#34;__main__\u0026#34;: main() 一个套接字可以同时接收全双工的\n一个攻击 扫描端口向缓冲区发送数据\n使用tcp进行文件下载\nclient:\nimport socket def main(): #1.创建套接字 tcp_socket = socket.socket(socket.AF_INET,socket.SOCK_STREAM) #2.获取服务器的ip port dest_ip = input(\u0026#34;ip:\u0026#34;) dest_port = input(\u0026#34;port:\u0026#34;) #3.连接服务器 tcp_socket.connect((dest_ip,dest_port)) #4.获取下载的名字 download_file_name = input(\u0026#34;input the file name\u0026#34;) #5.将名字发送到服务器 tcp_socket.send(download_file_name.encode(\u0026#34;utf-8\u0026#34;)) #6.接受文件中的数据 recv_data = tcp_socket.recv(1024)#1k if recv_data: #7.保存文件中的数据 with open(\u0026#34;[new]\u0026#34;+download_file_name,\u0026#34;wb\u0026#34;) as f: f.write(recv_data) #8.关闭套接字 tcp_socket.close() if __name__ == \u0026#34;__main__\u0026#34;: main() server:\nimport socket def send_file2client(new_client_socket,client_addr): #1.接受客户端需要下载的文件名 file_name = new_client_socket.recv(1024).decode(\u0026#39;utf-8\u0026#39;) print(\u0026#34;客户端下载的文件是:%s\u0026#34;%(str(client_addr),file_name)) #2.打开这个文件,读取数据 file_content = None try: f = open(file_name,\u0026#34;rb\u0026#34;) file_content = f.read() f.close() except Exception as ret: print(\u0026#34;没有要下载的文件(%s)\u0026#34;%file_name) #3.发送文件的数据给客户端 if file_content: new_client_socket.send(file_conect) def main(): # socket创建套接字 tcp_socket = socket.socket(socket.AF_INET,socket.SOCK_STREAM) # 绑定端口 tcp_socket .bind((\u0026#34;127.1\u0026#34;,7788)) # 设置为被动监听 tcp_socket .listen(128) while True: # accept阻塞等待链接 new_client_socket,client_addr = tcp_socket .accept()#阻塞等待一个客户端进行conect,返回元组: 新的套接字,(客户端的ip,端口) # 调用函数,发送文件 send_file2client(new_client_socket,client_addr) # 关闭套接字 new_client_socket.close() tcp_socket .close() if __name__ == \u0026#34;__main__\u0026#34;: main() ","date":"2019-02-21","img":"","permalink":"/posts/python/python-socket/","series":null,"tags":["Python","TCP","socket"],"title":"python socket编程"},{"categories":["notes"],"content":"rust学习 所有权\nRust 的核心功能（之一）是 所有权（ownership）。虽然该功能很容易解释，但它对语言的其他部分有着深刻的影响。\n所有运行的程序都必须管理其使用计算机内存的方式。一些语言中具有垃圾回收机制，在程序运行时不断地寻找不再使用的内存；在另一些语言中，程序员必须亲自分配和释放内存。Rust 则选择了第三种方式：通过所有权系统管理内存，编译器在编译时会根据一系列的规则进行检查。在运行时，所有权系统的任何功能都不会减慢程序。（其他的GC会不断运行来寻找垃圾）\n因为所有权对很多程序员来说都是一个新概念，需要一些时间来适应。好消息是随着你对 Rust 和所有权系统的规则越来越有经验，你就越能自然地编写出安全和高效的代码。持之以恒！\n当你理解了所有权，你将有一个坚实的基础来理解那些使 Rust 独特的功能。在本章中，你将通过完成一些示例来学习所有权，这些示例基于一个常用的数据结构：字符串。\n所有权（系统）是 Rust 最独特的功能，其令 Rust 无需垃圾回收（garbage collector）即可保障内存安全。因此，理解 Rust 中所有权如何工作是十分重要的。\n栈（Stack）与堆（Heap） 在很多语言中，你并不需要经常考虑到栈与堆。不过在像 Rust 这样的系统编程语言中，值是位于栈上还是堆上在更大程度上影响了语言的行为以及为何必须做出这样的抉择。我们会在本章的稍后部分描述所有权与栈和堆相关的内容，所以这里只是一个用来预热的简要解释。 栈和堆都是代码在运行时可供使用的内存，但是它们的结构不同。栈以放入值的顺序存储值并以相反顺序取出值。这也被称作 后进先出（last in, first out）。想象一下一叠盘子：当增加更多盘子时，把它们放在盘子堆的顶部，当需要盘子时，也从顶部拿走。不能从中间也不能从底部增加或拿走盘子！增加数据叫做 进栈（pushing onto the stack），而移出数据叫做 出栈（popping off the stack）。 栈的操作是十分快速的，这主要是得益于它存取数据的方式：因为数据存取的位置总是在栈顶而不需要寻找一个位置存放或读取数据。另一个让操作栈快速的属性是，栈中的所有数据都必须占用已知且固定的大小。 在编译时大小未知或大小可能变化的数据，要改为存储在堆上。堆是缺乏组织的：当向堆放入数据时，你要请求一定大小的空间。操作系统在堆的某处找到一块足够大的空位，把它标记为已使用，并返回一个表示该位置地址的 指针（pointer）。这个过程称作 在堆上分配内存（allocating on the heap），有时简称为 “分配”（allocating）。将数据推入栈中并不被认为是分配。因为指针的大小是已知并且固定的，你可以将指针存储在栈上，不过当需要实际数据时，必须访问指针。 想象一下去餐馆就座吃饭。当进入时，你说明有几个人，餐馆员工会找到一个够大的空桌子并领你们过去。如果有人来迟了，他们也可以通过询问来找到你们坐在哪。 访问堆上的数据比访问栈上的数据慢，因为必须通过指针来访问。现代处理器在内存中跳转越少就越快（缓存）。继续类比，假设有一个服务员在餐厅里处理多个桌子的点菜。在一个桌子报完所有菜后再移动到下一个桌子是最有效率的。从桌子 A 听一个菜，接着桌子 B 听一个菜，然后再桌子 A，然后再桌子 B 这样的流程会更加缓慢。出于同样原因，处理器在处理的数据彼此较近的时候（比如在栈上）比较远的时候（比如可能在堆上）能更好的工作。在堆上分配大量的空间也可能消耗时间。\n栈： 执行期间编译器自动分配，编译器用它实现函数调用，调用函数时，栈增长，函数返回时，栈收缩。局部变量、函数参数、返回数据、返回地址等放在栈中\n栈的特点 内存分配取决于编译器，用户栈在程序运行期间可以动态的扩展和收缩。 . 和数据结构中的“栈”本质上是不一样的，但是操作方式类似于栈。 数据从栈中的进出满足“后进先出”的规律。 . 栈向低地址方向增长，esp（栈指针）指向栈顶元素。 堆： ​ 动态储存器分配器维护着的一个进程的虚拟存储器区域。一般由程序员分配释放（堆在操作系统对进程初始化的时候分配），若程序员不释放，程序结束时可能由OS回收，每个进程，内核都维护着一个变量brk指向堆顶。\n堆的特点 内存分配取决于程序员，C/C++可以手动释放该片内存。 在所有权系统中，会自动完成清理堆的活动 . 和数据结构的”堆“完全两回事，没有半点关系，在这里堆的结构更像链表。 所有的对象，包括数组的对象都存在堆上。 . 堆内存被所有的线程共享。 引用类型总是放在堆中。 堆向高地址方向增长，内核都维护的变量brk指向堆顶。 注意：值类型和指针总是放在他们被声明的地方（复杂） 当值类型的数据在方法体内被声明时，它们都应该放在栈上。 如果一个只类型被声明在方法体外且存在于一个引用类型中，那么它将会被堆里的引用类型所取代。\n全局区/静态区： 全局变量、静态变量、常量的存储区域，程序终止时系统释放。\n文字常量区： 存放常量字符串，程序结束后由系统释放。\n程序代码区： 存放函数体（类成员函数和全局函数）的二进制代码。\n栈和堆的区别： 栈内存存储的的是局部变量，堆内存存储的是实体。 . 栈内存的更新的速度会更快些（局部变量），堆内存的更新速度相对更慢。 栈内存的访问直接从地址读取数据到寄存器，然后放到目标地址，而堆内存的访问更麻烦，先将分配的地址放到寄存器，在读取地址的值，最后再放到目标文件中，开销更大。 . 栈内存是连续的空间，堆内存一般情况不是连续的，频繁地开辟空间，释放空间容易产生内存碎片（外碎片）。 栈和堆的联系： 堆中对象是直接由栈中的句柄（引用）管理者，所以堆负责产生真实对象，栈负责管理对象。 当你的代码调用一个函数时，传递给函数的值（包括可能指向堆上数据的指针）和函数的局部变量被压入栈中。当函数结束时，这些值被移出栈。 跟踪哪部分代码正在使用堆上的哪些数据，最大限度的减少堆上的重复数据的数量，以及清理堆上不再使用的数据确保不会耗尽空间，这些问题正是所有权系统要处理的。一旦理解了所有权，你就不需要经常考虑栈和堆了，不过明白了所有权的存在就是为了管理堆数据，能够帮助解释为什么所有权要以这种方式工作。\n所有权规则 Rust 中的每一个值都有一个被称为其 所有者（owner）的变量。 值有且只有一个所有者。 当所有者（变量）离开作用域，这个值将被丢弃。 内存与分配 就字符串字面值来说，我们在编译时就知道其内容，所以文本被直接硬编码进最终的可执行文件中。这使得字符串字面值快速且高效。不过这些特性都只得益于字符串字面值的不可变性。不幸的是，我们不能为了每一个在编译时大小未知的文本而将一块内存放入二进制文件中，并且它的大小还可能随着程序运行而改变。\n对于 String 类型，为了支持一个可变，可增长的文本片段，需要在堆上分配一块在编译时未知大小的内存来存放内容。这意味着：\n必须在运行时向操作系统请求内存。 需要一个当我们处理完 String 时将内存返回给操作系统的方法。 第一部分由我们完成：当调用 String::from 时，它的实现 (implementation) 请求其所需的内存。这在编程语言中是非常通用的。\n然而，第二部分实现起来就各有区别了。在有 垃圾回收（garbage collector，GC）的语言中， GC 记录并清除不再使用的内存，而我们并不需要关心它。没有 GC 的话，识别出不再使用的内存并调用代码显式释放就是我们的责任了，跟请求内存的时候一样。从历史的角度上说正确处理内存回收曾经是一个困难的编程问题。如果忘记回收了会浪费内存。如果过早回收了，将会出现无效变量。如果重复回收，这也是个 bug。我们需要精确的为一个 allocate 配对一个 free。\nRust 采取了一个不同的策略：内存在拥有它的变量离开作用域后就被自动释放。\n具体的细节 两个数据指针指向了同一位置。这就有了一个问题：当 s2 和 s1 离开作用域，他们都会尝试释放相同的内存。这是一个叫做 二次释放（double free）的错误，也是之前提到过的内存安全性 bug 之一。两次释放（相同）内存会导致内存污染，它可能会导致潜在的安全漏洞。\n为了确保内存安全，这种场景下 Rust 的处理有另一个细节值得注意。与其尝试拷贝被分配的内存，Rust 则认为 s1 不再有效，因此 Rust 不需要在 s1 离开作用域后清理任何东西。\n因为只有 s2 是有效的，当其离开作用域，它就释放自己的内存，完毕。\n另外，这里还隐含了一个设计选择：Rust 永远也不会自动创建数据的 “深拷贝”。因此，任何 自动 的复制可以被认为对运行时性能影响较小。\n克隆，用于深拷贝 如果我们 确实 需要深度复制 String 中堆上的数据，而不仅仅是栈上的数据，可以使用一个叫做 clone 的通用函数。\nlet s1 = String::from(\u0026#34;hello\u0026#34;); let s2 = s1.clone(); println!(\u0026#34;s1 = {}, s2 = {}\u0026#34;, s1, s2); 只在栈上的数据：拷贝 这里还有一个没有提到的小窍门。这些代码使用了整型并且是有效的，他们是示例 4-2 中的一部分：\nlet x = 5; let y = x; println!(\u0026#34;x = {}, y = {}\u0026#34;, x, y); 但这段代码似乎与我们刚刚学到的内容相矛盾：没有调用 clone，不过 x 依然有效且没有被移动到 y 中。\n原因是像整型这样的在编译时已知大小的类型被整个存储在栈上，所以拷贝其实际的值是快速的。这意味着没有理由在创建变量 y 后使 x 无效。换句话说，这里没有深浅拷贝的区别.\nCopy trait Rust 有一个叫做 Copy trait 的特殊注解，可以用在类似整型这样的存储在栈上的类型上。如果一个类型拥有 Copy trait，一个旧的变量在将其赋值给其他变量后仍然可用。Rust 不允许自身或其任何部分实现了 Drop trait 的类型使用 Copy trait,比如string。如果我们对其值离开作用域时需要特殊处理的类型使用 Copy 注解，将会出现一个编译时错误。要学习如何为你的类型增加 Copy 注解，请阅读附录 C 中的 “可派生的 trait”。\n那么什么类型是 Copy 的呢？可以查看给定类型的文档来确认，不过作为一个通用的规则，任何简单标量值的组合可以是 Copy 的，不需要分配内存或某种形式资源的类型是 Copy 的。如下是一些 Copy 的类型：\n所有整数类型，比如 u32。 布尔类型，bool，它的值是 true 和 false。 所有浮点数类型，比如 f64。 字符类型，char。 元组，当且仅当其包含的类型也都是 Copy 的时候。比如，(i32, i32) 是 Copy 的，但 (i32, String) 就不是。 悬垂引用（Dangling References） 在具有指针的语言中，很容易通过释放内存时保留指向它的指针而错误地生成一个 悬垂指针（dangling pointer），所谓悬垂指针是其指向的内存可能已经被分配给其它持有者。相比之下，在 Rust 中编译器确保引用永远也不会变成悬垂状态：当你拥有一些数据的引用，编译器确保数据不会在其引用之前离开作用域。\n字符串字面值就是 slice let s = \u0026#34;Hello, world!\u0026#34;; 这里 s 的类型是 \u0026amp;str：它是一个指向二进制程序特定位置的 slice。这也就是为什么字符串字面值是不可变的；\u0026amp;str 是一个不可变引用。\nstructure 定义结构体，需要使用 struct 关键字并为整个结构体提供一个名字。结构体的名字需要描述它所组合的数据的意义。接着，在大括号中，定义每一部分数据的名字和类型，我们称为 字段（field）。\n使用了自身拥有所有权的 String 类型而不是 \u0026amp;str字符串 slice 类型。这是一个有意而为之的选择，因为我们想要这个结构体拥有它所有的数据，为此只要整个结构体是有效的话其数据也是有效的。可以使结构体存储被其他对象拥有的数据的引用，不过这么做的话需要用上 生命周期（lifetimes）\n使用没有命名字段的元组结构体来创建不同的类型 也可以定义与元组（在第三章讨论过）类似的结构体，称为 元组结构体（tuple structs）。元组结构体有着结构体名称提供的含义，但没有具体的字段名，只有字段的类型。当你想给整个元组取一个名字，并使元组成为与其他元组不同的类型时，元组结构体是很有用的，这时像常规结构体那样为每个字段命名就显得多余和形式化了。定义元组结构体，以 struct 关键字和结构体名开头并后跟元组中的类型。\n没有任何字段的类单元结构体 我们也可以定义一个没有任何字段的结构体，它们被称为 类单元结构体（unit-like structs）因为它们类似于 ()，即 unit 类型。类单元结构体常常在你想要在某个类型上实现 trait 但不需要在类型中存储数据的时候发挥作用。\nDebug 是一个 trait，它允许我们以一种对开发者有帮助的方式打印结构体，以便当我们调试代码时能看到它的值。\n枚举 枚举是一个很多语言都有的功能，不过不同语言中其功能各不相同。Rust 的枚举与Haskell中的 代数数据类型（algebraic data types）最为相似。\n","date":"2019-02-21","img":"","permalink":"/posts/note/rust%E5%AD%A6%E4%B9%A0/","series":["notes"],"tags":["notes"],"title":"rust学习"},{"categories":["notes"],"content":"Scala 入门之随便写写\nimport scala.util.control._ object HelloWorld{ def hello(name:String) = { s\u0026#34;Hello ,${name}\u0026#34; } def add(x: Int,y:Int) = x+y def main(args:Array[String]):Unit = { /** * 违反引用透明的例子: * 怎么样获得引用透明性:{ * 需要具有不变性,即为了获得引用透明性,任何值都不能改变 * } */ var x = new StringBuilder(\u0026#34;Hello \u0026#34;); println(x); var y = x.append(\u0026#34; world\u0026#34;); println(y); var z = x.append(\u0026#34; world\u0026#34;); println(z); /** * 递归函数: * 使用递归实现循环 * 尾递归函数 */ /** * 变量: * val 定义immutable variable:常量 * var 定义mutable variable:变量 * lazy val:惰性求值常量 * 可以再定义时不指定变量的类型,Scala会自动进行类型推导 */ println(hello(\u0026#34;Euraxluo\u0026#34;)) println(add(1,2)) /** * for循环 */ val list = List(\u0026#34;Euraxluo\u0026#34;,\u0026#34;xiaoli\u0026#34;,\u0026#34;xiaoxiong\u0026#34;) //循环1 for ( s \u0026lt;- list//generator )println(s) println(\u0026#34;\u0026#34;) //循环2 for { s\u0026lt;-list if (s.length\u0026gt;6)//filter }println(s) println(\u0026#34;\u0026#34;) //循环3 val res_for = for { s\u0026lt;- list s1 = s.toUpperCase()//变量绑定 if(s1 != \u0026#34;\u0026#34;) }yield (s1)//将s1放在新的collection中 println(res_for) println(\u0026#34;\u0026#34;) /** * 无限循环 */ // var a = 10 // while (true){ // println(s\u0026#34;a的值:${a}\u0026#34;) // } /** * 中断循环 */ var loop = new Breaks; val numl = List(0,1,2,3,6,5,6,7) loop.breakable{ for(a\u0026lt;-numl){ println(a) if(a\u0026gt;=6){ loop.break() } } } println(\u0026#34;\u0026#34;) /** * 嵌套循环 */ val outer = new Breaks; val inner = new Breaks; outer.breakable{ for (a\u0026lt;-numl){ inner.breakable{ for (b\u0026lt;-numl){//次数 println(a*a) if (a*a \u0026gt; 36){ inner.break; } } } } } println(\u0026#34;\u0026#34;) /** * try{}catch{}finally{} */ var res_try = try { Integer.parseInt(\u0026#34;sa\u0026#34;) }catch { case _ =\u0026gt; 2222222 }finally { println(\u0026#34;finally\u0026#34;) } println(res_try) println(\u0026#34;\u0026#34;) /** * match */ val code = 600 var res_match = code match { case 200 =\u0026gt; \u0026#34;OK\u0026#34; case 404 =\u0026gt; \u0026#34;Not Found\u0026#34; case 400 =\u0026gt; \u0026#34;Bad Request\u0026#34; case _ =\u0026gt; \u0026#34;Server Error\u0026#34; } println(res_match) println(\u0026#34;\u0026#34;) /** * 重要概念 * 表达式求值策略:严格求值与非严格求值 * Scala中:Call By Value vs. Call By Name * 惰性求值(lazy Evluation): * 当定义表达式时,不会立即求值,而是当这个表达式第一次被调用时才会求值 */ def bar(x:Int,y: =\u0026gt; Int) = x//Call By Value , Call By Name def Loop():Int= {println(\u0026#34;...\u0026#34;);Loop} //无限循环 // println(bar(Loop,1))//将Loop传给call by value ,函数体中即便没有使用到,也去运行这个无限循环 println(bar(1,Loop))//将Loop传给call by name ,函数体中没有使用到,因此不会去运行这个无限循环 /** * 柯里化 * @param a * @param b * @return */ //def curriedAdd(a:Int,b:Int) = a+b def curriedAdd(a:Int)(b:Int) = a+b println(curriedAdd(2)(2)) val addOne = curriedAdd(1)_//Int=\u0026gt;Int println(addOne(2)) println(\u0026#34;\u0026#34;) /** * 递归例子 * n! */ def factorial(n:Int):Int = if (n\u0026lt;=0) 1 else n*factorial(n-1) println(factorial(5)) println(\u0026#34;\u0026#34;) /** * 尾递归函数 * 尾递归函数中所有递归形式的调用都出现在函数的末尾 * 当编译器检测到一个函数调用是尾递归的时候, * 他就会覆盖当前的栈,而不是在栈中创建一个新的 * * 优化:把之前的递归调用的结果保存起来,而不是用栈去做这件事 */ @annotation.tailrec //开启尾递归调用优化 def factorial_tailrec(n:Int,m:Int):Int = if (n\u0026lt;=0) m else factorial_tailrec(n-1,m*n) println(factorial_tailrec(5,1)) println(\u0026#34;\u0026#34;) /** * 求f(x){x=a...b}的和 * @param f :一个func * @param a :x=a * @param b :x=b * @return :返回和 */ def sum (f:Int=\u0026gt;Int)(a:Int)(b:Int):Int = { //定义一个循环 @annotation.tailrec def loop(n: Int,acc:Int):Int = { if (n\u0026gt;b) acc//如果当前N大于b,返回相加结果 else loop(n+1,acc+f(n)) //尾调用优化 } loop(a,0) } println(sum(x=\u0026gt;x)(0)(100)) println(sum(x=\u0026gt;x*x)(0)(5)) val sumSquare = sum(x=\u0026gt;x*x)_ //定义一个函数,是平方的和,_通配a,b println(sumSquare(1)(5)) println(\u0026#34;\u0026#34;) /** * list相关操作 */ /** * 连接操作 */ val listB = List(5,6,7):::list //连接两个list for ( s \u0026lt;- listB//generator )println(s) println(\u0026#34;\u0026#34;) val listC = 6::list //连接一个对象和其他的对象(List/Object) //list是引用类型,6是值类型,因此listC的类型是List(Any) for ( s \u0026lt;- listC//generator )println(s) val listD = \u0026#34;7\u0026#34;::\u0026#34;8\u0026#34;::Nil for ( s \u0026lt;- listD//generator )println(s) println(\u0026#34;\u0026#34;) /** * head方法,获取第一个元素 */ println(listC.head) /** * tail方法,获取除了第一个元素以外的元素 */ println(listC.tail) /** * isEmpty:判断是否为空 * */ println(listC.isEmpty == Nil.isEmpty) /** * 自己的toString * @param l * @return */ def walkthru(l:List[Any]) :String = { if (l.isEmpty) \u0026#34;\u0026#34; else l.head.toString+\u0026#34; \u0026#34;+walkthru(l.tail) } println(walkthru(listC)) println(\u0026#34;\u0026#34;) /** * filter(func),如果func返回为true,保留此元素 */ val listE = List(1,2,3,4,5) // println(listE.filter(x=\u0026gt;x%2==1)) println(listE.filter(_%2==1)) /** * toList */ println(\u0026#34;Hello Scalar 666\u0026#34;.toList.filter(x=\u0026gt;Character.isDigit(x))) /** * takeWhile,获取元素,指导P返回为False */ println(\u0026#34;Hello Scalar 666\u0026#34;.toList.takeWhile(x =\u0026gt; !Character.isDigit(x))) /** * map */ println(\u0026#34;Hello Scalar 66\u0026#34;.toList.map(_.toUpper)) /** * flatMap */ val l1 = List(List(3,4),List(4,5,6)) println(l1) //map 返回值与原来的类型一致 println(l1.map(_.filter(_%2==0))) //会将多层的容器打平 println(l1.flatMap(_.filter(_%2==0))) println(\u0026#34;\u0026#34;) /** * reduce */ println(listE.reduce(_+_))//==reduceLeft println(listE.reduceLeft(_+_)) /** * foldLeft */ println(listE.fold(0)(_+_)) println(listE.fold(1)(_*_))//会根据U的值进行类型改变 /** * Range */ /** * to */ println((1 to 10).toList) /** * until */ println((1 until 10).toList) /** * stream is a lazy List */ val s1 = 1 #:: 2 #:: 3 #:: Stream.empty println(s1) val s2 = (1 to 1000000).toStream println(s2.tail) println(\u0026#34;\u0026#34;) /** * tuple */ /** * paire */ println((1,2)) println(1-\u0026gt;2) val t1 = (1,\u0026#34;Euraxluo\u0026#34;,21,\u0026#34;男\u0026#34;) println(\u0026#34;Euraxluo is :\u0026#34;+t1._4) println(\u0026#34;\u0026#34;) /** * * @param l:一个List * @return (List元素个数,List元素和,List元素平方和) */ def sumSq(l:List[Int]):(Int,Int,Int) = l.foldLeft((0,0,0))((t, v) =\u0026gt; (t._1 + 1, t._2 + v, t._3 + v * v)) println(sumSq(listE)) println(\u0026#34;\u0026#34;) /** * Map */ val map = Map(1-\u0026gt;\u0026#34;Euraxluo\u0026#34;,2-\u0026gt;\u0026#34;hehe\u0026#34;,4-\u0026gt;\u0026#34;sa\u0026#34;) println(map) println(map(4))//通过key获取value println(map.contains(3))//判断是否有这个key println(map.keys)//获取keys println(map.values)//获取values /** * +:添加一个k-v * 返回一个新Map */ println(map+(6-\u0026gt;\u0026#34;hehheheh\u0026#34;)) /** * -:根据key删除一个k-v * 返回一个新Map */ println(map - 1) /** * ++:添加多个 */ println( map ++ List(22-\u0026gt;\u0026#34;alice\u0026#34;,51-\u0026gt;\u0026#34;sas\u0026#34;)) /** * --:删除多个 */ println(map -- List(1,2)) println(\u0026#34;\u0026#34;) /** * 递归实现的快速排序 * @param l * @return */ def qSort(l:List[Int]):List[Int] = if (l.length \u0026lt; 2 ) l//如果List元素小于两个,返回其自身 else qSort(l.filter(_\u0026lt;l.head)) ++ //小于l.head的部分,然后加上剩下部分 l.filter(_==l.head) ++ //等于l.head的部分,加上大于l.head的部分 qSort(l.filter(_ \u0026gt; l.head))//大于l.head的部分 println(qSort(List(9,3,7,6,5,4,2,8,1))) } } //函数式编程的重要概念 //引用透明:对于相同的输入,总是得到相同的输出 //如果F(x)的参数x和函数体都是引用透明的,那么函数F是纯函数 ","date":"2019-02-21","img":"","permalink":"/posts/note/scala%E5%85%A5%E9%97%A8/","series":["notes"],"tags":["notes"],"title":"Scala入门"},{"categories":["notes"],"content":"SLAM 相机\n以一定的速率采集图像，形成视频 各类相机的区别 单目：无深度，需要其他手段估计 双目：通过视差计算深度 RGB-D：通过物理方法测量深度 相机的特点 以二维投影的形式记录了三维世界的信息 该过程丢掉了一个维度：距离 深度即第三维信息，对SLAM来说至关重要 VSLAM框架 前端：Visual Odometry 通过传感器数据计算，估计临近时刻的相机运动 方法：特征点法和直接法\n后端：Optimization 从带有噪声的数据中估计最优轨迹与地图 滤波器，图优化，最大后验概率估计 非线性优化\n回环：Loop Closing 检测相机是否到达过之间的位置 判断与之前位置的差异 计算图像之间的差异性 词袋模型\n建图：Mapping 导航，规划，通讯，交互，可视化 类型:度量地图，拓扑地图，稀疏地图，稠密地图\nSLAM的数学描述 把连续的时间离散化，避免使用随机场\n状态估计模型：\n运动方程 $$ X_{K+1}=f(x_k,u_k )+w_k $$ 观测方程 $$ Z_{k,j} = h(X_k,y_j)+W_{k,j} $$\n","date":"2019-02-21","img":"","permalink":"/posts/note/slam/","series":["notes"],"tags":["notes"],"title":"SLAM"},{"categories":["notes"],"content":"stream 编程\nimport java.util.function.Consumer; import java.util.stream.Collectors; import java.util.stream.IntStream; import java.util.stream.Stream; Consumer\u0026lt;String\u0026gt; P = System.out::println;//消费者 // P.andThen(P.andThen(P)).accept(2); /** * 流的创建 */ List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); //从集合创建流 list.stream(); list.parallelStream(); //从数组创建 Arrays.stream(new int[]{2,3,5}); // P.accept(Arrays.stream(new int[]{2,3,5}).map(x-\u0026gt;x+1).sum()); //创建数字流 IntStream.of(1,2,3); IntStream.rangeClosed(1,10); //从random创建一个无限流 new Random().ints().limit(10); //自己产生流 Stream.generate(()-\u0026gt;new Random().nextInt()).limit(20); // P.accept(Stream.generate(()-\u0026gt;new Random().nextInt()).limit(20).findAny().toString()); /** * 中间操作 */ //filter操作 Stream.of(msg.split(\u0026#34; \u0026#34;)).filter(s-\u0026gt;s.length()\u0026gt;1).forEach(P); //flatMap :将流中的属性提取出来作为流 //这里需要装箱,s.chars()返回IntStream,不是Stream的子类 Stream.of(msg.split(\u0026#34; \u0026#34;)).flatMap(s-\u0026gt;s.chars().boxed()).forEach(i-\u0026gt;System.out.println((char)i.intValue())); //limit new Random().ints().filter(x-\u0026gt;x\u0026gt;10\u0026amp;\u0026amp;x\u0026lt;1000).limit(10).forEach(System.out::println); //peek,用于debug Stream.of(msg.split(\u0026#34; \u0026#34;)).peek(System.out::println).forEach(P); /** * 终止操作 */ P.accept(\u0026#34;----终止操作----\u0026#34;); //foreach Order 用于在并行流中排序 Stream.of(msg.split(\u0026#34; \u0026#34;)).parallel().forEach(P); Stream.of(msg.split(\u0026#34; \u0026#34;)).parallel().forEachOrdered(P); //收集器 List\u0026lt;String\u0026gt; slist = Stream.of(msg.split(\u0026#34; \u0026#34;)).collect(Collectors.toList()); System.out.println(slist); //reduce 有个初始值 .orElse(\u0026#34;\u0026#34;):空判断 String s = Stream.of(msg.split(\u0026#34; \u0026#34;)).reduce(\u0026#34;\u0026#34;,(s1,s2)-\u0026gt;s1+\u0026#34;|\u0026#34;+s2); // 计算所有单词总长度 Integer reduce = Stream.of(msg.split(\u0026#34; \u0026#34;)).map(x -\u0026gt; x.length()).reduce(0, (x1, x2) -\u0026gt; x1 + x2); P.accept(s); P.accept(reduce.toString()); //max Optional\u0026lt;String\u0026gt; max = Stream.of(msg.split(\u0026#34; \u0026#34;)).max((x1, x2) -\u0026gt; x1.length() - x2.length()); P.accept(max.get()); 异步Servlet 异步是针对后端来说,这样可以让我们后端提高吞吐量\n@WebServlet(asyncSupported = true,urlPatterns = {\u0026#34;/AsyncServlet\u0026#34;}) public class AsyncServlet extends HttpServlet{ protected void doGet(HttpServletRequest req,HttpServletResponse res){ //开启异步 AsyncContext asyncCtx = req.startAAsync(); //使用线程 CompletableFuture.runAsync(()-\u0026gt;doing(asyncCtx,asyncCtx.getRequest(),asyncCtx.getResponse()); } private void doing(AsyncContext asyncCtx,HttpServletRequest req,HttpServletResponse res){ //异步线程中会进行一些耗时操作 TimeUmtil.SECONDS.sleep(5); res.getWriter().append(\u0026#34;done\u0026#34;); //业务处理完毕,通知线程结束 asyncCtx.complete(); } } reactor = jdk8 stream + jdk9 reactor stream @RestController @Slf4j public class TestController { @GetMapping(\u0026#34;/1\u0026#34;) private String get1(){ log.info(\u0026#34;get1 start\u0026#34;); String res = createStr(); log.info(\u0026#34;get1 end\u0026#34;); return \u0026#34;getMapping\u0026#34;; } private String createStr() { //睡5秒 try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { e.printStackTrace(); } return \u0026#34;createStr\u0026#34;; } @GetMapping(\u0026#34;/2\u0026#34;) private Mono\u0026lt;String\u0026gt; get2(){ log.info(\u0026#34;get2 start\u0026#34;); Mono\u0026lt;String\u0026gt; res = Mono.fromSupplier(()-\u0026gt;createStr()); log.info(\u0026#34;get2 end\u0026#34;); return res; } } ","date":"2019-02-21","img":"","permalink":"/posts/note/stream%E7%BC%96%E7%A8%8B/","series":["notes"],"tags":["notes"],"title":"stream编程"},{"categories":["notes"],"content":"VSLAM ## project1 熟悉Linux sudo apt-get install 安装软件，apt-get 下载后软件的路径一般为/var/cache/apt/archives\n具体的安装目录是由包维护者决定\n可以通过echo $PATH查看当前的PATH，通过export PATH=$PATH:/XXX/XXX将需要的配置路径加入$PATH等号两边不能有空格\n/usr/bin可执行文件 ，/usr/share文档的路径， /usr/liblib文件， /etc配置文件\nchmod +x 文件名 为文件增加可执行权限\nchown root filename 更改文件的所有者\nSLAM综述文献阅读 Visual Simultaneous Localization and Mapping:A Survey 最初，定位与建图是独立的。但是要在一个环境中精确的定位，必须有一个正确的地图；但是为了构造一个好的地图，必须在构造地图是，添加合适的定位信息\nVSLAM系统在以下条件下会失败：外部环境，动态环境，显著特征太多或者太少的环境，大规模环境，相机不稳定运动以及传感器发生部分或全部遮挡。一个成功的VSLAM系统的关键是可以在以下环境中任然能够正确操作。\n为了从环境中构建地图，物体必须拥有传感器。使其能够感知并获得周围环境中元素的测量值。这些传感器分为外部感受和本体感受。在外部传感器中有可能找到声纳、距离激光器，gps。所有的这戏传感器都是有噪声的，而且范围有限。此外，使用这些传感器只能获得环境的局部视图。\n同时他们有以下问题：\n1.在高度杂乱的环境中或在识别对象时，没有用处。者两种机器人都很昂贵，笨重，而且由大型设备组成，是的他们难以用于机载，而GPS传感器在狭窄的街道，水下，其他星球不能很好的工作。\n本体传感器可以获得位姿信息，速度，位置变化，加速度等测量值，但是这些方法不足以始终准确的估计实体位置，因为误差会累计\n使用相机作为唯一的外部传感器。\n基于摄像头的系统能够获取距离信息，同时也能获取环境的外观，颜色和纹理，这使得机器人可以集成其他高级任务，如对人和地点的检测和识别。并且相机更便宜更轻。\n","date":"2019-02-21","img":"","permalink":"/posts/note/vslam/","series":["notes"],"tags":["notes"],"title":"VSLAM"},{"categories":["notes"],"content":"关于musicplayer 首先给权限 \u0026lt;!-- 网络权限 --\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.INTERNET\u0026#34;/\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.READ_EXTERNAL_STORAGE\u0026#34;/\u0026gt; \u0026lt;!-- 向SD卡写入数据权限 --\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.WRITE_EXTERNAL_STORAGE\u0026#34;/\u0026gt; \u0026lt;!-- 在SD卡中创建与删除文件权限 --\u0026gt; \u0026lt;!-- 扫描数据库的权限 --\u0026gt; \u0026lt;uses-permission android:name=\u0026#34;android.permission.MOUNT_UNMOUNT_FILESYSTEMS\u0026#34; tools:ignore=\u0026#34;ProtectedPermissions\u0026#34;/\u0026gt; 包含ListView的布局文件\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;LinearLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:orientation=\u0026#34;vertical\u0026#34; android:layout_gravity=\u0026#34;center\u0026#34; tools:context=\u0026#34;.MainActivity\u0026#34;\u0026gt; \u0026lt;LinearLayout android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;400dp\u0026#34; android:orientation=\u0026#34;vertical\u0026#34;\u0026gt; \u0026lt;ListView android:id=\u0026#34;@+id/lv1\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34;\u0026gt;\u0026lt;/ListView\u0026gt; \u0026lt;/LinearLayout\u0026gt; \u0026lt;SeekBar android:id=\u0026#34;@+id/sb\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;30dp\u0026#34; android:maxHeight=\u0026#34;2dp\u0026#34; android:minHeight=\u0026#34;2dp\u0026#34; android:paddingBottom=\u0026#34;3dp\u0026#34; android:paddingLeft=\u0026#34;12dp\u0026#34; android:max=\u0026#34;200\u0026#34; android:paddingRight=\u0026#34;12dp\u0026#34; android:paddingTop=\u0026#34;3dp\u0026#34; /\u0026gt; \u0026lt;TextView android:id=\u0026#34;@+id/tv1\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; /\u0026gt; \u0026lt;LinearLayout android:orientation=\u0026#34;horizontal\u0026#34; android:layout_width=\u0026#34;wrap_content\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34;\u0026gt; \u0026lt;cn.study.euraxluo.androidtup.CircleImageView android:id=\u0026#34;@+id/imageView\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;70dp\u0026#34; android:scaleType=\u0026#34;centerCrop\u0026#34; /\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_last\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;@string/btn_last\u0026#34;/\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_star\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;@string/btn_star\u0026#34;/\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_next\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;@string/btn_next\u0026#34;/\u0026gt; \u0026lt;Button android:id=\u0026#34;@+id/btn_stop\u0026#34; android:layout_width=\u0026#34;70dp\u0026#34; android:layout_height=\u0026#34;wrap_content\u0026#34; android:text=\u0026#34;@string/btn_stop\u0026#34;/\u0026gt; \u0026lt;/LinearLayout\u0026gt; \u0026lt;/LinearLayout\u0026gt; MainActivity.java\npublic class MainActivity extends AppCompatActivity implements Runnable { private static final String TAG = \u0026#34;MainActivity\u0026#34;; int flag = 1;//设置一个标志，供点击“开始/暂停”按钮使用 private Button btnStart, btnStop, btnNext, btnLast; private TextView txtInfo; private ListView listView; private SeekBar seekBar; private MusicService musicService; private Handler handler;// 处理改变进度条事件 int UPDATE = 0x101; private boolean autoChange, manulChange;// 判断是进度条是自动改变还是手动改变 private boolean isPause;// 判断是从暂停中恢复还是重新播 AudioUtils audioUtils = new AudioUtils(); // ArrayList\u0026lt;Song\u0026gt; songs; Bitmap musicFm;//音乐的封面的bitmap private ImageView imageView;//封面的imageView RotateAnimation rotateAnimation;//特效 @Override protected void onCreate(Bundle savedInstanceState) { Log.d(TAG,\u0026#34;onCreate\u0026#34;); super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); Log.d(TAG,\u0026#34;checkSelfPermission\u0026#34;); //关于验证的函数，如果缺少这两个函数，那么需要自己开启应用的权限 //判断权限,申请权限 if (ContextCompat.checkSelfPermission(MainActivity.this, Manifest.permission.WRITE_EXTERNAL_STORAGE ) != PackageManager.PERMISSION_GRANTED) { ActivityCompat.requestPermissions(MainActivity.this, new String[]{Manifest .permission.WRITE_EXTERNAL_STORAGE}, 1); } else { initMediaPlayer(); } if (ContextCompat.checkSelfPermission(MainActivity.this, Manifest.permission.READ_EXTERNAL_STORAGE ) != PackageManager.PERMISSION_GRANTED) { ActivityCompat.requestPermissions(MainActivity.this, new String[]{Manifest .permission.READ_EXTERNAL_STORAGE}, 2); } else { initMediaPlayer(); } } //关于验证的函数 //请求权限处理回调 @Override public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) { Log.d(TAG,\u0026#34;onRequestPermissionsResult\u0026#34;); switch (requestCode) { case 1: if (grantResults.length \u0026gt; 0 \u0026amp;\u0026amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) { initMediaPlayer(); } else { Toast.makeText(this, \u0026#34;获取授权失败\u0026#34;, Toast.LENGTH_SHORT).show(); } break; case 2: if (grantResults.length \u0026gt; 0 \u0026amp;\u0026amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) { initMediaPlayer(); } else { Toast.makeText(this, \u0026#34;正在获取授权\u0026#34;, Toast.LENGTH_SHORT).show(); } break; default: Toast.makeText(this, \u0026#34;获取授权失败\u0026#34;, Toast.LENGTH_SHORT).show(); } } //如果有权限就会运行这里的函数 private void initMediaPlayer() { Log.d(TAG,\u0026#34;init MediaPlayer \u0026#34;); //必须在获取权限后new MusicService， musicService = new MusicService(); /* 非扫描的方式获取的音乐，是从数据库中直接获取 songs = audioUtils.getAllSongs(this); // for (Song song:songs){ // musicService.test(songs.get(0)); Bitmap fm = songs.get(0).getThumbnail(); imageView.setImageBitmap(fm); Toast.makeText(this, songs.get(0).getFileName()+\u0026#34; \u0026#34;+songs.size(), Toast.LENGTH_SHORT).show(); // } */ try { setListViewAdapter(); } catch (Exception e) { Log.i(\u0026#34;TAG\u0026#34;, \u0026#34;读取信息失败\u0026#34;); } imageView = (ImageView) findViewById(R.id.imageView); btnStart = (Button) findViewById(R.id.btn_star); //初始化特效 rotateAnimation = new RotateAnimation(0,360, Animation.RELATIVE_TO_SELF,0.5f, Animation.RELATIVE_TO_SELF,0.5f); //开始的监听按钮，我们可以直接从这开始 btnStart.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { try { /** * flag为1 的时候，此时player内没有东西，所以执行musicService.play()函数 * 进行第一次播放，然后flag自增二不再进行第一次播放 * 当再次点击“开始/暂停”按钮次数即大于1 将执行暂停或继续播放goplay()函数 */ if (flag == 1) { btnStart.setText(R.string.btn_pause); Rotate();//旋转开始 musicService.play(); flag++; } else { if (!musicService.player.isPlaying()) { btnStart.setText(R.string.btn_pause); Rotate();//旋转开始 musicService.goPlay(); } else if (musicService.player.isPlaying()) { btnStart.setText(R.string.btn_star); rotateAnimation.cancel();//暂停图片 musicService.pause(); } } } catch (Exception e) { Log.i(\u0026#34;LAT\u0026#34;, \u0026#34;开始异常！\u0026#34;); } } }); btnStop = (Button) findViewById(R.id.btn_stop); btnStop.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { try { btnStart.setText(R.string.btn_star); rotateAnimation.cancel();//暂停旋转 musicService.stop(); flag = 1;//当点击停止按钮时，flag置为1 seekBar.setProgress(0); txtInfo.setText(\u0026#34;播放已经停止\u0026#34;); } catch (Exception e) { Log.i(\u0026#34;LAT\u0026#34;, \u0026#34;停止异常！\u0026#34;); } } }); btnLast = (Button) findViewById(R.id.btn_last); btnLast.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { try { btnStart.setText(R.string.btn_pause); Rotate();//继续旋转 musicService.last(); } catch (Exception e) { Log.i(\u0026#34;LAT\u0026#34;, \u0026#34;上一曲异常！\u0026#34;); } } }); btnNext = (Button) findViewById(R.id.btn_next); btnNext.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { try { btnStart.setText(R.string.btn_pause); // Rotate();//继续旋转 rotateAnimation.startNow(); musicService.next(); } catch (Exception e) { Log.i(\u0026#34;LAT\u0026#34;, \u0026#34;下一曲异常！\u0026#34;); } } }); seekBar = (SeekBar) findViewById(R.id.sb); seekBar.setOnSeekBarChangeListener(new SeekBar.OnSeekBarChangeListener() { @Override public void onProgressChanged(SeekBar seekBar, int i, boolean b) {//用于监听SeekBar进度值的改变 } @Override public void onStartTrackingTouch(SeekBar seekBar) {//用于监听SeekBar开始拖动 } @Override public void onStopTrackingTouch(SeekBar seekBar) {//用于监听SeekBar停止拖动 SeekBar停止拖动后的事件 int progress = seekBar.getProgress(); Log.i(\u0026#34;TAG:\u0026#34;, \u0026#34;\u0026#34; + progress + \u0026#34;\u0026#34;); int musicMax = musicService.player.getDuration(); //得到该首歌曲最长秒数 int seekBarMax = seekBar.getMax(); musicService.player .seekTo(musicMax * progress / seekBarMax);//跳到该曲该秒 autoChange = true; manulChange = false; } }); txtInfo = (TextView) findViewById(R.id.tv1); Thread t = new Thread(this);// 自动改变进度条的线程 //实例化一个handler对象 handler = new Handler() { @Override public void handleMessage(Message msg) { super.handleMessage(msg); //更新UI int mMax = musicService.player.getDuration();//最大秒数 if (msg.what == UPDATE) { try { seekBar.setProgress(msg.arg1); txtInfo.setText(setPlayInfo(msg.arg2 / 1000, mMax / 1000)); } catch (Exception e) { e.printStackTrace(); } } else { seekBar.setProgress(0); txtInfo.setText(\u0026#34;播放已经停止\u0026#34;); } } } ; t.start(); } //向列表添加MP3名字，和listView有关的函数 private void setListViewAdapter() { Log.d(TAG,\u0026#34;musicList.size:\u0026#34;+musicService.musicList.size()); String[] str = new String[musicService.musicList.size()]; int i = 0; for (String path : musicService.musicList) { File file = new File(path); str[i++] = file.getName(); } ArrayAdapter adapter = new ArrayAdapter(this, android.R.layout.simple_list_item_1,str); listView = (ListView) findViewById(R.id.lv1); listView.setAdapter(adapter); //通过播放的音乐路径来得到音乐大的封面 String dataSource = musicService.musicList.get(musicService.songNum);//得到当前播放音乐的路径 musicFm = audioUtils.createAlbumArt(dataSource); imageView.setImageBitmap(musicFm); } @Override public void run() {//这里需要新开一个线程在后台播放，同时需要控制bar，因此需要service通信 int position, mMax, sMax; while (!Thread.currentThread().isInterrupted()) { if (musicService.player != null \u0026amp;\u0026amp; musicService.player.isPlaying()) { position = musicService.getCurrentProgress();//得到当前歌曲播放进度(秒) mMax = musicService.player.getDuration();//最大秒数 sMax = seekBar.getMax();//seekBar最大值，算百分比 Message m = handler.obtainMessage();//获取一个Message m.arg1 = position * sMax / mMax;//seekBar进度条的百分比 m.arg2 = position; m.what = UPDATE; handler.sendMessage(m); // handler.sendEmptyMessage(UPDATE); try { Thread.sleep(1000);// 每间隔1秒发送一次更新消息 } catch (InterruptedException e) { e.printStackTrace(); } } } } //设置当前播放的信息 private String setPlayInfo(int position, int max) { //设置图片 String dataSource = musicService.musicList.get(musicService.songNum);//得到当前播放音乐的路径 musicFm = audioUtils.createAlbumArt(dataSource); imageView.setImageBitmap(musicFm); //设置音乐信息 String info = \u0026#34;正在播放: \u0026#34; + musicService.songName + \u0026#34;\\t\\t\u0026#34;; int pMinutes = 0; while (position \u0026gt;= 60) { pMinutes++; position -= 60; } String now = (pMinutes \u0026lt; 10 ? \u0026#34;0\u0026#34; + pMinutes : pMinutes) + \u0026#34;:\u0026#34; + (position \u0026lt; 10 ? \u0026#34;0\u0026#34; + position : position); int mMinutes = 0; while (max \u0026gt;= 60) { mMinutes++; max -= 60; } String all = (mMinutes \u0026lt; 10 ? \u0026#34;0\u0026#34; + mMinutes : mMinutes) + \u0026#34;:\u0026#34; + (max \u0026lt; 10 ? \u0026#34;0\u0026#34; + max : max); return info + now + \u0026#34; / \u0026#34; + all; } //音乐封面旋转特效 public void Rotate(){ // AnimationSet animationSet = new AnimationSet(true); rotateAnimation.setDuration(20000);//设定转一圈的时间 rotateAnimation.setRepeatCount(Animation.INFINITE);//设定无限循环 rotateAnimation.setRepeatMode(Animation.RESTART);// // animationSet.addAnimation(rotateAnimation); imageView.startAnimation(rotateAnimation); } } 我的MusicService文件\npublic class MusicService { private static final File PATH = Environment.getExternalStorageDirectory();// 获取SD卡总目录。 public List\u0026lt;String\u0026gt; musicList;// 存放找到的所有mp3的绝对路径。 public MediaPlayer player; // 定义多媒体对象 public int songNum; // 当前播放的歌曲在List中的下标,flag为标致 public String songName; // 当前播放的歌曲名 class MusicFilter implements FilenameFilter { public boolean accept(File dir, String name) { return (name.endsWith(\u0026#34;.mp3\u0026#34;));//返回当前目录所有以.mp3结尾的文件 } } public MusicService() { super(); player = new MediaPlayer(); musicList = new ArrayList\u0026lt;String\u0026gt;(); try { File MUSIC_PATH = new File(PATH, \u0026#34;netease/cloudmusic/Music\u0026#34;);//获取Music文件的二级目录 if (MUSIC_PATH.listFiles(new MusicFilter()).length \u0026gt; 0) { for (File file : MUSIC_PATH.listFiles(new MusicFilter())) { musicList.add(file.getAbsolutePath()); } } } catch (Exception e) { Log.i(\u0026#34;TAG\u0026#34;, \u0026#34;读取文件异常\u0026#34;); } } public void setPlayName(String dataSource) { File file = new File(dataSource);//假设为D:\\\\mm.mp3 String name = file.getName();//name=mm.mp3 int index = name.lastIndexOf(\u0026#34;.\u0026#34;);//找到最后一个. songName = name.substring(0, index);//截取为mm } public void play() { try { player.reset(); //重置多媒体 String dataSource = musicList.get(songNum);//得到当前播放音乐的路径 setPlayName(dataSource);//截取歌名 // 指定参数为音频文件 player.setAudioStreamType(AudioManager.STREAM_MUSIC); player.setDataSource(dataSource);//为多媒体对象设置播放路径 player.prepare();//准备播放 player.start();//开始播放 //setOnCompletionListener 当当前多媒体对象播放完成时发生的事件 player.setOnCompletionListener(new MediaPlayer.OnCompletionListener() { public void onCompletion(MediaPlayer arg0) { next();//如果当前歌曲播放完毕,自动播放下一首. } }); } catch (Exception e) { Log.v(\u0026#34;MusicService\u0026#34;, e.getMessage()); } } /*和数据库有关的 public void test(Song song){//测试数据库 try { player.reset(); //重置多媒体 String dataSource = song.getFileUrl(); // String dataSource = musicList.get(songNum);//得到当前播放音乐的路径 setPlayName(dataSource);//截取歌名 // 指定参数为音频文件 player.setAudioStreamType(AudioManager.STREAM_MUSIC); player.setDataSource(dataSource);//为多媒体对象设置播放路径 player.prepare();//准备播放 player.start();//开始播放 //setOnCompletionListener 当当前多媒体对象播放完成时发生的事件 player.setOnCompletionListener(new MediaPlayer.OnCompletionListener() { public void onCompletion(MediaPlayer arg0) { next();//如果当前歌曲播放完毕,自动播放下一首. } }); } catch (Exception e) { Log.v(\u0026#34;MusicService\u0026#34;, e.getMessage()); } } */ //继续播放 public void goPlay() { int position = getCurrentProgress(); player.seekTo(position);//设置当前MediaPlayer的播放位置，单位是毫秒。 try { player.prepare();// 同步的方式装载流媒体文件。 } catch (Exception e) { e.printStackTrace(); } player.start(); } // 获取当前进度 public int getCurrentProgress() { if (player != null \u0026amp; player.isPlaying()) { return player.getCurrentPosition(); } else if (player != null \u0026amp; (!player.isPlaying())) { return player.getCurrentPosition(); } return 0; } public void next() { songNum = songNum == musicList.size() - 1 ? 0 : songNum + 1; play(); } public void last() { songNum = songNum == 0 ? musicList.size() - 1 : songNum - 1; play(); } // 暂停播放 public void pause() { if (player != null \u0026amp;\u0026amp; player.isPlaying()) { player.pause(); } } public void stop() { if (player != null \u0026amp;\u0026amp; player.isPlaying()) { player.stop(); player.reset(); } } } 我的圆形封面\npackage cn.study.euraxluo.androidtup;/* AndroidTup * cn.study.euraxluo.androidtup * CircleImageView * 2019/5/13 13:26 * author:Euraxluo * TODO */ import android.content.Context; import android.graphics.*; import android.graphics.drawable.BitmapDrawable; import android.graphics.drawable.ColorDrawable; import android.graphics.drawable.Drawable; import android.support.annotation.Nullable; import android.util.AttributeSet; import android.widget.ImageView; public class CircleImageView extends android.support.v7.widget.AppCompatImageView { private Paint mPaintBitmap = new Paint(Paint.ANTI_ALIAS_FLAG); private Bitmap mRawBitmap; private BitmapShader mShader; private Matrix mMatrix = new Matrix(); public CircleImageView(Context context,AttributeSet attrs) { super(context, attrs); } @Override protected void onDraw(Canvas canvas) { Bitmap rawBitmap = getBimap(getDrawable()); if (rawBitmap != null) { int viewWidth = getWidth(); int viewHeight = getHeight(); int viewMinSize = Math.min(viewWidth, viewHeight); float dstHeight = viewMinSize; float dstWidth = viewMinSize; if (mShader == null || !rawBitmap.equals(mRawBitmap)) { mRawBitmap = rawBitmap; mShader = new BitmapShader(mRawBitmap, Shader.TileMode.CLAMP, Shader.TileMode.CLAMP); } if (mShader != null) { mMatrix.setScale(dstWidth / rawBitmap.getWidth(), dstHeight / rawBitmap.getHeight()); mShader.setLocalMatrix(mMatrix); } mPaintBitmap.setShader(mShader); float radius = viewMinSize / 2.0f; canvas.drawCircle(radius, radius, radius, mPaintBitmap); } else super.onDraw(canvas); } private Bitmap getBimap(Drawable drawable) { if (drawable instanceof BitmapDrawable) { return ((BitmapDrawable) drawable).getBitmap(); } else if (drawable instanceof ColorDrawable) { Rect rect = drawable.getBounds(); int width = rect.right - rect.left; int height = rect.bottom - rect.top; int color = ((ColorDrawable) drawable).getColor(); Bitmap bitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ARGB_8888); Canvas canvas = new Canvas(bitmap); canvas.drawARGB(Color.alpha(color), Color.red(color), Color.green(color), Color.blue(color)); return bitmap; } else return null; } } 数据库扫描用的：Song实体类\npackage cn.study.euraxluo.androidtup; import android.graphics.Bitmap; public class Song { private String fileName; private String title; private int duration; private String singer; private String album; private String year; private String type; private String size; private String fileUrl; private Bitmap Thumbnail; public Bitmap getThumbnail() { return Thumbnail; } public void setThumbnail(Bitmap thumbnail) { Thumbnail = thumbnail; } public String getFileName() { return fileName; } public void setFileName(String fileName) { this.fileName = fileName; } public String getTitle() { return title; } public void setTitle(String title) { this.title = title; } public int getDuration() { return duration; } public void setDuration(int duration) { this.duration = duration; } public String getSinger() { return singer; } public void setSinger(String singer) { this.singer = singer; } public String getAlbum() { return album; } public void setAlbum(String album) { this.album = album; } public String getYear() { return year; } public void setYear(String year) { this.year = year; } public String getType() { return type; } public void setType(String type) { this.type = type; } public String getSize() { return size; } public void setSize(String size) { this.size = size; } public String getFileUrl() { return fileUrl; } public void setFileUrl(String fileUrl) { this.fileUrl = fileUrl; } public Song() { super(); } public Song(String fileName, String title, int duration, String singer, String album, String year, String type, String size, String fileUrl) { super(); this.fileName = fileName; this.title = title; this.duration = duration; this.singer = singer; this.album = album; this.year = year; this.type = type; this.size = size; this.fileUrl = fileUrl; } @Override public String toString() { return \u0026#34;Song [fileName=\u0026#34; + fileName + \u0026#34;, title=\u0026#34; + title + \u0026#34;, duration=\u0026#34; + duration + \u0026#34;, singer=\u0026#34; + singer + \u0026#34;, album=\u0026#34; + album + \u0026#34;, year=\u0026#34; + year + \u0026#34;, type=\u0026#34; + type + \u0026#34;, size=\u0026#34; + size + \u0026#34;, fileUrl=\u0026#34; + fileUrl + \u0026#34;]\u0026#34;; } } 扫描数据的AudioUtils.java\npackage cn.study.euraxluo.androidtup; import android.content.Context; import android.database.Cursor; import android.graphics.Bitmap; import android.graphics.BitmapFactory; import android.media.MediaMetadataRetriever; import android.provider.MediaStore; import java.util.ArrayList; public class AudioUtils { /** * 获取sd卡所有的音乐文件 * * @return * @throws Exception */ public static ArrayList\u0026lt;Song\u0026gt; getAllSongs(Context context) { ArrayList\u0026lt;Song\u0026gt; songs = null; Cursor cursor = context.getContentResolver().query( MediaStore.Audio.Media.EXTERNAL_CONTENT_URI, new String[] { MediaStore.Audio.Media._ID, MediaStore.Audio.Media.DISPLAY_NAME, MediaStore.Audio.Media.TITLE, MediaStore.Audio.Media.DURATION, MediaStore.Audio.Media.ARTIST, MediaStore.Audio.Media.ALBUM, MediaStore.Audio.Media.YEAR, MediaStore.Audio.Media.MIME_TYPE, MediaStore.Audio.Media.SIZE, MediaStore.Audio.Media.DATA }, MediaStore.Audio.Media.MIME_TYPE + \u0026#34;=? or \u0026#34; + MediaStore.Audio.Media.MIME_TYPE + \u0026#34;=?\u0026#34;, new String[] { \u0026#34;audio/mpeg\u0026#34;, \u0026#34;audio/x-ms-wma\u0026#34; }, null); songs = new ArrayList\u0026lt;Song\u0026gt;(); if (cursor.moveToFirst()) { Song song = null; do { song = new Song(); // 文件名 song.setFileName(cursor.getString(1)); // 歌曲名 song.setTitle(cursor.getString(2)); // 时长 song.setDuration(cursor.getInt(3)); // 歌手名 song.setSinger(cursor.getString(4)); // 专辑名 song.setAlbum(cursor.getString(5)); // 年代 if (cursor.getString(6) != null) { song.setYear(cursor.getString(6)); } else { song.setYear(\u0026#34;未知\u0026#34;); } // 歌曲格式 if (\u0026#34;audio/mpeg\u0026#34;.equals(cursor.getString(7).trim())) { song.setType(\u0026#34;mp3\u0026#34;); } else if (\u0026#34;audio/x-ms-wma\u0026#34;.equals(cursor.getString(7).trim())) { song.setType(\u0026#34;wma\u0026#34;); } // 文件大小 if (cursor.getString(8) != null) { float size = cursor.getInt(8) / 1024f / 1024f; song.setSize((size + \u0026#34;\u0026#34;).substring(0, 4) + \u0026#34;M\u0026#34;); } else { song.setSize(\u0026#34;未知\u0026#34;); } // 文件路径 if (cursor.getString(9) != null) { song.setFileUrl(cursor.getString(9)); } //获取专辑封面（如果数据量大的话，会很耗时——需要考虑如何开辟子线程加载） Bitmap albumArt = createAlbumArt(song.getFileUrl()); song.setThumbnail(albumArt); songs.add(song); } while (cursor.moveToNext()); cursor.close(); } return songs; } public static int calculateInSampleSize(BitmapFactory.Options options,int reqWidth,int reqHeight){ final int height = options.outHeight; final int width = options.outWidth; int inSampleSize = 1; if(height \u0026gt; reqHeight || width \u0026gt; reqWidth){ final int halfHeight = height/2; final int halfWidth = width/2; while ((halfHeight/inSampleSize)\u0026gt;reqHeight \u0026amp;\u0026amp; (halfWidth/inSampleSize)\u0026gt;reqWidth) inSampleSize*=2; } return inSampleSize; } public static Bitmap createAlbumArt(final String filePath) { Bitmap bitmap = null; //能够获取多媒体文件元数据的类 MediaMetadataRetriever retriever = new MediaMetadataRetriever(); try { retriever.setDataSource(filePath); //设置数据源 byte[] embedPic = retriever.getEmbeddedPicture(); //得到字节型数据 final BitmapFactory.Options options = new BitmapFactory.Options(); options.inJustDecodeBounds = true; BitmapFactory.decodeByteArray(embedPic, 0, embedPic.length,options); options.inSampleSize = calculateInSampleSize(options,100,100); options.inJustDecodeBounds = false; bitmap = BitmapFactory.decodeByteArray(embedPic, 0, embedPic.length,options); //转换为图片 } catch (Exception e) { e.printStackTrace(); } finally { try { retriever.release(); } catch (Exception e2) { e2.printStackTrace(); } } return bitmap; } } ","date":"2019-02-21","img":"","permalink":"/posts/note/%E5%85%B3%E4%BA%8Emusicplayer/","series":["notes"],"tags":["notes"],"title":"关于musicplayer"},{"categories":["notes"],"content":"关于ViewPager 使用方法：先在xml中定义\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;utf-8\u0026#34;?\u0026gt; \u0026lt;android.support.design.widget.CoordinatorLayout xmlns:android=\u0026#34;http://schemas.android.com/apk/res/android\u0026#34; xmlns:tools=\u0026#34;http://schemas.android.com/tools\u0026#34; xmlns:app=\u0026#34;http://schemas.android.com/apk/res-auto\u0026#34; android:id=\u0026#34;@+id/main_content\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; android:fitsSystemWindows=\u0026#34;true\u0026#34; tools:context=\u0026#34;.MainActivity\u0026#34;\u0026gt; \u0026lt;android.support.v4.view.ViewPager android:background=\u0026#34;@drawable/img5\u0026#34; android:id=\u0026#34;@+id/view_pager\u0026#34; android:layout_width=\u0026#34;match_parent\u0026#34; android:layout_height=\u0026#34;match_parent\u0026#34; app:layout_behavior=\u0026#34;@string/appbar_scrolling_view_behavior\u0026#34;/\u0026gt; \u0026lt;/android.support.design.widget.CoordinatorLayout\u0026gt; 再到Activity中写\npackage cn.euraxluo.myapplication; import android.support.annotation.NonNull; import android.support.v4.view.PagerAdapter; import android.support.v7.app.AppCompatActivity; import android.support.v4.view.ViewPager; import android.os.Bundle; import android.util.Log; import android.view.*; import android.widget.ImageView; import cn.euraxluo.myapplication.transform.ZoomOutPageTransformer; import java.util.ArrayList; import java.util.List; public class MainActivity extends AppCompatActivity { private static final String TAG = \u0026#34;MainActivity\u0026#34;; private ViewPager mViewPager;//viewpager private textViewAdapter mViewAdapter; private pictureViewAdapter mpViewAdapter;//图片的adapter private int[] mImage = new int[10]; private View view1, view2, view3; private List\u0026lt;View\u0026gt; viewList = new ArrayList\u0026lt;View\u0026gt;(3);//view数组 private LayoutInflater inflater; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); initView(); } private void initView() { Log.d(TAG, \u0026#34;initView\u0026#34;); mViewPager = (ViewPager) findViewById(R.id.view_pager); //关于图片的 // initmImage(); // mpViewAdapter = new pictureViewAdapter(mImage); // mViewPager.setAdapter(mpViewAdapter); //页面滑动 initmlayouts(); mViewAdapter = new textViewAdapter(); mViewPager.setAdapter(mViewAdapter); mViewPager.setPageTransformer(true, new ZoomOutPageTransformer());//这一句是特效 } private void initmImage() { mImage[0] = R.drawable.img1; mImage[1] = R.drawable.img2; mImage[2] = R.drawable.img3; mImage[3] = R.drawable.img4; mImage[4] = R.drawable.img5; mImage[5] = R.drawable.img6; } private void initmlayouts() { //findViewById是找具体的widget控件 inflater = getLayoutInflater();//寻找xml下的布局文件，并且实例化 view1 = (View) inflater.inflate(R.layout.activity_music, null);//这是三个layout view2 = (View) inflater.inflate(R.layout.activity_list, null);//实际用的时候发生了OOM view3 = (View) inflater.inflate(R.layout.activity_about, null); viewList.add(view1); viewList.add(view2); viewList.add(view3); } public class pictureViewAdapter extends PagerAdapter { private int[] mImage; public pictureViewAdapter(int[] mImage) { this.mImage = mImage;//接受传入的mImge } @NonNull @Override public Object instantiateItem(@NonNull ViewGroup container, int position) { ImageView imageView = new ImageView(container.getContext()); imageView.setImageResource(mImage[position]);//设置图片 container.addView(imageView); return imageView; } @Override public void destroyItem(@NonNull ViewGroup container, int position, @NonNull Object object) { container.removeView((View) object); } @Override public int getCount() {//在viewpager显示几个页面 return mImage.length; } @Override public boolean isViewFromObject(@NonNull View view, @NonNull Object o) { return view == o; } } public class textViewAdapter extends PagerAdapter { @Override public int getCount() { return viewList.size();//在viewPager中显示3个页面 } @NonNull @Override public Object instantiateItem(@NonNull ViewGroup container, int position) { container.addView(viewList.get(position));//添加到viewPager容器中 return viewList.get(position);//返回填充的对象 //1.将当前视图添加到container中，2.返回当前View } @Override public boolean isViewFromObject(@NonNull View view, @NonNull Object o) { return view == o; } public void destroyItem(ViewGroup container, int position, Object obj) { container.removeView((View) obj);//从当前container删除指定位置的view } } } 一些简单的特效 package cn.euraxluo.myapplication.transform; import android.support.v4.view.ViewPager; import android.util.Log; import android.view.View; //扇子变换 public class RotateDownTransformer implements ViewPager.PageTransformer { private static final float ROT_MAX = 20.0f; private float mRot; public void transformPage(View view, float position) { Log.e(\u0026#34;TAG\u0026#34;, view + \u0026#34; , \u0026#34; + position + \u0026#34;\u0026#34;); if (position \u0026lt; -1) { // [-Infinity,-1) // This page is way off-screen to the left. view.setRotation(0); } else if (position \u0026lt;= 1) // a页滑动至b页 ； a页从 0.0 ~ -1 ；b页从1 ~ 0.0 { // [-1,1] // Modify the default slide transition to shrink the page as well if (position \u0026lt; 0) { mRot = (ROT_MAX * position); view.setPivotX(view.getMeasuredWidth() * 0.5f); view.setPivotY(view.getMeasuredHeight()); view.setRotation( mRot); } else { mRot = (ROT_MAX * position); view.setPivotX(view.getMeasuredWidth() * 0.5f); view.setPivotY(view.getMeasuredHeight()); view.setRotation( mRot); } // Scale the page down (between MIN_SCALE and 1) // Fade the page relative to its size. } else { // (1,+Infinity] // This page is way off-screen to the right. view.setRotation( 0); } } } package cn.euraxluo.myapplication.transform;/* MyApplication2 * cn.euraxluo.myapplication.Transform * ScalePageTransformer * 2019/5/18 16:31 * author:Euraxluo * TODO */ import android.support.annotation.NonNull; import android.support.v4.view.ViewPager; import android.view.View; public class ScalePageTransformer implements ViewPager.PageTransformer { private static final float MIN_SCALE=0.75f; @Override public void transformPage(@NonNull View page, float position) { if(position\u0026lt;-1.0f) { page.setScaleX(MIN_SCALE); page.setScaleY(MIN_SCALE); } // slide left else if(position\u0026lt;=0.0f) { page.setAlpha(1.0f); page.setTranslationX(0.0f); page.setScaleX(1.0f); page.setScaleY(1.0f); } // slide right else if(position\u0026lt;=1.0f) { page.setAlpha(1.0f-position); page.setTranslationX(-page.getWidth()*position); float scale=MIN_SCALE+(1.0f-MIN_SCALE)*(1.0f-position); page.setScaleX(scale); page.setScaleY(scale); } // out of right screen else { page.setScaleX(MIN_SCALE); page.setScaleY(MIN_SCALE); } } } package cn.euraxluo.myapplication.transform;/* MyApplication2 * cn.euraxluo.myapplication.Transform * ZoomOutPageTransformer * 2019/5/18 17:06 * author:Euraxluo * TODO */ import android.annotation.SuppressLint; import android.support.v4.view.ViewPager; import android.view.View; public class ZoomOutPageTransformer implements ViewPager.PageTransformer { private static final float MIN_SCALE = 0.85f; private static final float MIN_ALPHA = 0.85f; @SuppressLint(\u0026#34;NewApi\u0026#34;) public void transformPage(View view, float position) { if (position \u0026lt;= 1) //a页滑动至b页 ； a页从 0.0 -1 ；b页从1 ~ 0.0 {// 还可以修改默认的幻灯片转换以缩小页面 float scaleFactor = Math.max(MIN_SCALE, 1 - Math.abs(position)); if (position \u0026lt; 0) {//代表左边的view view.setAlpha(1); } else {// 使页面相对于大小淡入颜色。 view.setAlpha(MIN_ALPHA + (scaleFactor - MIN_SCALE) / (2 - MIN_SCALE) * (2 - MIN_ALPHA)); } } } } ","date":"2019-02-21","img":"","permalink":"/posts/note/%E5%85%B3%E4%BA%8Eviewpager/","series":["notes"],"tags":["notes"],"title":"关于ViewPager"},{"categories":["notes"],"content":"前端 CSS 网格布局\ntable标签（具有性能问题）=\u0026gt;\nhack\nfloat流式布局=\u0026gt;position绝对定位（不利于使用响应式）-\u0026gt;inline(块级放在同一行)\nflexBox(正对某一维度进行自适应)\n=》grid布局\nBackbone.js提供了一套web开发的框架，通过Models进行key-value绑定及自定义事件处理，通过Collections提供一套丰富的API用于枚举功能，通过Views来进行事件处理及与现有的Application通过RESTful JSON接口进行交互.它是基于jQuery和underscore的一个前端js框架。\n在Backbonejs有几个重要的概念，先介绍一下:Model，Collection，View，Router。其中Model是根据现实数据建立的抽象，比如人（People）；Collection是Model的一个集合，比如一群人；View是对Model和Collection中数据的展示，把数据渲染（Render）到页面上；Router是对路由的处理，就像传统网站通过url现实不同的页面，在单页面应用（SPA）中通过Router来控制前面说的View的展示。\n通过Backbone，你可以把你的数据当作Models，通过Models你可以创建数据，进行数据验证，销毁或者保存到服务器上。当界面上的操作引起model中属性的变化时，model会触发change的事件。那些用来显示model状态的views会接受到model触发change的消息，进而发出对应的响应，并且重新渲染新的数据到界面。在一个完整的Backbone应用中，你不需要写那些胶水代码来从DOM中通过特殊的id来获取节点，或者手工的更新HTML页面，因为在model发生变化时，views会很简单的进行自我更新。\n","date":"2019-02-21","img":"","permalink":"/posts/note/%E5%89%8D%E7%AB%AF/","series":["notes"],"tags":["notes"],"title":"前端"},{"categories":["notes"],"content":"卡包开发步骤 开发步骤\n需求规划,需求拆解,需求辩论 技术选型:为什么是HBase or MySQL 工程设计:工程图各个模块设计的功能点,各个功能点涉及的技术 编码 测试:功能测试,压力测试 部署:自动化上线 开发技术\nkafka 消息队列 Mysql存储商户信息 HBase存储用户信息 Spring-boot 搭建项目 Redis存储Token信息 测试用例\n测试上线\n应用技术分层\n框架层:Spring-boot 存储层:MySql,HBase,Redis 消息队列:Kafka 基础工具介绍:\nMaven PostMan/RestAPI 需求分析: 功能需求解析:\n什么是卡包应用:卡券收集聚合类应用 包含哪些子系统:商户投放子系统,用户使用子系统 优惠卷使用方法:展示型,兑换型,token核销型 扩展:存储纪念性卡券,身份证件信息,银行卡 我的卡包:\n我的卡包(显示我领取的优惠券,临近过期时需要提醒) 过期优惠券(显示过期优惠券) 优惠券库存:可以领取商家投放的优惠券,每个优惠券只能领取一张(可以改一下?) 用户反馈:分为卡包应用反馈和优惠券反馈 商户投放系统\n商户接口字段:\nname 商户名 logo_url 商户logo business_license_url 商户营业执照 phone 商户联系电话 address 商户地址 is_audit 商户是否通过审核 优惠券接口字段:\nid 所属商户Id title 优惠卷标题 summary 优惠卷摘要 desc 优惠卷详细信息 limit 最大发放总数个数限制 has_token 是否具有token background 优惠卷背景颜色 start/end 优惠卷 开始/结束 时间 应用架构 表结构设计 Mysql name 商户名 logo_url 商户logo business_license_url 商户营业执照 phone 商户联系电话 address 商户地址 is_audit 商户是否通过审核 HBase passtemplate\nid 所属商户Id title 优惠卷标题 summary 优惠卷摘要 desc 优惠卷详细信息 has_token 是否具有token background 优惠卷背景颜色 limit 最大发放总数个数限制 start/end 优惠卷 开始/结束 时间 pass \u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; user_id 优惠卷所属用户 template_id 优惠卷id用于映射具体的优惠卷信息 token 优惠卷token,不存在为-1 assigned_date 领取日期 con_date 消费日期 feedback \u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; user_id 评论所属用户 template_id 如果type标识此评论针对优惠卷,则需要指出优惠卷id type 标识此评论针对卡包还是优惠卷 comment 评论内容 user \u0026mdash;\u0026mdash;\u0026mdash;- \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; name 用户名 age 用户年龄 sex 用户性别 phone 用户手机号 address 用户地址 开发步骤 修改配置文件 定义数据结构:merchants.sql 定义常量类以及枚举类 定义Token拦截器,去拿到每个请求中header中的token字段 定义实体类,与merchants.sql中的字段对应 定义dao接口,继承JpaRepository\u0026lt;Merchants, Integer\u0026gt; vo的编写,除了属性,还需要验证对象的有效性,以及对象的转换(vo-\u0026gt;entity/pojo) ","date":"2019-02-21","img":"","permalink":"/posts/note/%E5%BC%80%E5%8F%91%E6%AD%A5%E9%AA%A4/","series":["notes"],"tags":["notes"],"title":"卡包开发步骤"},{"categories":["notes"],"content":"操作系统小记\n并发系统 为什么需要并行\n业务需求，不同的线程完成不同的功能，交给操作系统进行调度 性能，提高cpu密集型在多核处理机的效率 同步synchronous和异步asynchronous 同步等待调用返回\n异步调用马上返回，但是后台新开一个线程/进行慢慢运行，再返回\n并发Concurrency和并行Parallelism 多核CPU天然并行，不同的CPU做不同的事\n并发，是指通过调度，一会儿做这个事，一会儿做另一个事\n临界区 表示一个公共的资源或者共享数据，可以被多个线程使用，但是每一次，只能有一个线程使用它，一旦临界资源被占用，其他线程想使用这个资源，必须等待 进程 ==》 进入去(申请资源，如果资源被占用，就进去阻塞等待队列) ==》临界区 ==》退出区 阻塞Blocking和非阻塞N-Blocking 阻塞和非阻塞通常用来形容多线程之间的相互影响 阻塞：一个线程占用了临界区资源，那么其他所有需要这个资源的线程都必须再这个临界区中等待，等待导致线程挂起，这就是阻塞。如果占用资源的线程一直不释放资源，那么其他所有在这个临界区上的的线程都不能工作 非阻塞允许多个线程同时进入临界区 死锁Deadlock，饥饿Starvation，活锁Livelock 死锁：\n一组进程中的每一个进程都在等待仅由该组中的其他进程才能引发的事件，那么该组进程是死锁的\n饥饿：\n由于个别资源长期被其他进程占用，而致等待该资源的进程迟迟无法开始运行\n活锁：\n进程为了避免死锁，而释放资源，导致资源一直在被释放和抢占中，同时活锁的进程也无法执行\n并发级别 阻塞 当一个线程进入临界区后，其他线程必须等待 无障碍 无障碍是一种最弱的非阻塞调度 自由出入临界区 无竞争时，有限步内完成操作 有竞争时，回滚数据 各个线程在尝试获取一个独立的系统快照 无锁 首先无障碍的 保证在至少一个线程可以胜出竞争 while(!atomicVar.compareAndSet(localVar,localVar+1)){//无锁计算 localVar = atomicVar.get(); } 无等待 首先无锁的 要求所有的线程都必须在有限步内完成 一定无饥饿 Amdahl定律 串行系统并行化后的加速比的计算公式和理论上限\n加速比 = 优化前系统耗时/优化后系统耗时\nCPU并行化后系统耗时的计算公式： $$ Tn = T_1(F+\\frac{1}{n}(1-F)) = \\frac{1}{F+\\frac{1}{n}(1-F)} $$ {n:处理器个数，F串行比例，(1-F)并行比例}\n","date":"2019-02-21","img":"","permalink":"/posts/note/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%B0%8F%E8%AE%A1/","series":["notes"],"tags":["notes"],"title":"操作系统小记"},{"categories":["notes"],"content":"数学杂谈 欧氏空间：在实数域上的有限的内积向量空间 对加法和数乘封闭\n意思是。在“向量空间”V这个向量集合中：\n①。任意取V的两个向量α，β。则α+β∈V，[这叫V对加法封闭]\n②，任意取V的一个向量α，及一个实数k.则kα∈V，[这叫V对数乘封闭]\n** 距离和空间 **\n傅里叶分析之掐死教程（完整版）更新于2014.06.06 欧拉公式 ","date":"2019-02-21","img":"","permalink":"/posts/note/%E6%95%B0%E5%AD%A6%E6%9D%82%E8%B0%88/","series":["notes"],"tags":["notes"],"title":"数学杂谈"},{"categories":["notes"],"content":"简易服务器 创建套接字 填充数据结构 绑定端口 监听，accept 获得accept的句柄并处理 封装resp字符串 写回到accept的句柄中 2.C标准函数\n1.int2float to string/array:\nC语言提供了几个标准库函数，可以将任意类型(整型、长整型、浮点型等)的数字转换为字符串，下面列举了各函数的方法及其说明。 ● itoa()：将整型值转换为字符串。 ● ltoa()：将长整型值转换为字符串。 ● ultoa()：将无符号长整型值转换为字符串。 ● gcvt()：将浮点型数转换为字符串，取四舍五入。 ● ecvt()：将双精度浮点型值转换为字符串，转换结果中不包含十进制小数点。 ● fcvt()：指定位数为转换精度，其余同ecvt()。\n除此外，还可以使用sprintf系列函数把数字转换成字符串，其比itoa()系列函数运行速度慢\nstring/array to int/float C/C++语言提供了几个标准库函数，可以将字符串转换为任意类型(整型、长整型、浮点型等)。 ● atof()：将字符串转换为双精度浮点型值。 ● atoi()：将字符串转换为整型值。 ● atol()：将字符串转换为长整型值。 ● strtod()：将字符串转换为双精度浮点型值，并报告不能被转换的所有剩余数字。 ● strtol()：将字符串转换为长整值，并报告不能被转换的所有剩余数字。 ● strtoul()：将字符串转换为无符号长整型值，并报告不能被转换的所有剩余数字。 itoa(num,str,10); int port = atoi(str); 创建套接字，绑定端口，监听 socket() setsockopt()//设置重启后可以重新使用端口 bzero()，将结构体的其他字段设置为空 int setsockopt(int sockfd, int level, int optname,const void *optval, socklen_t optlen); sockfd：标识一个套接口的描述字。 level：选项定义的层次；支持SOL_SOCKET、IPPROTO_TCP、IPPROTO_IP和IPPROTO_IPV6。 optname：需设置的选项。 optval：指针，指向存放选项待设置的新值的缓冲区。 optlen：optval缓冲区长度。 ","date":"2019-02-21","img":"","permalink":"/posts/note/%E7%AE%80%E6%98%93%E6%9C%8D%E5%8A%A1%E5%99%A8/","series":["notes"],"tags":["notes","{{.Params.x}}"],"title":"简易服务器"},{"categories":["NLP"],"content":"语料处理流程 语料收集 \u0026gt; 语料清洗 \u0026gt; 句子向量编码化 \u0026gt; 语料问答对构建 \u0026gt; 语料的模型保存 \u0026gt; 结束 语料收集 聊天记录\n电影对话\n台词片断\n语料清洗 要清洗的内容\n多余的空格\n不正规的符号\n多余的字符,英文\n清洗的方法\n正则化\n切分\n好坏语句判断\n语料问答对的构建 问答对的处理和拆分 句子向量的编码化 原始文本不能直接训练\n将句子转化为向量\n将向量转换为句子\n语料模型的保存 使用pickle来保存模型\n生成pkl格式\n利用pkl格式进行语料的训练\n最后通过深度模型过后打包成restful\n实操 收集语料: 收集了200M的电影台词作为语料\nM 你/没/事/吧/？/ M 是/的/，/我/没/事/ M 来/吧/，/我/在/做/早/餐/ M 好/的/ E M C/h/l/o/e/./ M J/a/c/k/!/ M 没/事/吧/?/ M 发/生/什/么/了/?/ M 杀/死/知/道/你/还/活/着/的/人/?/ M 我/不/知/道/,/ M 现/在/,/ /我/要/进/入/C/T/U/的/档/案/ M 秘/密/的 M 我/没/电/脑/不/行/ M 在/加/州/工/学/院/有/个/研/究/处/ M 我/们/能/进/去/ M 那/是/谁/?/ 语料清洗 # 语料清洗 ##合并和切分,去掉不常用的符号 def make_split(line): if re.match(r\u0026#39;.*([，···?!\\.,!？])$\u0026#39;, \u0026#39;\u0026#39;.join(line)): return [] return [\u0026#39;, \u0026#39;] ##筛选出好句子和坏句子,判断英文和数字是不是太多了 def good_line(line): if len(re.findall(r\u0026#39;[a-zA-Z0-9]\u0026#39;, \u0026#39;\u0026#39;.join(line))) \u0026gt; 2: return False return True ##替换掉多余的字符 def regular(sen): sen = re.sub(r\u0026#39;\\.{3,100}\u0026#39;, \u0026#39;···\u0026#39;, sen) sen = re.sub(r\u0026#39;···{2,100}\u0026#39;, \u0026#39;···\u0026#39;, sen) sen = re.sub(r\u0026#39;[,]{1,100}\u0026#39;, \u0026#39;，\u0026#39;, sen) sen = re.sub(r\u0026#39;[\\.]{1,100}\u0026#39;, \u0026#39;。\u0026#39;, sen) sen = re.sub(r\u0026#39;[\\?]{1,100}\u0026#39;, \u0026#39;？\u0026#39;, sen) sen = re.sub(r\u0026#39;[!]{1,100}\u0026#39;, \u0026#39;！\u0026#39;, sen) return sen 问答对的构建 #解压文件 print(\u0026#39;extract lines\u0026#39;)#dgk_shooter_min fp = open(\u0026#39;test.conv\u0026#39;, \u0026#39;r\u0026#39;, errors=\u0026#39;ignore\u0026#39;, encoding=\u0026#39;utf-8\u0026#39;) #去掉M空格,和斜杠,丢弃,无效的句子 groups = [] group = [] for line in tqdm(fp): if line.startswith(\u0026#39;M \u0026#39;): #表示这一行是句子,需要处理 line = line.replace(\u0026#39;\\n\u0026#39;, \u0026#39;\u0026#39;) if \u0026#39;/\u0026#39; in line:#如果这一行有\u0026#39;/\u0026#39;,我们就从第二个字符开始以\u0026#39;/\u0026#39;切分 line = line[2:].split(\u0026#39;/\u0026#39;) else: line = list(line[2:]) line = line[:-1] group.append(list(regular(\u0026#39;\u0026#39;.join(line)))) else: if group: groups.append(group) group = [] if group: groups.append(group) group = [] print(\u0026#39;extract group\u0026#39;) # 定义问答对 x_data = [] y_data = [] for group in tqdm(groups):#tqdm可以显示进度 for i, line in enumerate(group): #把他化为枚举类 last_line = None if i \u0026gt; 0:#表示最少有两行 last_line = group[i-1] if not good_line(last_line): last_line = None next_line = None if i \u0026lt; len(group) - 1: next_line = group[i+1] if not good_line(next_line): next_line = None next_next_line = None if i \u0026lt; len(group) - 2: next_next_line = group[i + 2] if not good_line(next_next_line): next_next_line = None if next_line: x_data.append(line) y_data.append(next_line) if last_line and next_line: x_data.append(last_line + make_split(last_line) + line) y_data.append(next_line) if next_line and next_next_line: x_data.append(line) y_data.append(next_line + make_split(next_line) + next_next_line) print(len(x_data), len(y_data)) 句子向量的编码化 # 把句子进行编码化 class WordSequence(object): # 字典定义 PAD_TAG = \u0026#39;\u0026lt;pad\u0026gt;\u0026#39; #填充标签 UNK_TAG = \u0026#39;\u0026lt;unk\u0026gt;\u0026#39; #未知标签 START_TAG = \u0026#39;\u0026lt;s\u0026gt;\u0026#39; #开始标记 END_TAG = \u0026#39;\u0026lt;/S\u0026gt;\u0026#39; #结束标记 PAD = 0 UNK = 1 START = 2 END = 3 def __init__(self): self.fited = False #是否训练 self.dict = {WordSequence.PAD_TAG: WordSequence.PAD, WordSequence.UNK_TAG: WordSequence.UNK, WordSequence.START_TAG: WordSequence.START, WordSequence.END_TAG: WordSequence.END} # 编码转换 def to_index(self, word): #word 2 index assert self.fited, \u0026#39;WordSequence尚未进行fit操作\u0026#39; if word in self.dict: return self.dict[word] return WordSequence.UNK def to_word(self, index): #index 2 word assert self.fited, \u0026#39;WordSequence尚未进行fit操作\u0026#39; for k, v in self.dict.items(): if v == index: return k return WordSequence.UNK_TAG def size(self): assert self.fited, \u0026#39;WordSequence尚未进行fit操作\u0026#39; return len(self.dict) + 1 def __len__(self): # 返回字典长度 return self.size() # 训练函数 def fit(self, sentences, min_count=5, max_count=None, max_features=None): assert not self.fited, \u0026#39;WordSequence只能fit一次\u0026#39; count = {} for sentence in sentences: arr = list(sentence) for a in arr: if a not in count: count[a] = 0 count[a] += 1 if min_count is not None: count = {k: v for k, v in count.items() if v \u0026gt;= min_count} if max_count is not None: count = {k: v for k, v in count.items() if v \u0026lt;= max_count} self.dict = {WordSequence.PAD_TAG: WordSequence.PAD, WordSequence.UNK_TAG: WordSequence.UNK, WordSequence.START_TAG: WordSequence.START, WordSequence.END_TAG: WordSequence.END} if isinstance(max_features, int): count = sorted(list(count.items()), key=lambda x: x[1])#排序,找到最大特征的数目 if max_features is not None and len(count) \u0026gt; max_features: count = count[-int(max_features):] for w, _ in count: self.dict[w] = len(self.dict) else: for w in sorted(count.keys()): self.dict[w] = len(self.dict) self.fited = True #把句子编码化 def transform(self, sentence, max_len=None): assert self.fited, \u0026#39;WordSequence尚未进行fit操作\u0026#39; if max_len is not None: r = [self.PAD] * max_len else: r = [self.PAD] * len(sentence) for index, a in enumerate(sentence): if max_len is not None and index \u0026gt;= len(r): break r[index] = self.to_index(a) return np.array(r) # 把句子解码 def inverse_transform(self, indices, ignore_pad=False, ignore_unk=False, ignore_start=False, ignore_end=False): ret = [] for i in indices: word = self.to_word(i) if word == WordSequence.PAD_TAG and ignore_pad: continue if word == WordSequence.UNK_TAG and ignore_unk: continue if word == WordSequence.START_TAG and ignore_start: continue if word == WordSequence.END_TAG and ignore_end: continue ret.append(word) return ret 效果:\nws = WordSequence() ws.fit([ [\u0026#39;你\u0026#39;, \u0026#39;好\u0026#39;, \u0026#39;啊\u0026#39;], [\u0026#39;你\u0026#39;, \u0026#39;好\u0026#39;, \u0026#39;哦\u0026#39;] ]) indice = ws.transform([\u0026#39;我\u0026#39;, \u0026#39;们\u0026#39;, \u0026#39;好\u0026#39;]) print(indice) back = ws.inverse_transform(indice,ignore_pad=True,ignore_unk=False,ignore_start=True,ignore_end=True) print(back) output:\n[1 1 1] [\u0026#39;\u0026lt;unk\u0026gt;\u0026#39;, \u0026#39;\u0026lt;unk\u0026gt;\u0026#39;, \u0026#39;\u0026lt;unk\u0026gt;\u0026#39;] 语料模型的训练和保存 def dump(x_data, y_data): from word_sequence import WordSequence # 生成pkl文件备用 data = list(zip(x_data, y_data)) data = [ (x, y) for x, y in data if limit \u0026gt; len(x) \u0026gt;= x_limit and limit \u0026gt; len(y) \u0026gt;= y_limit ] x_data, y_data = zip(*data) ## 训练以及词向量模型保存 ws_input = WordSequence() ws_input.fit(x_data + y_data) print(\u0026#39;dump\u0026#39;) pickle.dump((x_data, y_data), open(\u0026#39;chatbot_test.pkl\u0026#39;, \u0026#39;wb\u0026#39;)) pickle.dump(ws_input, open(\u0026#39;ws_test.pkl\u0026#39;, \u0026#39;wb\u0026#39;)) print(\u0026#39;done\u0026#39;) ","date":"2019-02-21","img":"","permalink":"/posts/nlp/%E8%AF%AD%E6%96%99%E5%A4%84%E7%90%86%E6%B5%81%E7%A8%8B/","series":["NLP"],"tags":["NLP"],"title":"语料处理基础"},{"categories":["notes"],"content":"逆波兰式 定义 一个表达式E的后缀形式可以如下定义：\n（1）如果E是一个变量或常量，则E的后缀式是E本身。\n（2）如果E是E1 op E2形式的表达式，这里op是如何二元操作符，则E的后缀式为E1\u0026rsquo;E2\u0026rsquo; op，这里E1\u0026rsquo;和E2\u0026rsquo;分别为E1和E2的后缀式。\n（3)如果E是（E1）形式的表达式，则E1的后缀式就是E的后缀式。\n如：我们平时写a+b，这是中缀表达式，写成后缀表达式就是：ab+\n(a+b)*c-(a+b)/e的后缀表达式为：\n(a+b)*c-(a+b)/e\n→((a+b)*c)((a+b)/e)-\n→((a+b)c*)((a+b)e/)-\n→(ab+c*)(ab+e/)-\n→ab+c*ab+e/-\n作用: 实现逆波兰式的算法，难度并不大，但为什么要将看似简单的中序表达式 转换为复杂的逆波兰式？原因就在于这个简单是相对人类的思维结构来说的，对计算机而言中序表达式是非常复杂的结构。相对的，逆波兰式在计算机看来却是比较简单易懂的结构。因为计算机普遍采用的内存结构是栈式结构，它执行先进后出的顺序。\n算法实现 将一个普通的中序表达式转换为逆波兰表达式的一般算法是：\n首先需要分配2个栈，一个作为临时存储运算符的栈S1（含一个结束符号），一个作为输入逆波兰式的栈S2（空栈），S1栈可先放入优先级最低的运算符#，注意，中缀式应以此最低优先级的运算符结束。可指定其他字符，不一定非#不可。从中缀式的左端开始取字符，逐序进行如下步骤：\n（1）若取出的字符是操作数，则分析出完整的运算数，该操作数直接送入S2栈\n（2）若取出的字符是运算符，则将该运算符与S1栈栈顶元素比较，如果该运算符优先级(不包括括号运算符)大于S1栈栈顶运算符优先级，则将该运算符进S1栈，否则，将S1栈的栈顶运算符弹出，送入S2栈中，直至S1栈栈顶运算符低于（不包括等于）该运算符优先级，最后将该运算符送入S1栈。\n（3）若取出的字符是“（”，则直接送入S1栈顶。\n（4）若取出的字符是“）”，则将距离S1栈栈顶最近的“（”之间的运算符，逐个出栈，依次送入S2栈，此时抛弃“（”。\n（5）重复上面的1~4步，直至处理完所有的输入字符\n（6）若取出的字符是“#”，则将S1栈内所有运算符（不包括“#”），逐个出栈，依次送入S2栈。\n完成以上步骤，S2栈便为逆波兰式输出结果。不过S2应做一下逆序处理。便可以按照逆波兰式的计算方法计算了！\nclass TransformReversePolishNotation { private: stack\u0026lt;char\u0026gt; temp; stack\u0026lt;char\u0026gt; rpn; unordered_map\u0026lt;char, int\u0026gt; dict; void init() { //初始化字典 dict[\u0026#39;#\u0026#39;] = -1; dict[\u0026#39;+\u0026#39;] = 1; dict[\u0026#39;-\u0026#39;] = 1; dict[\u0026#39;*\u0026#39;] = 2; dict[\u0026#39;/\u0026#39;] = 2; dict[\u0026#39;(\u0026#39;] = 0; dict[\u0026#39;)\u0026#39;] = 0; } public: stack\u0026lt;char\u0026gt; pn2rpn(string s) { stack\u0026lt;char\u0026gt; result; init(); temp.push(\u0026#39;#\u0026#39;); for (int i = 0; i \u0026lt; s.size(); ++i) { if (dict.count(s[i]) == 0) {//如果这个字符不存在 rpn.push(s[i]);//将操作数入栈 } else if (s[i] == \u0026#39;(\u0026#39;) {//直接进temp中 temp.push(s[i]); }else if (s[i] == \u0026#39;)\u0026#39;) {//将(间的元素放入pn,删除( while(temp.top()!=\u0026#39;(\u0026#39;) {//当temp的栈顶不为(且,当前运算符的优先级小于或等于栈顶 rpn.push(temp.top());//将temp栈顶元素放进pn中 temp.pop();//将栈顶元素出栈 } temp.pop();//删除\u0026#39;(\u0026#39; } else {//各种运算符 for (;dict[s[i]] \u0026lt;= dict[temp.top()];temp.pop()) {//当temp的栈顶不为(且,当前运算符的优先级小于或等于栈顶 rpn.push(temp.top());//将temp栈顶元素放进pn中 // temp.pop();//将栈顶元素出栈 } if(dict[s[i]] \u0026gt; dict[temp.top()]) temp.push(s[i]); } } for(;dict[temp.top()]\u0026gt;0;temp.pop()) rpn.push(temp.top());//将temp栈顶元素放进pn中 //遍历并逆序 for (; rpn.size() \u0026gt; 0; rpn.pop()) result.push(rpn.top()); return result; } }; 计算方法 新建一个表达式,如果当前字符为变量或者为数字，则压栈，如果是运算符，则将栈顶两个元素弹出作相应运算，结果再入栈，最后当表达式扫描完后，栈里的就是结果。\n举例 下面以(a+b)c为例子进行说明： (a+b)c的逆波兰式为ab+c，假设计算机把ab+c按从左到右的顺序压入栈中，并且按照遇到运算符就把栈顶两个元素出栈，执行运算，得到的结果再入栈的原则来进行处理，那么ab+c的执行结果如下： 1）a入栈（0位置） 2）b入栈（1位置） 3）遇到运算符“+”，将a和b出栈，执行a+b的操作，得到结果d=a+b，再将d入栈（0位置） 4）c入栈（1位置） 5）遇到运算符“”，将d和c出栈，执行d*c的操作，得到结果e，再将e入栈（0位置） 经过以上运算，计算机就可以得到(a+b)*c的运算结果e了。 逆波兰式除了可以实现上述类型的运算，它还可以派生出许多新的算法，数据结构，这就需要灵活运用了。逆波兰式只是一种序列体现形式。\n简单实现:10以内的式子\nclass TransformReversePolishNotation { private: stack\u0026lt;char\u0026gt; temp; stack\u0026lt;char\u0026gt; rpn; unordered_map\u0026lt;char, int\u0026gt; dict; void init() { //初始化字典 dict[\u0026#39;#\u0026#39;] = -1; dict[\u0026#39;+\u0026#39;] = 1; dict[\u0026#39;-\u0026#39;] = 1; dict[\u0026#39;*\u0026#39;] = 2; dict[\u0026#39;/\u0026#39;] = 2; dict[\u0026#39;(\u0026#39;] = 0; dict[\u0026#39;)\u0026#39;] = 0; } int computeRPN(stack\u0026lt;char\u0026gt; rpn) { init(); vector\u0026lt;int\u0026gt; count; while (rpn.size() \u0026gt; 0) { for (; rpn.size() \u0026gt; 0 \u0026amp;\u0026amp; dict.find(rpn.top()) == dict.end(); rpn.pop()) {//如果栈顶是操作数 int num = (int) rpn.top() - 48; // int number = atoi(num);//转换字符串的,用来处理123+1213等 count.push_back(num); } switch (rpn.top()) { case \u0026#39;+\u0026#39;: count[count.size() - 2] += count[count.size() - 1]; count.pop_back(); rpn.pop(); break; case \u0026#39;-\u0026#39;: count[count.size() - 2] -= count[count.size() - 1]; count.pop_back(); rpn.pop(); break; case \u0026#39;*\u0026#39;: count[count.size() - 2] *= count[count.size() - 1]; count.pop_back(); rpn.pop(); break; case \u0026#39;/\u0026#39;: count[count.size() - 2] = count[count.size() - 1] != 0 ? count[count.size() - 2] * count[count.size() - 1] : count[ count.size() - 2]; count.pop_back(); rpn.pop(); break; default: cout\u0026lt;\u0026lt;\u0026#34;不支持的运算类型\u0026#34;; } } return count[0]; } }; leetcode 150:逆波兰式计算: 题解:\nclass Solution { public: int evalRPN(vector\u0026lt;string\u0026gt;\u0026amp; tokens) { if (tokens.empty()) return 0; stack\u0026lt;long long int\u0026gt; st; for (auto token : tokens) { if (token == \u0026#34;+\u0026#34; || token == \u0026#34;-\u0026#34; || token == \u0026#34;*\u0026#34; || token == \u0026#34;/\u0026#34;) { int b = st.top(); st.pop(); int a = st.top(); st.pop(); if (token == \u0026#34;+\u0026#34;) { st.push(a+b); } else if (token == \u0026#34;-\u0026#34;) { st.push(a-b); } else if (token == \u0026#34;*\u0026#34;) { st.push(a*b); } else if (token == \u0026#34;/\u0026#34;) { st.push(a/b); } } else { st.push(stoi(token)); } } return (int)st.top(); } }; ","date":"2019-02-21","img":"","permalink":"/posts/note/%E9%80%86%E6%B3%A2%E5%85%B0%E5%BC%8F/","series":["notes"],"tags":["notes"],"title":"逆波兰式"},{"categories":["Flask"],"content":"Flask 学习 入门： 最小的Flask 程序 from flask import Flask # 导入flask app = Flask(__name__)#使用单一的模块（如本例），你应该使用 __name__ @app.route(\u0026#39;/hello\u0026#39;) #route()装饰器 什么样子的URL能触发我们的函数 def hello_word(): return \u0026#39;Hello Word!\u0026#39;#返回我们想在浏览器中显示的内容 if __name__ == \u0026#39;__main__\u0026#39;: #确保服务器只会在该脚本被 Python 解释器直接执行的时候才会运行，而不是作为模块导入的时候 #app.run()#让app这个应用在本地服务器运行起来 #app.run(host=\u0026#39;0.0.0.0\u0026#39;) #监听所有的公网IP app.debug = True app.run()#q启动调试器 模板渲染 Jinja2模板引擎文档\nfrom flask import Flask # 导入flask from flask import render_template #使用Jinja2的模版渲染 app = Flask(__name__)#使用单一的模块（如本例），你应该使用 __name__ @app.route(\u0026#39;/hello\u0026#39;) #route()装饰器 什么样子的URL能触发我们的函数 def hello_word(): return render_template(\u0026#34;hello.html\u0026#34;)#返回的模板文件（需要放在当前目录的templates文件夹内） if __name__ == \u0026#39;__main__\u0026#39;: #确保服务器只会在该脚本被 Python 解释器直接执行的时候才会运行，而不是作为模块导入的时候 #app.run()#让app这个应用在本地服务器运行起来 #app.run(host=\u0026#39;0.0.0.0\u0026#39;) #监听所有的公网IP app.debug = True app.run()#q启动调试器 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello Template\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Hello World!\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 变量规则 URL的变量部分：\u0026lt;variable_name\u0026gt;\n规则可以用 \u0026lt;converter:variable_name\u0026gt;指定一个可选的转换器。这里有一些不错的例子:\n@app.route(\u0026#39;/user/\u0026lt;username\u0026gt;\u0026#39;) def show_user_profile(username): # show the user profile for that user return \u0026#39;User %s\u0026#39; % username @app.route(\u0026#39;/post/\u0026lt;int:post_id\u0026gt;\u0026#39;) def show_post(post_id): # show the post with the given id, the id is an integer return \u0026#39;Post %d\u0026#39; % post_id 转换器的类型\nint ： 接受整数\nfloat ：同int，但是接受浮点数\npath ：和默认的相似，但也接受浮点数\nURL规范 以这两个规则为例:\n@app.route(\u0026#39;/projects/\u0026#39;) def projects(): return \u0026#39;The project page\u0026#39; @app.route(\u0026#39;/about\u0026#39;) def about(): return \u0026#39;The about page\u0026#39; 第一种情况中，指向 projects 的规范 URL 尾端有一个斜线。这种感觉很像在文件系统中的文件夹。访问一个结尾不带斜线的 URL 会被 Flask 重定向到带斜线的规范 URL 去。\n第二种情况的 URL 结尾不带斜线，类似 UNIX-like 系统下的文件的路径名。访问结尾带斜线的 URL 会产生一个 404 “Not Found” 错误。\n在遗忘尾斜线时，允许关联的 URL 接任工作，与 Apache 和其它的服务器的行为一样。此外，也保证了 URL 的唯一，有助于避免搜索引擎索引同一个页面两次。\n结论：使用不带尾斜线的url 构造URL 使用url_for() 来给指定的函数构造 URL\n优点 URL 构建会转义特殊字符和 Unicode 数据\n如果你的应用不位于 URL 的根路径（比如，在 /myapplication 下，而不是 / ）， url_for() 会妥善处理这个问题\n反向构建通常比硬编码的描述性更好。更重要的是，它允许你一次性修改 URL， 而不是到处边找边改\n例子：\nfrom flask import Flask, url_for app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def index(): pass @app.route(\u0026#39;/login\u0026#39;) def login(): pass @app.route(\u0026#39;/user/\u0026lt;username\u0026gt;\u0026#39;) def profile(username): pass with app.test_request_context(): \u0026#39;\u0026#39;\u0026#39;test_request_context:即使我们正在通过 Python 的 shell 进行交互，它依然会告诉 Flask 要表现为正在处理一个请求\u0026#39;\u0026#39;\u0026#39; print url_for(\u0026#39;index\u0026#39;) print url_for(\u0026#39;login\u0026#39;) print url_for(\u0026#39;login\u0026#39;, next=\u0026#39;/\u0026#39;) print url_for(\u0026#39;profile\u0026#39;, username=\u0026#39;John Doe\u0026#39;) 输出：\n/ /login /login?next=%2F /user/John%20Doe HTTP方法： 默认情况下，路由只回应 GET 请求，route() 装饰器传递 methods 参数可以改变这个行为\n例子：\nfrom flask import Flask # 导入flask from flask import render_template #使用Jinja2的模版渲染 from flask import request,redirect,url_for app = Flask(__name__) @app.route(\u0026#39;/login\u0026#39;, methods=[\u0026#39;POST\u0026#39;,\u0026#39;GET\u0026#39;]) def login(): error = None if request.method == \u0026#39;POST\u0026#39;: if request.form[\u0026#39;username\u0026#39;]==\u0026#39;admin\u0026#39; and request.form[\u0026#39;password\u0026#39;]==\u0026#39;root\u0026#39;: return redirect(url_for(\u0026#39;home\u0026#39;,username=request.form[\u0026#39;username\u0026#39;])) else: error = \u0026#39;Invalid username/password\u0026#39; return render_template(\u0026#39;login.html\u0026#39;, error=error,username=request.form[\u0026#39;username\u0026#39;]) @app.route(\u0026#39;/home\u0026#39;) def home(): return render_template(\u0026#39;home.html\u0026#39;, username=request.args.get(\u0026#39;username\u0026#39;)) if __name__ == \u0026#39;__main__\u0026#39;: #确保服务器只会在该脚本被 Python 解释器直接执行的时候才会运行，而不是作为模块导入的时候 #app.run()#让app这个应用在本地服务器运行起来 #app.run(host=\u0026#39;0.0.0.0\u0026#39;) #监听所有的公网IP app.debug = True app.run()#q启动调试器 /login.html文件:\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;login\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form style=\u0026#34;margin:20px;\u0026#34; method=\u0026#34;post\u0026#34; action=\u0026#34;/login\u0026#34;\u0026gt; username:\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;username\u0026#34; id=\u0026#34;name\u0026#34;\u0026gt; \u0026lt;br\u0026gt; password:\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;password\u0026#34; id=\u0026#34;pwd\u0026#34;\u0026gt; \u0026lt;br\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34; id=\u0026#34;loginBtn\u0026#34;\u0026gt;login\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; {% if error %} {% if username %} \u0026lt;h1 style=\u0026#34;color:red\u0026#34;\u0026gt;Dear {{ username }}:{{ error }}!\u0026lt;/h1\u0026gt; {% endif %} {% endif %} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; home主页：\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;zh-CN\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;home\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;wlcome {{username}} , this is home\u0026lt;/h1\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 解析 render_template ： 将请求定位到模板文件上，处理模板文件后，将结果作为请求的响应返回\nredirect：将请求的响应重定向到新的url上。当登录成功后，重定向到 home页面\nurl_for：根据参数生成url\nrequest对象包含了所有的请求信息，通过它可获取所需要的请求信息:\napp.route增加了methods参数，指明该url支持的http请求方式，默认是get方式。/login即作为get，也作为post的请求目标\n自定义错误处理程序 定制错误页面， @errorhandle装饰器\nfrom flask import Flask # 导入flask from flask import render_template #使用Jinja2的模版渲染 from flask import request,redirect,url_for app = Flask(__name__) @app.route(\u0026#39;/index\u0026#39;) #route()装饰器 什么样子的URL能触发我们的函数 def index(): return render_template(\u0026#34;index.html\u0026#34;) @app.errorhandler(404) def not_found_error(error): return render_template(\u0026#39;404.html\u0026#39;), 404 @app.errorhandler(404) def not_found(error): resp = make_response(render_template(\u0026#39;404.html\u0026#39;), 404) resp.headers[\u0026#39;X-Something\u0026#39;] = \u0026#39;A value\u0026#39; return resp @app.errorhandler(500) def internal_error(error): return render_template(\u0026#39;500.html\u0026#39;), 500 if __name__ == \u0026#39;__main__\u0026#39;: #确保服务器只会在该脚本被 Python 解释器直接执行的时候才会运行，而不是作为模块导入的时候 #app.run()#让app这个应用在本地服务器运行起来 #app.run(host=\u0026#39;0.0.0.0\u0026#39;) #监听所有的公网IP app.debug = True app.run()#q启动调试器 静态文件 只要在你的包中或是模块的所在目录中创建一个名为 static 的文件夹，在应用中使用 /static 即可访问CSS 和 JavaScript 静态文件\nurl_for('static', filename='style.css')\nflask的线程安全 环境局部变量 一个请求传入，Web 服务器决定生成一个新线程（ 或者别的什么东西，只要这个底层的对象可以胜任并发系统，而不仅仅是线程）。 当 Flask 开始它内部的请求处理时，它认定当前线程是活动的环境，并绑定当前的应用和 WSGI 环境到那个环境上（线程）。它的实现很巧妙，能保证一个应用调用另一个应用时不会出现问题。\n如果我们需要左自动化测试：\n创建一个请求对象并且把它绑定到环境中：用 test_request_context() 环境管理器。结合 with 声明.绑定一个测试请求\nfrom flask import request with app.test_request_context(\u0026#39;/hello\u0026#39;, method=\u0026#39;POST\u0026#39;): # now you can do something with the request until the # end of the with block, such as basic assertions: assert request.path == \u0026#39;/hello\u0026#39; assert request.method == \u0026#39;POST\u0026#39; 或者传递整个WSGI环境给request_context() from flask import request with app.request_context(environ): assert request.method == \u0026#39;POST\u0026#39; Request的常用操作 导入from flask import request\n通过 [method]属性来访问不同的HTTP请求\n通过:attr:~flask.request.form 属性来访问表单数据() POST 或 PUT 请求提交的数据)\n通过args属性访问url中提交的参数\nsearchword = request.args.get('q', '')\nothers 当访问 form 属性中的不存在的键会发生什么？会抛出一个特殊的 KeyError 异常。你可以像捕获标准的 KeyError 一样来捕获它，推荐用 get 来访问 URL 参数或捕获 KeyError\n文件上传 在html的表单中设置enctype=\u0026quot;multipart/form-data\u0026quot;\n通过请求对象的 files 属性访问文件的临时存储，它是一个标准的 Python file 对象，但它还有一个 save() 方法，允许你把文件保存到服务器的文件系统上\n3. filename 属性：上传前文件在客户端的文件名，这个值是可以伪造的\n例子：把客户端上传的文件按照上传前的文件名保存在服务器上\nfrom flask import request from werkzeug import secure_filename @app.route(\u0026#39;/upload\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def upload_file(): if request.method == \u0026#39;POST\u0026#39;: f = request.files[\u0026#39;the_file\u0026#39;] f.save(\u0026#39;/var/www/uploads/\u0026#39; + secure_filename(f.filename)) Cookies 通过 cookies 属性来访问 Cookies，用响应对象的 set_cookie 方法来设置 Cookies\n读取Cookies：\nfrom flask import request @app.route(\u0026#39;/\u0026#39;) def index(): username = request.cookies.get(\u0026#39;username\u0026#39;) # use cookies.get(key) instead of cookies[key] to not get a # KeyError if the cookie is missing. 存储Cookies\nfrom flask import make_response @app.route(\u0026#39;/\u0026#39;) def index(): resp = make_response(render_template(...)) \u0026#39;\u0026#39;\u0026#39; Cookies 是设置在resp对象上的。由于通常视图函数只是返回字符串，之后 Flask 将字符串转换为响应对象。如果你要显式地转换，你可以使用 make_response() 函数然后再进行修改。 \u0026#39;\u0026#39;\u0026#39; resp.set_cookie(\u0026#39;username\u0026#39;, \u0026#39;the username\u0026#39;) return resp Session 允许你在不同请求间存储特定用户的信息，是在 Cookies 的基础上实现的，并且对 Cookies 进行密钥签名。这意味着用户可以查看你 Cookie 的内容，但却不能修改它，除非用户知道签名的密钥\nfrom flask import Flask, session, redirect, url_for, escape, request app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def index(): if \u0026#39;username\u0026#39; in session: return \u0026#39;Logged in as %s\u0026#39; % escape(session[\u0026#39;username\u0026#39;]) return \u0026#39;You are not logged in\u0026#39; @app.route(\u0026#39;/login\u0026#39;, methods=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def login(): if request.method == \u0026#39;POST\u0026#39;: session[\u0026#39;username\u0026#39;] = request.form[\u0026#39;username\u0026#39;] return redirect(url_for(\u0026#39;index\u0026#39;)) return \u0026#39;\u0026#39;\u0026#39; \u0026lt;form action=\u0026#34;\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;p\u0026gt;\u0026lt;input type=text name=username\u0026gt; \u0026lt;p\u0026gt;\u0026lt;input type=submit value=Login\u0026gt; \u0026lt;/form\u0026gt; \u0026#39;\u0026#39;\u0026#39; @app.route(\u0026#39;/logout\u0026#39;) def logout(): # remove the username from the session if it\u0026#39;s there session.pop(\u0026#39;username\u0026#39;, None) return redirect(url_for(\u0026#39;index\u0026#39;)) # set the secret key. keep this really secret: app.secret_key = \u0026#39;A0Zr98j/3yX R~XHH!jmN]LWX/,?RT\u0026#39; 强壮的密钥\nimport os os.urandom(24) 响应对象 视图函数的返回值会被自动转换为一个响应对象。如果返回值是一个字符串， 它被转换为该字符串为主体的、状态码为 200 OK的 、 MIME 类型是 text/html 的响应对象。\nFlask 把返回值转换为响应对象的逻辑是这样：\n如果返回的是一个合法的响应对象，它会从视图直接返回。\n如果返回的是一个字符串，响应对象会用字符串数据和默认参数创建。\n如果返回的是一个元组，且元组中的元素可以提供额外的信息。这样的元组必须是 (response, status, headers) 的形式，且至少包含一个元素。 status 值会覆盖状态代码， headers 可以是一个列表或字典，作为额外的消息标头值。\n如果上述条件均不满足， Flask 会假设返回值是一个合法的 WSGI 应用程序，并转换为一个请求对象。\n例子可以看之前的错误页面的内容\nlogger 服务器错误，但要让代码继续运行，你需要日志\napp.logger.debug(\u0026#39;A value for debugging\u0026#39;) app.logger.warning(\u0026#39;A warning occurred (%d apples)\u0026#39;, 42) app.logger.error(\u0026#39;An error occurred\u0026#39;) ","date":"2019-02-14","img":"","permalink":"/posts/python/flask%E5%85%A5%E9%97%A8/","series":["Flask"],"tags":["python","Flask"],"title":"Flask入门"},{"categories":["ROS"],"content":"Ubuntu18.04安装ROS 源配置: sudo sh -c \u0026#39;. /etc/lsb-release \u0026amp;\u0026amp; echo \u0026#34;deb \u0026lt;http://mirrors.ustc.edu.cn/ros/ubuntu/\u0026gt; $DISTRIB_CODENAME main\u0026#34; \u0026gt; /etc/apt/sources.list.d/ros-latest.list\u0026#39; 更新: sudo apt-get update\n添加密匙: sudo apt-key adv --keyserver hkp://ha.pool.sks-keyservers.net:80 --recv-key 421C365BD9FF1F717815A3895523BAEEB01FA116\n和官网步骤一样: sudo apt-get install ros-melodic-desktop-full\nsudo rosdep init\n报错: 由于py版本导致,网上说切换为python2.7,我失败了\nTraceback (most recent call last): File \u0026#34;/usr/bin/rosdep\u0026#34;, line 3, in \u0026lt;module\u0026gt; from rosdep2.main import rosdep_mainModuleNotFoundError: No module named \u0026#39;rosdep2\u0026#39; 重头戏来了: sudo apt-get install python3-catkin-pkg\nsudo apt-get install python3-rosinstall python3-rosinstall-generator python3-wstool build-essential\n再次运行: sudo rosdep init\nrosdep update\n感觉没问题? echo \u0026quot;source /opt/ros/melodic/setup.bash\u0026quot; \u0026gt;\u0026gt; ~/.bashrc\nsource ~/.bashrc\n报错: 没有找到 /opt/ros/melodic/setup.bash 强行来: roscore\n报错: Command \u0026#39;roscore\u0026#39; not found, but can be installed with: sudo apt install python-roslaunch 输入\nsudo apt install python-roslaunch\n发现无法定位包?\n输入sudo apt-get update后再试,无效\u0026hellip;..\n给出的依賴要求python-roslib，可是我在安裝python3-*的指令時看到已经安好了,错误不在这里\n怎么办阿\u0026hellip;\ncd 到 /opt/ros/melodic/ cd /opt/ros/melodic/\nls -l\n发现没有sh脚本????!!!!\nsudo apt-get install ros-melodic-desktop\n我太机智了!\ncd 进去再看,有了!\nOK source ~/.bashrc 成功了\n安装完成,进行验证:roscore 报错: raise DistributionNotFound(req, requirers)pkg_resources.DistributionNotFound: The \u0026#39;rospkg==1.1.7\u0026#39; distribution was not found and is required by the application ???我最熟悉的python包报错!简单!\npip install rospkg\n看到whl下载的进度,成了\nroscore\n","date":"2019-02-10","img":"","permalink":"/posts/ros/ros%E5%AE%89%E8%A3%85/","series":["ROS"],"tags":["ROS"],"title":"Ubuntu18.04安装ROS"},{"categories":["java"],"content":"jdbc JAVA Database Connectivity java 数据库连接\n为什么会出现JDBC SUN公司提供的一种数据库访问规则、规范, 由于数据库种类较多，并且java语言使用比较广泛，sun公司就提供了一种规范，让其他的数据库提供商去实现底层的访问规则。 我们的java程序只要使用sun公司提供的jdbc驱动即可。\njdbc是一种接口规范\n优势:\n简单\n快捷\n移植性\n框架(在jdbc的基础上开发更好的框架)\njdbc Manager的上层JDBC API负责与java Application通信,JDBC Driver API 负责与具体的数据库通信(由数据库厂商开发和提供)\nAPI介绍: Driver:接口,定义了各个驱动程序都必须要实现的功能\nDriverManager:Driver的管理类\n用户通过Class.forname(DriverName)可以向DriverManager注册一个驱动程序,然后使用getConnection来建立物理连接,基于物理连接没使用SQL语句\neg:\nClass.forName(JDBC_DRIVER); conn= DriverManager.getConnection(DB_URL,USER,PASS); //DB_URL:链接,USER:用户名,PASS:密码 //例如 conn= DriverManager.getConnection(\u0026#34;jdbc:mysql://127.0.0.1:3306/test\u0026#34; ,USER,PASS); //jdbc:mysql://ip:端口/数据库名;协议:子协议:主机ip:端口/数据库 常用的3种格式 mysql jdbc:mysql://\u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;/database\noracle jdbc:oracle:thin:@\u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;:database\nsqlserver jdbc:microsoft:sqlserver://\u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;;DatabaseName=database\nConnection 常用方法 Statement对象\n创建(其实是一个sql语句的容器 ​\tStatement stmt = conn.createStatement();\n使用(使用Statement对象执行sql语句,返回结果为ResultSet/int): ​\tResultSet rs = stmt.executeQuery(\u0026quot;select userName from user\u0026quot;)\n​\t查询结果是一个ResultSet对象\nResultSet对象(Statement对象的查询结果)\nrs.next():将光标移动到下一行(默认在第一行)\nrs.previous():将光标移动到上一行\nrs.absolute():将光标定位到某一行\nrs.beforeFirst():直接将光标定位到第一行的前一行\nrs.afterLast():直接将光标移动到最后一行\nrs.getString(ColumnName/Index):通过列名或者列序号取值\nrs.getInt(ColumnName/Index):通过列名或者列序号取值\nrs.getObject(ColumnName/Index):通过列名或者列序号取值\n异常捕获 sql会抛出SQLException异常,我们通过捕获这个来处理异常\n构建步骤 装在驱动程序\n建立数据库连接\n执行SQL语句\n获取执行结果\n清理环境\neg:\npackage com.bean; import java.sql.*; public class Testjdbc { static final String JDBC_DRIVER = \u0026#34;com.mysql.jdbc.Driver\u0026#34;; static final String DB_URL = \u0026#34;jdbc:mysql://localhost/test\u0026#34;; static final String USER = \u0026#34;euraxluo\u0026#34;; static final String PASSWORD = \u0026#34;1234\u0026#34;; public static void test() throws ClassNotFoundException{ Connection conn = null; Statement stmt = null; ResultSet rs = null; //1.装载驱动程序 Class.forName(JDBC_DRIVER); //2.建立数据库物理连接 try { conn = DriverManager.getConnection(DB_URL,USER,PASSWORD); //3.创建statement容器,执行sql语句 stmt = conn.createStatement(); rs = stmt.executeQuery(\u0026#34;select * from user\u0026#34;); //4.获取执行结果 while(rs.next()){ System.out.println(rs.getString(\u0026#34;id\u0026#34;)+\u0026#34;:\u0026#34;+rs.getString(\u0026#34;userName\u0026#34;)); } } catch (SQLException e) { //异常处理 e.printStackTrace(); } finally { //关闭连接,清理环境 try { if(conn != null) conn.close(); if(stmt != null) stmt.close(); if(rs != null) rs.close(); } catch (SQLException e) { e.printStackTrace(); } } } public static void main(String[] args) throws ClassNotFoundException{ test(); } } JDBC 工具类\n资源释放工作的整合 public class JDBCUtil { public static void release(Connection conn,PreparedStatement ptmt,ResultSet rs){ close(rs); close(conn); close(ptmt); } public static void close(ResultSet rs){ try { if(rs != null) rs.close(); } catch (SQLException e) { e.printStackTrace(); }finally { rs = null; } } public static void close(PreparedStatement ptmt){ try { if(ptmt != null) ptmt.close(); } catch (SQLException e) { e.printStackTrace(); }finally { ptmt = null; } } public static void close(Statement st) { try { if (st != null) st.close(); } catch (SQLException e) { e.printStackTrace(); } finally { st = null; } } private static void close(Connection conn){ try { if(conn != null) conn.close(); } catch (SQLException e) { e.printStackTrace(); }finally { conn = null; } } } 驱动防二次注册\nDriverManager.registerDriver(new com.mysql.jdbc.Driver());\nDriver 这个类里面有静态代码块java.sql.DriverManager.registerDriver(new Driver());，一上来就执行了，所以等同于我们注册了两次驱动。 其实没这个必要的。\n//静态代码块 \u0026mdash;\u0026gt; 类加载了，就执行。\n最后形成以下代码即可。 ​\nClass.forName(\u0026quot;com.mysql.jdbc.Driver\u0026quot;);\t也可把我们的数据库驱动的装载放到公共类中 public static Connection getSConn(){ Connection conn = null; try { conn = DriverManager.getConnection(DB_URL2,USER2,PASSWORD); } catch (SQLException e) { e.printStackTrace(); } return conn; } public static Connection getLConn(){ Connection conn = null; try { conn = DriverManager.getConnection(DB_URL,USER,PASSWORD); } catch (SQLException e) { e.printStackTrace(); } return conn; } 创建 properties\n在src底下声明一个文件 jdbc.properties ，里面的内容吐下： JDBC_DRIVER = com.mysql.jdbc.Driver JDBC_DRIVER2 = com.mysql.cj.jdbc.Driver DB_URL = jdbc:mysql://localhost/test DB_URL2 = jdbc:mysql://192.168.23.1:3306/test?serverTimezone=GMT USER = euraxluo USER2 = root PASSWORD = 1234 FTLE_URL = IOTEST.txt 在工具类里面，使用静态代码块，读取属性\nstatic{\ntry { //1. 创建一个属性配置对象 Properties properties = new Properties(); //InputStream is = new FileInputStream(\u0026quot;jdbc.properties\u0026quot;); //对应文件位于工程根目录 ​\n//使用类加载器，去读取src底下的资源文件。 后面在servlet //对应文件位于src目录底下 InputStream is = JDBCUtil.class.getClassLoader().getResourceAsStream(\u0026quot;jdbc.properties\u0026quot;); //导入输入流。 properties.load(is); ​\n//读取属性 driverClass = properties.getProperty(\u0026quot;driverClass\u0026quot;); url = properties.getProperty(\u0026quot;url\u0026quot;); name = properties.getProperty(\u0026quot;name\u0026quot;); password = properties.getProperty(\u0026quot;password\u0026quot;); ​\n} catch (Exception e) { e.printStackTrace(); } } ​\n我们在文档中可以看到一句话,就是说Class.forName(),驱动加载,jdbc4中自动帮我们完成了这一步骤 ","date":"2018-12-20","img":"","permalink":"/posts/java/jdbc1/","series":["JDBC"],"tags":["JDBC"],"title":"JDBC1"},{"categories":["java"],"content":"业务场景1 过滤条件比较弱,一次读出多条记录 读取数据库表中的所有记录 海量数据读取 这些都容易产生内存溢出,为了不使得内存溢出,我们采用游标的方式\n游标:提供一种客户端读取部分服务器端结果集的机制 一个批次的大小为:Fetch Size\n游标的使用 开启游标,DB_URL的处理(加上useCursorFetch=true) eg:\njdbc:mysql://\u0026lt;ip\u0026gt;:\u0026lt;port\u0026gt;/\u0026lt;database\u0026gt;?useCursorFetch=true\n使用PreparedStatement接口\nPreparedStatement接口继承自Statement接口,我们可以使用PreparedStatement替代Statement\n这个接口要求创建时就要传入sql语句,但是这个sql语句,参数格式化.即过滤条件用问号表示,后续再用PreparedStatement.setString()和PreparedStatement.setInt()来设置过滤条件.还可以使用PreparedStatement.setFetchSize()设置游标的大小.即每次从数据库服务端取回记录的数量\neg:\n//使用prepareStatement()接口 ptmt = conn.prepareStatement(\u0026#34;select * from user\u0026#34;); ptmt.setFetchSize(1); rs = ptmt.executeQuery(); 业务场景2 读取的记录字段太大(例如博文) 也是会造成内存溢出,即使读取的记录很少\n流方式 把大字段按照二进制流的方式,分成多个区间,每次只读取一个区间的内容\n流方式的使用 利用ResultSet.getBinaryStream();获取对象流\n生成一个外部文件,把对象流采用边读边写的方式写入文件\neg:\nwhile(rs2.next()){ //5.获取对象流 InputStream in = rs1.getBinaryStream(\u0026#34;userName\u0026#34;); //6.将对象流写入文件 File f = new File(FTLE_URL); OutputStream out = null; try { out = new FileOutputStream(f); int temp = 0; while((temp = in.read()) != -1){//边读边写 out.write(temp); System.out.println(rs2.getString(\u0026#34;id\u0026#34;)+\u0026#34;:\u0026#34;+rs2.getString(\u0026#34;userName\u0026#34;)); System.out.println(\u0026#34;---rs2--\u0026#34;); } in.close(); out.close(); } catch (IOException e) { e.printStackTrace(); } } 业务场景3 大量数据插入操作 数据的插入操作太慢了\n批处理 一次操作多个SQL语句\n利用Statement的addBatch(),实现批处理 addBatch():把多个sql打包成一个Batch()\nexecuteBatch():执行一个Batch\nclearnBatch():清除Batch(),下次使用\neg:\nstmt = conn.createStatement(); for (String item:users){ stmt.addBatch(\u0026#34;insert into user(id,userName) values(\u0026#34;+item.id+\u0026#34;,\u0026#34;+item.user+\u0026#34;)\u0026#34;); } stmt.excuteBatch(); stmt.clearBatch(); 业务场景4 乱码 ###　编码，字符集\n你需要先查看数据库的内部编码\n编码优先级\nServer\u0026lt;Database\u0026lt;Table\u0026lt;column;\njdbc编码设置\n`DB_URL = DB_URL+\u0026ldquo;characterEncoding=utf8\u0026rdquo;\n","date":"2018-12-20","img":"","permalink":"/posts/java/jdbc2/","series":["JDBC"],"tags":["JDBC"],"title":"JDBC2"},{"categories":["java"],"content":"1. execute,executeQuery,executeUdate的区别 JDBCTM中Statement接口提供的execute,executeQuery,executeUdate之间的区别:\nexecuteQuery:\n用于产生单个结果集的语句,例如SELECT语句,使用最多的方法\nexecuteUpdate:\n用于执行INSERT,UPDATE,DELETE语句以及DDL语言,返回值是一个整数,指示受影响的行\nexecute:\n用于执行返回多个结果集,多个更新技术或者两者皆有的语句\n2. SQL注入 防范措施:\n使用动态封装的方式会导致SQL注入的风险,我们应该使用prepareStatement提供的参数化SQL\n严格的数据库权限管理\n仅给web应用访问数据库的最小权限\n避免Drop table等权限\n封装数据库错误\n不要直接将后端数据库异常信息暴露给用户\n对后端遗产信息进行必要的封装,避免用户直接看到后端异常\n机密信息禁止明文存储\n涉密信息需要加密处理\n使用AES_ENCRYPT/AES_DECRYPT加密和解密\n事务:{是并发控制的基本单位,指作为单个逻辑工作单位执行的一系列操作,而这些逻辑工作单元需要满足ACID特性} ACID:原子性,一致性,隔离性,持久性\njdbc事务控制 connection:\n.setAutoCommit('false')开启事务\n.commit()事务执行结束提交事务\n.rollback()回滚到事务开始之前的状态\neg:\ntry{ conn = JDCBUtil.getConnection; conn.setAutoCommit(false); /** *sql语句 * conn.commit(); }catch(){ //如果出错,事务回滚 conn.rollback(); } 事务并发执行 脏读:读取一个事务未提交的更新\n不可重复读:一个失误读取到另一个事务的更新,两次读取的结果包含的行记录的值不一样\n幻读:两次读取的结果包含的行记录不一样\n事务隔离级别 读未提交{允许脏读}\n读提交{不允许脏读,允许重复读}\n重复读{不允许不可重复读,可以幻读}\n串行化{严格的并发控制}{如果有一个连接的隔离级别设置为了串行化 ，那么谁先打开了事务， 谁就有了先执行的权利， 谁后打开事务，谁就只能得着，等前面的那个事务，提交或者回滚后，才能执行。 但是这种隔离级别一般比较少用。 容易造成性能上的问题。 效率比较低。}\n例子 查看隔离级别:select @@tx_isolation\n设置隔离级别为读未更新:set session transaction isolation level read uncommitted;\n开启事务:start transaction\n按效率划分,从高到低:\n读未更新\u0026gt;读已提交\u0026gt;可重复读\u0026gt;可串行化\n按拦截成都,从高到低 可串行化 \u0026gt; 可重复读 \u0026gt; 读已提交 \u0026gt; 读未提交\n默认隔离级别: mySql:可重复读\nOracle:读已提交\n在JDBC中使用事务 Connection\n.getTranactionlsolation()获取事务隔离级别\n.setTransactionlsolation设置事务隔离级别\n##　死锁\nMySql中的锁: |已有锁\\预加锁|X{排它锁}|S{共享锁}|\n|:\u0026ndash;:|:\u0026ndash;:|:\u0026ndash;:|\n|X|冲突|冲突|\n|S|冲突|兼容|\n加锁方式 外部加锁: 由应用程序添加,锁依赖关系较容易分析\n共享锁:select * from table lock in share mode\n排它锁:select * from table for update{解决丢失更新}\n内部加锁 为了实现ACID特性,由数据库系统内部自动添加\n加锁规则繁琐,与SQL执行计划,事务隔离级别,表索引结构有关\nSQL持有锁的情况\n快照读\nInnodb实现了多版本控制(MVCC),支持不加锁快照读\nSelect * from table where\n能够保证同一个Select结果集是一致的\n不能够保证同一个事务内部,Select语句和其他语句的数据一致性,如果业务需要,应该通过外部显式加锁\n分析死锁的原因,排查出死锁的SQL\nshow engine innodb status\n会反馈出发生死锁是等待的SQL\n","date":"2018-12-20","img":"","permalink":"/posts/java/jdbc3/","series":["JDBC"],"tags":["JDBC"],"title":"JDBC3"},{"categories":["architecture design"],"content":"MVC分层模型 DAO 模式初识 PO(persistant object) 持久对象 在o/r映射的时候出现的概念，如果没有o/r映射，没有这个概念存在了。通常对应数据模型(数据库),本身还有部分业务逻辑的处理。可以看成是与数据库中的表相映射的java对象。最简单的PO就是对应数据库中某个表中的一条记录，多个记录可以用PO的集合。PO中应该不包含任何对数据库的操作。\n最形象的理解就是一个PO就是数据库中的一条记录。\n好处是可以把一条记录作为一个对象处理，可以方便的转为其它对象。\nVO(value object) 值对象 通常用于业务层之间的数据传递，和PO一样也是仅仅包含数据而已。但应是抽象出的业务对象,可以和表对应,也可以不,这根据业务的需要.个人觉得同TO(数据传输对象),在web上传递。\n主要对应界面显示的数据对象。对于一个WEB页面，或者SWT、SWING的一个界面，用一个VO对象对应整个界面的值。\nTO(Transfer Object)，数据传输对象 在应用程序不同tie(关系)之间传输的对象\nBO(business object) 业务对象 从业务模型的角度看,见UML元件领域模型中的领域对象。封装业务逻辑的java对象,通过调用DAO方法,结合PO,VO进行业务操作。\nPOJO(plain ordinary java object) 简单无规则java对象 纯的传统意义的java对象。就是说在一些Object/Relation Mapping工具中，能够做到维护数据库表记录的persisent object完全是一个符合Java Bean规范的纯Java对象，没有增加别的属性和方法。我的理解就是最基本的Java Bean，只有属性字段及setter和getter方法！。\nDTO（Data Transfer Object）：数据传输对象 这个概念来源于J2EE的设计模式，原来的目的是为了EJB的分布式应用提供粗粒度的数据实体，以减少分布式调用的次数，从而提高分布式调用的性能和降低网络负载，但在这里，我泛指用于展示层与服务层之间的数据传输对象。\nDAO(data access object) 数据访问对象 是一个sun的一个标准j2ee设计模式，这个模式中有个接口就是DAO，它负持久层的操作。为业务层提供接口。此对象用于访问数据库。通常和PO结合使用，DAO中包含了各种数据库的操作方法。通过它的方法,结合PO对数据库进行相关的操作。夹在业务逻辑与数据库资源中间。配合VO, 提供数据库的CRUD操作\u0026hellip;\n这个大家最熟悉，和上面几个O区别最大，基本没有互相转化的可能性和必要.\n主要用来封装对数据库的访问。通过它可以把POJO持久化为PO，用PO组装出来VO、DTO\nO/R Mapper 对象/关系 映射 定义好所有的mapping之后，这个O/R Mapper可以帮我们做很多的工作。通过这些mappings,这个O/R Mapper可以生成所有的关于对象保存，删除，读取的SQL语句，我们不再需要写那么多行的DAL代码了。\n实体Model(实体模式)\nDAL(数据访问层)\nIDAL(接口层)\nDALFactory(类工厂)\nBLL(业务逻辑层)\nBOF Business Object Framework 业务对象框架\nSOA Service Orient Architecture 面向服务的设计\nEMF Eclipse Model Framework Eclipse建模框架\nDAO模式 分为四层\n客户层{包括Web浏览器,Applet}\nWeb{包括Servlet,JSP}\n业务逻辑{EJB}\n数据持久层{数据库}\nDAO过程\n客户端向服务器发出请求,服务器端由Web层进行接收,交给业务逻辑处理层来处理,对数据的访问由业务逻辑层去访问数据持久层\n简单的例子和结构 com.demo\nutils(工具类,公共类,模板类)\n数据库连接池工具类\nstatic:获取配置\n获取数据源\n获取连接\n获取配置信息\nDAO操作模板类IDUS{不同的impl实现类都可以用}\ndao{大部分都是一些接口}\nexception:定义异常处理的接口\nDAO异常类\n传参异常\u0026hellip;\n等等\n其他异常类\nDAO#接口#:定义IDUS操作,都会和DAO异常有关系\n学生DAO\n教师DAO\n课程DAO\nimpl:DAO接口的具体实现\nDAO的具体实现时,我们先优先采用组合后考虑继承\nStudentDAOImpl\ninsert:定义我们的UpdateSQL模板,从pojo中get字段,交给DAO操作模板类,完成Update操作(把结果交给匿名类)\nselect:QuerySQL模板+字段-\u0026gt;模板类的Query == 完成select(把结果交给匿名类)\n其他实现类\nrefactor:内部匿名类\nRowMapper\n把从数据库中获取的结果(resultSet对象)set到pojo中\n将数据中的每一行数据封装成用户定义的类。\nRowCall\npojo(数据持久层)\n学生\n教师\n课程\n其他表的实体类\ngetXXX\nsetXXX\n表字段\nDAOFactory(工厂类)\n使用单例模式,采取反射机制获取具体的DAO及其实现类的对象,在业务层就直接利用工厂类调用接口,完成业务(对DAO和业务层解耦)\n","date":"2018-11-20","img":"","permalink":"/posts/architecture_design/mvc/","series":null,"tags":["mvc","architecture"],"title":"MVC分层模型"},{"categories":["java"],"content":"jsp Java Server Page\n什么是jsp 从用户角度看待 ，就是是一个网页 ， 从程序员角度看待 ， 其实是一个java类， 它继承了servlet，所以可以直接说jsp 就是一个Servlet.\n为什么会有jsp? html 多数情况下用来显示静态内容 ， 一成不变的。 但是有时候我们需要在网页上显示一些动态数据， 比如： 查询所有的学生信息， 根据姓名去查询具体某个学生。 这些动作都需要去查询数据库，然后在网页上显示。 html是不支持写java代码 ， jsp里面可以写java代码。\njava服务器页面\njsp = html+java+JSP tag 处理流程：浏览器客户端向服务器发起请求，请求对应的jsp文件。然后jsp容器载入jsp文件，并且把jsp文件转化为Servlet(只是简单的把jsp文件改写为servlet语句)，然后jsp容器把servlet编译为可执行的class，然后把请求交给servlet容器，然后web组件就会调用servlet容器，载入对应的servlet实例。在执行时，会产生html页面，嵌入到response中返回给浏览器\n###　jsp与servlet比较\n１.\t侧重点\n​\tjsp侧重于视图\n​\tservlet侧重于逻辑\n２.\tjsp有一些内置对象\n３.\t本质jsp其实是servlet的一种简化\n###　jsp基本语法\njsp声明 \u0026lt;%! int a,b,c; %\u0026gt;\njsp表达式(表达式元素中可以包含任何符合java语言规范的表达式，但是不能使用分号来结束) \u0026lt;%= 表达式%\u0026gt;\neg：输出日期\u0026lt;p\u0026gt;Today's date:\u0026lt;% = (new java.util.Date()).toLocaleString()%\u0026gt;\u0026lt;/p\u0026gt;\njsp脚本(可以包含任意量的java语句,变量,方法或者表达式) \u0026lt;% 代码片段 %\u0026gt;\neg:打印ip\u0026lt;% out.println(\u0026quot;Your IP:\u0026quot;+request.getRemoteAddr()); %\u0026gt;\njsp注释 \u0026lt;-- 这部分是jsp注释 --\u0026gt;\njsp指令\npage指令(定义页面的依赖属性,比如脚本语言,error页面,缓存需求)\ninclude指令(把其他文件包含到这个jsp中)\ntaglib指令(引入自定义的标签库,并且可以指定前缀)\njsp内置对象\nrequest:HttpServletRequest类的实例\nresponse:HttpServletResponse类的实例\nout:PrintWriter类的实例\nsession:HttpSession类的实例\napplication:ServletContext类的实例\nconfig:ServletConfig类的实例\npage:类似于java类中的this关键字\npageContext:PageContext类的实例,提供对JSP页面所有对象以及命名空间的访问\nException:EXception类的对象,代表发生错误的jsp页面中对应的异常对象\njsp指令 1) page指令 表明jsp页面中可以写java代码\ncontentType 其实即使说这个文件是什么类型，告诉浏览器我是什么内容类型，以及使用什么编码\tcontentType=\u0026quot;text/html; charset=UTF-8\u0026quot;\n`text/html MIMEType 这是一个文本，html网页` pageEncoding jsp内容编码\nextends 用于指定jsp翻译成java文件后，继承的父类是谁，一般不用改。\nimport 导包使用的，一般不用手写。\nsession\n值可选的有true or false .\n用于控制在这个jsp页面里面，能够直接使用session对象。\n具体的区别是，请看翻译后的java文件 如果该值是true , 那么在代码里面会有getSession（）的调用，如果是false : 那么就不会有该方法调用，也就是没有session对象了。在页面上自然也就不能使用session了。\nerrorPage 指的是错误的页面， 值需要给错误的页面路径\nisErrorPage 上面的errorPage 用于指定错误的时候跑到哪一个页面去。 那么这个isErroPage , 就是声明某一个页面到底是不是错误的页面。\n2) include指令 包含另外一个jsp的内容进来。\n\u0026lt;%@ include file=\u0026quot;other02.jsp\u0026quot;%\u0026gt;\n背后细节: 把另外一个页面的所有内容拿过来一起输出。 所有的标签元素都包含进来。\n3) taglib指令 \u0026lt;%@ taglib prefix=\u0026quot;\u0026quot; uri=\u0026quot;\u0026quot;%\u0026gt;\n​\turi: 标签库路径\n​\tprefix : 标签库的别名\n​\nJSP 动作标签 \u0026lt;jsp:include page=\u0026#34;\u0026#34;\u0026gt;\u0026lt;/jsp:include\u0026gt; \u0026lt;jsp:param value=\u0026#34;\u0026#34; name=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;jsp:forward page=\u0026#34;\u0026#34;\u0026gt;\u0026lt;/jsp:forward\u0026gt; jsp:include \u0026lt;jsp:include page=\u0026quot;other02.jsp\u0026quot;\u0026gt;\u0026lt;/jsp:include\u0026gt;\n包含指定的页面， 这里是动态包含。 也就是不把包含的页面所有元素标签全部拿过来输出，而是把它的运行结果拿过来。\njsp:forward \u0026lt;jsp:forward page=\u0026quot;\u0026quot;\u0026gt;\u0026lt;/jsp:forward\u0026gt;\n前往哪一个页面。\n\u0026lt;% //请求转发 request.getRequestDispatcher(\u0026#34;other02.jsp\u0026#34;).forward(request, response); %\u0026gt;\tjsp:param 意思是： 在包含某个页面的时候，或者在跳转某个页面的时候，加入这个参数。\n\u0026lt;jsp:forward page=\u0026#34;other02.jsp\u0026#34;\u0026gt; \u0026lt;jsp:param value=\u0026#34;beijing\u0026#34; name=\u0026#34;address\u0026#34;/\u0026gt; \u0026lt;/jsp:forward\u0026gt; 在other02.jsp中获取参数 \u0026lt;br\u0026gt;收到的参数是：\u0026lt;br\u0026gt; \u0026lt;%= request.getParameter(\u0026#34;address\u0026#34;)%\u0026gt; JSP内置对象 所谓内置对象，就是我们可以直接在jsp页面中使用这些对象。 不用创建。\npageContext\nrequest\nsession\napplication\n以上4个是作用域对象 ,\n作用域 表示这些对象可以存值，他们的取值范围有限定。 setAttribute 和 getAttribute\n使用作用域来存储数据\u0026lt;br\u0026gt; \u0026lt;% pageContext.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;page\u0026#34;); request.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;request\u0026#34;); session.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;session\u0026#34;); application.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;application\u0026#34;); %\u0026gt; 取出四个作用域中的值\u0026lt;br\u0026gt; \u0026lt;%=pageContext.getAttribute(\u0026#34;name\u0026#34;)%\u0026gt; \u0026lt;%=request.getAttribute(\u0026#34;name\u0026#34;)%\u0026gt; \u0026lt;%=session.getAttribute(\u0026#34;name\u0026#34;)%\u0026gt; \u0026lt;%=application.getAttribute(\u0026#34;name\u0026#34;)%\u0026gt; 作用域范围大小：\npageContext -- request --- session -- application 四个作用域的区别 pageContext 【PageContext】 作用域仅限于当前的页面。\n还可以获取到其他八个内置对象。\nrequest 【HttpServletRequest】 作用域仅限于一次请求， 只要服务器对该请求做出了响应。 这个域中存的值就没有了。\nsession 【HttpSession】 作用域限于一次会话（多次请求与响应） 当中。\napplication 【ServletContext】 整个工程都可以访问， 服务器关闭后就不能访问了。\n如何使用 1. 取出4个作用域中存放的值。 \u0026lt;% pageContext.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;page\u0026#34;); request.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;request\u0026#34;); session.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;session\u0026#34;); application.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;application\u0026#34;); %\u0026gt; 按普通手段取值\n\u0026lt;%= pageContext.getAttribute(\u0026#34;name\u0026#34;)%\u0026gt; \u0026lt;%= request.getAttribute(\u0026#34;name\u0026#34;)%\u0026gt; \u0026lt;%= session.getAttribute(\u0026#34;name\u0026#34;)%\u0026gt; \u0026lt;%= application.getAttribute(\u0026#34;name\u0026#34;)%\u0026gt; 使用EL表达式取出作用域中的值\n${ pageScope.name } ${ requestScope.name } ${ sessionScope.name } ${ applicationScope.name } 如果域中所存的是数组 \u0026lt;%=String [] a = {\u0026#34;aa\u0026#34;,\u0026#34;bb\u0026#34;,\u0026#34;cc\u0026#34;,\u0026#34;dd\u0026#34;}; pageContext.setAttribute(\u0026#34;array\u0026#34;, a); %\u0026gt; 使用EL表达式取出作用域中数组的值\n${array[0] } , ${array[1] },${array[2] },${array[3] }\n如果域中锁存的是集合 \u0026lt;br\u0026gt;-------------Map数据----------------\u0026lt;br\u0026gt; \u0026lt;%\tMap map = new HashMap(); map.put(\u0026#34;name\u0026#34;, \u0026#34;zhangsna\u0026#34;); map.put(\u0026#34;age\u0026#34;,18); map.put(\u0026#34;address\u0026#34;,\u0026#34;北京..\u0026#34;); map.put(\u0026#34;address.aa\u0026#34;,\u0026#34;深圳..\u0026#34;); pageContext.setAttribute(\u0026#34;map\u0026#34;, map); %\u0026gt; 使用EL表达式取出作用域中集合的值\n${li[0] } , ${li[1] },${li[2] },${li[3] }\n取出Map集合的值 \u0026lt;% Map map = new HashMap(); map.put(\u0026#34;name\u0026#34;, \u0026#34;zhangsna\u0026#34;); map.put(\u0026#34;age\u0026#34;,18); map.put(\u0026#34;address\u0026#34;,\u0026#34;北京..\u0026#34;); map.put(\u0026#34;address.aa\u0026#34;,\u0026#34;深圳..\u0026#34;); pageContext.setAttribute(\u0026#34;map\u0026#34;, map); %\u0026gt; 使用EL表达式取出作用域中Map的值\n${map.name } , ${map.age } , ${map.address } , ${map[\u0026quot;address.aa\u0026quot;] }\n取值细节： 存值(从域中取值,先存) \u0026lt;%//pageContext.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;zhangsan\u0026#34;); session.setAttribute(\u0026#34;name\u0026#34;, \u0026#34;lisi...\u0026#34;); %\u0026gt; \u0026lt;br\u0026gt;直接指定说了，到这个作用域里面去找这个name\u0026lt;br\u0026gt; ${ pageScope.name } \u0026lt;br\u0026gt;//先从page里面找，没有去request找，去session，去application \u0026lt;br\u0026gt; ${ name } \u0026lt;br\u0026gt;指定从session中取值\u0026lt;br\u0026gt; ${ sessionScope.name } 取值方式 如果这份值是有下标的，那么直接使用[]\n\u0026lt;%\tString [] array = {\u0026#34;aa\u0026#34;,\u0026#34;bb\u0026#34;,\u0026#34;cc\u0026#34;} session.setAttribute(\u0026#34;array\u0026#34;,array); %\u0026gt; ${ array[1] } --\u0026gt; 这里array说的是attribute的name 如果没有下标， 直接使用 .的方式去取\n\u0026lt;%\tUser user = new User(\u0026#34;zhangsan\u0026#34;,18); session.setAttribute(\u0026#34;u\u0026#34;, user); %\u0026gt; ${ u.name } , ${ u.age } ##　EL表达式\n是为了简化咱们的jsp代码，具体一点就是为了简化在jsp里面写的那些java代码。\n写法格式 ${表达式 }\n如果从作用域中取值，会先从小的作用域开始取，如果没有，就往下一个作用域取。 一直把四个作用域取完都没有， 就没有显示。\n###　EL表达式 的11个内置对象。\n｀${ 对象名.成员 }｀\n-　pageContext\n作用域相关对象\npageScope\nrequestScope\nsessionScope\napplicationScope\n头信息相关对象\nheader\nheaderValues\n参数信息相关对象\nparam\nparamValues\ncookie\n全局初始化参数\ninitParam JSTL 全称 ： JSP Standard Tag Library jsp标准标签库\n简化jsp的代码编写。 替换 \u0026lt;%%\u0026gt; 写法。 一般与EL表达式配合\n怎么使用 导入jar文件到工程的WebContent/Web-Inf/lib jstl.jar standard.jar\n在jsp页面上，使用taglib 指令，来引入标签库\n注意： 如果想支持 EL表达式，那么引入的标签库必须选择1.1的版本，1.0的版本不支持EL表达式。\n\u0026lt;%@ taglib prefix=\u0026quot;c\u0026quot; uri=\u0026quot;http://java.sun.com/jsp/jstl/core\u0026quot; %\u0026gt;\n常用标签 \u0026lt;c:set\u0026gt;\u0026lt;/c:set\u0026gt; \u0026lt;c:if test=\u0026#34;\u0026#34;\u0026gt;\u0026lt;/c:if\u0026gt; \u0026lt;c:forEach\u0026gt;\u0026lt;/c:forEach\u0026gt; c:set \u0026lt;!-- 声明一个对象name,对象的值 zhangsan,存储到了page(默认),指定是session --\u0026gt; \u0026lt;c:set var=\u0026#34;name\u0026#34; value=\u0026#34;zhangsan\u0026#34; scope=\u0026#34;session\u0026#34;\u0026gt;\u0026lt;/c:set\u0026gt; ${sessionScope.name } c:if 判断test里面的表达式是否满足，如果满足，就执行c:if标签中的输出 ， c:if 是没有else的。\n\u0026lt;c:set var=\u0026#34;age\u0026#34; value=\u0026#34;18\u0026#34; \u0026gt;\u0026lt;/c:set\u0026gt; \u0026lt;c:if test=\u0026#34;${ age \u0026gt; 26 }\u0026#34;\u0026gt; 年龄大于了26岁...\u0026lt;/c:if\u0026gt; \u0026lt;c:if test=\u0026#34;${ age \u0026lt;= 26 }\u0026#34;\u0026gt; 年龄小于了26岁...\u0026lt;/c:if\u0026gt; ------------------------------ \u0026lt;!--定义一个变量名 flag 去接收前面表达式的值，然后存在session域中--\u0026gt; \u0026lt;c:if test=\u0026#34;${ age \u0026gt; 26 }\u0026#34; var=\u0026#34;flag\u0026#34; scope=\u0026#34;session\u0026#34;\u0026gt; 年龄大于了26岁...\u0026lt;/c:if\u0026gt; c:forEach \u0026lt;!--从1 开始遍历到10,得到的结果,赋值给i,并且会存储到page域中,step,增幅为2--\u0026gt; \u0026lt;c:forEach begin=\u0026#34;1\u0026#34; end=\u0026#34;10\u0026#34; var=\u0026#34;i\u0026#34; step=\u0026#34;2\u0026#34;\u0026gt; ${i}\u0026lt;/c:forEach\u0026gt; ----------------------------------------------- \u0026lt;!--items : 表示遍历哪一个对象，注意，这里必须写EL表达式。 var: 遍历出来的每一个元素用user 去接收。 --\u0026gt; \u0026lt;c:forEach var=\u0026#34;user\u0026#34; items=\u0026#34;${list }\u0026#34;\u0026gt; ${user.name } ----${user.age } \u0026lt;/c:forEach\u0026gt; 总结： JSP 三大指令\npage include taglib 三个动作标签\n\u0026lt;jsp:include\u0026gt; \u0026lt;jsp:forward\u0026gt; \u0026lt;jsp:param\u0026gt; 九个内置对象\n四个作用域\npageContext request session application out exception response page config EL ${ 表达式 }\n取4个作用域中的值\n${ name } 有11个内置对象。\npageContext\npageScope\nrequestScope\nsessionScope\napplicationScope\nheader\nheaderValues\nparam\nparamValues\ncookie\ninitParam\nJSTL 使用1.1的版本， 支持EL表达式， 1.0不支持EL表达式\n拷贝jar包， 通过taglib 去引入标签库\n\u0026lt;c:set\u0026gt;\n\u0026lt;c:if\u0026gt;\n\u0026lt;c:forEach\u0026gt;\neg:\n\u0026lt;%@ taglib prefix=\u0026#34;c\u0026#34; uri=\u0026#34;http://java.sun.com/jsp/jstl/core\u0026#34; %\u0026gt; \u0026lt;%@ taglib prefix=\u0026#34;fn\u0026#34; uri=\u0026#34;http://java.sun.com/jsp/jstl/functions\u0026#34; %\u0026gt; \u0026lt;td\u0026gt; \u0026lt;!--fn:contains(stu.hobby,\u0026#39;游泳\u0026#39;)-\u0026gt;boolean 用于确定一个字符串是否包含指定的子串--\u0026gt; \u0026lt;input \u0026lt;c:if test=\u0026#34;${fn:contains(stu.hobby,\u0026#39;游泳\u0026#39;)}\u0026#34;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026#34;checkbox\u0026#34; name=\u0026#34;hobby\u0026#34; value=\u0026#34;游泳\u0026#34;\u0026gt;游泳 \u0026lt;input \u0026lt;c:if test=\u0026#34;${fn:contains(stu.hobby,\u0026#39;篮球\u0026#39;)}\u0026#34;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026#34;checkbox\u0026#34; name=\u0026#34;hobby\u0026#34; value=\u0026#34;篮球\u0026#34;\u0026gt;篮球 \u0026lt;input \u0026lt;c:if test=\u0026#34;${fn:contains(stu.hobby,\u0026#39;足球\u0026#39;)}\u0026#34;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026#34;checkbox\u0026#34; name=\u0026#34;hobby\u0026#34; value=\u0026#34;足球\u0026#34;\u0026gt;足球 \u0026lt;input \u0026lt;c:if test=\u0026#34;${fn:contains(stu.hobby,\u0026#39;看书\u0026#39;)}\u0026#34;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026#34;checkbox\u0026#34; name=\u0026#34;hobby\u0026#34; value=\u0026#34;看书\u0026#34;\u0026gt;看书 \u0026lt;input \u0026lt;c:if test=\u0026#34;${fn:contains(stu.hobby,\u0026#39;写字\u0026#39;)}\u0026#34;\u0026gt;checked\u0026lt;/c:if\u0026gt; type=\u0026#34;checkbox\u0026#34; name=\u0026#34;hobby\u0026#34; value=\u0026#34;写字\u0026#34;\u0026gt;写字 \u0026lt;/td\u0026gt; JSP开发模式 开发模式一:\njavaBean +JSP\n在jsp里面直接写java代码,维护起来比较困难.并且jsp的页面代码会面的臃肿\n开发模式二:\nServlet+javaBean+JSP\n使用的MVC模式:\nM:model 模型层 封装数据,显示数据javaBean java类 EJB\nV:View 视图层 jsp 专注于显示\nC:Controller 控制层 Servlet 接受页面请求,找模型层去处理,然后响应数据给视图层\njavaEE:\n客户端\nWeb层 Servlet/jsp 对应MVC模式的Controller和Vew\n业务逻辑层 javaBean 对应Model\n数据访问层 Dao 对应Mode\n实战 学生信息管理\n与以往(我写过的)的mvc有点区别,在dao与Servlet中增加了Service(业务层)层\n好处：\nDao只针对单一的逻辑，对数据进行操作\nservice是业务层\n业务:分页,应该把这个事给业务处理层\n需求分析\n先写 login.jsp , 并且搭配一个LoginServlet 去获取登录信息。\n创建用户表， 里面只要有id , username 和 password\n创建UserDao, 定义登录的方法\n/** * 该dao定义了对用户表的访问规则 */ public interface UserDao { /** * 这里简单就返回一个Boolean类型， 成功或者失败即可。 * 但是开发的时候，登录的方法，一旦成功。这里应该返回该用户的个人信息 * @param userName * @param password * @return true : 登录成功， false : 登录失败。 */ boolean login(String userName , String password); } 创建UserDaoImpl , 实现刚才定义的登录方法。 public class UserDaoImpl implements UserDao { @Override public boolean login(String userName , String password) { Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { //1. 得到连接对象 conn = JDBCUtil.getConn(); String sql = \u0026#34;select * from t_user where username=? and password=?\u0026#34;; //2. 创建ps对象 ps = conn.prepareStatement(sql); ps.setString(1, userName); ps.setString(2, password); //3. 开始执行。 rs = ps.executeQuery(); //如果能够成功移到下一条记录，那么表明有这个用户。 return rs.next(); } catch (SQLException e) { e.printStackTrace(); }finally { JDBCUtil.release(conn, ps, rs); } return false; } } 在LoginServlet里面访问UserDao， 判断登录结果。 以区分对待\n创建stu_list.jsp , 让登录成功的时候跳转过去。\n创建学生表 ， 里面字段随意。\n定义学生的Dao . StuDao\npublic interface StuDao { /** * 查询出来所有的学生信息 * @return List集合 */ List\u0026lt;Student\u0026gt; findAll(); } 对上面定义的StuDao 做出实现 StuDaoImpl public class StuDaoImpl implements StuDao { @Override public List\u0026lt;Student\u0026gt; findAll() { List\u0026lt;Student\u0026gt; list = new ArrayList\u0026lt;Student\u0026gt;(); Connection conn = null; PreparedStatement ps = null; ResultSet rs = null; try { //1. 得到连接对象 conn = JDBCUtil.getConn(); String sql = \u0026#34;select * from t_stu\u0026#34;; ps = conn.prepareStatement(sql); rs = ps.executeQuery(); //数据多了，用对象装， 对象也多了呢？ 用集合装。 while(rs.next()){ //10 次 ，10个学生 Student stu = new Student(); stu.setId(rs.getInt(\u0026#34;id\u0026#34;)); stu.setAge(rs.getInt(\u0026#34;age\u0026#34;)); stu.setName(rs.getString(\u0026#34;name\u0026#34;)); stu.setGender(rs.getString(\u0026#34;gender\u0026#34;)); stu.setAddress(rs.getString(\u0026#34;address\u0026#34;)); list.add(stu); } } catch (SQLException e) { e.printStackTrace(); }finally { JDBCUtil.release(conn, ps, rs); } return list; } } 在登录成功的时候，完成三件事情。\n查询所有的学生\n把这个所有的学生集合存储到作用域中。\n跳转到stu_list.jsp\nprotected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { //提交的数据有可能有中文， 怎么处理。 request.setCharacterEncoding(\u0026#34;UTF-8\u0026#34;); response.setContentType(\u0026#34;text/html;charset=utf-8\u0026#34;); //1. 获取客户端提交的信息 String userName = request.getParameter(\u0026#34;username\u0026#34;); String password = request.getParameter(\u0026#34;password\u0026#34;); //2. 去访问dao ， 看看是否满足登录。 UserDao dao = new UserDaoImpl(); boolean isSuccess = dao.login(userName, password); //3. 针对dao的返回结果，做出响应 if(isSuccess){ //response.getWriter().write(\u0026#34;登录成功.\u0026#34;); //1. 查询出来所有的学生信息。 StuDao stuDao = new StuDaoImpl(); List\u0026lt;Student\u0026gt; list = stuDao.findAll(); //2. 先把这个集合存到作用域中。 request.getSession().setAttribute(\u0026#34;list\u0026#34;, list); //2. 重定向 response.sendRedirect(\u0026#34;stu_list.jsp\u0026#34;); }else{ response.getWriter().write(\u0026#34;用户名或者密码错误！\u0026#34;); } } 在stu_list.jsp中，取出域中的集合，然后使用c标签 去遍历集合。 \u0026lt;table border=\u0026#34;1\u0026#34; width=\u0026#34;700\u0026#34;\u0026gt; \u0026lt;tr align=\u0026#34;center\u0026#34;\u0026gt; \u0026lt;td\u0026gt;编号\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;姓名\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;年龄\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;性别\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;住址\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;操作\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;c:forEach items=\u0026#34;${list }\u0026#34; var=\u0026#34;stu\u0026#34;\u0026gt; \u0026lt;tr align=\u0026#34;center\u0026#34;\u0026gt; \u0026lt;td\u0026gt;${stu.id }\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${stu.name }\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${stu.age }\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${stu.gender }\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;${stu.address }\u0026lt;/td\u0026gt; \u0026lt;td\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;更新\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;删除\u0026lt;/a\u0026gt;\u0026lt;/td\u0026gt; \u0026lt;/tr\u0026gt; \u0026lt;/c:forEach\u0026gt; \u0026lt;/table\u0026gt; 查询的细节:\n1). 查询出来的数据先放在作用域\n2). 在页面跳转时,应该判断,跳转的页面或者逻辑层能否有能力处理数据\n3). 模糊查询\nString sql = \u0026#34;select * from stu where 1=1 \u0026#34;;//为了保留where List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;String\u0026gt;();//把参数放在list中 //判断有没有姓名， 如果有，就组拼到sql语句里面 if(!TextUtils.isEmpty(sname)){ sql = sql + \u0026#34; and sname like ?\u0026#34;; list.add(\u0026#34;%\u0026#34;+sname+\u0026#34;%\u0026#34;); } //判断有没有性别，有的话，就组拼到sql语句里面。 if(!TextUtils.isEmpty(sgender)){ sql = sql + \u0026#34; and gender = ?\u0026#34;; list.add(sgender); } 分页的拓展 物理分页(真分页)\n优点:内存中的数据量不会太大\n缺点:对数据库访问频繁\n逻辑分页\n一口气把所有数据全部查询出来,然后放在浏览器内存中\n优点:访问速度快\n缺点:如果数据量大,内存溢出\n物理分页: sql:select * from stu limit 5 offset 2 select * from stu 2,5 显示5条,偏移2两条 ","date":"2018-10-29","img":"","permalink":"/posts/java/jsp%E5%AD%A6%E4%B9%A0/","series":["JSP"],"tags":["JSP"],"title":"JSP"},{"categories":["Linux"],"content":"Linux基础 文件基本属性 ll/ls -l 显示一个文件的属性以及文件所属的用户组\neg: [root@www /]# ls -l total 64 dr-xr-xr-x 2 root root 4096 Dec 14 2012 bin dr-xr-xr-x 4 root root 4096 Apr 19 2012 boot …… bin 以d开头,表示这是一个目录\n当为[-]是文件 当为[l]表示为link file 当为[b]表示为可以进行存取的接口设备 当为[c]表示为串行端口设备 接下来以3个为一组,且均为[rwx]的组合,位置次序不变\n[r]表示可读,[w]可写,[x]可执行,如果没有这个权限,就会用[-]代替.\n第0位确定文件类型. 第1-3位确定属主（该文件的所有者）拥有该文件的权限 第4-6位确定属组（所有者的同组用户）拥有该文件的权限 第7-9位确定其他用户拥有该文件的权限 属主:对文件具有所有权的用户\n属组:用户按组分类,一个用户属于一个或者多个组\n所以,文件按照[文件所有者|所有者同组用户|所有着不同组用户]来规定访问权限\n对于root用户,权限对他无效\n2. 更改属性 chgrp [-R] 属组名 文件名 更改文件属组\nsudo chgrp name test\nchown [-R] 属主名 : 属组名 文件名 更改文件属主,也可以同时修改文件属组\nsudo chown 770:euraxluo test\nchmod [-R] xyz 文件或者目录 r:4\nw:2\nx:1\nxyz:\nx = owner = rwx = 4+2+1\ny = group = rwx = 4+2+1\nz = others = rwx = 4+2+1\neg:\nsudo chmod 670 test\n使用符号类型改变文件权限 | | | | | |\n| :\u0026mdash;- | \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;\u0026mdash;\u0026ndash; | \u0026mdash;- | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; |\n| chmod | u=user | +(加入) | r | 文件或者文件名 |\n| | g=group | - (减少) | w | |\n| | o=others | =(设定) | x | |\n| | a=all | | | |\n所以刚刚我们的代码也可以是\nsudo chmod u=rw,g=rwx,o= test\n文件目录的处理 ls [-adl] 目录名: -a:全部文件\n-d:列出目录本身\n-l:详细列出\nls -al ~\ncd 切换目录 cd ~ :回到xxx@www的/xxx下(家目录)\ncd .. 返回上一级\ncd ./xxx 使用相对路径切换\npwd [-P] (显示当前所在的目录) -P:针对联接档,可以显示出真的路径\nmkdir [-mp] 目录名: 创建新的目录\n-m: 配置文件的权限\n-p:你就可以使用 xxx/xxx/xxx的方式创建目录\neg:\nmkdir -m 440 -p test1/test2\nrmdir [-p] 目录名 删除空的目录\n-p:连同上级的空目录也删除\neg:\n$ rmdir -p test1/test2/test3/test4 $ ls -l 总用量 4 drwxrwxr-x 5 euraxluo euraxluo 4096 1月 15 11:14 \u0026#39;Tencent Files\u0026#39; -r--r--r-- 1 770 euraxluo 0 1月 17 15:06 test cp [-adfilprsu] source destination -i:destination已经存在,先询问\n-r:force ,目标已经存在,强制覆盖\n-p:连同文件的属性一起copy过去\n-d:若source是一个连接档(link file),就copy连接档\n-r:递归copy,用于copy目录\n-a:-all=-pdr\n-u:若 destination 比 source 旧才覆盖 destination\n-s:复制成为符号连结档 (symbolic link)，亦即(link)文件；\n-l:不是copy文件本身,而是copy连接档\neg:\n$ cp -sf test test1 $ cat test1 test $ ls -l total 8 drwxrwxr-x 5 euraxluo euraxluo 4096 1月 15 11:14 \u0026#39;Tencent Files\u0026#39; -rwxrwxrwx 1 770 euraxluo 5 1月 17 16:09 test lrwxrwxrwx 1 euraxluo euraxluo 4 1月 17 16:17 test1 -\u0026gt; test sudo apt-get install -f 安装上一个错误 scp [文件名][路径] 拷贝到远程 eg:\nscp test xxx@ip:拷贝到home\nrm [-fir] 文件或目录 -f:force 强制删除\n-i:会询问一下\n-r:递归删除\ncat [-bnT] 从第一行开始显示文件内容\n-b:列出行号\n-n:列出列号\n-T:打印tap\ntac [-bnT] 从最后一行显示\n-b:列出行号\n-n:列出列号\n-T:打印tap\nnl [-bnw] 显示的时候,输出行号\n-b ：指定行号指定的方式，主要有两种：\n-b a ：表示不论是否为空行，也同样列出行号(类似 cat -n)；\n-b t ：如果有空行，空的那一行不要列出行号(默认值)；\n-n ：列出行号表示的方法，主要有三种：\n-n ln ：行号在荧幕的最左方显示；\n-n rn ：行号在自己栏位的最右方显示，且不加 0 ；\n-n rz ：行号在自己栏位的最右方显示，且加 0 ；\n-w ：行号栏位的占用的位数。\nmore 一页一页显示\nless 和more一样,并且可以向前翻页\nhead [-n] 显示头几行\n-n:number\ntail [-n] 显示尾行\n-n:number\nman {命令} 查看命令的文档\nlinux 链接 1.硬连接\n硬连接指通过索引节点来进行连接,两个文件具有完全一样的地位\n删除原始文件,硬链接文件不受影响\n主要用于关键文件的保护\n2.软连接\n软链接文件类似于 Windows 的快捷方式,保存的是原始文件的位置信息.\n删除原始文件,软链接文件无效\n文件系統的索引 在 Linux 的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在 Linux 中，多个文件名指向同一索引节点是存在的.硬连接通过索引实现\n用户管理 useradd [-cdgsu] 用户名 添加新的用户:\n-c comment\n-d 目录 指定用户主目录，若目录不存在,使用-m选项，来创建。\n-g 用户组 指定用户所属的用户组。\n-G 用户组，用户组 指定用户所属的附加组。\n-s Shell文件 指定用户的登录Shell。\n-u 用户号 指定用户号，同时-o，则可以使用其他用户的标识号\neg:\n$ useradd –d /usr/test -m test\nuserdel [-r] 用户名 删除账号\n-r:同时删除用户的主目录\nusermod [-cdmGusol] 用户名 参数与useradd一样\n-l:制定新的用户名,就是更改名字\npasswd [-ludf] 用户名 修改用户的pwd\n-l:锁定口令，即禁用账号。\n-u:口令解锁。\n-d: 使账号无口令。\n-f: 强迫用户下次登录时修改口令。\n用户组管理 groupadd [-go] 用户组 -g:指定新用戶組的GID\n-o:一般和-g一起使用，表示新的用戶組可以和別人相同\ngroupdel 用户组 刪除一個用戶組\ngroupmod [-gon] 用戶組 -g:设置GID\n-o:与groupadd相同\n-n:更名\nnewgrp [目标用户组名] 用户可以在登录后，使用命令newgrp切换到其他用户组\neg:$ newgrp root\n用户标识号 是一个整数，系统内部用它来标识用户。\n一般情况下它与用户名是一一对应的。如果几个用户名对应的用户标识号是一样的，系统内部将把它们视为同一个用户，但是它们可以有不同的口令、不同的主目录以及不同的登录Shell等。\n0是超级用户root的标识号，1～99由系统保留，作为管理账号，普通用户的标识号从100开始。在Linux系统中，这个界限是500。\n/etc/shadow /etc/shadow中的记录行与/etc/passwd中的一一对应，它由pwconv命令根据/etc/passwd中的数据自动产生\n它的文件格式与/etc/passwd类似，由若干个字段组成，字段之间用\u0026quot;:\u0026ldquo;隔开。这些字段是：\n登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志\n磁盘管理 df [-ahikHTm] 目录或用户名 -a:all,列出全部\n-k:用kb显示\n-m:用mb显示\n-h:自己显示\n-H:用M=1000k来显示\n-T:显示文件系统的分区名\n-i:用inode(索引节点)的数量显示\ndu [-ahskm] 目录或用户名 参数和df一样\n-s:列出总量,不列出占用容量\n-S:不包括子目录的总计\nfdisk [-l] 磁盘名 输出各装置的分区\nmkfs [-t] 装置文件名 格式化这个分区\neg:格式化为fat32\n$ mkfs.fat -F32 /dev/sda1\nmount [-t 文件系统] [-L Label名] [-o 额外选项] [-n] 装置文件名 挂载点 挂載分區\neg:mount /dev/sda1 /mnt/boot/EFI\nunmount [-fn] 装置文件名|挂载点 卸载分区\n-f:強制卸載\n-n:不升級/etc/mtab的情況下卸载\nVI/VIM 下载: sudo apt-get install vim\n命令模式 刚刚启动时,或者在输入模式下`ESC`,进入命令模式. i:插入,进入输入模式 I:到行首插入 a:附加 A:到行尾附加 s:删除字符并插入 S:删除行并插入 x:删除当前光标所在的字符 r:替换当前光标所在的字符字符 R:替换模式:会把当前和后面的字符都替换 e|E:跳到这个词的末尾一个字符上 w|E:跳到下一个词的开头一个字符上 o:在这字符前分段 O:在这字符后分段 Y:拷贝行 p:在这字符后粘贴行 P:在这字符前粘贴行 (\u0026gt;\u0026lt;^v:表示方向键) d 动作:删除的范围 eg: d l|\u0026gt;:删除这个字符 d h|\u0026lt;:删除这个字符前面的字符 d k|^:删除这个字符所在行和上一行 d j|v:删除这个字符所在行和下一行 d H:删除屏幕顶行到这个字符 d L:删除屏幕尾行到这个字符 D:从这字符一直删除到行尾 \u0026gt;:缩进 \u0026lt;:反缩进 :切换到底线模式 (:跳转到句首 ):跳转到句尾巴 {:跳转到段首 }:跳转到段尾 V:让这一行高亮 输入模式 iI,aA,sS,RC进入\n字符按键以及Shift组合，输入字符\nENTER，回车键，换行\nBACK SPACE，退格键，删除光标前一个字符\nDEL，删除键，删除光标后一个字符\n方向键，在文本中移动光标\nHOME/END，移动光标到行首/行尾\nPage Up/Page Down，上/下翻页\nInsert，切换光标为输入/替换模式，光标将变成竖线/下划线\nESC，退出输入模式，切换到命令模式\n底线模式 :w(保存)\n:q(退出)\n:q!(不保存退出)\n:e f(打開文件f)\n:h(幫助)\n:new(新建文件 in vim)\n詳見： 問題： vim使用很不熟悉\n","date":"2018-10-29","img":"","permalink":"/posts/shell/linux%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/","series":["Linux"],"tags":["Linux"],"title":"Linux基础"},{"categories":["Java"],"content":"MyBatis 一个ORM框架,(不直接建立java对象到关系数据库表数据的映射,而是建立对对象的操作方法到SQL的映射)支持自定义SQL,存储过程和高级映射的持久化框架\n使用XML或者注解配置\n能够映射基本数据元素,接口,Java对象到数据库\nORM(Object/Relation Mapping) 作用:持久化类与数据库表之间的映射关系,让我们对持久化对象的操作自动转换成对关系数据库操作\n通过映射,我们把关系数据库中的每一行都映射为对象,数据库的每一列就映射成了对象的属性\n##　三层架构：\n１.\t接口层(数据查询接口,数据新增接口,数据更新接口,数据删除接口,获取配置接口)\n２.\t数据处理层(参数映射,SQL解析,SQL执行,结果映射)\n３.\t基础支撑层(连接管理，事务管理，配置加载，缓存处理)\n工作流机制: 根据XM(xml中定义了连接的地址,以及对象和SQL的映射和关系)L或者注解加载SQL语句,参数映射,结果映射到内存\n应用程序调用API传入参数和SQL ID\nMyBatis 自动生成SQL语句完成数据库访问,转换执行结构返回应用程序\n例如,完成一个数据库查询 加载配置文件 应用配置文件\n关联映射文件\nsqlSession 生成SqlSessionFactory\n获取SqlSession\n执行查询 Session 执行SQL\n","date":"2018-10-29","img":"","permalink":"/posts/java/mbatis%E5%9F%BA%E7%A1%80/","series":["MyBatis"],"tags":["MyBatis"],"title":"MyBatis"},{"categories":["Python"],"content":"Python构建开源软件 python的构建工具setup.py的应用场景 一般在安装python模块的时候,我们会使用pip install 模块名进行在线安装,会安装依赖包,或者python setup.py install通过源码在本地安装,不会安装依赖包\n在做一个开源项目的时候遇到了一些问题: 我的程序需要用到python的Redis等模块,以及自己写的入口文件run.py,怎么实现可以在服务器上方便的发布,也就是说,可以让依赖和自己写的程序一起安装,同时将自己写的模块变成一个可执行文件\n###　setup.py\n示例以及注释:\nfrom setuptools import setup, find_packages setup( name = \u0026#34;proxy-pool\u0026#34;, #包名 version = \u0026#34;1.0.0\u0026#34;, #版本 keywords = (\u0026#34;poxypool\u0026#34;, \u0026#34;redis\u0026#34;),#关键词列表 description = \u0026#34;test version proxy pool\u0026#34;, #程序的简单介绍 long_description = \u0026#34;A proxy pool project modified from Germey/ProxyPool\u0026#34;, #程序的详细介绍 url = \u0026#34;https://github.com/Euraxluo/ProxyPool\u0026#34;, #程序的官网 download_url = \u0026#34;https://github.com/Euraxluo/ProxyPool.git\u0026#34; #程序的下载地址 author = \u0026#34;Euraxluo\u0026#34;, #作者 author_email = \u0026#34;euraxluo@qq.com\u0026#34;, #程序作者的邮箱 #maintainer 维护者 #maintainer_email 维护者的邮箱地址 packages=[ \u0026#39;proxy-pool\u0026#39; ], py_modules = [\u0026#39;run\u0026#39;],#需要打包的python文件列表 include_package_data = True, platforms = \u0026#34;any\u0026#34;, #程序适用的软件平台列表 install_requires = [#需要安装的依赖包 \u0026#39;aiohttp\u0026#39;, \u0026#39;requests\u0026#39;, \u0026#39;flask\u0026#39;, \u0026#39;redis\u0026#39;, \u0026#39;pyquery\u0026#39; ], entry_points = { #动态发现服务和插件 \u0026#39;console_scripts\u0026#39;: [ #指定命令行工具的名称 \u0026#39;test = test.help:main\u0026#39; #工具包名=程序入口 ] }, license = \u0026#34;apache 2.0\u0026#34;, #程序的授权信息 zip_safe=False,#安装为文件夹还时打包为egg文件 classifiers = [#程序所属的分类列表 \u0026#39;Environment :: Console\u0026#39;, \u0026#39;Programming Language :: Python :: 3.6\u0026#39;, \u0026#39;Programming Language :: Python :: Implementation :: CPython\u0026#39; ] #data_files 打包时需要打包的数据文件,如图片,配置文件等 #package_dir = {\u0026#39;\u0026#39;:\u0026#39;lib\u0026#39;},#表示root pkg的模块都在lib目录中 # requires 定义依赖哪些模块 # provides定义可以为哪些模块提供依赖 #scripts = [],#安装时需要执行的脚本列表 #packages = find_packages(exclude=[\u0026#39;*.tests\u0026#39;]), #需要处理的包目录,可以手动增加手动增加packages参数很容易，刚刚我们用到了这个函数，它默认在和setup.py同一目录下搜索各个含有 __init__.py的包。其实我们可以将包统一放在一个src目录中，另外，这个包内可能还有aaa.txt文件和data数据文件夹,也可以使用exclude排除一些特定的包 ) requirement python项目中必须包含一个 requirements.txt 文件，用于记录所有依赖包及其精确的版本号。以便新环境部署\n示例:\naiohttp\u0026gt;=1.3.3 Flask\u0026gt;=0.11.1 redis\u0026gt;=2.10.5 requests\u0026gt;=2.13.0 pyquery\u0026gt;=1.2.17 生成:\npip freeze \u0026gt; requirements.txt\n也可以直接pip freeze查看列表\n安装:\n可以使用pip安装requeirments.txt的依赖:\npip install -r requirements.txt\nLICENSE文件的生成 在开源仓库中选择create files,取名为LICENSE,会让你选择开源协议,最后选好后创建文件即可\nlisence文件也可以用来对项目进行限制和控制\n##　.gitignore\n一般来说每个Git项目中都需要一个“.gitignore”文件，这个文件的作用就是告诉Git哪些文件不需要添加到版本管理中\n添加规则\n例子：\n*.vscode *.pyc *.db venv build/ #忽略build/目录下的所有文件 /.idea #仅仅忽略项目根目录下的.idea文件 如果我们要排除某些文件呢？\n过滤规则\n加一个｀!｀，比如我们需要排除掉/mtk/文件夹中的/mtk/test.txt\n/mtk/ !/mtk/test.txt .travis.yml yaml语法的写出来的配置文件，用来描述如何持续构建，支持各种语言，各种系统环境\n示例:\nlanguage: python python: - \u0026#34;3.6\u0026#34; services: - redis-server script: - python3 setup.py install - cd tests - python3 test_api.py - python3 test_db.py - python3 test_schedule.py python 命名规范 文件名 全小写,可使用下划线\n包 应该是简短的、小写的名字。如果下划线可以改善可读性可以加入。如mypackage。\n模块 与包的规范同。如mymodule。\n类 总是使用首字母大写单词串。如MyClass。内部类可以使用额外的前导下划线。\n函数\u0026方法 函数名应该为小写，可以用下划线风格单词以增加可读性。如：myfunction，my_example_function。\n注意：混合大小写仅被允许用于这种风格已经占据优势的时候，以便保持向后兼容。\n函数和方法的参数\n总使用“self”作为实例方法的第一个参数。总使用“cls”作为类方法的第一个参数。\n如果一个函数的参数名称和保留的关键字冲突，通常使用一个后缀下划线好于使用缩写或奇怪的拼写。\n全局变量 对于from M import *导入语句，如果想阻止导入模块内的全局变量可以使用旧有的规范，在全局变量上加一个前导的下划线。\n注意:应避免使用全局变量\n变量 变量名全部小写，由下划线连接各个单词。如color = WHITE，this_is_a_variable = 1\n注意：\n1.不论是类成员变量还是全局变量，均不使用 m 或 g 前缀。\n2.私有类成员使用单一下划线前缀标识，多定义公开成员，少定义私有成员。\n3.变量名不应带有类型信息，因为Python是动态类型语言。如 iValue、names_list、dict_obj 等都是不好的命名。\n常量 常量名所有字母大写，由下划线连接各个单词如MAX_OVERFLOW，TOTAL。\n异常 以“Error”作为后缀。\n缩写 命名应当尽量使用全拼写的单词，缩写的情况有如下两种：\n1.常用的缩写，如XML、ID等，在命名时也应只大写首字母，如XmlParser。\n2.命名中含有长单词，对某个单词进行缩写。这时应使用约定成俗的缩写方式。\n例如：\nfunction 缩写为 fn\ntext 缩写为 txt\nobject 缩写为 obj\ncount 缩写为 cnt\nnumber 缩写为 num，等。\n前导后缀下划线\n一个前导下划线：表示非公有。\n一个后缀下划线：避免关键字冲突。\n两个前导下划线：当命名一个类属性引起名称冲突时使用。\n两个前导和后缀下划线：“魔”（有特殊用图）对象或者属性，例如__init__或者__file__。绝对不要创造这样的名字，而只是使用它们。\n注意：关于下划线的使用存在一些争议。\n特定命名方式 主要是指 xxx 形式的系统保留字命名法。项目中也可以使用这种命名，它的意义在于这种形式的变量是只读的，这种形式的类成员函数尽量不要重载。如\nclass Base(object):\ndef init(self, id, parent = None):\nself.id = id\nself.parent = parent\ndef message(self, msgid):\n","date":"2018-10-29","img":"","permalink":"/posts/python/python%E6%9E%84%E5%BB%BA%E5%BC%80%E6%BA%90%E8%BD%AF%E4%BB%B6/","series":["Python"],"tags":["Python"],"title":"Python构建开源项目"},{"categories":["读书笔记"],"content":"Unix/Linux 编程實踐教程 ##　什麼是系統編程\n系统资源 处理器 程序由指令构成,处理器是执行指令的硬件设备,一个系统中可能有多个处理器,内核可以安排一个程序何时开始开始执行,暂时停止,恢复执行,终止执行\n输入输出 程序中所有的输入输出都必须流经内核,集中处理,保证了系统的正确性,安全性,有效性\n进程管理 每个程序执行都必须有自己的资源,内核可以新建进程,中止进程,进程调度\n内存 程序必须被装载到内存中才能运行,内核可以对进程进行管理,在程序需要的时候给程序分配内存,当程序不需要时,回收内存,还可以保证内存不被其他进程非法访问.\n设备 各种设备的操作方式不相同,通过内核,可以屏蔽這種差异,使我们对设备的操作简单统一\n计时器 程序的工作和时间有关,内核可以通过系统调用向应用程序提供计时器服务\n进程间通信 内核可以让进程之间进行通信\n网络 内核可以让不同主机上的不同进程进行通信\nbc:Unix计算器,可以接受逆波兰表达式 通过他的与处理器dc,转换为逆波兰表达式,通过pip给dc\n和web服务类似,web服务器作为預处理器,浏览器作为前端显示\nmore: more filename,分页显示file内容\ncommand | more:分页显示command命令\nmore \u0026lt; filename:分页+重定向\n自己写一个more\n//more command #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;stdlib.h\u0026gt; #define PAGELEN 24 #define LINELEN 512 void do_more(FILE* ); int see_more(FILE*,int ); int sum_size = 0; int main(int ac,char *av[]) { FILE* fp; if(ac == 1) do_more(stdin); else while(--ac) { if((fp = fopen(*++av,\u0026#34;r\u0026#34;)) != NULL) { fseek(fp,0L,SEEK_END); /*利用fseek函数将指针定位在文件结尾的位置*/ sum_size=ftell(fp); /*利用ftell函数返回指针相对于文件开头的位置，以字节计算*/ printf(\u0026#34;\\n the type of file is : %d\\n\u0026#34;,sum_size); /*进行输出文件总大小*/ fseek(fp,0L,SEEK_SET); /*将fp设置文件开始的位置*/ do_more(fp); fclose(fp); } else exit(1); } return 0; } void do_more(FILE* fp) { /* read PAGELEN lines, then call see_more() for further instructions */ char line[LINELEN]; int num_of_lines = 0; int see_more(FILE*,int),reply; FILE* fp_tty; fp_tty = fopen(\u0026#34;/dev/tty\u0026#34;,\u0026#34;r\u0026#34;); if(fp_tty == NULL) exit(1); while(fgets(line, LINELEN,fp)) { if(num_of_lines == PAGELEN) { int cur_size=ftell(fp); /*利用ftell函数返回指针相对于文件开头的位置，以字节计算*/ int per= (int)100* cur_size/sum_size; //计算当前占用比例。 reply =see_more(fp_tty,per); if(reply == 0 ) break; num_of_lines -= reply; } if(fputs(line,stdout) == EOF) exit(1); num_of_lines++; } } int see_more(FILE* cmd,int per) { /* print message, wait for response, return # of lines to advance q means no, space means yes CRmeans one line */ int c; system(\u0026#34;stty -icanon\u0026#34;);//关闭缓冲区，输入字符无需回车直接接受 printf(\u0026#34;\\033[7m more?##%d##\\033[m\u0026#34;,per); //实现反白 while((c=getc(cmd))!=EOF) { if(c == \u0026#39;q\u0026#39;) return 0; if(c == \u0026#39; \u0026#39;) return PAGELEN; if(c == \u0026#39;\\n\u0026#39;) return 1; } } who 查看有哪些用户在使用这台电脑\n自己写一个who:\n需要的步骤:\n#直接运行,了解大致的功能 who #查看文档 man who #可以看到,大致放在utmp这个文件中 #根据关键词查看帮助 man -k utmp #结果可以看到在帮助手册的第3节 man 3 utmp #结果中,可以知道这是一个数据结构,定义在某个.h文件中 #从文件中读取数据结构 man -k file | egrep read #于是我们找到了read(),进去看如何调用 #顺便,他还介绍了close()和open() #思路: #从utmp中读取我们需要的信息,循环输出 #关于怎么输出时间 man -k time | egrep transform #结果你应该可以看到ctime man 3 ctime ## 开始写吧: who:\n#include\u0026lt;stdlib.h\u0026gt; #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;utmp.h\u0026gt; #include\u0026lt;fcntl.h\u0026gt; #include\u0026lt;unistd.h\u0026gt; #include\u0026lt;time.h\u0026gt; #define SHOWHOST #define USER_PROCESS 7 void showtime(long); void show_info(struct utmp * utbufp){ if(utbufp-\u0026gt;ut_type != USER_PROCESS) return; printf(\u0026#34;%-8.8s\u0026#34;,utbufp-\u0026gt;ut_name); printf(\u0026#34; \u0026#34;); printf(\u0026#34;%-8.8s\u0026#34;,utbufp-\u0026gt;ut_line); printf(\u0026#34; \u0026#34;); showtime(utbufp-\u0026gt;ut_time); #ifdef SHOWHOST if(utbufp-\u0026gt;ut_host[0] != \u0026#39;\\0\u0026#39;) printf(\u0026#34;(%s)\u0026#34;,utbufp-\u0026gt;ut_host); #endif printf(\u0026#34;\\n\u0026#34;);\t} void showtime(long timeval){ char *cp; cp = ctime(\u0026amp;timeval); printf(\u0026#34;%12.12s\u0026#34;,cp+4); } int main(){ struct\tutmp current_record; int utmpfd; int reclen = sizeof(current_record); if((utmpfd = open(UTMP_FILE,O_RDONLY)) == -1){ perror(UTMP_FILE); exit(1);} while (read(utmpfd,\u0026amp;current_record,reclen) == reclen) show_info(\u0026amp;current_record); close(utmpfd); return 0; } #使用缓冲区的who\n#include\u0026lt;stdlib.h\u0026gt; #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;utmp.h\u0026gt; #include\u0026lt;fcntl.h\u0026gt; #include\u0026lt;unistd.h\u0026gt; #include\u0026lt;time.h\u0026gt; #define SHOWHOST #define USER_PROCESS 7 #define NRECS 16 #define NULLUT ((struct utmp*)NULL) #define UTSIZE (sizeof(struct utmp)) static char utmpbuf[NRECS * UTSIZE]; static NULLUT () void showtime(long); void show_info(struct utmp * utbufp){ if(utbufp-\u0026gt;ut_type != USER_PROCESS) return; printf(\u0026#34;%-8.8s\u0026#34;,utbufp-\u0026gt;ut_name); printf(\u0026#34; \u0026#34;); printf(\u0026#34;%-8.8s\u0026#34;,utbufp-\u0026gt;ut_line); printf(\u0026#34; \u0026#34;); showtime(utbufp-\u0026gt;ut_time); #ifdef SHOWHOST if(utbufp-\u0026gt;ut_host[0] != \u0026#39;\\0\u0026#39;) printf(\u0026#34;(%s)\u0026#34;,utbufp-\u0026gt;ut_host); #endif printf(\u0026#34;\\n\u0026#34;);\t} void showtime(long timeval){ char *cp; cp = ctime(\u0026amp;timeval); printf(\u0026#34;%12.12s\u0026#34;,cp+4); } int main(){ struct\tutmp current_record; int utmpfd; int reclen = sizeof(current_record); if((utmpfd = open(UTMP_FILE,O_RDONLY)) == -1){ perror(UTMP_FILE); exit(1);} while (read(utmpfd,\u0026amp;current_record,reclen) == reclen) show_info(\u0026amp;current_record); close(utmpfd); return 0; } cp cp命令把源文件复制到目标文件，如果目标文件不存在，就创建这个命令，如果已经存在就覆盖\n创建和重写文件：\n系统调用函数creat：\nint fd = creat(char *filename,mode_t mode)\nmode:如果内核成功创建了file，则把mode设置为许可位\n系统调用函数write：\nssize_t result = write(int fd,void *buf,size_t amt)\n提高文件i/o效率的方法：使用缓冲 系统调用是需要时间的：\n当这个程序去调用read时，read的代码在内核中。\n系统调用开销大的原因：\n内核和程序之间不只是会传输数据，还会在root模和用户模式之间来回切换\n","date":"2018-10-29","img":"","permalink":"/posts/shell/linux%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B5/","series":["读书笔记"],"tags":["读书笔记"],"title":"Unix/Linux编程实践1"},{"categories":["message queue"],"content":"RbbitMQ 学习笔记 AMQP协议组成部分\nModule layer：协议最高层，定义了供客户端使用的命令 Session layer：中间层，负责将客户端的命令发送给服务端，再将服务端的命令返回给客户端，为客户端和服务端之间提供可靠的通信 Transport layer：最底层，包括二进制流的传输，帧处理，信道复用，错误检测 生产者使用AMQP的过程 Producter 建立连接 开启通道 发送消息 释放资源 消费者使用AMQP的过程 Consumer 建立连接 开启通道 准备接受消息 发送确认 释放资源 AMQP命令和javaAPI的对应 Connection.Start : factory.newConnection 新建连接 Connection.close : connection.close 关闭连接 Channel.Open : channel.openChannel 开启信道 Channel.close : channel.close 关闭信道 Exchange.Declare : channel.exchangeDeclare 声明交换器 Exchange.Delete : channel.exchangeDelete删除交换器 Exchange.Bind : channel.exchangeBind 交换器和交换器绑定 Exchange.Unbind : channel.exchangeUnbind 交换器和交换器解绑 Queue.Declare : channel.queueDeclare 声明队列 Queue.Bind : channel.queueBind 队列和交换机绑定 Queue.Purge : channel.queuePurge 清除队列 Queue.Delete : channel.queueDelect 删除队列 Queue.Unbind : channel.queueUnbind 队列和交换机解绑 Basic.Qos : channel.basicQos 设置未被确认消费的个数 Basic.Consume : channel.basicConsume 消费消息（推） Basic.Cancel : channel.basicCancel 取消 Basic.Publish : channel.basicPublish 发送消息 Basic.Get : channel.basicGet 消费消息（拉） Basic.Ack : channel.basicAck 确认消息 Basic.Reject : channel.basicReject 拒绝单条消息 Basic.Recover : channel.basicRecover 请求Broker重新发送未被确认的消息 Tx.Select : channel.txSelect 事务开启 Tx.Commit : channel.txCommit 事务提交 Tx.Rollback : channel.txRollback,事务回滚\n在rabbitMQ的使用中分为\nProducer（生产者）、Exchange、Binding、Queue、Consumer（消费者）\n其中在消息路由的过程中还涉及以下关系\nRouting Key、Binding Key、Exchange Type 的关系\n客户端连接过程: 客户端连接到消息服务器，打开一个channel 客户端声明一个exchange，并设置相关属性 客户端声明一个queue，并设置相关属性 客户端使用routing key，在exchange和queue之间建立好绑定关系 客户端投递消息到exchange 客户端从指定的queue中消费消息 Item Comment Exchange 消息交换机，它指定消息按什么规则，路由到哪个队列 Queue 消息队列，每个消息都会被投入到一个或多个队列 Binding 绑定，它的作用就是把exchange和queue按照路由规则绑定起来 Routing Key 路由关键字，exchange根据这个关键字进行消息投递 Vhost 虚拟主机，可以开设多个vhost，用作不同用户的权限分离 Producer 消息生产者，就是投递消息的程序 Consumer 消息消费者，就是接受消息的程序 Channel 消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务 #channel 会话通道，与客户端通过socket建立长连\n发送消息过程： 生产者和Broker建立TCP链接 生产者和Broker建立通道 生产者通过通道将消息发送到Broker，有Exchange将消息进行转发 Exchange将消息转发指定的Queue 接受消息过程： 消费者和Broker建立TCP链接 消费者和Broker建立通道 消费者监听指定的Queue 当有消息到达Queue时，Broker默认将消息推送给消费者 消费者接收到消息 ack回复 Channel信道： Channel是创建于连接对象之上的虚拟连接，每一个信道都分配一个唯一Id，由信道完成生产者或消费者和Broker之间的连接\n为什么需要channel 为什么有TCP连接对象，还需要Channel信道，那是因为每一次TCP的创建都非常消耗资源，RabbitMQ采用一个NIO机制（io多路复用）进行通信连接达到减少性能消耗的目的\nRabbitMQ 工作模式 Work queuees工作队列 Publish、Subscribe 发布订阅模式 Routing 路由模式 Topics 通配符模式 Header Hearder转发器 RPC远程调用模式 Work queues work queues 和hello world程序相比，多了一个消费者 也就是多个消费者共同消费同一个队列中的消息\n特点： 一个生产者讲消息发送给一个队列 多个消费者共同监听一个队列的消息 消息不能被重复消费 4.rabbit 采用轮询的方式将消息平均发送给消费者 Publish/Subscribe 特点： 一个生产者将消息发给交换机 与交换机绑定得有多个queue，每个消费者监听自己的队列 生产者讲消息发送给交换机，由交换机讲消息转发给绑定词交换机的每个队列，每个绑定交换机的队列都将收到该消息 如果消息发给没有绑定队列的交换机上，消息将会丢失 与work queue 模式的区别 publish、subscribe可以定义一个交换机绑定多个队列，一个消息可以发送给多个队列 work queues无需定义交换机，一个消息只能发送给一个队列 pub/sub比work queues的功能更强大，pub/sub也可以将多个消费者监听同一个队列实现work queues的功能 交换机的类型为fanout 使用场景: 一个消息、任务。需要同时被多个客户端获取/执行\nRouting 特点： 每个消费者监听自己的队列，并且设置routingkey，可以设置多个routingkey。我看范例里面是举得log日志的例子。一个队列监听所有级别（error，info）的routingkey。另一个队列可能是告警信息业务绑定的队列，他会设置（error）的routingkey 生产者将消息发送给交换机，发送消息时需要指定routingkey，由交换机根据routingkey来转发消息到指定的队列 生产者将消息发给交换机，发送消息时需要指定routingkey的值，交换机来判断该routingkey的值和哪个队列的routingkey相等，如果相等则将该消息转发给该队列 Routing与pub/sub的区别 Pub/Sub模式在绑定交换机时不需要指定routingkey，交换机会将消息同时发送给绑定自己的多个队列。 Routing模式要求队列在绑定交换机时指定routingkey，会在exchange那里做一层direct，有选择的将消息发送到，rroutingkey对应的队列中去 交换机类型为direct Topics 特点： 每个消费者监听自己的队列，并且设置带通配符的routingkey 符号：① #，匹配一个或者多个词，info.# 可以匹配info.s,info.a。②*只能匹配一个词 一个交换机可以绑定等多个队列，每个队列需要设置一个或者多个带通配符的routingkey。 生产者将消息发送给交换机，交换机根据routingkey的值来匹配，匹配时采用通配符匹配 与Routing的区别 Routing是完全匹配，Topics是通配符匹配 交换机类型为topic Header header模式与routing模式不同的是，header模式取消routingkey，使用header中的key、value 匹配队列\nRPC RPC即客户端远程调用服务端的犯法，使用MQ可以实现RPC的远程异步调用，基于Direct交换机实现 流程如下：\n客户端既是消费者也是生产者，向RPC请求队列发送RPC调用信息，同时会监听RPC响应队列 服务端监听RPC请求队列的消息，收到消息后执行服务端的方法，得到方法返回的结果 服务端讲RPC方法的结果发送到RPC响应队列 特点： 可以通过消息队列实现双方服务的异步通信\npython 例程： \u0026#34;\u0026#34;\u0026#34; 整体实现基于同步模式： - BlockingConnection 阻塞/连接 \u0026gt; 该适配器虽然是同步阻塞适配器，但是依然支持异步RPC特性 \u0026gt; 组成： BlockingConnection 和 BlockingChannel \u0026gt; 异步适配器 \u0026gt; 1.Select Connection Adapter 没有第三方依赖包的异步模式 \u0026gt; 2.Tornado Connection Adapter 基于Tornado 的异步IO请求模式 \u0026gt; 3.Twisted Connection Adapter 基于Twisted’的异步IO请求模式 \u0026#34;\u0026#34;\u0026#34; # coding:utf8 from common.config.dev import RABBITMQ_HOST,RABBITMQ_PASS,RABBITMQ_PORT,RABBITMQ_USER import uuid import pika import json from common.utils.logger import Logger from common.utils.helpers import JsonObject logger = Logger() class RabbitMQ(): def __init__(self,v_host=\u0026#34;/\u0026#34;,host=RABBITMQ_HOST, port=RABBITMQ_PORT, user=RABBITMQ_USER, password=RABBITMQ_PASS): \u0026#34;\u0026#34;\u0026#34; RabbitMQ 封装 :param v_host: 虚拟机host :param host: RabbitMQ 服务host :param port: RabbitMQ服务端口 :param user: RabbitMq 用户认证-用户名 :param password: RabbitMq 用户认证-密码 \u0026#34;\u0026#34;\u0026#34; self._v_host = v_host self._host = host self._port = port self._user = user self._password = password self.exchange_type = \u0026#34;\u0026#34; self.exchange = \u0026#34;\u0026#34; self.responses = {} #rpc客户端收到的所有结果 self.do_connection() def do_connection(self): \u0026#34;\u0026#34;\u0026#34; 进行了连接这个动作 :return: \u0026#34;\u0026#34;\u0026#34; try: self.connection = self.blocking_connection(host=self._host, port=self._port, user=self._user, password=self._password, v_host=self._v_host) self.channel = self.connection.channel() except ValueError as e: print(e) def blocking_connection(self, host=RABBITMQ_HOST, port=RABBITMQ_PORT, user=RABBITMQ_USER, password=RABBITMQ_PASS, v_host=\u0026#34;/\u0026#34;): \u0026#34;\u0026#34;\u0026#34; Connection Adapters 连接适配器 pika.PlainCredentials( ：param str用户名：用于验证的用户名,默认为guest ：param str password：用于验证的密码，默认为guest ：param bool delete_on_connect：连接完成后，凭证将不会存储在内存中。删除连接凭据。 ) pika.ConnectionParameters( host=host port=port, virtual_host=要使用的rabbitmq虚拟主机, 一个mq服务可以设置多个虚拟机，每个虚拟机就相当于一个独立的mq credentials=PlainCredentials身份验证凭证, channel_max=允许的最大channel通道数, frame_max=AMQP frame的最大字节大小, heartbeat=AMQP callable 心跳超时协商, ssl_options=pika.SSLOptions`实例, connection_attempts=最大重试尝试次数, retry_delay=下一次等待的时间，以秒为单位, socket_timeout=套接字连接超时时间, stack_timeout=完整协议栈启动超时时间，应该高于socket_timeout, locale=设置语言环境值, blocked_connection_timeout=如果非负，阻止链接保持；如果 tcp_options=为套接字设置的TCP选项的字典 ） \u0026#34;\u0026#34;\u0026#34; credential_params = pika.PlainCredentials(user, password) connection = pika.BlockingConnection( pika.ConnectionParameters(host, port, v_host, credential_params) ) return connection def model(self,exchange,model=\u0026#34;fanout\u0026#34;): \u0026#34;\u0026#34;\u0026#34; 可以选择，自己想构建的模式， 然后该函数会把需要设置的交换机参数帮你设置好 :param model: model_exchangeType = { \u0026#34;fanout\u0026#34;:\u0026#34;fanout\u0026#34;, \u0026#34;worker\u0026#34;:\u0026#34;fanout\u0026#34;, \u0026#34;routing\u0026#34;:\u0026#34;direct\u0026#34;, \u0026#34;direct\u0026#34;:\u0026#34;direct\u0026#34;, \u0026#34;route\u0026#34;:\u0026#34;direct\u0026#34;, \u0026#34;topic\u0026#34;:\u0026#34;topic\u0026#34;, \u0026#34;rpc\u0026#34;:\u0026#34;direct\u0026#34;#默认为路由模式 } :return: \u0026#34;\u0026#34;\u0026#34; model_exchangeType = { \u0026#34;fanout\u0026#34;: \u0026#34;fanout\u0026#34;, \u0026#34;worker\u0026#34;: \u0026#34;fanout\u0026#34;, \u0026#34;routing\u0026#34;: \u0026#34;direct\u0026#34;, \u0026#34;direct\u0026#34;: \u0026#34;direct\u0026#34;, \u0026#34;route\u0026#34;: \u0026#34;direct\u0026#34;, \u0026#34;topic\u0026#34;: \u0026#34;topic\u0026#34;, \u0026#34;rpc\u0026#34;: \u0026#34;direct\u0026#34; } self.exchange_type = model_exchangeType[model] self.exchange = exchange return self def producer_init(self,exchange=None,exchange_type=None): \u0026#34;\u0026#34;\u0026#34; 生产者初始化代码 :param v_host: 默认为/，默认虚拟机 :param exchange:交换机名字，默认为“” :param exchange_type:交换机类型，默认为“fanout”,广播模式 :return: channel \u0026#34;\u0026#34;\u0026#34; try: self.exchange = exchange if exchange else self.exchange self.exchange_type = exchange_type if exchange_type else self.exchange_type self.check_Value(self.exchange, self.exchange_type, self.channel) \u0026#34;\u0026#34;\u0026#34;默认这里connection 和 channel都有了，没有raise 异常\u0026#34;\u0026#34;\u0026#34; # 声明交换机 self.channel.exchange_declare(exchange=self.exchange, exchange_type=self.exchange_type) return self except Exception as e: print(e) def consumer_init(self,exchange=None,exchange_type=None,queue=\u0026#34;\u0026#34;,routings=[\u0026#34;\u0026#34;]): \u0026#34;\u0026#34;\u0026#34; 消费者初始化代码 :param exchange: 交换机名字，默认为 :param exchange_type: 交换机类型，默认为“fanout”，广播模式 :param queue: 队列名，默认为“”，为随机队列 :param routings: 路由key列表，默认为[\u0026#34;\u0026#34;],会将这些路由key都绑定到该队列上 :return: channel \u0026#34;\u0026#34;\u0026#34; try: self.exchange = exchange if exchange else self.exchange self.exchange_type = exchange_type if exchange_type else self.exchange_type self.check_Value(self.exchange,self.exchange_type,self.channel) \u0026#34;\u0026#34;\u0026#34;默认这里connection 和 channel都有了，没有raise 异常\u0026#34;\u0026#34;\u0026#34; # 声明交换机 self.channel.exchange_declare(exchange=self.exchange, exchange_type=self.exchange_type) # 随机生成临时队列,绑定到交换机.当然也可以指定出多条名字固定的队列，exclusive设置为True当接收端退出时，自动销毁队列 self.queue = self.channel.queue_declare(queue=queue, auto_delete=True) self.qname = self.queue.method.queue # 将这个随机队列绑定到交换机上，并设置路由键 for routing in routings: self.channel.queue_bind(exchange=self.exchange,queue=self.qname,routing_key=routing) return self except Exception as e: print(e) def rpc_client_init(self,routings:list,exchange=None,exchange_type=None,queue=\u0026#34;\u0026#34;,auto_ack=True): \u0026#34;\u0026#34;\u0026#34; rpc 模型 1. 先定义消费者 2. 再定义生产者 :param exchange: 客户端接受调用结果的交换机 :param exchange_type: 客户端接受调用结果的交换机的类型 :param queue: 客户端接受调用结果的队列，当为空时，该队列名字随机 :param routings: 客户端接受调用结果的队列路由键,必选参数，客户端接受调用结果的队列的路由 :param auto_ack: 是否自动确认 :return: \u0026#34;\u0026#34;\u0026#34; try: self.consumer_init(exchange=exchange, exchange_type=exchange_type, queue=queue, routings=routings) self.channel.basic_consume(queue=self.qname, auto_ack=auto_ack, on_message_callback=self.rpc_client_response) return self except Exception as e: print(e) def rpc_client_response(self,ch, method, properties, body)-\u0026gt;any: \u0026#34;\u0026#34;\u0026#34; 收到结果后的回调函数 :param ch: :param method: :param properties: :param body: :return: \u0026#34;\u0026#34;\u0026#34; if self.corr_id == properties.correlation_id: self.response = json.loads(body) def rpc_client_request(self,body:any,exchange:str,routing_key:str): \u0026#34;\u0026#34;\u0026#34; 启动rpc客户端请求循环，拿到消息后返回 :param body: 请求体 :param exchange:服务端的交换机 :param routing_key:请求发送到服务端的哪个队列，由路由指定 :return: \u0026#34;\u0026#34;\u0026#34; self.response = None self.corr_id = str(uuid.uuid4()) self.responses[self.corr_id] = None self.channel.basic_publish(exchange=exchange, routing_key=routing_key, properties=pika.BasicProperties( reply_to=self.qname, correlation_id=self.corr_id ), body=json.dumps(body)) while self.response is None: self.connection.process_data_events() self.responses[self.corr_id] = self.response return self.response def rpc_server_init(self,call=None,exchange=None,exchange_type=None,queue=\u0026#34;\u0026#34;,routings=[\u0026#34;\u0026#34;]): \u0026#34;\u0026#34;\u0026#34; rpc服务端初始化，会初始化一条消费者队列，这个队列的到达路由需要和客户端进行约定 :param call: 处理远程调用请求的函数 :param exchange: 服务端的客户端约定好的交换机 :param exchange_type: 交换机类型 :param queue: 队列名，默认为\u0026#34;\u0026#34;，为临时队列，名字随机 :param routings:路由键，服务端的队列需要绑定到某个路由上，默认为\u0026#34;\u0026#34;,即该交换机为广播模式时生效 :return:self \u0026#34;\u0026#34;\u0026#34; try: #将可以主动设置处理远程调用请求的函数，也可以由回调函数rpc_server_callback自己去找 self.remote_callback = call self.consumer_init(exchange=exchange,exchange_type=exchange_type,queue=queue,routings=routings) self.channel.basic_qos(prefetch_count=100) self.channel.basic_consume(queue=self.qname, auto_ack=False,on_message_callback=self.rpc_server_callback) return self except Exception as e: print(e) def rpc_server_callback(self,ch, method, properties, body): \u0026#34;\u0026#34;\u0026#34; 这里应该是解析参数，寻找被调用者，然后进行调用后 将调用结果发送会请求中要求返回的路由中 :param ch: channel :param method: method :param properties: 客户端发的消息带的参数 :param body: 请求体，会封装调用信息 :return: \u0026#34;\u0026#34;\u0026#34; # 将计算结果发送回该请求体要求发送的路由中 # 这里的发送，直接发送到请求体传过来的队列中，所以设置exchange=\u0026#34;\u0026#34; ch.basic_publish(exchange=\u0026#34;\u0026#34;, routing_key=properties.reply_to, properties=pika.BasicProperties( reply_to=self.qname, correlation_id=properties.correlation_id ), body=json.dumps(self.remote_callback(json.loads(body))), ) ch.basic_ack(delivery_tag=method.delivery_tag) def rpc_server_start(self): \u0026#34;\u0026#34;\u0026#34; 启动rpc的服务端 :return: \u0026#34;\u0026#34;\u0026#34; self.channel.start_consuming() def check_Value(self,*args): \u0026#34;\u0026#34;\u0026#34;参数校验\u0026#34;\u0026#34;\u0026#34; for i in args: assert i != None ","date":"2018-10-22","img":"","permalink":"/posts/message_queue/rabbitmq_%E5%85%A5%E9%97%A8/","series":["message queue"],"tags":["RabbitMQ","Python"],"title":"RabbitMQ-入门"},{"categories":["爬虫"],"content":"前记： 爬虫：使用任何技术手段，批量获取网站信息的一种方式。关键在于批量。\n反爬虫：使用任何技术手段，阻止别人批量获取自己网站信息的一种方式。关键也在于批量。\n误伤：在反爬虫的过程中，错误的将普通用户识别为爬虫。误伤率高的反爬虫策略，效果再好也不能用。\n拦截：成功地阻止爬虫访问。这里会有拦截率的概念。通常来说，拦截率越高的反爬虫策略，误伤的可能性就越高。因此需要做个权衡。\n资源：机器成本与人力成本的总和。\nurl 管理器：管理待抓取url集合和已抓取url集合 个人：set(),python的set()可以自动去重\n大量带爬取url：关系数据库mysql\n互联网公司：缓存数据库(高性能)\n网页下载器： 1.urllib2：python官方基础模块（py2.7） 下载方法：\n1.直接下载\nimport urllib2 response = urllib2.urlopen(url)#直接下载 print response.getcode()#获取状态码 cont = response.read()#读取内容 2.伪装和密码\nimport urllib2 request = urllib2.Request(url)#创建request对象 request.add_data(\u0026#39;a\u0026#39;,\u0026#39;l\u0026#39;)#添加数据，a-l,诸如账号密码 request.add_header(\u0026#39;User-Agent\u0026#39;,\u0026#39;Mozilla/5.0\u0026#39;)#添加http的header，用于伪装 response = urllib2.urlopen(request)#发送请求获取结果 cont = response.read()#读取内容 3.复杂情景（加套子）\nHTTPCookie用户登录情景/Proxy代理信息/HTTPS加密信息/Readirect防止URL互相跳转\nimport urllib2,cookielib cj = cookielib.CookieJar()#创建cookie容器 opener = urllib2.builb_opener(urllib2.HTTPCookieProcessor(cj))#httpcookie用户登陆 urllib2.intall_opener(opener)#给urllib2安装opener response = urllib2.urlopen(url)#使用带有cookie的urllib2爬取网页 2.urllib.request:(py3) 2.1 request.urlopen方法： urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None) urlopen无法判断数据的encoding，所以返回的是bytes对象。一般会对返回的数据进行decode。\nurl参数，可以是一个string，或者一个Request对象。\ndata一定是bytes对象，传递给服务器的数据，或者为None。目前只有HTTP requests会使用data，提供data时会是一个post请求，如若没有data，那就是get请求。data在使用前需要使用urllib.parse.urlencode()函数转换成流数据\nurlopen方法： read() , readline() ,readlines() , fileno() , close() ：对HTTPResponse类型数据进行操作\ninfo()：返回HTTPMessage对象，表示远程服务器返回的头信息\ngetcode()：返回Http状态码。如果是http请求，200请求成功完成;404网址未找到\ngeturl()：返回请求的url\neg: from urllib import request req = request.urlopen(\u0026#39;http://euraxluo.cn\u0026#39;) print(req.read().decode())#read()方法是读取返回数据内容，decode是转换返回数据的bytes格式为str 2.2 urllib.request.Reques： urllib.request.Request(url, data=None, headers={},origin_req_host=None, unverifiable=False, method=None)\neg: import urllib.request req=urllib.request.Request(\u0026#39;http://euraxluo.cn\u0026#39;) with urllib.request.urlopen(req) as response: page=response.read(300).decode(\u0026#39;utf-8\u0026#39;)#我们获取的数据一般是ascii的，decode成utf-8. print(page) 2.3 用来包装头部的数据： User-Agent ：这个头部可以携带如下几条信息：浏览器名和版本号、操作系统名和版本号、默认语言 百度图片 “Baiduspider-image+(+http://www.baidu.com/search/spider.htm)” 百度最新UA如下： PC： Mozilla/5.0 (compatible; Baiduspider-render/2.0; +http://www.baidu.com/search/spider.html) 移动： Mozilla/5.0 (iPhone; CPU iPhone OS 9_1 like Mac OS X) AppleWebKit/601.1.46 (KHTML, like Gecko) Version/9.0 Mobile/13B143 Safari/601.1 (compatible; Baiduspider-render/2.0; +http://www.baidu.com/search/spider.html) 360搜索 Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0); 360网站安全检测 360spider (http://webscan.360.cn) Google “Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)” Google图片搜索 “Googlebot-Image/1.0” Adwords移动网络 “AdsBot-Google-Mobile (+http://www.google.com/mobile/adsbot.html) Mozilla (iPhone; U; CPU iPhone OS 3 0 like Mac OS X) AppleWebKit (KHTML, like Gecko) Mobile Safari” 微软 bing，必应 “Mozilla/5.0 (compatible; bingbot/2.0; +http://www.bing.com/bingbot.htm)” 腾讯搜搜 “Sosospider+(+http://help.soso.com/webspider.htm)” 搜搜图片 “Sosoimagespider+(+http://help.soso.com/soso-image-spider.htm)” 雅虎英文 “Mozilla/5.0 (compatible; Yahoo! Slurp; http://help.yahoo.com/help/us/ysearch/slurp)” 雅虎中国 “Mozilla/5.0 (compatible; Yahoo! Slurp China; http://misc.yahoo.com.cn/help.html)” 搜狗图片 “http://pic.sogou.com” “Sogou Pic Spider/3.0(+http://www.sogou.com/docs/help/webmasters.htm#07)” 搜狗 “Sogou web spider/4.0(+http://www.sogou.com/docs/help/webmasters.htm#07)” 网易有道 “Mozilla/5.0 (compatible; YoudaoBot/1.0; http://www.youdao.com/help/webmaster/spider/; )” 瑞典 Speedy Spider “Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) Speedy Spider (http://www.entireweb.com/about/search_tech/speedy_spider/)” 俄罗斯 yandex “Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots)” 宜搜 EasouSpider Mozilla/5.0 (compatible; EasouSpider; +http://www.easou.com/search/spider.html) 华为赛门铁克蜘蛛 “HuaweiSymantecSpider/1.0+DSE-support@huaweisymantec.com+(compatible; MSIE 7.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR ; http://www.huaweisymantec.com/cn/IRL/spider)” 华为赛门铁克科技有限公司网页信誉分析系统的一个页面爬取程序，其作用是用于爬取互联网网页并进行信誉分析，从而检查该网站上的是否含有恶意代码。 七牛镜像蜘蛛 qiniu-imgstg-spider-1.0 监控宝 “Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.1; SV1; JianKongBao Monitor 1.1)” DNSPod监控 DNSPod-Monitor/2.0 Referer：可以用来防止盗链，有一些网站图片显示来源http://*.com，就是检查Referer来鉴定的\nConnection：表示连接状态，记录Session的状态\n#urllib.request.Request(url, data=None, headers={}, method=None) #使用request（）来包装请求，再通过urlopen（）获取页面。 2.4 Post数据 urlopen()的data参数默认为None，当data参数不为空的时候，urlopen（）提交方式为Post urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)\n`\nurlencode（）主要作用就是将url附上要提交的数据。\nPost的数据必须是bytes或者iterable of bytes，不能是str，因此需要进行encode（）编码 page = request.urlopen(req, data=data).read()\n当然，也可以把data的数据封装在urlopen（）参数中\ndata = {'first': 'true',}\ndata = parse.urlencode(data).encode('utf-8')\neg: import urllib.parse as up import urllib.request as ur url = \u0026#39;http://www.uustv.com/\u0026#39; values = {\u0026#39;word\u0026#39;: \u0026#39;Euraxluo\u0026#39;,\u0026#39;sizes\u0026#39;: \u0026#39;60\u0026#39;,\u0026#39;fonts\u0026#39;: \u0026#39;jfcs.ttf\u0026#39;,\u0026#39;fontcolor\u0026#39;: \u0026#39;#000000\u0026#39;}#Post的数据 data = up.urlencode(values)#编码 data = data.encode(\u0026#39;ascii\u0026#39;)#解码,server,只接受ascii数据 req = ur.Request(url,data) with ur.urlopen(req) as response: page = response.read().decode(\u0026#39;utf-8\u0026#39;) #我们获取的数据一般是ascii的，decode成utf-8. print(page) 2.5 使用代理 当需要抓取的网站设置了访问限制，这时就需要用到代理来抓取数据 urllib.request.ProxyHandler(proxies=None)\neg: proxy = urllib.request.ProxyHandler({\u0026#39;http\u0026#39;: \u0026#39;ip\u0026#39;}) # 设置proxy opener = urllib.request.build_opener(proxy) # 挂载opener urllib.request.install_opener(opener) # 安装opener data = urllib.parse.urlencode(data).encode(\u0026#39;utf-8\u0026#39;)#下载 ","date":"2018-10-22","img":"","permalink":"/posts/crawler/%E7%88%AC%E8%99%AB%E5%88%9D%E7%BA%A71/","series":["Python"],"tags":["爬虫","Python"],"title":"爬虫学习1-概念及urllib2"},{"categories":["爬虫"],"content":"请求方法： r=requests.get(\u0026#39;http://httpbin.org/get\u0026#39;)#get r = requests.post(\u0026#34;http://httpbin.org/post\u0026#34;)#post r = requests.put(\u0026#34;http://httpbin.org/put\u0026#34;)#put r = requests.delete(\u0026#34;http://httpbin.org/delete\u0026#34;)#delect r = requests.head(\u0026#34;http://httpbin.org/get\u0026#34;)#head r = requests.options(\u0026#34;http://httpbin.org/get\u0026#34;)#options GET eg import requests r = requests.get(url=\u0026#39;http://www.euraxluo.cn\u0026#39;) # 最基本的GET请求 print(r.status_code) # 内置的状态码查询对象 #状态码非200视为出错 响应状态码 eg:404 r = requests.get(\u0026#39;http://httpbin.org/status/404\u0026#39;) print(r.status_code)#404 error_info = r.raise_for_status()#Response.raise_for_status()抛出异常 带参数的url请求： #向url传递参数 r = requests.get(url=\u0026#39;http://dict.baidu.com/s\u0026#39;, params={\u0026#39;wd\u0026#39;: \u0026#39;python\u0026#39;})#带参数的GET请求 #当你不知道你的编码类型时 r.encoding = r.apparent_encoding#获取编码类型 print(r.text)#返回解码后的数据 tips 若有图片 r.content 返回bytes数据\neg：r.content r = requests.get(url=\u0026#39;http://music.baidu.com\u0026#39;)#实测，没啥区别 html=r.content #html_doc=str(html,\u0026#39;utf-8\u0026#39;) html_doc=html.decode(\u0026#34;utf-8\u0026#34;,\u0026#34;ignore\u0026#34;) print(html_doc) 响应内容 不同的内容处理方式 Json：request.json() 二进制：一般用于图片 from PIL import Image from io import BytesIO m = request.content#未解码内容 i = Image.open(m)#用二进制数据创建图片 text:可以自动解码。用的最多 import requests r=requests.get(\u0026#39;https://euraxluo.cn\u0026#39;) r.text#已经经过自动解码 编码问题： 1.get_encodings_from_content if req.encoding == \u0026#39;ISO-8859-1\u0026#39;: encodings = requests.utils.get_encodings_from_content(req.text) if encodings: encoding = encodings[0] else: encoding = req.apparent_encoding # encode_content = req.content.decode(encoding, \u0026#39;replace\u0026#39;).encode(\u0026#39;utf-8\u0026#39;, \u0026#39;replace\u0026#39;) global encode_content encode_content = req.content.decode(encoding, \u0026#39;replace\u0026#39;) #如果设置为replace，则会用?取代非法字符； 2.防御编程 try: r = requests.get(url,timeout = 30) r.raise_for_status() r.encoding = r.apparent_encoding return r.text except: print(\u0026#34;error\u0026#34;) 定制headers headers必须是string，bytestring,Unicode url=\u0026#39;https://euraluo.cn\u0026#39; headers={\u0026#39;user-agent\u0026#39;:\u0026#39;my-app/0.0.1\u0026#39;}#UA r=requests.get(url,headers=headers) POST POST表单 多个元素使用同一key的时候可以将dict替换成元祖列表，\n可以将data=替换成json=，传入json对象。\npayload={\u0026#39;key1\u0026#39;:\u0026#39;value1\u0026#39;,\u0026#39;key2\u0026#39;:\u0026#39;value2\u0026#39;} r=requests.post(\u0026#39;http://httpbin.org/post\u0026#39;, data=payload) POST文件 url = \u0026#39;http://httpbin.org/post\u0026#39; files={\u0026#39;file\u0026#39;:open(\u0026#39;report.xls\u0026#39;,\u0026#39;rb\u0026#39;)}#使用二进制模式打开文件。 r=requests.post(url,files=files) Cookie 访问cookie r.cookies['cookie_name']\n发送cookie到服务器 cookies=dict(cookies_are='workding')\nr.requests.get(url,cookies=cookies)\neg #Cookie的返回对象为RequestsCookieJar，类似于字典，适合跨域名路径使用。 jar=requests.cookies.RequestsCookieJar() jar.set(\u0026#39;tasty_cookie\u0026#39;, \u0026#39;yum\u0026#39;, domain=\u0026#39;httpbin.org\u0026#39;, path=\u0026#39;/cookies\u0026#39;) jar.set(\u0026#39;gross_cookie\u0026#39;, \u0026#39;blech\u0026#39;, domain=\u0026#39;httpbin.org\u0026#39;, path=\u0026#39;/elsewhere\u0026#39;) url = \u0026#39;http://httpbin.org/cookies\u0026#39; r = requests.get(url, cookies=jar) r.text#打印出cookie 会话 使用get()时，先构建Request对象，发送请求；再返回Response对象，包含服务器返回的所有信息 eg #会话也可用来为请求方法提供缺省数据 s=requests.Session() s.auth=(\u0026#39;user\u0026#39;,\u0026#39;pass\u0026#39;) s.headers.update({\u0026#39;x-test\u0026#39;:\u0026#39;true\u0026#39;}) #x-test和x-test2都会发送出去 s.get(\u0026#39;http://httpbin.org/headers\u0026#39;, headers={\u0026#39;x-test2\u0026#39;:\u0026#39;true\u0026#39;}) print(s) SSL证书验证 如果设置为False，会忽略对SSL证书的验证。\nrequests.get('https://github.com', verify=True)\nSSL验证默认开始，如果验证失败，会抛出SSLErro\n代理 通过代理爬取\nimport requests proxies = {\u0026#34;http\u0026#34;: \u0026#34;171.38.24.164:8132\u0026#34;} r=requests.get(\u0026#34;http://ip.chinaz.com/getip.aspx\u0026#34;, ,proxies=proxies) print(r.text) 获取代理ip import requests import bs4 from bs4 import BeautifulSoup User_Agent = \u0026#39;Mozilla/5.0 (Windows NT 6.3; WOW64; rv:43.0) Gecko/20100101 Firefox/43.0\u0026#39; header = {} header[\u0026#39;User-Agent\u0026#39;] = User_Agent url = \u0026#39;http://www.xicidaili.com/nn/1\u0026#39; r = requests.get(url,headers=header) res = r.text soup = BeautifulSoup(res,\u0026#34;html.parser\u0026#34;) ips = soup.findAll(\u0026#39;tr\u0026#39;) f = open(\u0026#34;./ip_proy/ip\u0026#34;,\u0026#34;w\u0026#34;) for x in range(1,len(ips)): ip = ips[x]#一行 tds = ip.findAll(\u0026#34;td\u0026#34;) line = \u0026#34;%s:%s;%s\u0026#34; % (tds[1].contents[0],tds[2].contents[0],tds[5].contents[0])+\u0026#34;\\n\u0026#34; ip_temp = tds[2].contents[0]+\u0026#34;\\t\u0026#34;+tds[3].contents[0]+\u0026#34;\\n\u0026#34; f.write(line) print(line) 验证能否连接 #Unicode gbk import socket import re import sys import requests #socket.setdefaulttimeout(3)#全局延时 #f2 = open(\u0026#34;./ip_proy/run_ip\u0026#34;, \u0026#34;w\u0026#34;) f = open(\u0026#34;./ip_proy/ip\u0026#34;) lines = f.readlines() proxys = [] for i in range(0,len(lines)): ip = lines[i].strip(\u0026#34;\\n\u0026#34;).split(\u0026#34;\\t\u0026#34;) ip_line = re.split(r\u0026#34;[.:;]\u0026#34;,ip[0])#re.split分割 proxy_host = \u0026#34;http://\u0026#34;+ip_line[0]+\u0026#34;.\u0026#34;+ip_line[1]+\u0026#34;.\u0026#34;+ip_line[2]+\u0026#34;.\u0026#34;+ip_line[3]+\u0026#34;:\u0026#34;+ip_line[4] proxy_temp = {\u0026#34;http\u0026#34;:proxy_host} proxys.append(proxy_temp) url = \u0026#34;http://ip.chinaz.com/getip.aspx\u0026#34; for proxy in proxys: try: res = requests.get(url,proxies=proxy,timeout=30) res.encoding = res.apparent_encoding res = res.text print(proxy) print(res+\u0026#34;\\n\u0026#34;) \u0026#39;\u0026#39;\u0026#39;#hava a bug for values in proxy.values(): print(values) f2.write(str(values)+\u0026#34;\\n\u0026#34;) \u0026#39;\u0026#39;\u0026#39; except: print(proxy) print(\u0026#34;times out\\n\u0026#34;) f.close() #f2.close() sys.exit() ","date":"2018-10-22","img":"","permalink":"/posts/crawler/%E7%88%AC%E8%99%AB%E5%88%9D%E7%BA%A72/","series":["Python"],"tags":["爬虫","Python"],"title":"爬虫学习2-Requests库学习"},{"categories":["爬虫"],"content":"BeautifulSoup解析器： 解析器 使用方法 条件 bs4的html解析器 BeautifulSoup(html,\u0026lsquo;html.parser\u0026rsquo;) 安装bs4 lxml的html解析器 BeautifulSoup(html,\u0026rsquo;lxml') pip install lxml lxml的xml解析器 BeautifulSoup(html,\u0026lsquo;xml\u0026rsquo;) pip install lxml html5lib的解析器 BeautifulSoup(html,\u0026lsquo;html5lib\u0026rsquo;) pip install html5lib 基本元素 基本元素 说明 tag 标签,\u0026lt;\u0026gt;开头，\u0026lt;/\u0026gt;结尾 name 标签的名字，,\u0026lt;tag\u0026gt;.name attrs 标签的属性，\u0026lt;tag\u0026gt;.attrs NavigableString String,\u0026lt;tag\u0026gt;.String Comment 标签内字符串的注释部分，Comment类型 搜索节点(html中的标签) find_all(name,attrs,recursive,string)\nname:对标签名称的检索字符串\nattrs:对标签属性值的检索字符串,可棕注属性栓索\nrecursive:是否对子孙全部检索,默以True\nstring:\u0026lt;\u0026gt;..\u0026lt;/\u0026gt;中字符串区域的检索字符串\neg: import bs4 from bs4 import BeautifulSoup import re html = \u0026#34;\u0026lt;body\u0026gt;\u0026lt;a href=\u0026#39;./test/123.txt\u0026#39;\u0026gt;hjhkj\u0026lt;/a\u0026gt; \u0026lt;div class=\u0026#39;test\u0026#39;\u0026gt;fdfdfd\u0026lt;div class=\u0026#39;test\u0026#39;\u0026gt;fdfdfd\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/body\u0026gt;\u0026#34; soup = BeautifulSoup(html,\u0026#34;html.parser\u0026#34;) #查找所有标签为a，链接为./test/123.txt形式的节点 m = soup.find_all(\u0026#39;a\u0026#39;,href=re.compile(r\u0026#39;./test/(.*).txt\u0026#39;))# (另一种写法\\d+\\) #查找所有标签为div，class为test，文字为fdfdfd的节点 m=soup.find_all(\u0026#39;div\u0026#39;,class_=\u0026#39;test\u0026#39;,string = \u0026#39;fdfdfd\u0026#39;) m = soup.div(class_=\u0026#39;test\u0026#39;,string = \u0026#39;fdfdfd\u0026#39;) soup.div.attrs#tag的attrs soup.div.parent.name#tag的父亲节点的名字 m = soup.a.string#String #显示： m = soup.prettify()#友好度+1 print(m) ###标签树的遍历\n上行遍历\n属性 说明 .parent 节点的父亲标签 .parents 节点父辈的迭代，用来遍历父辈节点 下行遍历\n属性 说明 .contents tag的子节点列表 .children 子结点的迭代，用于循环儿子节点 .descendants 子孙节点的迭代，循环遍历所有子孙节点 平行遍历\n属性 说明 .next_sibling 返回下一个平行节点的tag .previous_sibling 分返回上一个平行节点 .next_siblings 迭代类型，返回后续所有平行节点 .previous_siblings 迭代类型，返回前序所有平行节点 实例 # coding:utf-8 from bs4 import BeautifulSoup import re html_doc = \u0026#34;\u0026#34;\u0026#34; #定义一个长字符串，存储html代码,\u0026#39;\u0026#39;\u0026#39;可以保留格式 \u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;The Dormouse\u0026#39;s story\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p class=\u0026#34;title\u0026#34;\u0026gt;\u0026lt;b\u0026gt;The Dormouse\u0026#39;s story\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p class=\u0026#34;story\u0026#34;\u0026gt;Once upon a time there were three little sisters; and their names were \u0026lt;a href=\u0026#34;http://example.com/elsie\u0026#34; class=\u0026#34;sister\u0026#34; id=\u0026#34;link1\u0026#34;\u0026gt;Elsie\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;http://example.com/lacie\u0026#34; class=\u0026#34;sister\u0026#34; id=\u0026#34;link2\u0026#34;\u0026gt;Lacie\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;http://example.com/tillie\u0026#34; class=\u0026#34;sister\u0026#34; id=\u0026#34;link3\u0026#34;\u0026gt;Tillie\u0026lt;/a\u0026gt;; and they lived at the bottom of a well.\u0026lt;/p\u0026gt; http://example.com/lacie \u0026lt;p class=\u0026#34;story\u0026#34;\u0026gt;...\u0026lt;/p\u0026gt; \u0026#34;\u0026#34;\u0026#34; soup = BeautifulSoup(html_doc, \u0026#39;html.parser\u0026#39;)#传入的html字符串；使用的解析器；编码方式 print(soup.prettify())#按照标准的缩进格式输出获取的soup内容 #提取所有的连接出来 links = soup.find_all(\u0026#39;a\u0026#39;) for link in links: print(link.name, link[\u0026#39;href\u0026#39;], link[\u0026#39;class\u0026#39;], link.get_text()) #获取lacie连接 link_node = soup.find(\u0026#39;a\u0026#39;, href=\u0026#39;http://example.com/lacie\u0026#39;) print(link_node.name, link_node[\u0026#39;href\u0026#39;], link_node.get_text()) #用强大的 正则匹配 link_node = soup.find(\u0026#39;a\u0026#39;, href=re.compile(r\u0026#34;ill\u0026#34;)) print(link_node.name, link_node[\u0026#39;href\u0026#39;], link_node.get_text()) #获取P标签 p_node = soup.find(\u0026#39;p\u0026#39;, class_=re.compile(r\u0026#34;ti\u0026#34;)) print(p_node.name, p_node[\u0026#39;class\u0026#39;], p_node.get_text()) #抓取暗链接 link_node = soup.find_all(style=\u0026#39;display:none;\u0026#39;) print(link_node) #选择器 soup.select(\u0026#39;title\u0026#39;)#选择title标签 soup.select(\u0026#39;p nth-of-type(3)\u0026#39;) #通过tag标签逐层查找 soup.select(\u0026#39;body a\u0026#39;)#查找body标签下面的a标签 #找到某个tag标签下的直接子标签： soup.select(\u0026#39;head\u0026gt;title\u0026#39;) #通过id来查找： soup.select(\u0026#39;#link1\u0026#39;) #通过class来查找： soup.select(\u0026#39;.story\u0026#39;) soup.select(\u0026#39;[class~=story]\u0026#39;) #通过是否存在某个属性来查找： soup.select(\u0026#39;a[href]\u0026#39;) #通过属性的值来查找： soup.select(\u0026#39;a[href=\u0026#34;http://example.com/lacie]\u0026#39;) 正则RE 特殊字符：(使用r\u0026rsquo;string\u0026rsquo;定义字符) \u0026#39;.\u0026#39;，#点号，在默认模式中，匹配任何一个字符，除了新的行newline。如果DOTALL标记指定了，那么还可以匹配newline。 \u0026#39;^\u0026#39;，#匹配字符串的开始 \u0026#39;$\u0026#39;，#匹配字符串的结束。比如foo匹配foo或者foobar，但是foo$只能匹配到foo。 \u0026#39;*\u0026#39;，#匹配0个或者多个字符，比如ab*，可以匹配a，ab，abbbb等 \u0026#39;+\u0026#39;，#匹配1个或者多个字符，比如ab+，可以匹配ab，或者abbbb \u0026#39;?\u0026#39;，#匹配0或者1个字符，比如ab?只能匹配a或者ab。 \u0026#39;*？+\u0026#39;，#贪婪模式的，会尽可能多的匹配字符， \u0026#39;*？+\u0026#39;,#在后面加上一个？则会变为非贪婪模式，尽可能匹配少的字符。 #我们一般用非贪婪模式。 #m,n表示匹配的数量，如果不指定m或者n，则表示没有上限，下限不能低于0个 \u0026#39;{m}\u0026#39;,#指定匹配的数量，比如a{6}表示将匹配6个a字符，而不是5个，准确匹配。 \u0026#39;{m,n}\u0026#39;,#匹配在m~n个字符之间，包含m和n，比如a{3,5}将匹配3-5个a字符，一般会取上限来匹配。 \u0026#39;{m,n}?\u0026#39;,#非贪婪模式的匹配，尽可能匹配少，取下限m来匹配。 \u0026#39;[]\u0026#39;,#用于创造一个字符的集合，字符可以单独出现或者使用0-9，a-z这种格式。 比如： 1.[amk]会匹配a，m或者k字符。[a-z]将会匹配a-z之间的任何一个字符。[0-5][0-9]匹配从00-59的所有字符。 2.如果在[]中包含一个特殊字符的集合，比如[(+*)]，这些特殊字符将会失去其特殊含义，只匹配字面意义，\u0026#39;(\u0026#39;\u0026#39;)\u0026#39;\u0026#39;+\u0026#39;\u0026#39;*\u0026#39;。 3.如果在[]的开始有一个\u0026#39;^\u0026#39;，比如[^5]，将会匹配任何一个不是5的字符。 \u0026#39;|\u0026#39;,#A|B，AB是任意的RE表达式，可以匹配A或者B \u0026#39;(...)\u0026#39;,#括号内的表达式将作为分组，从表达式左边开始每遇到一个分组的左括号，编号+1。分组表达式作为一个整体，可以后接数量词。 比如: 1.(abc){2}匹配abcabc，a(123|456)c匹配a456c或者a123c。 \u0026#39;(?P\u0026lt;name\u0026gt;...)\u0026#39;，#分组，除了原有的编号外，指定一个额外的别名，比如：(?P\u0026lt;id\u0026gt;abc){2}，可以匹配abcabc，通过.\u0026#39;id\u0026#39;来访问。 \u0026#39;\\\u0026lt;number\u0026gt;\u0026#39;，#引用编号为\u0026lt;number\u0026gt;的分组匹配到的字符串。比如(\\d)abc\\1，可以匹配1abc1，或者5abc5 \u0026#39;(?P=name)\u0026#39;,#引用别名为\u0026lt;name\u0026gt;的分组匹配到的字符串，比如(?P\u0026lt;id\u0026gt;\\d)abc(?P=id),可以匹配1abc1，5abc5等。 \u0026#39;\\d\u0026#39;,#表示数字，0-9之间的一个，比如a\\dc,可以匹配a1c; \u0026#39;\\D\u0026#39;,#表示非数字，也可以用[^\\d]来代替， \u0026#39;\\s\u0026#39;，#表示空白字符 \u0026#39;\\S\u0026#39;，#表示非空白字符 \u0026#39;\\w\u0026#39;,#表示单词字符，[A-Za-z0-9_] \u0026#39;\\W\u0026#39;，#表示非单词字符。 \u0026#39;\\A\u0026#39;,#仅匹配字符串的开头，\\Aabc可以匹配abc。 \u0026#39;\\Z\u0026#39;,#仅匹配字符串结尾，abc\\Z,匹配abc 方法： 1. re.findall(pattern,string) 对string中所有符合pattern规则的进行匹配\n2. re.compile(pattern,flag=0) 返回一个对象的模式，用法：re.compile(pattern,flag=0).findall(string)\npattern为正则字符串\nflag，匹配模式,以下可选\nre.I #忽略大小写 re.M #多行模式 re.S #点任意匹配， re.L # re.U re.X #详细模式，这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释 3. re.match(pattern, string, flags=0) match方法会从要匹配的string的开头开始，尝试匹配pattern，一直向后，如果遇到无法匹配的字符，就返回None，如果匹配未结束已经到达string的末尾也会返回None，表示匹配失败。匹配成功会返回True，以及匹配到的内容的group,非完全匹配，完全匹配需要在表达式末尾加上\u0026rsquo;$'\neg: pattern=re.compile(r\u0026#39;hello\u0026#39;) result1=re.match(pattern,\u0026#39;hello\u0026#39;) result2=re.match(pattern,\u0026#39;helloo world\u0026#39;) result3=re.match(pattern,\u0026#39;helo world\u0026#39;) result4=re.match(pattern,\u0026#39;hello world\u0026#39;) if result1: print(result1.group()) else: print(\u0026#39;1匹配失败!\u0026#39;) if result2: print(result2.group()) else: print(\u0026#39;2匹配失败!\u0026#39;) if result3: print(result3.group()) else: print(\u0026#39;3匹配失败!\u0026#39;) if result4: print(result4.group()) else: print(\u0026#39;4匹配失败!\u0026#39;) m=re.match(r\u0026#39;(\\w+) (\\w+)(?P\u0026lt;sign\u0026gt;.*)\u0026#39;,\u0026#39;hello world!\u0026#39;)#单词+空格+单词+任意字符 print(m.string)#获取匹配时使用的文本 print(m.re)#获取匹配时使用的pattern对象 print(m.pos)#文本中开始搜索的位置 print(m.endpos)#返回结束搜索的位置 print(m.lastindex)#最后一个被捕获的分组在文本中的索引 print(m.lastgroup)#最后一个最捕获的分组的别名 print(m.group())#获得一个或多个分组截获的字符串，如果指定多个参数，将会以元祖形式返回 print(m.group(1,2))#指定多个参数 print(m.groups())#以元组形式返回所有分组截获的字符串 print(m.groupdict())#返回具有别名的组的别名为Key，字符串为value的字典，不包含别名的组不统计 print(m.start(2))#返回指定的组截获的子串在string中的起始索引 print(m.end(2))#返回指定的组在string中的结束索引 print(m.span(2))#返回(start(group),end(group)) 4. re.search(pattern, string, flags=0) 类似与match方法，但是match会检测re是不是在string的开始位置就能够匹配到，而search会扫描整个string来匹配。match方法只有在0位置匹配成功的话才会返回，如果不是开始i位置，即使后面由匹配，也会返回None。\neg: pattern=re.compile(r\u0026#39;world\u0026#39;) match=re.search(pattern,\u0026#39;hello world!\u0026#39;) if match: print(match.group() 5. re.split(pattern, string, maxsplit=0, flags=0) 将string按照匹配的子串分割后返回列表，maxsplit参数指定最大分割次数，不指定的话会全部分割。\neg: pattern=re.compile(r\u0026#39;\\d+\u0026#39;) split=re.split(pattern,\u0026#39;one1two2three3four4\u0026#39;) print(split) 6. re.findall(pattern, string, flags=0) 搜索string，以列表的形式返回全部能匹配的子串。\neg: pattern = re.compile(r\u0026#39;\\d+\u0026#39;) print(re.findall(pattern,\u0026#39;one1two23three3four4\u0026#39;)) 7. re.finditer(pattern, string, flags=0) 搜索string，返回一个顺序访问每一个匹配结果的迭代器\neg: pattern=re.compile(r\u0026#39;\\d+\u0026#39;) for m in re.finditer(pattern,\u0026#39;one1two23three3four4\u0026#39;): print(m.group()) 8. re.sub(pattern, repl, string, count=0, flags=0) 使用repl替换string中的每一个匹配的子串后返回替换的字符串。\nrepl可以是一个方法，这个方法应该只接受一个match对象作为参数，并且返回一个字符串用于替换。\ncount可以指定最多替换次数，不指定的话就全部替换。\neg: pattern=re.compile(r\u0026#39;(\\w+) (\\w+)\u0026#39;) string=\u0026#39;i say, hello world!\u0026#39; print(re.sub(pattern,r\u0026#39;\\2 \\1\u0026#39;,string)) def func(m): return m.group(1).title()+\u0026#39; \u0026#39;+m.group(2).title() print(re.sub(pattern,func,string)) ","date":"2018-10-22","img":"","permalink":"/posts/crawler/%E7%88%AC%E8%99%AB%E5%88%9D%E7%BA%A73/","series":["Python"],"tags":["爬虫","Python"],"title":"爬虫学习3-网页解析器"},{"categories":["爬虫"],"content":"PyQuery 初始化 %%html \u0026lt;div id = \u0026#34;container\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;list\u0026#34;\u0026gt; \u0026lt;li class = \u0026#34;item-0\u0026#34;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-1\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link2.html\u0026#34;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-0 active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link3.html\u0026#34; style=\u0026#34;color:black;\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;bold\u0026#34;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-1 active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link4.html\u0026#34;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-0\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link5.html\u0026#34;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; 字符串初始化 html = \u0026#39;\u0026#39;\u0026#39; \u0026lt;div id = \u0026#34;container\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;list\u0026#34;\u0026gt; \u0026lt;li class = \u0026#34;item-0\u0026#34;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-1\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link2.html\u0026#34;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-0 active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link3.html\u0026#34; style=\u0026#34;color:black;\u0026#34;\u0026gt;\u0026lt;span class=\u0026#34;bold\u0026#34;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-1 active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link4.html\u0026#34;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class = \u0026#34;item-0\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;link5.html\u0026#34;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt; \u0026#39;\u0026#39;\u0026#39; from pyquery import PyQuery as pq doc = pq(html) print(doc(\u0026#34;li\u0026#34;)) \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ​\nURL初始化 doc = pq(url=\u0026#34;http://www.baidu.com\u0026#34;) print(doc(\u0026#34;head\u0026#34;).text().encode(\u0026#39;iso8859-1\u0026#39;).decode(\u0026#39;utf8\u0026#39;)) 百度一下，你就知道 文件初始化 doc = pq(filename = \u0026#34;test.html\u0026#34;) print(doc(\u0026#34;li\u0026#34;)) \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ​\ncss选择器 doc = pq(html) print(doc(\u0026#34;#container .list li\u0026#34;)) \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ​\n查找元素 doc = pq(html) items = doc(\u0026#34;.list\u0026#34;) print(type(items)) print(items) print(\u0026#34;------------------\u0026#34;) lis = items.find(\u0026#34;li\u0026#34;) print(type(lis)) print(lis) \u0026lt;class 'pyquery.pyquery.PyQuery'\u0026gt; \u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; ------------------ \u0026lt;class 'pyquery.pyquery.PyQuery'\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ​\n子元素 lis1 = items.children() print(lis1) print(\u0026#34;------------------\u0026#34;) lis2 = items.children(\u0026#34;.active\u0026#34;) print(lis2) \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ------------------ \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ​\n父级元素 parent = items.children().parent() print(parent) \u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; ​\nparents =items.children().parents() print(parents) print(\u0026#34;------------------\u0026#34;) print(parents(\u0026#34;.list\u0026#34;)) \u0026lt;div id=\u0026quot;container\u0026quot;\u0026gt; \u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; ------------------ \u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;ul class=\u0026quot;list\u0026quot;\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; ​\n兄弟元素 third = doc(\u0026#34;.list .item-0.active\u0026#34;) print(third) print(\u0026#34;----------\u0026#34;) brothers = third.siblings() print(brothers) \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ---------- \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ​\n遍历 doc = pq(html) lis = doc(\u0026#34;li\u0026#34;).items() print(type(lis)) for li in lis: print(li) print(\u0026#34;---\u0026#34;) \u0026lt;class 'generator'\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;frist item\u0026lt;/li\u0026gt; --- \u0026lt;li class=\u0026quot;item-1\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link2.html\u0026quot;\u0026gt;second item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; --- \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; --- \u0026lt;li class=\u0026quot;item-1 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link4.html\u0026quot;\u0026gt;fourth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; --- \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link5.html\u0026quot;\u0026gt;fifth item\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; --- 获取信息 获取属性 doc = pq(html) a = doc(\u0026#34;.item-0.active a\u0026#34;) print(a) print(\u0026#34;---\u0026#34;) print(a.attr(\u0026#34;style\u0026#34;)) print(\u0026#34;---\u0026#34;) print(a.attr.href) \u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; --- color:black; --- link3.html 获取文本 texts = doc.items() for text in texts: print(text.text()) frist item second item third item fourth item fifth item 获取html a = doc(\u0026#34;.item-0.active a\u0026#34;) print(a) print(\u0026#34;---\u0026#34;) print(a.html()) \u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt; --- \u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt; addClass,removeClass doc = pq(html) li = doc(\u0026#34;.item-0.active\u0026#34;) print(li) li.removeClass(\u0026#39;active\u0026#39;) print(li) li.addClass(\u0026#39;active\u0026#39;) print(li) \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ​\nattr,css doc = pq(html) li = doc(\u0026#34;.item-0.active\u0026#34;) print(li) li.attr(\u0026#39;name\u0026#39;,\u0026#39;link\u0026#39;) print(li) li(\u0026#34;a\u0026#34;).css(\u0026#39;font-size\u0026#39;,\u0026#39;14px\u0026#39;) print(li) \u0026lt;li class=\u0026quot;item-0 active\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot; name=\u0026quot;link\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black;\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li class=\u0026quot;item-0 active\u0026quot; name=\u0026quot;link\u0026quot;\u0026gt;\u0026lt;a href=\u0026quot;link3.html\u0026quot; style=\u0026quot;color:black; font-size: 14px\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;bold\u0026quot;\u0026gt;third item\u0026lt;/span\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; ​\nremove doc =pq(html) li = doc(\u0026#34;li\u0026#34;) print(li.text()) li.find(\u0026#39;a\u0026#39;).remove() print(li.text()) frist item second item third item fourth item fifth item frist item API %%html \u0026lt;pre style=\u0026#34;line-height: 1.25; white-space: pre;\u0026#34;\u0026gt; \\ SORRY / \\ / \\ This page does / ] not exist yet. [ ,\u0026#39;| ] [ / | ]___ ___[ ,\u0026#39; | ] ]\\ /[ [ |: | ] ] \\ / [ [ |: | ] ] ] [ [ [ |: | ] ] ]__ __[ [ [ |: | ] ] ] ]\\ _ /[ [ [ [ |: | ] ] ] ] (#) [ [ [ [ :====\u0026#39; ] ] ]_].nHn.[_[ [ [ ] ] ] HHHHH. [ [ [ ] ] / `HH(\u0026#34;N \\ [ [ ]__]/ HHH \u0026#34; \\[__[ ] NNN [ ] N/\u0026#34; [ ] N H [ / N \\ / q, \\ / \\ \u0026lt;/pre\u0026gt; 伪类选择器 doc = pq(html) li = doc(\u0026#34;li:first-child\u0026#34;) print(li.text()) li = doc(\u0026#34;li:last-child\u0026#34;) print(li.text()) li = doc(\u0026#34;li:nth-child(2)\u0026#34;) print(li.text()) li = doc(\u0026#34;li:nth-child(3n)\u0026#34;) print(li.text()) li = doc(\u0026#34;li:gt(3)\u0026#34;)#取第5个,即第4个以后,第四个下标为3 print(li.text()) li = doc(\u0026#34;li:contains(second)\u0026#34;)#搜索文本 print(li.text()) frist item fifth item second item third item fifth item second item css选择器 ","date":"2018-10-22","img":"","permalink":"/posts/python/pyquerystudy/","series":["Pathon"],"tags":["爬虫","Pathon"],"title":"爬虫学习4"},{"categories":["读书笔记"],"content":"线性表(每个线性表上的数据最多只有前和后两个方向):数组,链表,队列,栈 非线性表(数据之间并不是简单的前后关系):二叉树,堆,图\n数组的概念 数组( Array )是一种线性表数据结构。它用一组连续的内存空间,来存储一组具有相同类型的数据。\n数组的特点 连续的内存空间和相同类型的数据\n数组的优点 随机访问:利用寻址公式对元素进行访问:\na[i]_address = base_address + i * data_type_size\n数组的查找操作时间复杂度不是O(1),即便是排好的数组,用二分查找,时间复杂度也是O(logn);正确的说法\n数组支持随机访问,根据下标随机访问的时间复杂度为O(1)\n数组的缺点 低效的插入和删除\n插入:最好O(1),最坏O(n) 数组若无序,插入新的元素时,可以将第 K 个位置元素移动到数组末尾,把新的元素,插入到第 k 个位置,此处复杂度为O(1)\n删除:最好O(1),最坏O(n) 多次删除集中在一起,提高删除效率,记录下已经被删除的数据,每次的删除操作并不是搬移数据,只是记录数据已经被删除,当数组没有更多的存储空间时,再触发一次真正的删除操作。即 JVM 标记清除垃圾回收算法。\n标记 - 清除算法\n标记 - 清除算法在垃圾收集时会先标记出需要回收的对象,标记完成后统一回收所有被标记的对象。清除之后会产生大量不连续的内存碎片。标记 - 整理垃圾回收算法在标记完成之后让所有存活的对象都向一端移动,然后直接清理掉边界以外的内存\n访问越界\n数组越界在 C 语言中是一种未决行为,并没有规定数组访问越界时编译器应该如何处理。因为,访问数组的本质就是访问一段连续内存,只要数组通过偏移计算得到的内存地址是可用的,那么程序就可能不会报任何错误\n数组和容器 容器能否完全替代数组(ArrayList,vector)\n相比于数组, java 中的 ArrayList 封装了数组的很多细节(插入删除时数据的迁移工作),并支持动态扩容。一旦超过存储容量,扩容时比较耗时,因为涉及到内存申请和数据搬移。\nJava ArrayList 无法存储基本类型,比如 int 、 long ,需要封装为 Integer 、 Long 类,而Autoboxing 、 Unboxing 则有一定的性能消耗,所以如果特别关注性能,或者希望使用基本类型,就可以选用数组。\n如果数据大小事先已知,并且对数据的操作非常简单,用不到 ArrayList 提供的大部分方法,也可以直接使用数组。\n当要表示多维数组时,用数组往往会更加直观。比如 Object[][]array ;而用容器的话则需要这样定义: ArrayList\u0026lt;ArrayList \u0026gt; array 。\n总结 对于业务开发,直接使用容器就足够了,省时省力。毕竟损耗一丢丢性能,完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发,比如开发网络框架,性能的优化需要做到极致,这个时候数组就会优于容器,成为首选\n数组的下标 下标从内存来看,就是偏移量.如果用1开始计数.array[k]的内存地址为:a[k]_address = base_address + (k-1)*type_size;可以看出,多了一个减法运算,数组作为非常基础的数据结构,通过下标随机访问数组元素又是其非常基础的编程操作,效率的优化就要尽可能做到极致。所以为了减少一次减法操作,数组选择了从 0 开始号,而不是从 1开始。(python下标可以为任何整数)\n","date":"2018-10-20","img":"","permalink":"/posts/algorithm/%E6%95%B0%E7%BB%84/","series":["读书笔记"],"tags":["数据结构"],"title":"数组"},{"categories":["读书笔记"],"content":"单链表 data.next--\u0026gt;data.next--\u0026gt;NULL\n时间复杂度 插入节点:\n时间复杂度:O1\n删除节点\n时间复杂度:O1\n查找节点\n时间复杂度:O(n)\n链表想要随机访问第K个元素arr[k],需要根据指针一个一个找\n双向链表 --\u0026gt;prev.data.next\u0026lt;==\u0026gt;prev.data.next\u0026lt;==\u0026gt;prev.data.next 即支持两个方向,每个节点不知有一个后继指针next,还有一个前驱指针prev指向前面的结点\n空间复杂度 双向链表需要额外的两个空间来存储后继结点和其前驱结点的地址.所以,如果存储同样多的数据,双向链表要比单链表占用更多的内存空间.虽然两个指针比较浪费存储空间,但是可以支持双向遍历.这样也带来了双向链表操作的灵活性\n特点 双向链表可以支持O1时间复杂度的情况下找到前驱结点,这样,双向链表在某些情况的插入,删除操作都要比单链表简单高校.\n循环链表 单链表的尾节点指针指向空地址\n循环链表的尾节点指针指向链表的头结点\n优点:从链尾到链头比较方便.当要处理的数据具有环型结构特点时,就特别适合采用循环链表 把约瑟夫问题降低到O(n)时间复杂度\n具体的复杂度分析: 删除操作,有两种情况 删除结点中 “ 值等于某个给定值 ” 的结点; 删除给定指针指向的结点。 第一种情况,为了找到节点的值等于给定值的结点,单链表和双向链表都要从头结点一个一个一次遍历比较,直到找到这个节点,才利用指正操作进行删除.\n主要的时间复杂度在于遍历结点,时间复杂度为On\n第二种情况,我们知道要删除哪一个结点,可是删除这个结点的操作需要其前驱结点的参与,因此我们还要知道指向前驱结点的指正.这时双向链表和单链表的区别就体现出来了.\n单链表依然需要从头结点开始遍历链表.因此,单链表删除的时间复杂度为On\n双向链表的结点中有prev,可以直接删除,因此,双向链表删除的时间复杂度为O1\n查找 除了插入和删除操作以外,双向链表的按值查询效率也比单链表快\n记录上次查找的位置P,每次查询时,根据要查找的值与P的大小关系,决定是往前还是往后查找,平均下来只需要查找一般的数据\n范例 LinkedHashMap,采用了双向链表的数据结构\n链表与数组 数组 实现上使用的是连续的内存空间,可以借助CPU的缓存机制,预读数组中的数据,所以访问效率高\n缺点:大小固定,如果内存不够,只能重新再申请一个更大的内存空间,把原数组拷贝进去,费时\n链表 在内存中并不是连续存储,对于CPU缓存不友好,没有办法有效预读.\n与数组相比,天然支持动态扩容\n缺点:需要消耗额外的存储空间去存储一份指向下一个结点的指正,所以内存消耗会翻倍.并且,对链表进行频繁的插入,删除操作,还会导致频繁的内存申请和释放,容易造成内存碎片.比如java:会导致频繁的GC(垃圾回收)\n基于链表实现LRU缓存淘汰法 思路:\n我们维护一个有序单链表,越靠近链表尾部的结点是越早之前访问的,当有一个新的数据被访问时,我们从链表头开始顺序遍历链表.\n如果此数据之前已经被缓存在链表中了,我们遍历得到这个数据对应的结点,并将其从原来的位置删除,然后插入到链表的头部\n如果这数据没有在缓存链表中,又可以分为两种情况:\n如果此时缓存未满,则将此节点直接插入到链表的头部\n如果此时缓存已满,则链表尾结点删除,将新的数据结点插入到链表的头部\n时间复杂度:O(n)\n优化:引入散列表,来记录每个数据的位置,将缓存访问的时间复杂度降到O1\n代码: 查找key:\n//在数组中a中,查找key,返回key所在的位置 int find(char* a, int n, char key) { //边界条件处理,如果 a 为空,或者n\u0026lt;=0,说明数组中没有数据,就不用while循环比较了 if(a == null || n \u0026lt;= 0) { return -1; } int i = 0; //这里有两个比较操作: i\u0026lt;n 和 a[i]==key. while (i \u0026lt; n) { if (a[i] == key) { return i; } ++i; } return -1; } //在数组a中,查找key,返回key所在的位置 //n表示数组a的长度 int find(char*　ａ，int n,char key){ if(a == null || n\u0026lt;= 0 ){ return -1; } //这里因为要将a[n-1]的值替换成key,所以要特殊处理这个值 if(a[n-1]==key){ return n-1; } //要把a[n-1]的值临时保存在变量tmp中,以便之后恢复 char tmp = a[n-1]; a[n-1] = key; int i = 0; while (a[i] != key){ ++i; } //恢复a[n-1]原来的值 a[n-1] = tmp; if(i == n-1){ //如果i == n-1 说明,在0...n-2之间没有key,所以返回-1 return -1; }else{ //否则,返回i,就是要等key值的元素的下标 return i; } } 注意点: 1.理解指针或引用的含义\njava,Python没有指针,而是引用{都是用来存储所指对象的内存地址}\n2.警惕指针丢失和内存泄露\n简单地说,对结点进行操作时,注意操作的顺序\n例如C语言:\n//--\u0026gt;a.next--\u0026gt;b.next--\u0026gt;,插入一个结点x.next x-\u0026gt;next = p-\u0026gt;next;//将x的结点的next指针指向b结点 p-\u0026gt;next = x//将p的next指针指向x结点 3.利用哨兵简化实现难度\n普通的实现方式,在针对链表的插入删除时,需要对插入第一个结点和最后一个节点的情况进行特殊处理,例如:\n//向空链表插入第一个节点 if(head == null){ head = new_node; } //删除链表中的是最后一个节点 if(head-\u0026gt;next == null){ head = null; } 引入哨兵结点:处理边界问题,我们不管链表是否为空,head指针都会一直指向这个哨兵结点.\n带头链表:有哨兵节点的链表\nnull.next--\u0026gt;a.next--\u0026gt;b.next\n4.留意边界条件处理\n检查边界条件是否考虑全面,代码在边界条件下能否正确运行\n如果链表为空,代码能否正常工作 如果链表只包含一个结点时,代码能否正常工作 如果链表只包含两个结点,代码能否正常工作 代码逻辑在处理头结点和尾节点时,能否正常工作 5.对于复杂的链表操作,可以举例,画图进行理解\n6.常见的链表操作:\n单链表反转 链表中环的检测 两个有序的链表的合并 删除链表倒数第n个结点 求链表的中间结点 7.对于链表,需要注意内存管理\n","date":"2018-10-20","img":"","permalink":"/posts/algorithm/%E9%93%BE%E8%A1%A8/","series":["读书笔记"],"tags":["数据结构"],"title":"链表"},{"categories":["tools"],"content":"Git 学习笔记 cd相对路径 cd 什么都不加 回到用户的家目录下 cd ~ 回到root目录下 cd .. 进入上一级目录\ncd - 返回上一次目录\ncd . 当前目录\n创建和删除目录 创建目录mkdir mkdir=make directory\nmkdir dirname 创建目录\nmkdir -p /etc/dirname/test/ 级联创建目录\nmkdir -pv /etc/dirname/test/ 加上v可以看到创建的过程\n删除目录rmdir rmdir=remove directory\nrmdir dirname 可 删除空目录（下面无目录和文件）\n删除文件 rm = remove命令 rmdir -p 可级联删除一串目录，但是是从最开始的目录删起。比较危险，慎用\nrm /tmp/ww/2/3/1.txt 会提示是否删除1.txt\nrm -f /tmp/ww/2/3/1.txt 强制删除，不给提示\nrm -r 级联删除目录，但是会提示是否删除，直接rm不能删目录\nrm -rf 直接级联强制删除\nrm -rfv 加上v显示删除过程\n更新仓库 //在github上创建项目 $ git clone https://github/xx账号/xx项目.git//克隆到本地 //编辑项目 $ git add .//(将改动添加到暂存区) $ git commit –m”提交说明” // $ git push origin master//将本地更改推送到远程master分支 实例：\ngit clone https://github.com/Euraxluo/-.git //我更改了一个文件的名字 cd ./-//选中我的文件目录 git add *.py//选中我要更新的文件 git commit -m \u0026#34;rename\u0026#34;//提交说明 git push -u origin master//推送 //这时，由于我的项目地址是https,而不是git，要求更新 //我打算更改路径 git push -u origin master//重新提交 注： 1.提交：\ngit add -A //提交所有变化 git add -u //提交被修改(modified)和被删除(deleted)文件，不包括新文件(new) git add . //提交新文件(new)和被修改(modified)文件，不包括被删除(deleted)文件 2.删除：\n$ git rm 我的文件//删除文件 $ git rm -r 我的文件夹//删除文件夹 $ git rm -h//git rm [\u0026lt;选项\u0026gt;] [--] \u0026lt;文件\u0026gt;... -n, --dry-run 演习 -q, --quiet 不列出删除的文件 --cached 只从索引区删除 -f, --force 忽略文件更新状态检查 -r 允许递归删除 --ignore-unmatch 即使没有匹配，也以零状态退出 创建仓库 $ makdir ~/hello-world //创建一个项目hello-world $ cd~/hello-world //打开这个项目 $ git init //初始化 $ touch README $ git add README //更新README文件 $ git commit-m \u0026#39;first commit\u0026#39;//提交更新，并注释信息 $ git remote add origin git@.:.git//连接远程github项目 $ git push -u origin master //将本地项目更新到github项目上去 删除仓库 git branch//显示所有的本地分支 结果：* master ls -a//找到目录下的.git 结果：./ ../ .git rm -rf .git//删除操作 结果：.git 被删除，本地库删除成功 查看分支并切换 # 查看远程分支 git branch -a # 新建一个分支 git checkout -b \u0026lt;new branch name\u0026gt; # 查看本地分支 git branch # 分支切换 git checkout version 查看当前的远程库 #不带参数，列出已经存在的远程分支 git remote #列出详细信息，在每一个名字后面列出其远程url #此时， -v 选项(译注:此为 –verbose 的简写,取首字母),显示对应的克隆地址 git remote -v | --verbose 暂存修改 git stash 把不想提交的修改暂存起来\ngit stash apply 取回暂存修改\ngit 文件过大 在频繁增删改、commit之后，.git文件会出现过大的情况。这个时候如何彻底清理以前的历史版本（也就是说只保留当前版本，不可能再回滚了） 方法是首先建立一个分支，然后将master版本给删除，再将当前分支重命名为master，再强制push到远程仓库即可。 具体步骤：\n第一步： `git checkout --orphan latest_branch` 第二步：添加所有文件 `git add -A` 第三步：提交更改 `git commit -am \u0026#34;commit message\u0026#34;` 注意这里commit message是你提交的修改说明 第四步：删除分支 `git branch -D master` 第五步：将当前分支重命名 `git branch -m master` 最后：强制更新存储库 `git push -f origin master` 就此完成。 要注意尽量不要往git上提交二进制文件，二进制文件是不按diff保存的，即使提交了也不要每次改一点然后再提交一遍。\n一：常规办法 1.删除无用的分支\ngit branch -d \u0026lt;branch_name\u0026gt; 2.删除无用的tag\ngit tag -d \u0026lt;tag_name\u0026gt; 3.清理本地版本库\ngit gc --prune=now 二：高级办法 注意高级办法会导致push冲突，需要强制提交，其他人pull也会遇到冲突，建议重新克隆.\n1.完全重建版本库\nrm -rf .git git init git add . git commit -m \u0026#34;first commit\u0026#34; git remote add origin \u0026lt;your_github_repo_url\u0026gt; git push -f -u origin master 2.有选择性的合并历史提交\ngit rebase -i \u0026lt;first_commit\u0026gt; 会进入一个如下所示的文件\npick ba07c7d add bootstrap theme and format import pick 7d905b8 add newline at file last line pick 037313c fn up_first_char rename to caps pick 34e647e add fn of \u0026amp;\u0026amp; use for index.jsp pick 0175f03 rename common include pick 7f3f665 update group name \u0026amp;\u0026amp; update config 将想合并的提交的pick改成s，如\npick ba07c7d add bootstrap theme and format import pick 7d905b8 add newline at file last line pick 037313c fn up_first_char rename to caps s 34e647e add fn of \u0026amp;\u0026amp; use for index.jsp pick 0175f03 rename common include pick 7f3f665 update group name \u0026amp;\u0026amp; update config 这样第四个提交就会合并进入第三个提交。 等合并完提交之后再运行\ngit push -f git gc --prune=now 三.其他方法\ndh -d 1 -h 查看哪个目录最大，确认是git目录\ngit rev-list --objects --all | grep \u0026quot;$(git verify-pack -v .git/objects/pack/*.idx | sort -k 3 -n | tail -5 | awk '{print$1}')\u0026quot; 查看占用空间最大的5个文件\n重写commit，删除大文件git filter-branch --force --index-filter 'git rm -rf --cached --ignore-unmatch big-file.jar' --prune-empty --tag-name-filter cat -- --all big-file.jar 换成之前查询出来的大文件名\ngit push origin master --force以强制覆盖的方式推送repo\n清理空间\nrm -rf .git/refs/original/ git reflog expire --expire=now --all git gc --prune=now 合并分支 创建与合并分支 每次提交，Git都把它们串成一条时间线，这条时间线就是一个分支。截止到目前，只有一条时间线，在Git里，这个分支叫主分支，即master分支。HEAD严格来说不是指向提交，而是指向master，master才是指向提交的，所以，HEAD指向的就是当前分支。\n一开始的时候，master分支是一条线，Git用master指向最新的提交，再用HEAD指向master，就能确定当前分支，以及当前分支的提交点：\n每次提交，master分支都会向前移动一步，这样，随着你不断提交，master分支的线也越来越长。\n当我们创建新的分支，例如dev时，Git新建了一个指针叫dev，指向master相同的提交，再把HEAD指向dev，就表示当前分支在dev上：\n你看，Git创建一个分支很快，因为除了增加一个dev指针，改改HEAD的指向，工作区的文件都没有任何变化！\n不过，从现在开始，对工作区的修改和提交就是针对dev分支了，比如新提交一次后，dev指针往前移动一步，而master指针不变：\n假如我们在dev上的工作完成了，就可以把dev合并到master上。Git怎么合并呢？最简单的方法，就是直接把master指向dev的当前提交，就完成了合并：\n所以Git合并分支也很快！就改改指针，工作区内容也不变！\n合并完分支后，甚至可以删除dev分支。删除dev分支就是把dev指针给删掉，删掉后，我们就剩下了一条master分支：\n实践 首先，我们创建dev分支，然后切换到dev分支：\n$ git checkout -b dev Switched to a new branch \u0026#39;dev\u0026#39; git checkout命令加上-b参数表示创建并切换，相当于以下两条命令：\n$ git branch dev $ git checkout dev Switched to branch \u0026#39;dev\u0026#39; 然后，用git branch命令查看当前分支：\n$ git branch * dev master git branch命令会列出所有分支，当前分支前面会标一个*号。\n然后，我们就可以在dev分支上正常提交，比如对readme.txt做个修改，加上一行：\nCreating a new branch is quick. 然后提交：\n$ git add readme.txt $ git commit -m \u0026#34;branch test\u0026#34; [dev b17d20e] branch test 1 file changed, 1 insertion(+) 现在，dev分支的工作完成，我们就可以切换回master分支：\n$ git checkout master Switched to branch \u0026#39;master\u0026#39; 切换回master分支后，再查看一个readme.txt文件，刚才添加的内容不见了！因为那个提交是在dev分支上，而master分支此刻的提交点并没有变：\n现在，我们把dev分支的工作成果合并到master分支上：\n$ git merge dev Updating d46f35e..b17d20e Fast-forward readme.txt | 1 + 1 file changed, 1 insertion(+) git merge命令用于合并指定分支到当前分支。合并后，再查看readme.txt的内容，就可以看到，和dev分支的最新提交是完全一样的。\n注意到上面的Fast-forward信息，Git告诉我们，这次合并是“快进模式”，也就是直接把master指向dev的当前提交，所以合并速度非常快。\n当然，也不是每次合并都能Fast-forward，我们后面会讲其他方式的合并。\n合并完成后，就可以放心地删除dev分支了：\n$ git branch -d dev Deleted branch dev (was b17d20e). 删除后，查看branch，就只剩下master分支了：\n$ git branch * master 因为创建、合并和删除分支非常快，所以Git鼓励你使用分支完成某个任务，合并后再删掉分支，这和直接在master分支上工作效果是一样的，但过程更安全。\n合并分支相关小结 查看分支：git branch\n创建分支：git branch \u0026lt;name\u0026gt;\n切换分支：git checkout \u0026lt;name\u0026gt;\n创建+切换分支：git checkout -b \u0026lt;name\u0026gt;\n合并某分支到当前分支：git merge \u0026lt;name\u0026gt; 如果遇到报错$ git checkout dev warning: refname 'dev' is ambiguous. 需要查看是否有同名指针: git show-ref --heads --tags 然后选择需要的指针合并\n删除分支：git branch -d \u0026lt;name\u0026gt;\n","date":"2018-07-11","img":"","permalink":"/posts/tools/git%E5%AD%A6%E4%B9%A0/","series":null,"tags":["git"],"title":"Git学习笔记"},{"categories":["读书笔记"],"content":"CleanCode读书笔记 最小惊异原则 1.从一而终，便于修改 2.遵守大家的约定 有意义的命名 1.名副其实 1.命名需要注释来补充，那就不算名副其实 2.在命名时尽量采用有意义的名称，代码的简洁不会改变（运算符和常量的数量，嵌套数量） 2.避免误导 1.避免使用与本意相驳的词 2.提防使用不同之处较小的词 3.不要使用小写l和大写O作为变量名 4.命名有区分，应当有明显的区分，应使读者可以鉴别 3.使用读得出来的名称 4.使用可搜索的名称 1.长名称胜于短名称，搜得到的名称胜于自造的名称 2.单字母仅用于短方法中的本地变量 3.名称长短应与其作用域大小相对应 4.若变量或常量可能在代码中多次使用，则应赋予其便于搜索的名称 5.避免使用编码和前缀 6.避免思维映射 不应当让读者在脑中把你的名称翻译为他们熟知的名称 7.类名和方法名 1.类名和对象名应该是名词 2.类名不应是动词 3.方法名应当是动词或动词短语 4.属性访问器，修改器和断言应该根据其值命名 8.宁可明确，勿为好玩 9.每个概念对应一个词 10.避免将同一单词用于不同目的 11.使用解决方案领域名称 12.使用源自所涉问题领域的名称 13.添加有意义的语境 2.函数 1.短小 1.if,else,while 语句，其中的代码块应该只有一行 并且应该大抵是一个函数调用语句 2.函数不应该大到足以容纳嵌套语句 3.永不调用的函数应该丢弃 2.只做一件事 要判断函数是否不止做了一件事，就是看能否再拆出一个函数 3.使用描述性的名称 1.函数越短小，功能越集中，就便于取个好名字 2.长而具有描述性的名称要比短的名称或者注释好 4.函数参数应少，并且不要使用输出参数 1.如果函数需要很多参数，说明需要封装为类 2.函数名称为动词可以明确函数是做什么的 3.函数参数自然而然的视为输入参数 4.将代码集中到基类i，避免冗余和重复 3.注释 1.注释不能美化糟糕的代码 2.注释的内容 1.版权及著作权声明 2.提供基本信息 3.对意图解释（提供某个决定的意图） 4.阐释（如果参数或者返回值是某个标准库的一部分，或者不能修改，帮助其阐释含义） 5.警告其他程序员会出现某种后果 6.//TODO注释（放置工作列表：程序员认为应该做，但由于某些原因还没有做的工作） 7.不要留下注释代码 格式 1.纵向格式 1.封包声明，导入声明，每个函数之间，用空白行隔开 2.关系密切或概念相关的代码应该互相靠近 3.变量声明应尽可能的靠近使用位置 4.实体变量应该在类的顶部声明 5.循环中的控制变量应该在循环语中声明 6.相关函数（相互靠近，调用者应该在被调用者的上面） 2.横向格式 1.赋值操作符周围加空格 2.函数名和左圆括号不能分开（函数于其参数关系紧密） 3.根据运算符优先级在运算部分加空格 4.if,whle,短函数 不要违反或忽视缩进 5.while,for 语句的语句体为空，应该把语句体分号换行缩进 对象和数据结构 1.数据对象的反对称性 1.过程式（使用数据结构）代码便于在添加新函数 2.面向对象代码难以添加新类 2.Demeter律 1.模块不应了解他所操作对象内部的情况 3.DTO 1.数据传送对象，只有一个公共变量，没有函数的类 2.使用于数据库通信，解析套接字传递 错误和异常处理 1.给出异常发生的环境说明 2.依调用者需要定义异常类 3.不能返回和传递NULL值 类应该短小 启发 一般性问题 1.一个源文件不要使用多种语言（尽力） 2.明显的行为未被实现，阅读者不会再相信编写者 3.尽可能找到并且删除重复 4.基类不能依赖于派生类 5.不执行的代码应该删除 java 1.通过使用通配符避免过长的导入清单 2.不要继承常量 3.多使用enum而非常量 单元测试及JUnit以后再读一遍 1.测试不充分 2.使用覆盖率工具（容易发现测试不足的模块） 3.别略过过小的测试 4.特别注意测试边界条件 5.缺陷趋于扎堆，全面测试相近的部分 6.测试应该快速 ","date":"2018-01-22","img":"","permalink":"/posts/reading/cleancode/","series":["读书笔记"],"tags":["CleanCode"],"title":"CleanCode-读书笔记"},{"categories":null,"content":"关于切片和slice的内存共享 package main import ( \u0026#34;bufio\u0026#34; \u0026#34;bytes\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; _errors \u0026#34;github.com/pkg/errors\u0026#34; \u0026#34;os\u0026#34; \u0026#34;reflect\u0026#34; \u0026#34;regexp\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;strings\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; \u0026#34;time\u0026#34; ) func main() { /** * @Description: foo boo内存共享 * @param []int * @param 5 */ foo := make([]int, 5) foo[3] = 3 foo[4] = 4 boo := foo[1:4] boo[1] = 2 for i := 0; i \u0026lt; 5; i++ { println(foo[i]) } /** * @Description: 当capcity够的时候，那么就不会重新分配内存 * @param []int * @param 8 */ a := make([]int, 8) b := a[1:8] b[1] = 1 //[01...],a=[001] a[2] = 2 //[002...] a = append(a, 1) //新内存空间 b[1] = 3 //b=[03...],a=[002] a[2] = 4 //a=[004] for i := 0; i \u0026lt; len(a); i++ { print(a[i]) } println() for i := 0; i \u0026lt; len(b); i++ { print(b[i]) } /** * @Description: dir1和dir2 共享内存，虽然dir1有个append， * 但是由于空间足够，所以没有重新申请空间 * */ println() path := []byte(\u0026#34;AAAAAA/BBBBBB\u0026#34;) sep := bytes.IndexByte(path, \u0026#39;/\u0026#39;) //dir1:=path[:sep] dir1 := path[:sep:sep] //todo 这个语法设置了最小的cap，后续append，就会重新分配内存 dir2 := path[sep+1:] println(string(dir1)) println(string(dir2)) dir1 = append(dir1, \u0026#34;/suffix\u0026#34;...) println(string(dir1)) println(string(dir2)) /** * @Description:深度比较 deepEqual */ v1 := data{} v2 := data{} println(reflect.DeepEqual(v1, v2)) m1 := map[string]string{\u0026#34;1\u0026#34;: \u0026#34;a\u0026#34;, \u0026#34;2\u0026#34;: \u0026#34;b\u0026#34;} m2 := map[string]string{\u0026#34;2\u0026#34;: \u0026#34;b\u0026#34;, \u0026#34;1\u0026#34;: \u0026#34;a\u0026#34;} println(reflect.DeepEqual(m1, m2)) s1 := []int{1, 2, 3} s2 := []int{2, 3, 4} println(reflect.DeepEqual(s1, s2)) /** * @Description: 成员函数Receiver */ p := Persion{ Name: \u0026#34;Euraxluo\u0026#34;, Sex: \u0026#34;Male\u0026#34;, Age: 44, } p.printPersion() /** * @Description:面向接口编程 */ c := Country{\u0026#34;CHINA\u0026#34;} city := City{\u0026#34;shanghai\u0026#34;} printStr(c) printStr(city) /** * @Description: 时间处理 */ //now time now := time.Now() fmt.Println(now) str_now := time.Now().String() fmt.Println(str_now) //Unix timestamp unix_now := time.Now().Unix() fmt.Println(unix_now) //获取日期 date_time := time.Now().Day() fmt.Println(date_time) //获取年份 year := time.Now().Year() fmt.Println(year) //获取月份 month := time.Now().Month() fmt.Println(month) //数字转字符串 x := strconv.Itoa(32131) println(x) //避免把String转成[]Byte //如果需要在for循环中对某个slice使用append()，先把slice的容量整到位，避免浪费内存 //拼接字符串 使用stringBuffer,StringBuild //plus 符号适合用于字面常量的拼接。编译器会直接进行优化 //StringBuild 通过合理的内存预分配，可以减少拼接时，内存的分配次数，减少GC次数 str_list := []string{\u0026#34;你好\u0026#34;, \u0026#34;世界\u0026#34;} s_build := StringBuilder(str_list, 20) println(s_build) //已有字符串的情况下，使用 strings.join比较好 s_join := strings.Join(str_list, \u0026#34;\u0026#34;) println(s_join) //![](https://www.flysnow.org/2018/11/11/golang-concat-strings-performance-analysis.html) //使用gorouting并发，使用sync.WaitGroup同步分片 //var wgs sync.WaitGroup wgs := new(sync.WaitGroup) for i := 0; i \u0026lt; 10; i++ { wgs.Add(1) //todo add 1 //go download(\u0026#34;test.com\u0026#34;, i,\u0026amp;wgs) go download(\u0026#34;test.com\u0026#34;, i, wgs) } wgs.Wait() //避免在热代码中进行内存分配，这样会导致gc繁忙，使用sync.Pool来重用对象 //![](https://zhuanlan.zhihu.com/p/76812714) //![](https://www.cnblogs.com/sunsky303/p/9706210.html) /** * @Description: sync.Pool 的使用场景： × 1.最好是高并发 × 2.最好两次GC之间的间隔长 */ time1 := time.Now().Unix() for i := 0; i \u0026lt; 900000; i++ { obj := make([]byte, 1024) _ = obj } time2 := time.Now().Unix() for j := 0; j \u0026lt; 900000; j++ { obj := bytePool.Get().(*[]byte) _ = obj bytePool.Put(obj) } time3 := time.Now().Unix() println(time2 - time1) println(\u0026#34;SYNC POOL\u0026#34;, time3-time2) //使用lock-free操作，避免使用mutex,应该使用sync/Atomic包 //lock free编程 https://www.cnblogs.com/gaochundong/p/lock_free_programming.html //todo https://coolshell.cn/articles/9703.html //todo https://coolshell.cn/articles/8239.html //提供原子操作 //加法(add), 比较并交换(compare and swap, 简称CAS)，加载(load), 存储(store),交换(swap) var l uint32 = 10 atomic_plus(\u0026amp;l, 10) fmt.Println(l) atomic_sub(\u0026amp;l, 5) fmt.Println(l) //使用I/O缓存，使用bufio.NewWrite()，bufio.NewReader() readBuffer() writeBuffer() //在for循环中使用正则，要使用regexp.Compile()编译正则，性能更高 for i := 0; i \u0026lt; 10; i++ { x := re_compile(\u0026#34;hello World\u0026#34;, `\\w+`) println(x) } //如果需要高性能，使用protobuf,msgp //使用Map时，使用整形的Key更快 //todo https://golang.org/doc/effective_go.html //todo https://github.com/uber-go/guide/blob/master/style.md //todo http://devs.cloudimmunity.com/gotchas-and-common-mistakes-in-go-golang/ //todo https://github.com/cristaloleg/go-advice //todo https://www.instana.com/blog/practical-golang-benchmarks/ //todo https://github.com/alecthomas/go_serialization_benchmarks //todo https://github.com/golang/go/wiki/Performance //2.错误处理 //一段代码的改进 testa := []int{1, 2, 3, 4, 5} testb := []int{1, 2, 3, 4, 5} testc := Compares{ V1: 2, V2: 2, V3: 2, V4: 2, V5: 4, } if err := testc.exception_handler4(testa, testb); err != nil { println(err.Error()) } else { println(\u0026#34;check pass\u0026#34;) } //3.选项模式 //建造者模式 sb := OptionBuilder{} if option, err := sb.Create(\u0026#34;127.0.0.1\u0026#34;, \u0026#34;8080\u0026#34;).WithOption3(1).WithOption4(1.1).Build(); err == nil { option.printOpt() } //选项模式 op1, _ := NewSetting(Option1(\u0026#34;localhost\u0026#34;), Option2(\u0026#34;1023\u0026#34;)) op1.printOpt() //4.嵌入和委托 //嵌入结构多态 button1 := Button{Label{Widget{10, 70}, \u0026#34;OK\u0026#34;}} button2 := Button{Label{Widget{50, 70}, \u0026#34;NO\u0026#34;}} listBox := ListBox{Widget{10, 40}, []string{\u0026#34;AL\u0026#34;, \u0026#34;AK\u0026#34;, \u0026#34;AZ\u0026#34;, \u0026#34;AR\u0026#34;}, 0} println(\u0026#34;Painters\u0026#34;) for _, painter := range []Painter{listBox, button1, button2} { painter.Paint() } println(\u0026#34;Painters2\u0026#34;) for _, widget := range []interface{}{listBox, button1, button2} { widget.(Painter).Paint() if clicker, ok := widget.(Clicker); ok { clicker.Click() } fmt.Println() // print a empty line } //控制反转 //控制逻辑依赖业务逻辑： intSet := NewIntSet() intSet.Add(1) intSet.Add(2) intSet.Add(3) intSet.Delete(3) println(\u0026#34;intSet\u0026#34;) for k, v := range intSet.data { fmt.Println(k, v) } undoSet := NewUndoSet() undoSet.Add(1) undoSet.Add(2) undoSet.Add(3) undoSet.Delete(3) undoSet.Undo() println(\u0026#34;undoSet\u0026#34;) for k, v := range undoSet.data { fmt.Println(k, v) } strSet := NewStrSet() strSet.Add(\u0026#34;1\u0026#34;) strSet.Add(\u0026#34;2\u0026#34;) strSet.Add(\u0026#34;3\u0026#34;) strSet.Delete(\u0026#34;3\u0026#34;) strSet.Undo() println(\u0026#34;strSet\u0026#34;) for k, v := range strSet.data { fmt.Println(k, v) } //5.1map list := []string{\u0026#34;Euraxluo\u0026#34;, \u0026#34;Hello\u0026#34;, \u0026#34;World\u0026#34;} var mapres []interface{} mapres = Map(list, func(s interface{}) interface{} { return strings.ToUpper(reflect.ValueOf(s).String()) }) for k, v := range mapres { fmt.Println(k, v) } mapres = Map(list, func(s interface{}) interface{} { return len(reflect.ValueOf(s).String()) }) for k, v := range mapres { fmt.Println(k, v) } reduceres := Reduce(list, func(s interface{}) interface{} { return len(reflect.ValueOf(s).String()) }) println(reduceres.(int64)) reduceress := Reduce(list, func(s interface{}) interface{} { return reflect.ValueOf(s).String() + \u0026#34; \u0026#34; }) println(reduceress.(string)) var int_set = []int{1, 2, 3, 4, 5, 6, 7, 87, 8} out := Filter(int_set, func(s interface{}) bool { return reflect.ValueOf(s).Int()%2 == 1 }) for k, v := range out { fmt.Println(k, v) } } /** * @Description: 通用的map函数 * @param arr * @param fn * @return []interface{} */ func Map(arr interface{}, fn func(s interface{}) interface{}) []interface{} { if reflect.ValueOf(arr).Kind() != reflect.Slice { return nil } var newArr []interface{} for i := 0; i \u0026lt; reflect.ValueOf(arr).Len(); i++ { newArr = append(newArr, fn(reflect.ValueOf(arr).Index(i).Interface())) } return newArr } /** * @Description: 通用的reduce函数 * @param arr * @param fn * @return interface{} */ func Reduce(arr interface{}, fn func(s interface{}) interface{}) interface{} { if reflect.ValueOf(arr).Kind() != reflect.Slice { return nil } var sum interface{} for i := 0; i \u0026lt; reflect.ValueOf(arr).Len(); i++ { res := fn(reflect.ValueOf(arr).Index(i).Interface()) if sum == nil { psum := reflect.Indirect(reflect.ValueOf(sum)) if psum.CanSet() { psum.Set(reflect.ValueOf(res)) } else { sum = res } } else { switch reflect.ValueOf(sum).Kind() { case reflect.Interface: return nil case reflect.Int: sum = reflect.ValueOf(sum).Int() + reflect.ValueOf(res).Int() case reflect.String: sum = reflect.ValueOf(sum).String() + reflect.ValueOf(res).String() case reflect.Ptr: sum = reflect.ValueOf(sum).Pointer() + reflect.ValueOf(res).Pointer() } } } return sum } /** * @Description: 通用的filter函数 * @param arr * @param fn * @return []interface{} */ func Filter(arr interface{}, fn func(s interface{}) bool) []interface{} { if reflect.ValueOf(arr).Kind() != reflect.Slice { return nil } var newArr []interface{} for i := 0; i \u0026lt; reflect.ValueOf(arr).Len(); i++ { if fn(reflect.ValueOf(arr).Index(i).Interface()) == true { newArr = append(newArr, reflect.ValueOf(arr).Index(i).Interface()) } } return newArr } /** * @Description: 控制功能Undo依赖业务功能 */ type IntSet struct { data map[int]bool } func NewIntSet() IntSet { return IntSet{make(map[int]bool)} } func (set *IntSet) Add(x int) { set.data[x] = true } func (set *IntSet) Delete(x int) { delete(set.data, x) } func (set *IntSet) Contains(x int) bool { return set.data[x] } type UndoSet struct { IntSet functions []func() } func NewUndoSet() UndoSet { return UndoSet{NewIntSet(), nil} } func (set *UndoSet) Add(x int) { //重写 if !set.Contains(x) { set.data[x] = true set.functions = append(set.functions, func() { set.Delete(x) }) } else { set.functions = append(set.functions, nil) } } func (set *UndoSet) Delete(x int) { //重写 if set.Contains(x) { delete(set.data, x) set.functions = append(set.functions, func() { set.Add(x) }) } else { set.functions = append(set.functions, nil) } } func (set *UndoSet) Undo() error { if len(set.functions) == 0 { return errors.New(\u0026#34;No functions to undo\u0026#34;) } index := len(set.functions) - 1 if function := set.functions[index]; function != nil { function() set.functions[index] = nil } set.functions = set.functions[:index] return nil } /** * @Description: 定义协议 */ type UndoIOC []func() func (undo *UndoIOC) Add(function func()) { *undo = append(*undo, function) } func (undo *UndoIOC) UndoIOC() error { functions := *undo if len(functions) == 0 { return errors.New(\u0026#34;No functions to Undo\u0026#34;) } index := len(functions) - 1 if function := functions[index]; function != nil { function() functions[index] = nil } *undo = functions[:index] return nil } /** * @Description: 控制反转，将业务逻辑依赖控制逻辑。 * 应该是这样 服务想实现什么控制协议，由服务决定，控制能通用 */ type StrSet struct { data map[string]bool undo UndoIOC } func NewStrSet() StrSet { return StrSet{data: make(map[string]bool)} } func (set *StrSet) Undo() { set.undo.UndoIOC() } func (set *StrSet) Add(x string) { if !set.Contains(x) { set.data[x] = true set.undo.Add(func() { set.Delete(x) }) } else { set.undo.Add(nil) } } func (set *StrSet) Delete(x string) { if set.Contains(x) { delete(set.data, x) set.undo.Add(func() { set.Add(x) }) } else { set.undo.Add(nil) } } func (set *StrSet) Contains(x string) bool { return set.data[x] } type Painter interface { Paint() } type Clicker interface { Click() } type Widget struct { X, Y int } type Label struct { Widget //嵌入 Text string //聚合 } func (label Label) Paint() { println(\u0026#34;Paint\u0026#34;, \u0026amp;label, label.Text) } type Button struct { Label } func (button Button) Paint() { println(\u0026#34;Paint\u0026#34;, \u0026amp;button, button.Text) } func (button Button) Click() { println(\u0026#34;Click\u0026#34;, \u0026amp;button, button.Text) } type ListBox struct { Widget Texts []string Index int } func (listBox ListBox) Paint() { println(\u0026#34;Paint\u0026#34;, \u0026amp;listBox, listBox.Texts) } func (listBox ListBox) Click() { println(\u0026#34;Click\u0026#34;, \u0026amp;listBox, listBox.Texts) } /** * @Description: 选项模式 */ type Option struct { option1 string option2 string option3 int option4 float64 } func (p *Option) printOpt() { println(p.option1, p.option2, p.option3, p.option4) } /** * @Description: 第一种最复杂，最臃肿的方式进行设置 * @param option1 * @param option2 * @return *Option * @return error */ func newDefaultOption(option1 string, option2 string) (*Option, error) { return \u0026amp;Option{option1, option2, 1, 1.0}, nil } func new2Option(option1 string, option2 string, option3 int) (*Option, error) { return \u0026amp;Option{option1, option2, option3, 1.0}, nil } func new3Option(option1 string, option2 string, option4 float64) (*Option, error) { return \u0026amp;Option{option1, option2, 1, option4}, nil } func new4Option(option1 string, option2 string, option3 int, option4 float64) (*Option, error) { return \u0026amp;Option{option1, option2, option3, option4}, nil } /** * @Description: 第二种，使用两个结构体，一个传固定参数，一个传可选参数 */ type Config struct { option1 string option2 string configs *Configs } type Configs struct { option3 int option4 float64 } func NewConfig(option1 string, option2 string, configs *Configs) (*Config, error) { return \u0026amp;Config{option1, option2, configs}, nil } /** * @Description: 第三种，使用builder建造者模式 */ type OptionBuilder struct { Option err error } /** * @Description: 显式的将interface声明为Void */ type Void interface{} /** * @Description: 实现一个指针赋值的函数 * @param void * @param value */ func SetValue(void Void, value interface{}) { pvoid := reflect.Indirect(reflect.ValueOf(void)) pvoid.Set(reflect.ValueOf(value)) } func (b *OptionBuilder) setOption(option Void, value interface{}) { if b.err == nil { SetValue(option, value) } } func (b *OptionBuilder) Create(option1 string, option2 string) *OptionBuilder { b.setOption(\u0026amp;b.Option.option1, option1) b.setOption(\u0026amp;b.Option.option2, option2) return b } func (b *OptionBuilder) WithOption3(option3 int) *OptionBuilder { b.setOption(\u0026amp;b.Option.option3, option3) return b } func (b *OptionBuilder) WithOption4(option4 float64) *OptionBuilder { b.setOption(\u0026amp;b.Option.option4, option4) return b } func (b *OptionBuilder) Build() (Option, error) { return b.Option, b.err } /** * @Description: 第四种，使用Functional Options * @param *Option */ type Setting func(*Option) func Option1(op string) Setting { return func(option *Option) { option.option1 = op } } func Option2(op string) Setting { return func(option *Option) { option.option2 = op } } func Option3(op int) Setting { return func(option *Option) { option.option3 = op } } func Option4(op float64) Setting { return func(option *Option) { option.option4 = op } } func NewSetting(options ...func(*Option)) (*Option, error) { opt := Option{} for _, option := range options { option(\u0026amp;opt) } return \u0026amp;opt, nil } /** * @Description: * 1.c语言使用返回值+errno的方式来进行异常处理，后来又使用函数参数，通过入参和出参来标识 * 2.java语言使用try-catch-finally的方式来进行检查 */ func check_origin(a []int, b []int, c int) ([]int, error) { if len(a) != len(b) { return nil, errors.New(\u0026#34;len of a and len of b not equal\u0026#34;) } result := make([]int, len(a)) for i := 0; i \u0026lt; len(a); i++ { res, err := add_and_compare(a[i], b[i], c) if err != nil { return nil, err } else { result[i] = res } } return result, nil } func add_and_compare(a int, b int, c int) (n int, err error) { if a+b \u0026gt;= c { return a + b, nil } else { return a + b, errors.New(\u0026#34;a+b not bigger than c\u0026#34;) } } type Compares struct { V1 int V2 int V3 int V4 int V5 int err error } /** * @Description: 我们需要将这个函数进行改进 * @receiver c * @param a * @param b * @return error */ func (c *Compares) exception_handler1(a []int, b []int) error { if _, err := check_origin(a, b, c.V1); err != nil { return err } if _, err := check_origin(a, b, c.V2); err != nil { return err } if _, err := check_origin(a, b, c.V3); err != nil { return err } if _, err := check_origin(a, b, c.V4); err != nil { return err } if _, err := check_origin(a, b, c.V5); err != nil { return err } return nil } /** * @Description: 通过函数式编程来改进 * @param a * @param b * @param c.V1 */ func (c *Compares) exception_handler2(a []int, b []int) error { var err error check := func(a []int, b []int, data int) { if err != nil { return } _, err = check_origin(a, b, data) } check(a, b, c.V1) check(a, b, c.V2) check(a, b, c.V3) check(a, b, c.V4) check(a, b, c.V5) if err != nil { return err } return nil } /** * @Description: use struct handler exception */ type Check struct { err error } func (check *Check) check(a []int, b []int, c int) { if check.err == nil { _, check.err = check_origin(a, b, c) } } func (c *Compares) exception_handler3(a []int, b []int) error { check := Check{} check.check(a, b, c.V1) check.check(a, b, c.V2) check.check(a, b, c.V3) check.check(a, b, c.V4) check.check(a, b, c.V5) if check.err != nil { return check.err } return nil } /** * @Description: 利用流式编程实现 * @receiver c * @param a * @param b * @param m */ func (c *Compares) check(a []int, b []int, m int) { if c.err == nil { _, c.err = check_origin(a, b, m) } } func (c *Compares) checkV1(a []int, b []int) *Compares { c.check(a, b, c.V1) return c } func (c *Compares) checkV2(a []int, b []int) *Compares { c.check(a, b, c.V2) return c } func (c *Compares) checkV3(a []int, b []int) *Compares { c.check(a, b, c.V3) return c } func (c *Compares) checkV4(a []int, b []int) *Compares { c.check(a, b, c.V4) return c } func (c *Compares) checkV5(a []int, b []int) *Compares { c.check(a, b, c.V5) return c } func (c *Compares) exception_handler4(a []int, b []int) error { c.checkV1(a, b).checkV2(a, b).checkV3(a, b).checkV4(a, b).checkV5(a, b) if c.err != nil { return _errors.Wrap(c.err, \u0026#34; !!chech faild\u0026#34;) } return nil } func re_compile(data string, expr string) string { reg, err := regexp.Compile(expr) if err == nil { return reg.FindString(data) } return \u0026#34;\u0026#34; } func writeBuffer() { write_buffer := bufio.NewWriter(os.Stdout) fmt.Fprint(write_buffer, \u0026#34;hello\u0026#34;) fmt.Fprint(write_buffer, \u0026#34;gogogog\u0026#34;) write_buffer.Flush() } func readBuffer() { str_reader := strings.NewReader(\u0026#34;buffer reader test\u0026#34;) bufio_reader := bufio.NewReader(str_reader) //peek 只读不取 data, _ := bufio_reader.Peek(10) println(string(data)) //打印，读到的内容 println(bufio_reader.Buffered()) //显示缓存中的直字节数 //readString 从缓存中读取 first_black, _ := bufio_reader.ReadString(\u0026#39; \u0026#39;) println(first_black) //打印，读到的内容 println(bufio_reader.Buffered()) //显示缓存中的直字节数 //Read指定从缓存中读取固定的字节数 num_bytes := make([]byte, 6) n_bytes, err := bufio_reader.Read(num_bytes) println(n_bytes) println(num_bytes) println(err) } func atomic_plus(l *uint32, r uint32) { atomic.AddUint32(l, r) } func atomic_sub(l *uint32, r uint32) { atomic.AddUint32(l, ^uint32(r-1)) } var bytePool = sync.Pool{ New: func() interface{} { b := make([]byte, 1024) return \u0026amp;b }, } func StringBuilder(p []string, cap int) string { var b strings.Builder l := len(p) b.Grow(cap) for i := 0; i \u0026lt; l; i++ { b.WriteString(p[i]) } return b.String() } func download(url string, i int, wg *sync.WaitGroup) { println(\u0026#34;http://\u0026#34; + url + \u0026#34;/\u0026#34; + strconv.Itoa(i)) time.Sleep(time.Nanosecond) wg.Done() println(\u0026#34;done\u0026#34;, strconv.Itoa(i)) } func (p *Persion) printPersion() { fmt.Printf(\u0026#34;Name=%s,Sex=%s,Age=%d\\n\u0026#34;, p.Name, p.Sex, p.Age) } type Persion struct { Name string Sex string Age int } type data struct { } func printStr(p stringable) { println(p.toString()) } type Country struct { Name string } func (c Country) toString() string { return \u0026#34;Country Name = \u0026#34; + c.Name } type City struct { Name string } func (c City) toString() string { return \u0026#34;City Name = \u0026#34; + c.Name } type stringable interface { toString() string } ","date":"0001-01-01","img":"","permalink":"/posts/go/%E5%85%B3%E4%BA%8E%E5%88%87%E7%89%87%E5%92%8Cslice%E7%9A%84%E5%86%85%E5%AD%98%E5%85%B1%E4%BA%AB/","series":null,"tags":null,"title":""},{"categories":["无人驾驶"],"content":"Apollo无人车架构 以HD-map为核心\n线控车辆，计算机和传感器通过CAN卡进行通信 ROTS(Ubuntu+apollo kernel) 保证实时性\nFeameworf(ROS+) 共享内存 减少传输中的数据拷贝，提高传输效率，减少传输延迟\n有效解决一对多传输\n共享内存减少CPU资源占用，提高机器计算能力\n数据兼容 引入了protopuf文件格式\n可以向后兼容\nROS深度兼容protopuf格式\n去中心化，减小单点故障的影响 使用RTPS服务发现协议\n以域作为划分，通过rtps相互广播，实现完全P2P\nsub节点启动，组播registerNode-\u0026gt;节点发现及建立unicast-\u0026gt;向新加节点发送历史消息-\u0026gt;收发双方建立连接，开始通信\napplication planning\ncontrol\nend-to-end driving\nhuman-machine\nmap-engine\nlocalization\npreception\nREDME： 定位 GPS+IMU -\u0026gt; Real Time Kine\nGPS+IMU+激光雷达（光探测，测距传感器）-\u0026gt;多传感器融合\n预测 从感知模块接受障碍物信息（位置，方向速度，加速度）\n生成不同概率的预测轨迹\n容器 存储订阅通道的输入数据（障碍物，车辆定位，车辆规划）\n评估器 对任何给定的障碍物分别预测路径和速度，通过模型给出的路径概率来进行评估\n1).成本评估器:概率是由成本函数给出\n2).MLP评估器:用MLP模型计算概率\n3).RNN评估器:用RNN模型计算\n预测器 生成障碍物的预测轨迹，预测规则有很多：\n1). 单行道：在公路导航模式下障碍物沿着单条车道移动。不在车道上的障碍物将被忽略。\n2). 车道顺序：障碍物沿车道移动\n3). 移动序列：障碍物沿其运动模式沿车道移动\n4). 自由运动：障碍物自由移动\n5). 区域运动：障碍物在可能的区域中移动\n路由 根据路由请求(开始和结束位置)以及地图数据生成高级导航信息\n依赖路由拓扑文件 规划 通过配置和参数规划不同的场景\napollo是车道保持，通过障碍物，通过十字路有\nplanning\n1). FSM，有限状态机\n2). Planning Dispatcher,根据车辆状态和其他信息，调用合适的planner\n3). planner获取context，确定车辆意图，执行该意图所需的规划任务，并生成规划轨迹，并更新未来作业的contxt\n4)Deciders\u0026amp;Optimizers：实现决策和优化的无状态库。优化器优化车辆的轨迹和速度。决策者对当前场景进行分类\n控制 基于规划和当前的汽车状态，使用不同的控制算法，控制模块可以在正常模式和导航模式下工作\n输入：规划轨迹，车辆状态，定位和自动模式更改请求\n输出：给底盘的控制指令\nHD Map 给出道路网的精确三维表征\n提供语义信息，帮助决策规划器减小选择范围\nHD-map构建过程\ndata source（百度有300辆地图车）\ndata peocessing，整理，分类，清洗 -\u0026gt;without semantic \u0026amp; annotation\nobj detection\n手动验证（apollo使用软件进行地图编辑）\nmap publication（使用众包，加快构建过程，大家都可以参与）\n定位 GNSS RTK\n惯性导航\nLIDAR定位\n视觉定位\nApollo定位\nGNSS RTK GPS是最广泛的GNSS系统，分为三个部分：\n卫星（Satellites），在任何时间大约有30颗GPS卫星在外太空运行\n地面上世界各地的控制站组成（Control Stations）:用于监视和控制卫星\nGPS接收器（手机，汽车，电脑，轮船等上）\n这样的话GPS是有很大的误差的，距离太远，时间太长。使用实时运动定位（或RTK）\n可信性 RTK涉及在地面上建立几个基站，每个基站都知道自己精确的“地面实况”位置，但是每个基站也通过GPS测量自己的位置，将测出来的位置与自身位置对比得出误差，再将这个误差传给接收设备，以供其调整自身位置计算。\n不可行性 虽然在RTK的作用下，能将车辆的位置精度确定在10厘米以内，但还是存在很多问题，比如GPS信号被高楼大厦挡住了，或者受到天气影响，导致更本无法接收到信号，另外更新频率很低，大于10赫兹或者每秒更新10次 。\n惯性导航 可行性 我们需要知道将测量值转换为全局坐标系，这种转换需要一个名叫陀螺仪的传感器，三轴陀螺仪的三个外部平衡环一直在旋转， 但三轴陀螺仪的旋转轴始终固定在世界坐标系中，计算车辆在坐标系中的位置是通过测量旋转轴和三个外部平衡环的相对位置来计算的。加速度计和陀螺仪是惯性测量单元（或IMU）的主要组件，IMU的主要特征在于高频更新，更新速度达到1000赫兹，所以IMU所提供的位置几乎是实时位置信息。\n不可行性 运动误差随时间的增加而增加\n因此可以集合GPS和IMU\nLIDAR定位 利用激光雷达可以通过点云匹配来给车给汽车进行定位，该方法来自于激光雷达传感器的检测数据与预先存在的高精度地图连续匹配，通过这种匹配可以获得汽车在高精度地图上的全球位置及行驶方向。\n匹配点运算法很多，几个常见的算法如下\n其中：迭代最近点（或IPC）是一种方法。\n假如我们相对两次点云扫描进行匹配，对第一次扫描的每一个点我们需要找到另一次扫描中最近的匹配点，最终我们会收都许多匹配点对，将每对点距离误差相加，然后计算平均距离误差。目标是通过点云旋转和平移来最大限度地降低这一平均误差，一旦实现，就可以在传感器扫描和地图之间找到匹配，这样我们将传感器扫描得到到的位置转换成全球地图上的位置，并计算出地图上的精度位置。\n其次：滤波算法是LIDAR定位的另一种算法。\n可消除冗余信息，并在地图上找最可能的车辆位置，Apollo采用了直方图滤波算法（有时也叫误差平方和算法（或SSD））,为了利用直方滤波，我们将通过传感器扫描的点云滑过地图的每一个位置，在每个位置，我们计算扫描的点和高精度地图上对应点之间的距离误差或距离，然后对误差的平方求和，求和的数越小说明扫描结果与地图之间的匹配越好。在该示例中，匹配最好的点显示红色，最差的点显示蓝色，绿色代表适中的点。\n最后：卡尔曼滤波是LIDAR的另一种定位方法。\n卡尔曼滤波是一种算法，用于根据我们在过去的状态和新的传感器测量的结果预测我们当前的状态。卡尔曼滤波使用了预测更新周期，首先我们根据之前的状态以及对移动距离和方向的估计来估计和“预测”我们新的位置。\nLIDAR定位的优势：稳健性\n主要缺点：难以构建高精度地图，即使能够绘制也无法跟上世界瞬时变化的速度。\n视觉定位 图像数据是收集最容易的数据，摄像头便宜且种类繁多，还易于使用，但要用摄像头来实现高精度定位是很困难的。但是可以将摄像头数据与地图和GPS结合起来，利用概率来判断摄像头数据与地图或者GPS等传感器采集的数据做比对，来定位车辆或者障碍物的位置。下图为利用视觉概率思维来确定树的位置。\n优点：图像易于采集\n缺点：缺乏三维信息和对三维地图的依赖\nApollo定位 Apollo使用基于GPS,IMU和激光雷达等多种传感器融合的定位系统。这种融合利用了不同传感器的互补优势，提高了稳定性和准确性。Apollo定位模块依赖于IMU,GPS,激光雷达，雷达和高精度地图，这些传感器同时支持GNSS定位和LIDAR定位，GNSS定位输出速度和位置信息，LIDAR定位输出位置和行进方向信息，融合框架通过卡尔曼滤波将这些输出结合在一起，卡尔曼滤波建立在两步预测测量周期之上。\n*在Apollo中，惯性导航解决方案，用于卡尔曼滤波的预测步骤，GNSS定位和LIDAR定位用于卡尔曼滤波的测量结果更新步骤。\n分类器有很多种，但他们都包含类似的步骤：**\n首先，计算机接收类似摄像头这样的成像设备的输入，这通常被捕获为图像或一系列图像\n然后，通过预处理发送每个图像，预处理对每个图片进行了标准化处理，常见的预处理步骤包括\n调整图像大小或者旋转图像\n将图像从一个色彩空间换到另一个色彩空间，如从全彩到灰度\n预处理可以帮助我们的模型更快地处理和学习图像。\n提取特征，特征有助于计算机理解图片，例如：将自行车和汽车区分开来的一些特征\n这些特征最后被输入到分类模型中，此步骤用特征来选择图像类别。\n感知 摄像头图像 摄像头图像是最常见的计算机视觉数据，从计算机的角度来看，图像就是一张二维网格，也被称为矩阵，矩阵中的每个单元格都包含一个数字，数字图像全由像素组成，其中包括非常小的颜色和强度单位，图像中的每个像素都只是一个数值，这些数值构成了我们的图像矩阵，甚至可以改变这些像素值，我们可以通过为每一个像素值添加一个标量整数来改变图片的亮度，向右移动每个像素，也可以执行其它的许多操作。数字网格是许多图像处理技术的基础，多数颜色和形状转换都是通过对图像进行了数学运算以及逐一像素进行更改完成的。\n彩色图像组成 彩色图像被构建为值的三维立方， 每个立方体都有长度，宽度，高度。深度为颜色通道数量，大多数图像由三种颜色组成表示，分别为红色，绿色，蓝色，这些图像被称为RGB图像，对于RGB图像深度为3，可以将其看成一个盒子，三个颜色通道看成三层。三层叠加形成了一张彩色图片。\nLIDAR图像 感知扩展到传感器，而不仅是摄像头，激光雷达传感器创建环境的点云表征，提供了难以通过摄像头获得的信息，通过对点云信息的聚类和分析，这些数据提供里足够的对象检测，跟踪和分类信息，如距离和高度，物体形状和纹理等。\n激光雷达采用光线，尤其是采用激光来测量与环境中反射该光线的物体的距离，将每个激光脉冲反射回传感器所花费的时间，反射所需的时间越长，说明物体离传感器越远，激光雷达正是通过这种方式来构建世界的视觉表征。如下图检测和聚类的结果：红点代表行人，绿点代表其它车辆。\n机器学习 机器学习是使用特殊的算法来训练计算机从数据中学习的计算机科学领域，通常，这种学习结果被存放在一个叫‘模型’的数据结构中，有很多中“模型”，事实上“模型”就是一种可以用于理解和预测世界的数据结构。\n应用领域：\n（1）金融领域正用机器学习来对汇率和证券交易进行预测\n（2）零售业用机器学习来预测需求\n（3）医生甚至运用机器学习来辅助诊断\n机器学习涉及使用数据和相关的真值标记来进行模型训练\n监督学习：可能显示车辆和行人计算机的图像，以及告诉计算机哪个是哪个的标签，我们要让计算机学习如何最好地区分两类图像，这类学习也被成为监督式学习。\n无监督学习：没有真值标记的行人和车辆图片，让计算机自行决定，哪些图片相似，哪些图片不同。在这里我们不用提供真值标记，通过分析输入数据，在这种情况下为计算机图像，计算机凭借自己学习来区别。\n**半监督学习：**将监督学习和无监督学习的特点结合在一起，使用少量的标记数据和大量的为标记数据来训练模型。\n**强化学习：**强化学习涉及允许模型通过尝试许多不同的方法来解决问题，然后衡量哪种方法最为成功，计算机将尝试许多种不同的解决方案，最终使其方法与环境相适应。例如：在模拟器中，强化学习智能体可以训练汽车进行右转，智能体将在初始位置启动车辆，然后进行实验性驾驶，以多种方向和速度，如果汽车实际完成了右转，智能体会提高奖励，即得分，这是针对导致成功结果的初始化操作。最初可能车辆会出现走错的结果，多学习几次之后，汽车就不会再错了。\n反向传播算法 学习方法也被称为训练，一般由三部循环组成：\n前馈\n误差测定\n反向传播\n通过前馈来输出每张图片的值，误差是输出值与输入值的差距，将误差通过与前馈相反的方向传回从而更新权重，达到误差最小化的过程叫反向传播。通过这样多次循环，得出误差最小的结果。前馈一般采用梯度下降来实现，想更多了解点击下面链接。\n梯度下降 用梯度下降，我们通过多个小步骤来实现目标。我们希望一步一步改变权重来减小误差。误差就像是山，我们希望走到山下。下山最快的路应该是最陡峭的那个方向，因此我们也应该寻找能够使误差最小化的方向。我们可以通过计算误差平方的梯度来找到这个方向。\n梯度是改变率或者斜度的另一个称呼。如果你需要回顾这个概念，可以看下可汗学院对这个问题的讲解 。\n反向传播 如何让多层神经网络学习呢？首先了解如何使用梯度下降来更新权重，反向传播算法则是它的一个延伸。以一个两层神经网络为例，可以使用链式法则计算输入层-隐藏层间权重的误差。\n要使用梯度下降法更新隐藏层的权重，需要知道各隐藏层节点的误差对最终输出的影响。每层的输出是由两层间的权重决定的，两层之间产生的误差，按权重缩放后在网络中向前传播。既然我们知道输出误差，便可以用权重来反向传播到隐藏层。\n卷积神经网络CNN 卷积神经网络（CNN）是一种人工神经网络，对感知问题特别有效，CNN接受多维度输入，包括大多数传感器数据的二维和三维形状。\n标准神经网络：将图像矩阵重塑为一个矢量，并在一大行中链接所有列，将图像“展开”为一维像素阵列。这种方法打破了图像中的空间信息\nCNN可以维持图像输入的的空间信息，CNN通过过滤器连续滑过图像来收集信息，每次收集信息只对图片的一小部分区域进行分析，这被称为卷积。\n例如：CNN可以识别第一个卷积层的基本边缘和颜色信息，然后通过在第一层上卷积新过滤器，CNN可以使用边缘和颜色信息来归纳更复杂的结构，如车轮，车门和挡风玻璃，而另一个卷积可以使用车轮和车门，挡风玻璃来识别整个车，最后神经网络可以使用这一高阶信息对车辆进行分类。\n检测和分类 在感知任务中，首先想到的是障碍物的检测和分类，动态的障碍物，如行走的人，车，自行车等；静态的障碍物，如树木，停好的车，自行车，建筑物等；计算机首先需要知道障碍物的位置，然后进行分类，无人驾驶车载途中会探测到许多不同物体，汽车根据检测到的物体类型来确定路径和速度。\n无人车是靠什么进行检测和分类？\n使用检测CNN来来查找图像中的对象位置，在对图像中的对象进行定位后，我们可以将图像发给另一个CNN进行分类。也可以用一个单一的CNN结构体系对对象进行检测和分类，在单个网络体系的末端加几个不同的“头”，一个头执行检测，一个头执行分类。一个经典结构为R-CNN及其变体Fast R-CNN和 Faster R-CNN。\n论文\nR-CNN Fast R-CNN Faster-RCNN YOLO SSD 跟踪 在检测完对象之后我们需要追踪。\n追踪的意义：对每个帧中的对象进行检测并用边界框对每个对象进行标记。\n跨帧追踪的好处：\n（1）追踪在检测失败时是至关重要的，如果在运用检测算法时，对象被其他对象遮挡一部分，则检测算法可能会失败，追踪可以解决这一问题。\n（2）追中可以保留身份，障碍物检测的输出为包含对象的边界框，但是对象没有与任何身份关联，单独使用对象检测时，计算机不知道一帧中的哪些对象与下一帧的哪些对象相对应。\n追踪步骤：\n确认身份：通过查找对象相特征似度最高的对象，将在之前一帧中检测的所有对象与之前一帧中检测到的对象进行匹配，对象具有很多特征，一些特征可能基于颜色，一些特征可能基于形状，计算机视觉算法可以计算出复杂的图像特征。\n快速找到匹配的对象：还要考虑连续视频帧中的。两个障碍物之间的位置和速度。由于两帧之间的对象位置和速度没有太大变化，该信息可以帮助快速找到匹配的对象。\n分割 语义分割涉及对图像的每个像素进行分类，用于尽可能详细的了解环境，并确定车辆可行驶区域。\n语义分割依赖于一种特殊的CNN，全卷积神经网络（或CFN） ,FCN用卷积层来替代传统CNN的末端平坦层，使得网络中的每一层都是卷积层。故名为全卷积网络。\nCFN提供了可在原始输入图像之上叠加的逐像素输出，复杂因素是大小，传统CNN输出的图片大小比输入小得多，为了进行语义分割，我们必须得到与输入同样大小的输出。\n编码和解码，下面图片前部分叫编码，后部分叫解码，经过这样的处理使得输入尺寸与输出尺寸相等。\nApollo感知 Apollo软件栈可感知障碍物，交通信号灯和车道\n对三维对象检测 Apollo在高精度地图上使用感兴趣区域（ROI）来重点关注相关对象，Apollo将ROI过滤器用于点云和图像数据以缩小搜素范围并加快感知。\n然后，通过检测网络馈送已过滤的点云，输出用于构建围绕对象三维边界框 。\n最后，使用被称为检测跟踪关联的算法来跨时间步识别单个对象，该算法先保留在每个时间步要跟踪的对象列表，然后在下一个时间步中找到每一个对象的最佳匹配。\n对于交通信号灯的分类 Apollo先利用高精度地图来确认前方是否有交通信号灯，如果前方有交通信号灯，高精度地图就会返回信号灯的位置，这侧重于摄像头搜索范围，在摄像头捕捉到交通信号灯的图像后，Apollo使用检测网络对图像中的灯进行定位，然后Apollo从较大图像中提取交通灯信号，Apollo将裁剪的交通灯图像提供给分类网络， 以确定灯的颜色，如果有学多灯，系统需要选择哪些灯与其车道有关。\nYOLO网络 Apollo使用YOLO网络来检测车道线和动态物体，其中包括车辆，卡车，骑自行车的人和行人，在经过YOLO网络检测后，在线检测模块会并入来自其它传感器的数据，对车道线进行调整，车道线最终被并入名为“虚拟车道”的单一数据结构中，同样，也通过其它传感器的数据，对YOLO检测到的动态对象进行调整，以获得每个对象的类型，位置，速度，和前进方向。虚拟通道和动态对象都被传到规划和控制模块。\n传感器数据比较 雷达与激光雷达\n雷达已经在汽车上使用很多年，在各种系统中都需要雷达，如自适应巡航控制、盲点警告、碰撞浸膏和碰撞预防系统等。尽管雷达技术已经成熟，它仍在不断进步，作用不断提升。其他传感器测量速度的方法是计算两次读数之间的差距，而雷达则通过多普勒效应来直接测量速度。多普勒效应根据对象在远离还是接近你，测量出雷达的频率变化。就像消防车警报器一样，当车辆正在远离你和驶向你时，听起来声是不一样的。多普勒效应对传感器融合至关重要。因为它可以把速度作为独立的测量参数，从而提升了融合算法的收敛速度。雷达还可以生成环境的雷达地图，进而实现定位。因为雷达波在坚硬表面会回弹。因此，它可以直接测量对象距离，无需在视线范围内也可以。雷达可以看到其他车辆底部。并发现可能会被阻挡的建筑物和对象。在车上的所有传感器中，雷达是至不容易受雨雾影响的。而且视野宽阔，可达 150 度，距离可达200 多米。与激光雷达和摄像头相比，雷达分辨率较低，尤其是在垂直方向，分辨率非常有限。分辨率低意味着来自静态物体的反射可能产生问题。例如，街道上检修孔盖或汽水罐，可能产生很高的雷达反射率，但他们并不大。我们将其称为雷达杂波。因此，当前的车载雷达通常会忽视静态物体。\n激光雷达是激光探测与测量的简称，而雷达则谁无线电探测与测量的简称。雷达使用无线电波，而激光雷达则使用红激光束来确定传感器和附近对象的距离。目前的激光雷达大多使用 900 纳米光波长度的光源。但部分激光雷达使用的光波长度更长，在雨雾中性能更好。当前的激光雷达使用旋转座架发射激光，扫描周边环境。激光室脉冲式的，脉冲被对象反射，然后返回一个点云，来代表这些物体。激光雷达的空间分辨率远远高于雷达。因为激光束越聚焦，垂直方向的扫描层数量就越多，因此每层的激光雷达的密度也越高。目前，激光雷达还不能直接测量对象的速度，必须使用两次或多次扫描之间的位置差来确定。激光雷达受天气和传感器清洁程度影响也很大，因此需要保持清洁。它们块头也比其他传感器更大，因此也很难安装，除非你只想在车顶安装一个大的激光扫描器。\n感知融合策略 Apollo采用雷达和激光雷达来检测障碍物，用于融合输出的算法为卡尔曼滤波，卡尔曼滤波有两步。卡尔曼算法时预测更新步骤的无限循环。\n第一步预测状态\n第二部为更新测量结果\n两种测量结果更新步骤\n同步更新：同步融合同时更新来自不同传感器的测量结果\n异步更新：异步融合则逐个更新所收到的传感器测量结果\n传感器融合可提高感知性能，因为各传感器相辅相成，融合也可以减少跟踪误差。\n预测 预测路径目标要求： 实时性要求：想要我们的算法的延时越短越好\n准确性要求：能让无人车尽可能准确的做出决策\n预测模块也应该能学习新的行为\n预测的两种不同方式： 基于模型的预测 例如：怎样预测左侧的车是直行还是右转？\n基于模型的预测，无人车将会提供两个模型，预测车辆直行的模型和右转的模型，然后根据预测车辆的下一步来更新模型，最终确定车辆下一步的动作。\n数据驱动的预测 数据驱动预测使用机器学习算法，通过观察结果来训练模型，一旦机器模型训练好，就可以在现实中利用此模型去做做预测。\n数据驱动预测优点：训练数据越多训练模型效果越好\n基于模型预测优点：比较直观，并且结合了现有的物理知识和交通法规还有人类行为多方面知识。\n基于车道序列的预测 为了建立车道序列，现将车道分为多个部分，每一部分覆盖了一个易于描述车辆运动的区域，我们如果要预测别的车辆运动状态，只要预测该车在此区域的转换，而不是在某一区域的具体行为。\n将车辆的行为划分为一组有限的模式组合，并将这些模式组合描述物车道的系列。例如：将直行车的路径划分为一个0-1-3-7的系列。\n障碍物状态\n为了预测物体的运动，需要了解障碍物的状态，一般人是通过物体朝向，位置，速度，加速度等来预测物体将做什么？\n无人车也是同样的道理，除了朝向，位置，速度，加速度外，无人车还得考虑该段车道内物体的位置。例如：预测模块会考虑从物体到车道路线段边界的纵向和横向距离，预测模块还包括前面提到的时间间隔状态信息，以便做出更准确的信息。\n预测目标车道\n前面运用车道系列将一个复杂的问题简单化了，现在是预测车辆最有可能采取的车道系列。可以通过计算每个车道系列的概率来进行选择。我们需要一个模型，将车辆状态和车道系列作为输入，该模型用于提供车辆可能采用每个车道系列的概率，我们希望我们的模型能学习新的行为，因此应该使用观测数据对模型进行经验性训练，整改记录由一系列车道段和对象相关状态组成。\n递归神经网络或RNN RNN是利用时间系列数据特征的一种预测方法，利用神经网络建立多重结构递归神经网络，称做MLP单元，从数据中提取高级特征，每个MLP单元将系列的一个元素作为一个输入，并预测系列的下一个元素作为输出，为了对元素的顺序关系建立模型，在每个单元之间建立额外的连接，这意味着每个单元根据原始输入和前一单元的输出进行预测，这就是RNN的基本结构。\nRNN在目标车道预测中的应用\nApollo为车道系列提供一个RNN模型，为相关对象状态提供另一个RNN模型，Apollo连接这两个RNN的输出并将其馈送到另一个神经网络，该神经网络会估计每个车道系列的概率，具有最高概率的车道系列，是我们预测目标车辆将遵循的系列。\n为了训练这个网络，比较真值，得出误差，反向传播更新权重，从而使得模型更好，预测结果更精确。\n轨道生成\n轨道生成是预测的最后一步，一旦我们预测到物体的车道系列，我们就可以预测物体的轨迹，在任何两个点A和,B之间，物体的行进轨迹有无限种可能。\n如何确定我们想要的轨迹？可以先设置条件去除大部分的轨迹路线，我们并不是逐一排除，相反，只是在数学理论上来运用这一想法，注意车辆在两点之间的位置和方位，这两个姿势表示运动模型的初始状态和最终状态，我们可以使用这两个条件来拟合一个多项式模型，在大多数情况下，这种多项式足够满足预测。RNN在目标车道预测中的应用\nApollo为车道系列提供一个RNN模型，为相关对象状态提供另一个RNN模型，Apollo连接这两个RNN的输出并将其馈送到另一个神经网络，该神经网络会估计每个车道系列的概率，具有最高概率的车道系列，是我们预测目标车辆将遵循的系列。\n为了训练这个网络，比较真值，得出误差，反向传播更新权重，从而使得模型更好，预测结果更精确。\n规划 规划中通过结合高进度地图，定位和预测来构建车辆的轨迹。\n第一步：路径导航，如从A地道B地，将地图数据作为输入，并输出可行驶路径\n第二步：路径规划目标：找到从地图上的A地到B地的最佳路线。\n路由 路线规划使用三个输入：\n地图：地图数据包括公路网和实时交通信息\n我们当前在地图上的位置\n我们的目的地：通常取决于车辆的乘客\n世界地图 从地图A-B，无人驾驶通常货沿道路搜索有没有任何路径，称作搜索。Apollo也利用搜索来查找路径，但搜索算法更智能，在搜索之前将地图重新格式化成“图形”的数据结构，该图形由“节点”和“边缘”组成。\n可以对从一个节点到另一节点所需要的成本进行建模，从实际中就可以得出从1-3所需成本是比1到其它节点的要少，从上图可知，蓝色的为低成本。在计算机领域里，人们已经发现许多用于从图形中搜索路径的算法，所以将地图装换为图形有利于无人驾驶车搜索路径。\n网格世界 从初始节点开始，还需要相邻的八个节点中哪个是最有希望的最佳候选节点，对每个候选节点都要考虑两件事：\n首先：计算候选节点到开始节点的成本；\n然后：计算从候选节点到最后节点的成本，可以自己定义计算成本的规则，比如有交通堵塞等情况。\n定义：\ng:代表从初始节点到候选节点的成本\nh:表示候选节点到目标节点的成本\nf:表示两个值的和，值越小，表示成本越低。\nA*算法 通过g,h值相加得到的f值来确定最佳路线，如下图，最佳路线是网右转，f值最小。\n从路由到轨迹\n高等级地图只是规划过程的一部分，我们需要构建沿这条道路的低等级轨迹，意味找要处理地图上没有的物体，如其它车辆，行人及自行车等。如试图与调头的车辆互动。这一级别的规划称为轨迹生成。\n3D轨迹\n轨迹生成目的是：生成由一系列路径点所定义的轨迹，每个路径点都分配了一个时间戳和速度，让一条曲线与这些路径点拟合，生成轨迹的几何表征，移动的障碍物可能会暂时阻挡部分路段，路段的每个路径点都有一个时间戳，将时间戳与预测模块的输出结合起来，以确保车辆在通过时，路径上的每个点都未被占用。这些时间戳创建了一个三维轨迹。\n评估一条轨迹\n如何评估一条轨迹，采用成函数，选择成本最低的路径。轨迹成本由各种规范和处罚组成。\n例如：\n车辆偏离中心线的距离\n可能发生碰撞\n速度限制\n舒适度\n通过将这些成本计算成数字，最终的出最佳的路径。\n车辆甚至可以在不同环境中使用不同的成本函数。\nFrenet坐标 笛卡尔坐标系 通常我们使用笛卡尔坐标系来描述物体的位置，但对于车辆来说，确不是最佳的选择，我们即使能够知道车辆的(x,y)坐标，我们不知道路在哪里，很难知道车辆行驶了多远，以难以确定车辆是否偏移车道中心。\nFrenet坐标系 描述了汽车相对于车道的位置，在Frenet框架中，s代表沿道路的距离，已被称为纵坐标，d表示与纵向线的位移，已被称为横坐标，在道路的每个点，横轴与纵轴都是垂直的。\n纵坐标表示车辆行驶距离，横坐标表示车辆偏离中心线的距离。\n路径速度解耦规划 路径-速度解耦规划将轨迹规划划分为两步：\n路径规划：生成候选曲线，这是车辆可行驶的路径，我们使用成本函数对每条路径进行成本评估，该函数包含平滑，安全性，与车道中心的偏离，以及我们想要考虑的其它的任何因素。按成本对路径进行排名，并选择成本最低的路径。\n速度规划：路径规划之后就考虑速度的规划，我们可能希望改变在该路段是的速度，我们需要选择的事与路径点相关的一系列速度，而不是单个速度，该系列称之为“速度曲线”，可以用优化功能为路径选择，受到各种限制的良好速度曲线，通过将路径曲线和速度曲线相结合，可构建车辆的行驶轨迹。\n控制 控制的输入和输出一样？转向角，加速度和制动？\nPID控制 P是比例控制器\nD是阻尼项，让控制更加稳定，较少控制器输出的变化速度\nI是惩罚项，对累计误差进行惩罚\n线性二次调节器 保持误差的总和和控制输入的综合，我没听懂他在说啥。。总之就是给每一项加权重，大致有控制输入项和误差项生成一个代价函数，最小化它\nx^=Ax+Bu 为状态空间方程\n模型预测控制MPC 建立汽车模型\n使用优化器计算有限时间范围的控制输出\n执行第一组控制输出\n每个时间段单独计算当前时间段的的控制输出，避免误差\n车辆模型 无人车可以提供的控制输入有两个，一个是刹车|油门，反映在汽车的线性加速度上，一个是方向盘，可以控制在前轮和行驶方向的夹角。\n在感知和定位之后，无人车的路线规划会选择路线。而这个时候控制模块要保证无人车安全的贴近这个预计的路线（参考路线）。一般来说一个路线可以用一个三次曲线来描述。\nSlip angle\n轮胎前进方向，和轮胎轮盘平面的夹角。也可以用轮胎平面的速度和轮胎的漂移速度的反三角来表示。不同的轮胎产生的力不同。赛车胎在同样的Slip angle会产生更大的力。（赛车抓地力更强更不容易出现漂移）\n漂移率\n轮胎在自己平面上面打滑了多少。轮胎受到的力和漂移角是非线性的。另外似乎有一个最优的转向角，那个角度上面轮胎可以提供最大的力来转向，超过那个角度力会下降。另外一般轮胎的转角有30度的限制。\n越大的漂移角会产生越大的力\n轮胎不打滑的情况下，轮胎受力的方向应该是垂直于轮胎的。打滑的话，打滑那个方向也会有一个速度。摩擦力应该和速度反向。在不打滑的时候应该有一个可以提供最大转向力的夹角，打滑的时候这个夹角应该会减小。\nMPC MPC是一个总称，有着各种各样的算法。其动态矩阵控制（DMC）是代表作。DMC采用的是系统的阶跃响应曲线，其突出的特点是解决了约束控制问题。那么是DMC是怎么解决约束的呢？在这里只给出宏观的解释，而不做详细的说明。DMC把线性规划和控制问题结合起来，用线性规划解决输出约束的问题，同时解决了静态最优的问题\n","date":"0001-01-01","img":"","permalink":"/posts/driverless/apollo%E6%9E%B6%E6%9E%84/","series":null,"tags":["Apollo无人驾驶"],"title":"Apollo无人车架构"}]